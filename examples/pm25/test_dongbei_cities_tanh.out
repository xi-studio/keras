X_train[0].shape = (7018, 40, 23)

training haerbin0
Train on 7018 samples, validate on 1870 samples
Before training:
            haerbin013175.4733      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.61018 nan 4.61018
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            haerbin018014.6675      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.72171 nan 8.72171
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 8117.3802 - val_loss: 7191.0345
Epoch 00000: val_loss improved from inf to 7191.03452, saving model to haerbin0_weights.hdf5
            haerbin0 5857.3923      0.66  0.25  0.54      0.67  0.22  0.56      0.64  0.21  0.55
            haerbin0 7191.0344      0.93  0.37  0.60      0.93  0.35  0.62      0.94  0.34  0.64
forget mean min: 0.972925 0.454233
incx.max(), incx.min(), incx.mean() 4.75052 -2.79745 3.37057
fgtx.max(), fgtx.min(), fgtx.mean() 2.10345 -1.31943 1.47764
abs_mean, abs_mean+, abs_mean-: 5.12819 3.63274 9.89167
U_c = [[-0.10504838]] U_f = [[ 0.]] b_c = [ 0.11215984] b_f = [ 1.09059644]
W_c max, min, mean, abs_mean: 0.136608 -0.136582 -0.00637341 0.134271
W_f max, min, mean, abs_mean: 0.0616679 -0.0616834 -0.00317036 0.0608921
Epoch 2/300
1s - loss: 5459.3850 - val_loss: 6744.4954
Epoch 00001: val_loss improved from 7191.03452 to 6744.49543, saving model to haerbin0_weights.hdf5
            haerbin0 5143.0955      0.78  0.34  0.55      0.79  0.31  0.58      0.78  0.28  0.60
            haerbin0 6744.4954      0.88  0.38  0.57      0.88  0.36  0.59      0.89  0.34  0.61
forget mean min: 0.956653 0.573636
incx.max(), incx.min(), incx.mean() 8.03987 -3.5536 6.11529
fgtx.max(), fgtx.min(), fgtx.mean() 1.56528 -0.746062 1.18152
abs_mean, abs_mean+, abs_mean-: 6.03052 5.05806 7.84972
U_c = [[-0.07093001]] U_f = [[ 0.]] b_c = [ 0.18887813] b_f = [ 1.11424339]
W_c max, min, mean, abs_mean: 0.212365 -0.212349 -0.0101642 0.210013
W_f max, min, mean, abs_mean: 0.0426578 -0.042673 -0.00222386 0.0418721
Epoch 3/300
1s - loss: 4878.3145 - val_loss: 7735.3793
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 4653.3924 - val_loss: 9136.1840
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 4583.0680 - val_loss: 9234.7471
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 4528.5502 - val_loss: 11634.7579
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 4492.6921 - val_loss: 11770.7382
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 4429.3558 - val_loss: 10002.2166
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 4379.4490 - val_loss: 11967.9998
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 4341.1920 - val_loss: 9796.6254
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 4270.0534 - val_loss: 11692.4124
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 4258.5763 - val_loss: 15262.0629
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 4222.6679 - val_loss: 11594.6323
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 4216.2869 - val_loss: 12066.0877
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 4192.0785 - val_loss: 10986.1100
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 4169.8120 - val_loss: 12228.7460
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 4133.3702 - val_loss: 11360.9108
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 4098.3501 - val_loss: 13986.0327
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 4048.8436 - val_loss: 13797.1463
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 3949.0453 - val_loss: 14628.0765
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 3833.5409 - val_loss: 17372.5623
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 3694.7747 - val_loss: 16279.9321
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 3546.1096 - val_loss: 22391.8849
Epoch 00022: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training changchun0
Train on 6380 samples, validate on 1700 samples
Before training:
          changchun012143.1943      0.03  -nan  0.02      0.03  -nan  0.03      0.03  -nan  0.03
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.72789 nan 4.72789
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
          changchun011375.2543      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.14317 nan 6.14317
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 8439.2833 - val_loss: 7931.6806
Epoch 00000: val_loss improved from inf to 7931.68063, saving model to changchun0_weights.hdf5
          changchun0 6009.0052      0.56  0.45  0.39      0.57  0.38  0.42      0.58  0.32  0.45
          changchun0 7931.6807      0.06  -nan  0.05      0.06  -nan  0.05      0.06  -nan  0.06
forget mean min: 0.776187 0.474981
incx.max(), incx.min(), incx.mean() 2.69501 -1.5252 0.491479
fgtx.max(), fgtx.min(), fgtx.mean() 1.94272 -1.21797 0.292407
abs_mean, abs_mean+, abs_mean-: 7.99759 1.2912 8.55173
U_c = [[-0.10170525]] U_f = [[ 0.]] b_c = [ 0.10103739] b_f = [ 1.09287369]
W_c max, min, mean, abs_mean: 0.121012 -0.120779 0.0242559 0.119308
W_f max, min, mean, abs_mean: 0.0913129 -0.0908475 0.018208 0.0893538
Epoch 2/300
1s - loss: 5489.8533 - val_loss: 7004.3070
Epoch 00001: val_loss improved from 7931.68063 to 7004.30699, saving model to changchun0_weights.hdf5
          changchun0 5076.4975      0.67  0.42  0.45      0.67  0.36  0.49      0.68  0.30  0.52
          changchun0 7004.3070      0.17  0.35  0.15      0.15  0.38  0.14      0.13  0.52  0.12
forget mean min: 0.875446 0.278615
incx.max(), incx.min(), incx.mean() 6.63898 -5.19615 2.65568
fgtx.max(), fgtx.min(), fgtx.mean() 2.63918 -2.18519 1.01542
abs_mean, abs_mean+, abs_mean-: 8.28587 4.27714 12.8074
U_c = [[-0.05568607]] U_f = [[ 0.]] b_c = [ 0.16459812] b_f = [ 1.0782665]
W_c max, min, mean, abs_mean: 0.188736 -0.18859 0.0378014 0.187037
W_f max, min, mean, abs_mean: 0.0782027 -0.077725 0.015574 0.0762442
Epoch 3/300
1s - loss: 4894.4185 - val_loss: 7145.8065
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 4710.0143 - val_loss: 6379.4318
Epoch 00003: val_loss improved from 7004.30699 to 6379.43184, saving model to changchun0_weights.hdf5
          changchun0 4571.5663      0.75  0.43  0.48      0.74  0.39  0.50      0.73  0.35  0.52
          changchun0 6379.4318      0.26  0.32  0.23      0.25  0.28  0.22      0.22  0.19  0.20
forget mean min: 0.875827 0.167422
incx.max(), incx.min(), incx.mean() 10.4937 -9.06731 4.50365
fgtx.max(), fgtx.min(), fgtx.mean() 2.99648 -2.71762 1.24663
abs_mean, abs_mean+, abs_mean-: 11.1786 7.18919 17.1243
U_c = [[-0.03560996]] U_f = [[ 0.]] b_c = [ 0.23592752] b_f = [ 1.05472517]
W_c max, min, mean, abs_mean: 0.266937 -0.266705 0.0534368 0.265192
W_f max, min, mean, abs_mean: 0.0794787 -0.0790009 0.0158135 0.0774684
Epoch 5/300
1s - loss: 4661.5135 - val_loss: 6598.3076
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 4637.9426 - val_loss: 6911.1333
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 4629.0670 - val_loss: 7091.1216
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 4612.8208 - val_loss: 7628.4903
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 4600.4904 - val_loss: 6990.2145
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 4564.1715 - val_loss: 6894.5044
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 4576.3629 - val_loss: 6845.8368
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 4554.1571 - val_loss: 7149.8005
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 4537.2003 - val_loss: 6980.8899
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 4522.7742 - val_loss: 6992.9674
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 4525.4631 - val_loss: 7487.2576
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 4511.7360 - val_loss: 7193.1969
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 4507.8047 - val_loss: 6630.4598
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 4488.4894 - val_loss: 6312.3161
Epoch 00017: val_loss improved from 6379.43184 to 6312.31613, saving model to changchun0_weights.hdf5
          changchun0 4366.3081      0.75  0.44  0.47      0.74  0.39  0.51      0.74  0.34  0.54
          changchun0 6312.3161      0.23  0.25  0.21      0.22  0.21  0.20      0.22  0.18  0.21
forget mean min: 0.872452 0.1083
incx.max(), incx.min(), incx.mean() 12.0652 -9.54578 4.40709
fgtx.max(), fgtx.min(), fgtx.mean() 3.52613 -2.97348 1.22286
abs_mean, abs_mean+, abs_mean-: 10.3906 6.92932 15.2198
U_c = [[-0.02319762]] U_f = [[ 0.]] b_c = [ 0.34088856] b_f = [ 1.01498163]
W_c max, min, mean, abs_mean: 0.31683 -0.316567 0.063382 0.314878
W_f max, min, mean, abs_mean: 0.097179 -0.0966645 0.0192808 0.0947009
Epoch 19/300
1s - loss: 4501.8538 - val_loss: 6482.0404
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 4493.6209 - val_loss: 6374.2474
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 4514.1875 - val_loss: 6452.2069
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 4503.5485 - val_loss: 6470.5775
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 4496.0276 - val_loss: 6291.6674
Epoch 00022: val_loss improved from 6312.31613 to 6291.66739, saving model to changchun0_weights.hdf5
          changchun0 4350.8414      0.73  0.43  0.47      0.72  0.38  0.50      0.72  0.33  0.53
          changchun0 6291.6674      0.24  0.24  0.21      0.22  0.19  0.20      0.23  0.16  0.21
forget mean min: 0.870575 0.118034
incx.max(), incx.min(), incx.mean() 12.3035 -9.36061 4.40995
fgtx.max(), fgtx.min(), fgtx.mean() 3.58006 -2.91947 1.21184
abs_mean, abs_mean+, abs_mean-: 10.4334 6.98931 15.1666
U_c = [[-0.02349342]] U_f = [[ 0.]] b_c = [ 0.37039772] b_f = [ 1.0096451]
W_c max, min, mean, abs_mean: 0.324635 -0.324565 0.0649326 0.322655
W_f max, min, mean, abs_mean: 0.0993921 -0.0988699 0.019706 0.0967996
Epoch 24/300
1s - loss: 4507.8498 - val_loss: 6941.6963
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 4487.3922 - val_loss: 6833.3475
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 4493.9861 - val_loss: 6674.9073
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 4510.7948 - val_loss: 6695.3210
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 4497.1074 - val_loss: 6236.4733
Epoch 00027: val_loss improved from 6291.66739 to 6236.47325, saving model to changchun0_weights.hdf5
          changchun0 4362.6551      0.76  0.44  0.47      0.76  0.39  0.51      0.76  0.33  0.55
          changchun0 6236.4732      0.28  0.26  0.24      0.26  0.21  0.23      0.26  0.16  0.24
forget mean min: 0.873643 0.101389
incx.max(), incx.min(), incx.mean() 12.6282 -9.39911 4.57427
fgtx.max(), fgtx.min(), fgtx.mean() 3.7445 -2.9995 1.27862
abs_mean, abs_mean+, abs_mean-: 10.6722 7.18458 15.788
U_c = [[-0.02087983]] U_f = [[ 0.]] b_c = [ 0.3977049] b_f = [ 1.00644469]
W_c max, min, mean, abs_mean: 0.331961 -0.332058 0.066369 0.329874
W_f max, min, mean, abs_mean: 0.103793 -0.10315 0.0205483 0.100993
Epoch 29/300
1s - loss: 4499.1712 - val_loss: 6321.8214
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 4478.3255 - val_loss: 6427.3888
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 4461.5261 - val_loss: 6459.3205
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 4470.8860 - val_loss: 6841.1969
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 4456.3480 - val_loss: 6487.0061
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 4442.6850 - val_loss: 6924.7187
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 4407.8292 - val_loss: 6230.3758
Epoch 00034: val_loss improved from 6236.47325 to 6230.37583, saving model to changchun0_weights.hdf5
          changchun0 4262.1879      0.72  0.43  0.47      0.72  0.38  0.50      0.71  0.33  0.53
          changchun0 6230.3758      0.25  0.26  0.23      0.23  0.20  0.21      0.23  0.18  0.21
forget mean min: 0.873653 0.143144
incx.max(), incx.min(), incx.mean() 13.4829 -8.96166 4.71229
fgtx.max(), fgtx.min(), fgtx.mean() 3.84021 -2.77494 1.25501
abs_mean, abs_mean+, abs_mean-: 10.6677 7.2922 15.2575
U_c = [[-0.02479464]] U_f = [[ 0.]] b_c = [ 0.45332909] b_f = [ 0.99065936]
W_c max, min, mean, abs_mean: 0.371042 -0.372242 0.0741625 0.368948
W_f max, min, mean, abs_mean: 0.112403 -0.111116 0.0221142 0.10874
Epoch 36/300
1s - loss: 4399.5065 - val_loss: 7174.7886
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 4353.4231 - val_loss: 6749.7305
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 4327.5341 - val_loss: 6742.4305
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 4289.4064 - val_loss: 6763.6435
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 4240.4425 - val_loss: 6239.5344
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 4192.3018 - val_loss: 6401.0772
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 4156.0448 - val_loss: 6825.5273
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 4110.7229 - val_loss: 6615.2198
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 4065.6947 - val_loss: 6612.8290
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 4021.9292 - val_loss: 6740.3564
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 3970.1177 - val_loss: 7115.0334
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 3924.9323 - val_loss: 6660.6191
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 3874.8587 - val_loss: 6801.7863
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 3808.0626 - val_loss: 6551.9421
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 3758.5865 - val_loss: 6702.0070
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 3716.8638 - val_loss: 7198.0667
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 3663.7143 - val_loss: 6045.5288
Epoch 00051: val_loss improved from 6230.37583 to 6045.52878, saving model to changchun0_weights.hdf5
          changchun0 3572.7773      0.80  0.40  0.52      0.81  0.34  0.57      0.82  0.26  0.64
          changchun0 6045.5288      0.37  0.33  0.31      0.38  0.28  0.33      0.37  0.25  0.32
forget mean min: 0.857543 0.174266
incx.max(), incx.min(), incx.mean() 20.9335 -10.2401 5.48579
fgtx.max(), fgtx.min(), fgtx.mean() 4.73111 -2.54465 1.13685
abs_mean, abs_mean+, abs_mean-: 10.987 8.62815 13.384
U_c = [[-0.03498895]] U_f = [[ 0.]] b_c = [ 0.62339097] b_f = [ 0.91598457]
W_c max, min, mean, abs_mean: 0.702426 -0.759859 0.131881 0.670113
W_f max, min, mean, abs_mean: 0.166066 -0.166653 0.032424 0.155905
Epoch 53/300
1s - loss: 3617.6953 - val_loss: 6952.4256
Epoch 00052: val_loss did not improve
Epoch 54/300
1s - loss: 3569.9573 - val_loss: 7017.8007
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 3511.6036 - val_loss: 6594.1024
Epoch 00054: val_loss did not improve
Epoch 56/300
1s - loss: 3479.9465 - val_loss: 6729.4532
Epoch 00055: val_loss did not improve
Epoch 57/300
1s - loss: 3436.6787 - val_loss: 6625.3559
Epoch 00056: val_loss did not improve
Epoch 58/300
1s - loss: 3397.0861 - val_loss: 6671.2624
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 3348.1128 - val_loss: 6546.8187
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 3317.9769 - val_loss: 6147.4137
Epoch 00059: val_loss did not improve
Epoch 61/300
1s - loss: 3287.8871 - val_loss: 6288.3519
Epoch 00060: val_loss did not improve
Epoch 62/300
1s - loss: 3247.9645 - val_loss: 6590.5040
Epoch 00061: val_loss did not improve
Epoch 63/300
1s - loss: 3211.2477 - val_loss: 6039.0269
Epoch 00062: val_loss improved from 6045.52878 to 6039.02693, saving model to changchun0_weights.hdf5
          changchun0 3140.3315      0.80  0.40  0.52      0.82  0.32  0.59      0.83  0.25  0.65
          changchun0 6039.0269      0.52  0.36  0.40      0.53  0.33  0.42      0.52  0.30  0.42
forget mean min: 0.866099 0.223977
incx.max(), incx.min(), incx.mean() 25.4421 -13.0692 7.44352
fgtx.max(), fgtx.min(), fgtx.mean() 3.88358 -2.25259 1.14326
abs_mean, abs_mean+, abs_mean-: 12.6294 10.5882 14.8521
U_c = [[-0.04374248]] U_f = [[ 0.]] b_c = [ 0.74897873] b_f = [ 0.87247783]
W_c max, min, mean, abs_mean: 1.04602 -1.26623 0.178677 0.937046
W_f max, min, mean, abs_mean: 0.181422 -0.183486 0.0315227 0.142153
Epoch 64/300
1s - loss: 3179.2433 - val_loss: 6695.0200
Epoch 00063: val_loss did not improve
Epoch 65/300
1s - loss: 3119.6687 - val_loss: 6617.0671
Epoch 00064: val_loss did not improve
Epoch 66/300
1s - loss: 3084.0721 - val_loss: 7026.2872
Epoch 00065: val_loss did not improve
Epoch 67/300
1s - loss: 3025.8855 - val_loss: 6758.3211
Epoch 00066: val_loss did not improve
Epoch 68/300
1s - loss: 2961.9821 - val_loss: 6304.5676
Epoch 00067: val_loss did not improve
Epoch 69/300
1s - loss: 2898.4323 - val_loss: 6804.4838
Epoch 00068: val_loss did not improve
Epoch 70/300
1s - loss: 2844.8026 - val_loss: 7265.7392
Epoch 00069: val_loss did not improve
Epoch 71/300
1s - loss: 2787.2112 - val_loss: 6431.4802
Epoch 00070: val_loss did not improve
Epoch 72/300
1s - loss: 2727.3191 - val_loss: 7143.6320
Epoch 00071: val_loss did not improve
Epoch 73/300
1s - loss: 2673.3340 - val_loss: 6732.1064
Epoch 00072: val_loss did not improve
Epoch 74/300
1s - loss: 2605.1674 - val_loss: 7318.7948
Epoch 00073: val_loss did not improve
Epoch 75/300
1s - loss: 2540.6192 - val_loss: 7267.9146
Epoch 00074: val_loss did not improve
Epoch 76/300
1s - loss: 2489.3047 - val_loss: 7232.6759
Epoch 00075: val_loss did not improve
Epoch 77/300
1s - loss: 2429.1063 - val_loss: 7276.1655
Epoch 00076: val_loss did not improve
Epoch 78/300
1s - loss: 2380.0972 - val_loss: 7080.5630
Epoch 00077: val_loss did not improve
Epoch 79/300
1s - loss: 2334.9675 - val_loss: 7859.9324
Epoch 00078: val_loss did not improve
Epoch 80/300
1s - loss: 2271.7130 - val_loss: 7787.7393
Epoch 00079: val_loss did not improve
Epoch 81/300
1s - loss: 2223.7153 - val_loss: 7783.5802
Epoch 00080: val_loss did not improve
Epoch 82/300
1s - loss: 2181.8543 - val_loss: 7971.4974
Epoch 00081: val_loss did not improve
Epoch 83/300
1s - loss: 2151.2083 - val_loss: 7679.7988
Epoch 00082: val_loss did not improve
Epoch 84/300
1s - loss: 2113.1039 - val_loss: 7652.6877
Epoch 00083: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training shenyang0
Train on 5742 samples, validate on 1530 samples
Before training:
           shenyang011934.3135      0.02  -nan  0.02      0.02  -nan  0.02      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.95023 nan 4.95023
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           shenyang013222.5701      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.6349 nan 6.6349
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 7508.1168 - val_loss: 5063.5662
Epoch 00000: val_loss improved from inf to 5063.56617, saving model to shenyang0_weights.hdf5
           shenyang0 5486.3715      0.53  0.27  0.45      0.54  0.22  0.47      0.54  0.17  0.49
           shenyang0 5063.5662      0.68  0.34  0.50      0.69  0.30  0.53      0.69  0.28  0.54
forget mean min: 0.930582 0.242103
incx.max(), incx.min(), incx.mean() 3.98014 -3.62592 2.27651
fgtx.max(), fgtx.min(), fgtx.mean() 2.47726 -2.37236 1.39097
abs_mean, abs_mean+, abs_mean-: 6.09072 3.05517 11.0638
U_c = [[-0.11827346]] U_f = [[ 0.]] b_c = [ 0.09488912] b_f = [ 1.08287406]
W_c max, min, mean, abs_mean: 0.114082 -0.114075 -0.0117366 0.111253
W_f max, min, mean, abs_mean: 0.0721993 -0.0727124 -0.00736689 0.070939
Epoch 2/300
1s - loss: 4638.6253 - val_loss: 5925.5991
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 3891.1515 - val_loss: 5937.8904
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 3442.1364 - val_loss: 6296.5221
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 3295.1005 - val_loss: 6254.1732
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 3232.8834 - val_loss: 5892.4249
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 3174.1246 - val_loss: 5875.3289
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 3140.5632 - val_loss: 6090.5068
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3127.9299 - val_loss: 6037.5807
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 3123.2127 - val_loss: 6279.1362
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 3095.4356 - val_loss: 6318.4291
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 3063.2069 - val_loss: 6476.7613
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 3053.7485 - val_loss: 6199.1369
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 3029.6549 - val_loss: 6158.5744
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 3034.5966 - val_loss: 6638.3810
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 3025.7975 - val_loss: 6031.5717
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 3011.9396 - val_loss: 6547.6479
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 2992.1350 - val_loss: 6138.8290
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 2998.0610 - val_loss: 6274.5734
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 2984.2612 - val_loss: 6684.7710
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 2958.7688 - val_loss: 6196.8013
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 2958.3692 - val_loss: 6080.4241
Epoch 00021: val_loss did not improve

haerbin
            haerbin0 5143.0955      0.78  0.34  0.55      0.79  0.31  0.58      0.78  0.28  0.60
            haerbin0 6744.4954      0.88  0.38  0.57      0.88  0.36  0.59      0.89  0.34  0.61
forget mean min: 0.956653 0.573636
incx.max(), incx.min(), incx.mean() 8.03987 -3.5536 6.11529
fgtx.max(), fgtx.min(), fgtx.mean() 1.56528 -0.746062 1.18152
abs_mean, abs_mean+, abs_mean-: 6.03052 5.05806 7.84972
U_c = [[-0.07093001]] U_f = [[ 0.]] b_c = [ 0.18887813] b_f = [ 1.11424339]
W_c max, min, mean, abs_mean: 0.212365 -0.212349 -0.0101642 0.210013
W_f max, min, mean, abs_mean: 0.0426578 -0.042673 -0.00222386 0.0418721

changchun
          changchun0 3140.3315      0.80  0.40  0.52      0.82  0.32  0.59      0.83  0.25  0.65
          changchun0 6039.0269      0.52  0.36  0.40      0.53  0.33  0.42      0.52  0.30  0.42
forget mean min: 0.866099 0.223977
incx.max(), incx.min(), incx.mean() 25.4421 -13.0692 7.44352
fgtx.max(), fgtx.min(), fgtx.mean() 3.88358 -2.25259 1.14326
abs_mean, abs_mean+, abs_mean-: 12.6294 10.5882 14.8521
U_c = [[-0.04374248]] U_f = [[ 0.]] b_c = [ 0.74897873] b_f = [ 0.87247783]
W_c max, min, mean, abs_mean: 1.04602 -1.26623 0.178677 0.937046
W_f max, min, mean, abs_mean: 0.181422 -0.183486 0.0315227 0.142153

shenyang
           shenyang0 5486.3715      0.53  0.27  0.45      0.54  0.22  0.47      0.54  0.17  0.49
           shenyang0 5063.5662      0.68  0.34  0.50      0.69  0.30  0.53      0.69  0.28  0.54
forget mean min: 0.930582 0.242103
incx.max(), incx.min(), incx.mean() 3.98014 -3.62592 2.27651
fgtx.max(), fgtx.min(), fgtx.mean() 2.47726 -2.37236 1.39097
abs_mean, abs_mean+, abs_mean-: 6.09072 3.05517 11.0638
U_c = [[-0.11827346]] U_f = [[ 0.]] b_c = [ 0.09488912] b_f = [ 1.08287406]
W_c max, min, mean, abs_mean: 0.114082 -0.114075 -0.0117366 0.111253
W_f max, min, mean, abs_mean: 0.0721993 -0.0727124 -0.00736689 0.070939
