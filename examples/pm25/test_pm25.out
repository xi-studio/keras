trainset.shape, testset.shape = (60075, 48, 11) (20025, 48, 11)
training rlstm0 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 309.4234 - val_loss: 1182.4007
Epoch 00000: val_loss improved from inf to 1182.40071, saving model to rlstm0_weights.hdf5
Epoch 2/300
10s - loss: 223.0260 - val_loss: 821.8950
Epoch 00001: val_loss improved from 1182.40071 to 821.89503, saving model to rlstm0_weights.hdf5
Epoch 3/300
10s - loss: 196.3071 - val_loss: 633.8369
Epoch 00002: val_loss improved from 821.89503 to 633.83695, saving model to rlstm0_weights.hdf5
Epoch 4/300
10s - loss: 181.8436 - val_loss: 656.9387
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 174.3260 - val_loss: 649.7272
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 169.3190 - val_loss: 620.6029
Epoch 00005: val_loss improved from 633.83695 to 620.60288, saving model to rlstm0_weights.hdf5
Epoch 7/300
10s - loss: 164.8671 - val_loss: 713.2945
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 160.6896 - val_loss: 724.7737
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 157.1337 - val_loss: 617.8043
Epoch 00008: val_loss improved from 620.60288 to 617.80431, saving model to rlstm0_weights.hdf5
Epoch 10/300
10s - loss: 154.2826 - val_loss: 670.2617
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 151.7512 - val_loss: 627.3629
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 149.3431 - val_loss: 584.6036
Epoch 00011: val_loss improved from 617.80431 to 584.60363, saving model to rlstm0_weights.hdf5
Epoch 13/300
10s - loss: 147.0757 - val_loss: 604.6949
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 144.9059 - val_loss: 576.6310
Epoch 00013: val_loss improved from 584.60363 to 576.63096, saving model to rlstm0_weights.hdf5
Epoch 15/300
10s - loss: 142.9975 - val_loss: 579.7123
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 141.1525 - val_loss: 562.7679
Epoch 00015: val_loss improved from 576.63096 to 562.76789, saving model to rlstm0_weights.hdf5
Epoch 17/300
10s - loss: 139.4489 - val_loss: 589.6745
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 137.8737 - val_loss: 564.6067
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 136.5368 - val_loss: 567.3046
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 135.1847 - val_loss: 556.1836
Epoch 00019: val_loss improved from 562.76789 to 556.18362, saving model to rlstm0_weights.hdf5
Epoch 21/300
10s - loss: 134.0690 - val_loss: 585.9317
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 132.9206 - val_loss: 667.5563
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 131.8089 - val_loss: 587.3001
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 130.7449 - val_loss: 544.5605
Epoch 00023: val_loss improved from 556.18362 to 544.56052, saving model to rlstm0_weights.hdf5
Epoch 25/300
10s - loss: 129.7822 - val_loss: 665.4383
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 128.7871 - val_loss: 600.5652
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 127.9401 - val_loss: 600.9739
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 127.1261 - val_loss: 572.4355
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 126.3134 - val_loss: 575.9815
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 125.5262 - val_loss: 632.4334
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 124.9049 - val_loss: 580.7588
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 124.1742 - val_loss: 565.6991
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 123.5510 - val_loss: 622.7038
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 122.8951 - val_loss: 562.4647
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 122.3022 - val_loss: 600.9705
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 121.7411 - val_loss: 607.0219
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 121.1172 - val_loss: 644.3529
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 120.5477 - val_loss: 596.1667
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 119.9867 - val_loss: 568.9050
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 119.5314 - val_loss: 590.9446
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 118.9752 - val_loss: 564.0366
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 118.4221 - val_loss: 550.6380
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 117.9372 - val_loss: 563.0937
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 117.4168 - val_loss: 560.0099
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 116.9886 - val_loss: 574.5753
Epoch 00044: val_loss did not improve
training rlstm1 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 308.2296 - val_loss: 1134.4614
Epoch 00000: val_loss improved from inf to 1134.46141, saving model to rlstm1_weights.hdf5
Epoch 2/300
10s - loss: 222.9804 - val_loss: 768.9015
Epoch 00001: val_loss improved from 1134.46141 to 768.90153, saving model to rlstm1_weights.hdf5
Epoch 3/300
10s - loss: 195.4353 - val_loss: 632.9006
Epoch 00002: val_loss improved from 768.90153 to 632.90059, saving model to rlstm1_weights.hdf5
Epoch 4/300
10s - loss: 181.9412 - val_loss: 619.3723
Epoch 00003: val_loss improved from 632.90059 to 619.37228, saving model to rlstm1_weights.hdf5
Epoch 5/300
10s - loss: 174.1261 - val_loss: 626.0071
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 167.7706 - val_loss: 645.2006
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 161.8357 - val_loss: 652.3036
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 157.1737 - val_loss: 666.3640
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 153.7912 - val_loss: 646.3476
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 151.2038 - val_loss: 645.8668
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 148.8585 - val_loss: 654.2201
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 146.6090 - val_loss: 641.6696
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 144.5093 - val_loss: 661.0506
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 142.5414 - val_loss: 660.9041
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 140.7016 - val_loss: 625.2790
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 138.7767 - val_loss: 629.4507
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 136.9532 - val_loss: 662.3183
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 135.3135 - val_loss: 616.2928
Epoch 00017: val_loss improved from 619.37228 to 616.29276, saving model to rlstm1_weights.hdf5
Epoch 19/300
10s - loss: 133.8643 - val_loss: 683.3298
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.3698 - val_loss: 683.6092
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.0510 - val_loss: 666.1996
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 129.8835 - val_loss: 630.1431
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 128.8313 - val_loss: 595.3657
Epoch 00022: val_loss improved from 616.29276 to 595.36575, saving model to rlstm1_weights.hdf5
Epoch 24/300
10s - loss: 127.8552 - val_loss: 636.3937
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 126.9998 - val_loss: 720.3016
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 126.0426 - val_loss: 664.2005
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 125.2401 - val_loss: 621.7166
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 124.3770 - val_loss: 632.8887
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 123.5787 - val_loss: 651.5327
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 122.8819 - val_loss: 695.8876
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 122.1086 - val_loss: 663.0504
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 121.3881 - val_loss: 682.1777
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 120.6071 - val_loss: 620.1917
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 119.9308 - val_loss: 654.1289
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 119.3461 - val_loss: 661.3049
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 118.5732 - val_loss: 704.2701
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 118.0065 - val_loss: 697.8662
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 117.3978 - val_loss: 643.5306
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 116.8797 - val_loss: 676.2333
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 116.3479 - val_loss: 631.0759
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 115.7839 - val_loss: 676.6162
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 115.2703 - val_loss: 600.2214
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 114.9144 - val_loss: 593.8247
Epoch 00042: val_loss improved from 595.36575 to 593.82472, saving model to rlstm1_weights.hdf5
Epoch 44/300
10s - loss: 114.3976 - val_loss: 630.0905
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 114.0309 - val_loss: 633.0323
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 113.5653 - val_loss: 634.1440
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 113.1145 - val_loss: 667.9296
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 112.8156 - val_loss: 622.6251
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 112.4036 - val_loss: 611.2227
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 112.0607 - val_loss: 641.7326
Epoch 00049: val_loss did not improve
Epoch 51/300
10s - loss: 111.6947 - val_loss: 609.1058
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 111.3548 - val_loss: 583.2700
Epoch 00051: val_loss improved from 593.82472 to 583.26995, saving model to rlstm1_weights.hdf5
Epoch 53/300
10s - loss: 111.0372 - val_loss: 642.5994
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 110.7612 - val_loss: 593.3543
Epoch 00053: val_loss did not improve
Epoch 55/300
10s - loss: 110.4353 - val_loss: 616.0562
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 110.1954 - val_loss: 768.8789
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 109.8794 - val_loss: 588.7790
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 109.5811 - val_loss: 659.0211
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 109.3943 - val_loss: 652.2165
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 109.1555 - val_loss: 604.4597
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 108.8891 - val_loss: 641.8744
Epoch 00060: val_loss did not improve
Epoch 62/300
10s - loss: 108.7485 - val_loss: 585.9295
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 108.3637 - val_loss: 651.2610
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 108.1742 - val_loss: 721.7362
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 107.9722 - val_loss: 581.0618
Epoch 00064: val_loss improved from 583.26995 to 581.06181, saving model to rlstm1_weights.hdf5
Epoch 66/300
10s - loss: 107.7906 - val_loss: 658.8357
Epoch 00065: val_loss did not improve
Epoch 67/300
10s - loss: 107.5590 - val_loss: 606.2731
Epoch 00066: val_loss did not improve
Epoch 68/300
10s - loss: 107.3247 - val_loss: 608.1773
Epoch 00067: val_loss did not improve
Epoch 69/300
10s - loss: 107.1302 - val_loss: 584.4528
Epoch 00068: val_loss did not improve
Epoch 70/300
10s - loss: 106.9834 - val_loss: 680.4201
Epoch 00069: val_loss did not improve
Epoch 71/300
10s - loss: 106.7358 - val_loss: 617.0755
Epoch 00070: val_loss did not improve
Epoch 72/300
10s - loss: 106.5337 - val_loss: 579.4633
Epoch 00071: val_loss improved from 581.06181 to 579.46326, saving model to rlstm1_weights.hdf5
Epoch 73/300
10s - loss: 106.3637 - val_loss: 737.1455
Epoch 00072: val_loss did not improve
Epoch 74/300
10s - loss: 106.1587 - val_loss: 545.2177
Epoch 00073: val_loss improved from 579.46326 to 545.21773, saving model to rlstm1_weights.hdf5
Epoch 75/300
10s - loss: 106.0061 - val_loss: 597.8601
Epoch 00074: val_loss did not improve
Epoch 76/300
10s - loss: 105.8058 - val_loss: 619.7748
Epoch 00075: val_loss did not improve
Epoch 77/300
10s - loss: 105.5579 - val_loss: 602.4336
Epoch 00076: val_loss did not improve
Epoch 78/300
10s - loss: 105.4992 - val_loss: 587.6661
Epoch 00077: val_loss did not improve
Epoch 79/300
10s - loss: 105.3155 - val_loss: 617.0217
Epoch 00078: val_loss did not improve
Epoch 80/300
10s - loss: 105.1334 - val_loss: 643.4436
Epoch 00079: val_loss did not improve
Epoch 81/300
10s - loss: 104.9956 - val_loss: 565.2324
Epoch 00080: val_loss did not improve
Epoch 82/300
10s - loss: 104.7907 - val_loss: 571.1162
Epoch 00081: val_loss did not improve
Epoch 83/300
10s - loss: 104.5534 - val_loss: 720.7242
Epoch 00082: val_loss did not improve
Epoch 84/300
10s - loss: 104.5556 - val_loss: 552.9889
Epoch 00083: val_loss did not improve
Epoch 85/300
10s - loss: 104.2996 - val_loss: 610.5013
Epoch 00084: val_loss did not improve
Epoch 86/300
10s - loss: 104.1544 - val_loss: 551.2719
Epoch 00085: val_loss did not improve
Epoch 87/300
10s - loss: 103.9860 - val_loss: 607.9273
Epoch 00086: val_loss did not improve
Epoch 88/300
10s - loss: 103.8930 - val_loss: 548.1815
Epoch 00087: val_loss did not improve
Epoch 89/300
10s - loss: 103.7287 - val_loss: 557.3445
Epoch 00088: val_loss did not improve
Epoch 90/300
10s - loss: 103.5518 - val_loss: 551.4662
Epoch 00089: val_loss did not improve
Epoch 91/300
10s - loss: 103.4134 - val_loss: 571.6298
Epoch 00090: val_loss did not improve
Epoch 92/300
10s - loss: 103.3223 - val_loss: 615.7248
Epoch 00091: val_loss did not improve
Epoch 93/300
10s - loss: 103.1489 - val_loss: 545.2125
Epoch 00092: val_loss improved from 545.21773 to 545.21254, saving model to rlstm1_weights.hdf5
Epoch 94/300
10s - loss: 103.0985 - val_loss: 566.0087
Epoch 00093: val_loss did not improve
Epoch 95/300
10s - loss: 102.9664 - val_loss: 559.9297
Epoch 00094: val_loss did not improve
Epoch 96/300
10s - loss: 102.8025 - val_loss: 621.3007
Epoch 00095: val_loss did not improve
Epoch 97/300
10s - loss: 102.6356 - val_loss: 594.1047
Epoch 00096: val_loss did not improve
Epoch 98/300
10s - loss: 102.5008 - val_loss: 596.0636
Epoch 00097: val_loss did not improve
Epoch 99/300
10s - loss: 102.3853 - val_loss: 596.2586
Epoch 00098: val_loss did not improve
Epoch 100/300
10s - loss: 102.3054 - val_loss: 555.5361
Epoch 00099: val_loss did not improve
Epoch 101/300
10s - loss: 102.1795 - val_loss: 550.1018
Epoch 00100: val_loss did not improve
Epoch 102/300
10s - loss: 102.1181 - val_loss: 566.0410
Epoch 00101: val_loss did not improve
Epoch 103/300
10s - loss: 101.9848 - val_loss: 690.3504
Epoch 00102: val_loss did not improve
Epoch 104/300
10s - loss: 101.8186 - val_loss: 546.1458
Epoch 00103: val_loss did not improve
Epoch 105/300
10s - loss: 101.7208 - val_loss: 540.6969
Epoch 00104: val_loss improved from 545.21254 to 540.69686, saving model to rlstm1_weights.hdf5
Epoch 106/300
10s - loss: 101.6926 - val_loss: 553.3329
Epoch 00105: val_loss did not improve
Epoch 107/300
10s - loss: 101.5557 - val_loss: 577.4293
Epoch 00106: val_loss did not improve
Epoch 108/300
10s - loss: 101.4570 - val_loss: 563.1664
Epoch 00107: val_loss did not improve
Epoch 109/300
10s - loss: 101.4601 - val_loss: 550.0080
Epoch 00108: val_loss did not improve
Epoch 110/300
10s - loss: 101.2857 - val_loss: 621.1942
Epoch 00109: val_loss did not improve
Epoch 111/300
10s - loss: 101.2756 - val_loss: 537.2044
Epoch 00110: val_loss improved from 540.69686 to 537.20435, saving model to rlstm1_weights.hdf5
Epoch 112/300
10s - loss: 101.0947 - val_loss: 554.9636
Epoch 00111: val_loss did not improve
Epoch 113/300
10s - loss: 100.9841 - val_loss: 542.4080
Epoch 00112: val_loss did not improve
Epoch 114/300
10s - loss: 100.9706 - val_loss: 550.1137
Epoch 00113: val_loss did not improve
Epoch 115/300
10s - loss: 100.8853 - val_loss: 556.6125
Epoch 00114: val_loss did not improve
Epoch 116/300
10s - loss: 100.6646 - val_loss: 538.8490
Epoch 00115: val_loss did not improve
Epoch 117/300
10s - loss: 100.6793 - val_loss: 546.6279
Epoch 00116: val_loss did not improve
Epoch 118/300
10s - loss: 100.6956 - val_loss: 541.8885
Epoch 00117: val_loss did not improve
Epoch 119/300
10s - loss: 100.5469 - val_loss: 529.6144
Epoch 00118: val_loss improved from 537.20435 to 529.61439, saving model to rlstm1_weights.hdf5
Epoch 120/300
10s - loss: 100.4869 - val_loss: 545.9607
Epoch 00119: val_loss did not improve
Epoch 121/300
10s - loss: 100.2689 - val_loss: 556.3398
Epoch 00120: val_loss did not improve
Epoch 122/300
10s - loss: 100.2133 - val_loss: 535.6991
Epoch 00121: val_loss did not improve
Epoch 123/300
10s - loss: 100.1813 - val_loss: 574.9693
Epoch 00122: val_loss did not improve
Epoch 124/300
10s - loss: 100.1124 - val_loss: 571.6081
Epoch 00123: val_loss did not improve
Epoch 125/300
10s - loss: 99.9887 - val_loss: 577.6127
Epoch 00124: val_loss did not improve
Epoch 126/300
10s - loss: 99.9590 - val_loss: 541.3212
Epoch 00125: val_loss did not improve
Epoch 127/300
10s - loss: 99.8428 - val_loss: 552.3111
Epoch 00126: val_loss did not improve
Epoch 128/300
10s - loss: 99.7901 - val_loss: 535.7041
Epoch 00127: val_loss did not improve
Epoch 129/300
10s - loss: 99.6316 - val_loss: 541.6282
Epoch 00128: val_loss did not improve
Epoch 130/300
10s - loss: 99.6217 - val_loss: 560.6533
Epoch 00129: val_loss did not improve
Epoch 131/300
10s - loss: 99.5227 - val_loss: 542.3432
Epoch 00130: val_loss did not improve
Epoch 132/300
10s - loss: 99.4660 - val_loss: 541.1074
Epoch 00131: val_loss did not improve
Epoch 133/300
10s - loss: 99.4956 - val_loss: 513.2186
Epoch 00132: val_loss improved from 529.61439 to 513.21857, saving model to rlstm1_weights.hdf5
Epoch 134/300
10s - loss: 99.3438 - val_loss: 562.6323
Epoch 00133: val_loss did not improve
Epoch 135/300
10s - loss: 99.2406 - val_loss: 533.3363
Epoch 00134: val_loss did not improve
Epoch 136/300
10s - loss: 99.1072 - val_loss: 541.0038
Epoch 00135: val_loss did not improve
Epoch 137/300
10s - loss: 99.1277 - val_loss: 533.0771
Epoch 00136: val_loss did not improve
Epoch 138/300
10s - loss: 99.0557 - val_loss: 529.8979
Epoch 00137: val_loss did not improve
Epoch 139/300
10s - loss: 98.9324 - val_loss: 539.8355
Epoch 00138: val_loss did not improve
Epoch 140/300
10s - loss: 98.9363 - val_loss: 530.8457
Epoch 00139: val_loss did not improve
Epoch 141/300
10s - loss: 98.8000 - val_loss: 523.7818
Epoch 00140: val_loss did not improve
Epoch 142/300
10s - loss: 98.8106 - val_loss: 529.9594
Epoch 00141: val_loss did not improve
Epoch 143/300
10s - loss: 98.7042 - val_loss: 539.4828
Epoch 00142: val_loss did not improve
Epoch 144/300
10s - loss: 98.6707 - val_loss: 520.8857
Epoch 00143: val_loss did not improve
Epoch 145/300
10s - loss: 98.6377 - val_loss: 532.8295
Epoch 00144: val_loss did not improve
Epoch 146/300
10s - loss: 98.5554 - val_loss: 522.1817
Epoch 00145: val_loss did not improve
Epoch 147/300
10s - loss: 98.4930 - val_loss: 520.0105
Epoch 00146: val_loss did not improve
Epoch 148/300
10s - loss: 98.3970 - val_loss: 558.1478
Epoch 00147: val_loss did not improve
Epoch 149/300
10s - loss: 98.4070 - val_loss: 526.0996
Epoch 00148: val_loss did not improve
Epoch 150/300
10s - loss: 98.2946 - val_loss: 518.3734
Epoch 00149: val_loss did not improve
Epoch 151/300
10s - loss: 98.3016 - val_loss: 515.4880
Epoch 00150: val_loss did not improve
Epoch 152/300
10s - loss: 98.1091 - val_loss: 540.9456
Epoch 00151: val_loss did not improve
Epoch 153/300
10s - loss: 98.1375 - val_loss: 520.3265
Epoch 00152: val_loss did not improve
Epoch 154/300
10s - loss: 98.1627 - val_loss: 513.1024
Epoch 00153: val_loss improved from 513.21857 to 513.10239, saving model to rlstm1_weights.hdf5
Epoch 155/300
10s - loss: 98.0083 - val_loss: 536.0875
Epoch 00154: val_loss did not improve
Epoch 156/300
10s - loss: 98.0036 - val_loss: 524.4070
Epoch 00155: val_loss did not improve
Epoch 157/300
10s - loss: 98.0188 - val_loss: 514.2265
Epoch 00156: val_loss did not improve
Epoch 158/300
10s - loss: 97.9255 - val_loss: 523.6582
Epoch 00157: val_loss did not improve
Epoch 159/300
10s - loss: 97.8770 - val_loss: 524.5521
Epoch 00158: val_loss did not improve
Epoch 160/300
10s - loss: 97.7869 - val_loss: 516.9256
Epoch 00159: val_loss did not improve
Epoch 161/300
10s - loss: 97.6990 - val_loss: 519.7030
Epoch 00160: val_loss did not improve
Epoch 162/300
10s - loss: 97.6992 - val_loss: 509.1201
Epoch 00161: val_loss improved from 513.10239 to 509.12005, saving model to rlstm1_weights.hdf5
Epoch 163/300
10s - loss: 97.6469 - val_loss: 523.5668
Epoch 00162: val_loss did not improve
Epoch 164/300
10s - loss: 97.6500 - val_loss: 524.2969
Epoch 00163: val_loss did not improve
Epoch 165/300
10s - loss: 97.5837 - val_loss: 507.2569
Epoch 00164: val_loss improved from 509.12005 to 507.25692, saving model to rlstm1_weights.hdf5
Epoch 166/300
10s - loss: 97.5020 - val_loss: 507.5912
Epoch 00165: val_loss did not improve
Epoch 167/300
10s - loss: 97.4536 - val_loss: 503.1484
Epoch 00166: val_loss improved from 507.25692 to 503.14844, saving model to rlstm1_weights.hdf5
Epoch 168/300
10s - loss: 97.4319 - val_loss: 516.0109
Epoch 00167: val_loss did not improve
Epoch 169/300
10s - loss: 97.3313 - val_loss: 519.7418
Epoch 00168: val_loss did not improve
Epoch 170/300
10s - loss: 97.3499 - val_loss: 523.2489
Epoch 00169: val_loss did not improve
Epoch 171/300
10s - loss: 97.2828 - val_loss: 511.3969
Epoch 00170: val_loss did not improve
Epoch 172/300
10s - loss: 97.2719 - val_loss: 516.0629
Epoch 00171: val_loss did not improve
Epoch 173/300
10s - loss: 97.2604 - val_loss: 505.0196
Epoch 00172: val_loss did not improve
Epoch 174/300
10s - loss: 97.1284 - val_loss: 506.7707
Epoch 00173: val_loss did not improve
Epoch 175/300
10s - loss: 97.1051 - val_loss: 522.5898
Epoch 00174: val_loss did not improve
Epoch 176/300
10s - loss: 97.0890 - val_loss: 499.0615
Epoch 00175: val_loss improved from 503.14844 to 499.06145, saving model to rlstm1_weights.hdf5
Epoch 177/300
10s - loss: 97.0196 - val_loss: 507.3646
Epoch 00176: val_loss did not improve
Epoch 178/300
10s - loss: 96.7859 - val_loss: 512.8690
Epoch 00177: val_loss did not improve
Epoch 179/300
10s - loss: 96.9275 - val_loss: 503.8598
Epoch 00178: val_loss did not improve
Epoch 180/300
10s - loss: 96.8748 - val_loss: 511.2760
Epoch 00179: val_loss did not improve
Epoch 181/300
10s - loss: 96.8603 - val_loss: 511.0370
Epoch 00180: val_loss did not improve
Epoch 182/300
10s - loss: 96.7467 - val_loss: 516.0297
Epoch 00181: val_loss did not improve
Epoch 183/300
10s - loss: 96.7218 - val_loss: 505.4154
Epoch 00182: val_loss did not improve
Epoch 184/300
10s - loss: 96.6595 - val_loss: 497.2986
Epoch 00183: val_loss improved from 499.06145 to 497.29857, saving model to rlstm1_weights.hdf5
Epoch 185/300
10s - loss: 96.6128 - val_loss: 497.5153
Epoch 00184: val_loss did not improve
Epoch 186/300
10s - loss: 96.6174 - val_loss: 512.8869
Epoch 00185: val_loss did not improve
Epoch 187/300
10s - loss: 96.5945 - val_loss: 504.0561
Epoch 00186: val_loss did not improve
Epoch 188/300
10s - loss: 96.4973 - val_loss: 499.4014
Epoch 00187: val_loss did not improve
Epoch 189/300
10s - loss: 96.4709 - val_loss: 526.0246
Epoch 00188: val_loss did not improve
Epoch 190/300
10s - loss: 96.4189 - val_loss: 524.5115
Epoch 00189: val_loss did not improve
Epoch 191/300
10s - loss: 96.4269 - val_loss: 496.7089
Epoch 00190: val_loss improved from 497.29857 to 496.70886, saving model to rlstm1_weights.hdf5
Epoch 192/300
10s - loss: 96.3086 - val_loss: 509.3137
Epoch 00191: val_loss did not improve
Epoch 193/300
10s - loss: 96.3036 - val_loss: 529.2963
Epoch 00192: val_loss did not improve
Epoch 194/300
10s - loss: 96.3127 - val_loss: 508.3426
Epoch 00193: val_loss did not improve
Epoch 195/300
10s - loss: 96.2492 - val_loss: 491.0817
Epoch 00194: val_loss improved from 496.70886 to 491.08172, saving model to rlstm1_weights.hdf5
Epoch 196/300
10s - loss: 96.2033 - val_loss: 505.9037
Epoch 00195: val_loss did not improve
Epoch 197/300
10s - loss: 96.1117 - val_loss: 544.2036
Epoch 00196: val_loss did not improve
Epoch 198/300
10s - loss: 96.0915 - val_loss: 499.4244
Epoch 00197: val_loss did not improve
Epoch 199/300
10s - loss: 96.1570 - val_loss: 509.8736
Epoch 00198: val_loss did not improve
Epoch 200/300
10s - loss: 96.0567 - val_loss: 515.9687
Epoch 00199: val_loss did not improve
Epoch 201/300
10s - loss: 95.9625 - val_loss: 510.5210
Epoch 00200: val_loss did not improve
Epoch 202/300
10s - loss: 95.9346 - val_loss: 523.6184
Epoch 00201: val_loss did not improve
Epoch 203/300
10s - loss: 95.9854 - val_loss: 525.7816
Epoch 00202: val_loss did not improve
Epoch 204/300
10s - loss: 95.9542 - val_loss: 509.6203
Epoch 00203: val_loss did not improve
Epoch 205/300
10s - loss: 95.8552 - val_loss: 509.2760
Epoch 00204: val_loss did not improve
Epoch 206/300
10s - loss: 95.8327 - val_loss: 499.9292
Epoch 00205: val_loss did not improve
Epoch 207/300
10s - loss: 95.8348 - val_loss: 528.3879
Epoch 00206: val_loss did not improve
Epoch 208/300
10s - loss: 95.7959 - val_loss: 539.6874
Epoch 00207: val_loss did not improve
Epoch 209/300
10s - loss: 95.6742 - val_loss: 506.1658
Epoch 00208: val_loss did not improve
Epoch 210/300
10s - loss: 95.7037 - val_loss: 516.8279
Epoch 00209: val_loss did not improve
Epoch 211/300
10s - loss: 95.7047 - val_loss: 538.4079
Epoch 00210: val_loss did not improve
Epoch 212/300
10s - loss: 95.6360 - val_loss: 526.0064
Epoch 00211: val_loss did not improve
Epoch 213/300
10s - loss: 95.4885 - val_loss: 518.2866
Epoch 00212: val_loss did not improve
Epoch 214/300
10s - loss: 95.5289 - val_loss: 523.0408
Epoch 00213: val_loss did not improve
Epoch 215/300
10s - loss: 95.4542 - val_loss: 546.9780
Epoch 00214: val_loss did not improve
Epoch 216/300
10s - loss: 95.4929 - val_loss: 536.7736
Epoch 00215: val_loss did not improve
training rlstm2 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 309.6597 - val_loss: 1167.1935
Epoch 00000: val_loss improved from inf to 1167.19348, saving model to rlstm2_weights.hdf5
Epoch 2/300
10s - loss: 224.9876 - val_loss: 775.5714
Epoch 00001: val_loss improved from 1167.19348 to 775.57144, saving model to rlstm2_weights.hdf5
Epoch 3/300
10s - loss: 197.3071 - val_loss: 649.4312
Epoch 00002: val_loss improved from 775.57144 to 649.43115, saving model to rlstm2_weights.hdf5
Epoch 4/300
10s - loss: 183.0690 - val_loss: 652.6749
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 174.7694 - val_loss: 648.6964
Epoch 00004: val_loss improved from 649.43115 to 648.69636, saving model to rlstm2_weights.hdf5
Epoch 6/300
10s - loss: 168.9115 - val_loss: 662.8140
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 163.6359 - val_loss: 699.7849
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 159.1838 - val_loss: 685.6667
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 155.5472 - val_loss: 675.2021
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 152.5065 - val_loss: 674.7168
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 149.7607 - val_loss: 682.0360
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 147.4711 - val_loss: 645.4494
Epoch 00011: val_loss improved from 648.69636 to 645.44944, saving model to rlstm2_weights.hdf5
Epoch 13/300
10s - loss: 145.2545 - val_loss: 629.0323
Epoch 00012: val_loss improved from 645.44944 to 629.03227, saving model to rlstm2_weights.hdf5
Epoch 14/300
10s - loss: 143.0643 - val_loss: 612.9716
Epoch 00013: val_loss improved from 629.03227 to 612.97158, saving model to rlstm2_weights.hdf5
Epoch 15/300
10s - loss: 140.8987 - val_loss: 607.3532
Epoch 00014: val_loss improved from 612.97158 to 607.35325, saving model to rlstm2_weights.hdf5
Epoch 16/300
10s - loss: 138.7929 - val_loss: 588.9415
Epoch 00015: val_loss improved from 607.35325 to 588.94154, saving model to rlstm2_weights.hdf5
Epoch 17/300
10s - loss: 136.9594 - val_loss: 589.6628
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 135.2261 - val_loss: 628.9779
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 133.6703 - val_loss: 627.5592
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.3637 - val_loss: 622.9364
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.0516 - val_loss: 601.1845
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 129.8713 - val_loss: 603.1755
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 128.6364 - val_loss: 603.6525
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 127.5819 - val_loss: 653.7278
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 126.5241 - val_loss: 632.2149
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 125.5736 - val_loss: 623.7390
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 124.6721 - val_loss: 610.4100
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 123.8171 - val_loss: 639.7289
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 122.9696 - val_loss: 614.9656
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 122.1504 - val_loss: 693.3543
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 121.4091 - val_loss: 678.8212
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 120.6182 - val_loss: 679.5679
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 119.8646 - val_loss: 668.7449
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 119.2884 - val_loss: 627.9880
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 118.6902 - val_loss: 666.5636
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 118.1158 - val_loss: 726.2846
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 117.6221 - val_loss: 639.8731
Epoch 00036: val_loss did not improve
training rlstm3 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 309.7202 - val_loss: 1218.3034
Epoch 00000: val_loss improved from inf to 1218.30337, saving model to rlstm3_weights.hdf5
Epoch 2/300
10s - loss: 223.1559 - val_loss: 780.3961
Epoch 00001: val_loss improved from 1218.30337 to 780.39613, saving model to rlstm3_weights.hdf5
Epoch 3/300
10s - loss: 195.6035 - val_loss: 631.7932
Epoch 00002: val_loss improved from 780.39613 to 631.79323, saving model to rlstm3_weights.hdf5
Epoch 4/300
10s - loss: 181.8328 - val_loss: 647.4689
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 172.7053 - val_loss: 655.3516
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 165.3131 - val_loss: 672.3649
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 160.0648 - val_loss: 705.3595
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 155.9172 - val_loss: 669.7248
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 152.5363 - val_loss: 656.0056
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 149.6193 - val_loss: 639.5044
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 147.1950 - val_loss: 630.8114
Epoch 00010: val_loss improved from 631.79323 to 630.81137, saving model to rlstm3_weights.hdf5
Epoch 12/300
10s - loss: 144.9437 - val_loss: 643.0791
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 143.0134 - val_loss: 638.2064
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 141.1642 - val_loss: 653.5618
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 139.4222 - val_loss: 674.6464
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 137.8636 - val_loss: 732.5464
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 136.3774 - val_loss: 705.7572
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 134.9911 - val_loss: 678.6841
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 133.6966 - val_loss: 696.5066
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.5242 - val_loss: 754.4093
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.3068 - val_loss: 671.7810
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 130.1250 - val_loss: 697.1285
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 129.0801 - val_loss: 729.4430
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 127.9709 - val_loss: 739.9086
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 126.9502 - val_loss: 765.7561
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 126.0953 - val_loss: 729.7887
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 125.1886 - val_loss: 663.6467
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 124.3741 - val_loss: 701.8663
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 123.6693 - val_loss: 703.2924
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 122.7789 - val_loss: 807.3551
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 122.0031 - val_loss: 742.0369
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 121.3505 - val_loss: 715.7898
Epoch 00031: val_loss did not improve
training rlstm4 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 309.6721 - val_loss: 1227.2156
Epoch 00000: val_loss improved from inf to 1227.21563, saving model to rlstm4_weights.hdf5
Epoch 2/300
10s - loss: 222.3503 - val_loss: 757.5529
Epoch 00001: val_loss improved from 1227.21563 to 757.55286, saving model to rlstm4_weights.hdf5
Epoch 3/300
10s - loss: 194.7049 - val_loss: 634.8608
Epoch 00002: val_loss improved from 757.55286 to 634.86075, saving model to rlstm4_weights.hdf5
Epoch 4/300
10s - loss: 182.4961 - val_loss: 634.5592
Epoch 00003: val_loss improved from 634.86075 to 634.55922, saving model to rlstm4_weights.hdf5
Epoch 5/300
10s - loss: 175.0469 - val_loss: 639.7128
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 168.8587 - val_loss: 679.8209
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 162.6502 - val_loss: 702.4041
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 157.2219 - val_loss: 705.0228
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 153.2113 - val_loss: 679.0659
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 150.0337 - val_loss: 667.7050
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 147.3619 - val_loss: 651.8654
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 145.1083 - val_loss: 672.5285
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 142.9933 - val_loss: 666.1312
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 141.0691 - val_loss: 668.8063
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 139.2897 - val_loss: 685.4212
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 137.6655 - val_loss: 673.9061
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 136.1328 - val_loss: 688.9259
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 134.7540 - val_loss: 667.7824
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 133.4575 - val_loss: 680.5753
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.3219 - val_loss: 697.2398
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.2424 - val_loss: 686.5618
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 130.1942 - val_loss: 698.3033
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 129.2634 - val_loss: 711.8485
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 128.4095 - val_loss: 708.3944
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 127.4794 - val_loss: 732.3726
Epoch 00024: val_loss did not improve
training rlstm5 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 310.1703 - val_loss: 1157.2658
Epoch 00000: val_loss improved from inf to 1157.26576, saving model to rlstm5_weights.hdf5
Epoch 2/300
10s - loss: 220.5731 - val_loss: 726.2930
Epoch 00001: val_loss improved from 1157.26576 to 726.29299, saving model to rlstm5_weights.hdf5
Epoch 3/300
10s - loss: 192.7070 - val_loss: 614.7991
Epoch 00002: val_loss improved from 726.29299 to 614.79913, saving model to rlstm5_weights.hdf5
Epoch 4/300
10s - loss: 182.1242 - val_loss: 626.2561
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 175.3444 - val_loss: 639.1047
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 169.9456 - val_loss: 687.6382
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 164.7654 - val_loss: 653.6072
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 159.8813 - val_loss: 683.4881
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 155.7281 - val_loss: 671.0706
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 152.2427 - val_loss: 667.1004
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 149.4047 - val_loss: 686.8126
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 146.8400 - val_loss: 641.9243
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 144.5831 - val_loss: 638.2610
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 142.3868 - val_loss: 649.5289
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 140.2899 - val_loss: 623.6269
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 138.4284 - val_loss: 606.3868
Epoch 00015: val_loss improved from 614.79913 to 606.38677, saving model to rlstm5_weights.hdf5
Epoch 17/300
10s - loss: 136.7294 - val_loss: 650.4174
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 135.1001 - val_loss: 613.9816
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 133.6220 - val_loss: 645.0458
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.3806 - val_loss: 639.2989
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.1286 - val_loss: 603.5840
Epoch 00020: val_loss improved from 606.38677 to 603.58400, saving model to rlstm5_weights.hdf5
Epoch 22/300
10s - loss: 129.9852 - val_loss: 583.1287
Epoch 00021: val_loss improved from 603.58400 to 583.12868, saving model to rlstm5_weights.hdf5
Epoch 23/300
10s - loss: 128.9729 - val_loss: 657.0064
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 127.9368 - val_loss: 619.9614
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 126.9942 - val_loss: 632.8471
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 126.1438 - val_loss: 596.2055
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 125.3117 - val_loss: 609.1495
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 124.4864 - val_loss: 608.8617
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 123.7084 - val_loss: 659.0470
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 122.9795 - val_loss: 631.1226
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 122.2750 - val_loss: 631.9611
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 121.6657 - val_loss: 590.6246
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 121.0359 - val_loss: 619.3295
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 120.3408 - val_loss: 703.3321
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 119.7880 - val_loss: 604.3875
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 119.2872 - val_loss: 593.2282
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 118.7915 - val_loss: 601.8295
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 118.1959 - val_loss: 598.4669
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 117.7101 - val_loss: 599.9546
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 117.3036 - val_loss: 582.0741
Epoch 00039: val_loss improved from 583.12868 to 582.07413, saving model to rlstm5_weights.hdf5
Epoch 41/300
10s - loss: 116.8700 - val_loss: 610.9259
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 116.4444 - val_loss: 606.4348
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 116.0509 - val_loss: 664.9754
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 115.6301 - val_loss: 585.5085
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 115.2007 - val_loss: 617.3042
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 114.8656 - val_loss: 597.1340
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 114.5923 - val_loss: 646.6685
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 114.1332 - val_loss: 608.4659
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 113.9103 - val_loss: 648.0776
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 113.5209 - val_loss: 563.7690
Epoch 00049: val_loss improved from 582.07413 to 563.76901, saving model to rlstm5_weights.hdf5
Epoch 51/300
10s - loss: 113.2205 - val_loss: 615.4018
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 112.8268 - val_loss: 611.4377
Epoch 00051: val_loss did not improve
Epoch 53/300
10s - loss: 112.4912 - val_loss: 611.5371
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 112.3302 - val_loss: 616.7445
Epoch 00053: val_loss did not improve
Epoch 55/300
10s - loss: 111.9856 - val_loss: 636.8088
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 111.7048 - val_loss: 601.0697
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 111.4427 - val_loss: 617.9938
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 111.1434 - val_loss: 641.3925
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 110.8908 - val_loss: 635.3750
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 110.6186 - val_loss: 674.3088
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 110.4565 - val_loss: 629.2085
Epoch 00060: val_loss did not improve
Epoch 62/300
10s - loss: 110.1420 - val_loss: 700.8402
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 109.8776 - val_loss: 638.6745
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 109.7102 - val_loss: 620.7635
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 109.4309 - val_loss: 610.3671
Epoch 00064: val_loss did not improve
Epoch 66/300
10s - loss: 109.0990 - val_loss: 665.6963
Epoch 00065: val_loss did not improve
Epoch 67/300
10s - loss: 108.8734 - val_loss: 621.0529
Epoch 00066: val_loss did not improve
Epoch 68/300
10s - loss: 108.6488 - val_loss: 599.1399
Epoch 00067: val_loss did not improve
Epoch 69/300
10s - loss: 108.4962 - val_loss: 682.7795
Epoch 00068: val_loss did not improve
Epoch 70/300
10s - loss: 108.1552 - val_loss: 652.8215
Epoch 00069: val_loss did not improve
Epoch 71/300
10s - loss: 108.0278 - val_loss: 622.2863
Epoch 00070: val_loss did not improve
training rlstm6 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 308.4577 - val_loss: 1171.5279
Epoch 00000: val_loss improved from inf to 1171.52786, saving model to rlstm6_weights.hdf5
Epoch 2/300
10s - loss: 219.3334 - val_loss: 663.1128
Epoch 00001: val_loss improved from 1171.52786 to 663.11279, saving model to rlstm6_weights.hdf5
Epoch 3/300
10s - loss: 192.7263 - val_loss: 622.6684
Epoch 00002: val_loss improved from 663.11279 to 622.66837, saving model to rlstm6_weights.hdf5
Epoch 4/300
10s - loss: 181.7908 - val_loss: 643.1777
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 174.8069 - val_loss: 641.7489
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 168.8660 - val_loss: 640.6406
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 163.2621 - val_loss: 717.5257
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 158.3138 - val_loss: 671.0838
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 154.3606 - val_loss: 636.9767
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 151.2153 - val_loss: 662.9820
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 148.4970 - val_loss: 645.6442
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 146.1162 - val_loss: 652.5938
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 144.0300 - val_loss: 636.3041
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 142.1337 - val_loss: 642.6920
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 140.2388 - val_loss: 654.6701
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 138.6218 - val_loss: 630.8571
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 137.2104 - val_loss: 631.2838
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 135.8334 - val_loss: 628.0005
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 134.5787 - val_loss: 619.5806
Epoch 00018: val_loss improved from 622.66837 to 619.58062, saving model to rlstm6_weights.hdf5
Epoch 20/300
10s - loss: 133.4591 - val_loss: 658.6220
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 132.3241 - val_loss: 607.0844
Epoch 00020: val_loss improved from 619.58062 to 607.08440, saving model to rlstm6_weights.hdf5
Epoch 22/300
10s - loss: 131.3524 - val_loss: 691.7898
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 130.5610 - val_loss: 626.3210
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 129.7231 - val_loss: 617.8210
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 128.9335 - val_loss: 629.7135
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 128.2096 - val_loss: 623.1902
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 127.4215 - val_loss: 658.5942
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 126.5912 - val_loss: 603.5651
Epoch 00027: val_loss improved from 607.08440 to 603.56508, saving model to rlstm6_weights.hdf5
Epoch 29/300
10s - loss: 125.9051 - val_loss: 607.9879
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 125.3137 - val_loss: 629.1134
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 124.6372 - val_loss: 646.6182
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 124.0525 - val_loss: 617.4973
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 123.5169 - val_loss: 580.0506
Epoch 00032: val_loss improved from 603.56508 to 580.05063, saving model to rlstm6_weights.hdf5
Epoch 34/300
10s - loss: 122.9311 - val_loss: 636.6484
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 122.4369 - val_loss: 626.4824
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 122.0061 - val_loss: 657.8691
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 121.5326 - val_loss: 589.6047
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 121.0445 - val_loss: 621.4676
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 120.6618 - val_loss: 632.1491
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 120.2246 - val_loss: 614.7836
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 119.7849 - val_loss: 702.4039
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 119.4006 - val_loss: 608.2101
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 118.9746 - val_loss: 619.2145
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 118.5650 - val_loss: 636.6213
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 118.1713 - val_loss: 600.0910
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 117.7812 - val_loss: 567.0213
Epoch 00045: val_loss improved from 580.05063 to 567.02129, saving model to rlstm6_weights.hdf5
Epoch 47/300
10s - loss: 117.3511 - val_loss: 590.5530
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 117.0195 - val_loss: 619.3926
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 116.7035 - val_loss: 612.7137
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 116.3105 - val_loss: 639.1358
Epoch 00049: val_loss did not improve
Epoch 51/300
10s - loss: 115.9150 - val_loss: 599.5886
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 115.6325 - val_loss: 607.0618
Epoch 00051: val_loss did not improve
Epoch 53/300
10s - loss: 115.2942 - val_loss: 628.2480
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 114.8413 - val_loss: 642.0485
Epoch 00053: val_loss did not improve
Epoch 55/300
10s - loss: 114.5675 - val_loss: 578.4973
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 114.1769 - val_loss: 591.6909
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 113.9387 - val_loss: 613.7434
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 113.6410 - val_loss: 620.0969
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 113.3343 - val_loss: 600.3725
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 113.0458 - val_loss: 592.5390
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 112.7936 - val_loss: 655.2838
Epoch 00060: val_loss did not improve
Epoch 62/300
10s - loss: 112.5535 - val_loss: 574.0850
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 112.2084 - val_loss: 586.5247
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 112.0720 - val_loss: 617.2534
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 111.8135 - val_loss: 571.1423
Epoch 00064: val_loss did not improve
Epoch 66/300
10s - loss: 111.5939 - val_loss: 687.5149
Epoch 00065: val_loss did not improve
Epoch 67/300
10s - loss: 111.3569 - val_loss: 654.2966
Epoch 00066: val_loss did not improve
training rlstm7 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 310.2251 - val_loss: 1244.1485
Epoch 00000: val_loss improved from inf to 1244.14848, saving model to rlstm7_weights.hdf5
Epoch 2/300
10s - loss: 222.8026 - val_loss: 774.1756
Epoch 00001: val_loss improved from 1244.14848 to 774.17561, saving model to rlstm7_weights.hdf5
Epoch 3/300
10s - loss: 196.3420 - val_loss: 630.2042
Epoch 00002: val_loss improved from 774.17561 to 630.20422, saving model to rlstm7_weights.hdf5
Epoch 4/300
10s - loss: 183.3102 - val_loss: 638.4746
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 175.5805 - val_loss: 658.6538
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 169.7688 - val_loss: 644.9718
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 163.5332 - val_loss: 663.2423
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 158.5444 - val_loss: 664.5391
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 154.9248 - val_loss: 660.3686
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 152.1506 - val_loss: 654.0966
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 149.6954 - val_loss: 654.5608
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 147.4131 - val_loss: 658.9071
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 145.3631 - val_loss: 663.7090
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 143.4991 - val_loss: 695.7214
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 141.6304 - val_loss: 665.8433
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 139.9240 - val_loss: 701.9415
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 138.3173 - val_loss: 692.0702
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 136.8072 - val_loss: 675.0344
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 135.2983 - val_loss: 654.9156
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 133.8577 - val_loss: 692.9003
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 132.5171 - val_loss: 707.7826
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 131.2341 - val_loss: 731.7321
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 130.0986 - val_loss: 722.5082
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 129.0462 - val_loss: 670.5825
Epoch 00023: val_loss did not improve
training rlstm8 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 308.3684 - val_loss: 1114.3426
Epoch 00000: val_loss improved from inf to 1114.34260, saving model to rlstm8_weights.hdf5
Epoch 2/300
10s - loss: 220.1960 - val_loss: 718.4501
Epoch 00001: val_loss improved from 1114.34260 to 718.45007, saving model to rlstm8_weights.hdf5
Epoch 3/300
10s - loss: 194.1323 - val_loss: 624.1966
Epoch 00002: val_loss improved from 718.45007 to 624.19662, saving model to rlstm8_weights.hdf5
Epoch 4/300
10s - loss: 182.1505 - val_loss: 621.7042
Epoch 00003: val_loss improved from 624.19662 to 621.70420, saving model to rlstm8_weights.hdf5
Epoch 5/300
10s - loss: 173.5160 - val_loss: 653.7983
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 167.6395 - val_loss: 722.2827
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 162.3781 - val_loss: 671.9632
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 157.4824 - val_loss: 660.9843
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 153.5421 - val_loss: 671.7345
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 150.3805 - val_loss: 693.4578
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 147.8450 - val_loss: 658.7973
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 145.4829 - val_loss: 638.0652
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 143.4535 - val_loss: 638.5501
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 141.4147 - val_loss: 629.3846
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 139.5608 - val_loss: 646.8588
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 137.8714 - val_loss: 662.5724
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 136.2627 - val_loss: 676.9305
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 134.7992 - val_loss: 657.5717
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 133.4317 - val_loss: 695.5180
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 132.2136 - val_loss: 664.3937
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 131.0724 - val_loss: 684.5823
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 129.9447 - val_loss: 625.6887
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 128.9771 - val_loss: 659.1532
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 127.9910 - val_loss: 680.7464
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 127.0326 - val_loss: 730.7874
Epoch 00024: val_loss did not improve
training rlstm9 batch_size = 128
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 308.3708 - val_loss: 1239.6505
Epoch 00000: val_loss improved from inf to 1239.65053, saving model to rlstm9_weights.hdf5
Epoch 2/300
10s - loss: 222.4069 - val_loss: 781.5773
Epoch 00001: val_loss improved from 1239.65053 to 781.57725, saving model to rlstm9_weights.hdf5
Epoch 3/300
10s - loss: 195.4609 - val_loss: 619.7474
Epoch 00002: val_loss improved from 781.57725 to 619.74735, saving model to rlstm9_weights.hdf5
Epoch 4/300
10s - loss: 183.4730 - val_loss: 642.3506
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 175.9955 - val_loss: 660.7355
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 170.2825 - val_loss: 664.7428
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 164.8006 - val_loss: 711.9214
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 159.6785 - val_loss: 693.0672
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 155.6868 - val_loss: 711.5679
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 152.5006 - val_loss: 672.7541
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 149.6891 - val_loss: 671.9114
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 147.1209 - val_loss: 667.1212
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 145.0324 - val_loss: 622.8538
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 142.8231 - val_loss: 627.9169
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 141.0744 - val_loss: 628.5035
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 139.3979 - val_loss: 628.3739
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 137.9842 - val_loss: 585.4012
Epoch 00016: val_loss improved from 619.74735 to 585.40121, saving model to rlstm9_weights.hdf5
Epoch 18/300
10s - loss: 136.6361 - val_loss: 634.4201
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 135.3760 - val_loss: 616.8696
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 134.2854 - val_loss: 633.0934
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 133.2015 - val_loss: 603.8377
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 132.0637 - val_loss: 604.8090
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 130.9448 - val_loss: 586.5211
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 129.8640 - val_loss: 622.3675
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 128.7915 - val_loss: 612.4817
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 127.7719 - val_loss: 647.6778
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 126.8223 - val_loss: 646.4992
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 125.8970 - val_loss: 632.8373
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 125.0665 - val_loss: 612.6500
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 124.1968 - val_loss: 646.8197
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 123.5191 - val_loss: 633.6818
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 122.6950 - val_loss: 625.8896
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 122.0565 - val_loss: 610.3960
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 121.3972 - val_loss: 613.9054
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 120.8168 - val_loss: 613.2153
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 120.2117 - val_loss: 687.6470
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 119.6810 - val_loss: 657.6040
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 119.1324 - val_loss: 615.6453
Epoch 00037: val_loss did not improve
training rlstm10 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 368.8473 - val_loss: 1142.8742
Epoch 00000: val_loss improved from inf to 1142.87416, saving model to rlstm10_weights.hdf5
Epoch 2/300
6s - loss: 244.3092 - val_loss: 1091.0504
Epoch 00001: val_loss improved from 1142.87416 to 1091.05040, saving model to rlstm10_weights.hdf5
Epoch 3/300
6s - loss: 219.4116 - val_loss: 750.8297
Epoch 00002: val_loss improved from 1091.05040 to 750.82971, saving model to rlstm10_weights.hdf5
Epoch 4/300
6s - loss: 198.9206 - val_loss: 631.3979
Epoch 00003: val_loss improved from 750.82971 to 631.39789, saving model to rlstm10_weights.hdf5
Epoch 5/300
6s - loss: 189.1421 - val_loss: 622.5435
Epoch 00004: val_loss improved from 631.39789 to 622.54353, saving model to rlstm10_weights.hdf5
Epoch 6/300
6s - loss: 181.8717 - val_loss: 623.3657
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 176.2372 - val_loss: 631.6177
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 171.9081 - val_loss: 642.8836
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.3911 - val_loss: 644.7056
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 165.1906 - val_loss: 674.5145
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 162.5545 - val_loss: 689.4305
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 160.1931 - val_loss: 671.0498
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 157.8157 - val_loss: 654.5929
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 155.6265 - val_loss: 666.9019
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 153.5446 - val_loss: 634.8137
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 151.7551 - val_loss: 654.0699
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 150.1765 - val_loss: 657.8227
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 148.6803 - val_loss: 631.6884
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 147.2750 - val_loss: 631.3748
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 145.9159 - val_loss: 624.6530
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 144.4808 - val_loss: 620.1442
Epoch 00020: val_loss improved from 622.54353 to 620.14419, saving model to rlstm10_weights.hdf5
Epoch 22/300
6s - loss: 143.2597 - val_loss: 663.7387
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 142.0706 - val_loss: 622.9869
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 140.8988 - val_loss: 627.9011
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 139.8658 - val_loss: 634.7637
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 138.8246 - val_loss: 629.2306
Epoch 00025: val_loss did not improve
Epoch 27/300
6s - loss: 137.7525 - val_loss: 662.1539
Epoch 00026: val_loss did not improve
Epoch 28/300
6s - loss: 136.7762 - val_loss: 651.0088
Epoch 00027: val_loss did not improve
Epoch 29/300
6s - loss: 135.7220 - val_loss: 655.5771
Epoch 00028: val_loss did not improve
Epoch 30/300
6s - loss: 134.8423 - val_loss: 659.4408
Epoch 00029: val_loss did not improve
Epoch 31/300
6s - loss: 133.9371 - val_loss: 701.7882
Epoch 00030: val_loss did not improve
Epoch 32/300
6s - loss: 133.0357 - val_loss: 675.8392
Epoch 00031: val_loss did not improve
Epoch 33/300
6s - loss: 132.4004 - val_loss: 690.7371
Epoch 00032: val_loss did not improve
Epoch 34/300
6s - loss: 131.6376 - val_loss: 673.2771
Epoch 00033: val_loss did not improve
Epoch 35/300
6s - loss: 130.9445 - val_loss: 744.0824
Epoch 00034: val_loss did not improve
Epoch 36/300
6s - loss: 130.3423 - val_loss: 720.6866
Epoch 00035: val_loss did not improve
Epoch 37/300
6s - loss: 129.8442 - val_loss: 655.8422
Epoch 00036: val_loss did not improve
Epoch 38/300
6s - loss: 129.1921 - val_loss: 726.9679
Epoch 00037: val_loss did not improve
Epoch 39/300
6s - loss: 128.6128 - val_loss: 748.4840
Epoch 00038: val_loss did not improve
Epoch 40/300
6s - loss: 128.0401 - val_loss: 684.3617
Epoch 00039: val_loss did not improve
Epoch 41/300
6s - loss: 127.5419 - val_loss: 723.1724
Epoch 00040: val_loss did not improve
Epoch 42/300
6s - loss: 127.0181 - val_loss: 678.8321
Epoch 00041: val_loss did not improve
training rlstm11 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 368.8387 - val_loss: 1133.1006
Epoch 00000: val_loss improved from inf to 1133.10064, saving model to rlstm11_weights.hdf5
Epoch 2/300
6s - loss: 243.3347 - val_loss: 1140.6469
Epoch 00001: val_loss did not improve
Epoch 3/300
6s - loss: 217.4920 - val_loss: 689.9111
Epoch 00002: val_loss improved from 1133.10064 to 689.91114, saving model to rlstm11_weights.hdf5
Epoch 4/300
6s - loss: 197.0224 - val_loss: 612.8435
Epoch 00003: val_loss improved from 689.91114 to 612.84350, saving model to rlstm11_weights.hdf5
Epoch 5/300
6s - loss: 187.3180 - val_loss: 624.9968
Epoch 00004: val_loss did not improve
Epoch 6/300
6s - loss: 180.3904 - val_loss: 627.7226
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 175.1886 - val_loss: 635.9894
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 171.2963 - val_loss: 660.0452
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 167.9344 - val_loss: 675.4931
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 164.6706 - val_loss: 662.3192
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 161.6260 - val_loss: 732.9414
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 159.0635 - val_loss: 727.3051
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 156.9131 - val_loss: 689.2757
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 154.9293 - val_loss: 672.0163
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 153.3763 - val_loss: 677.9867
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 151.7183 - val_loss: 671.5373
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 150.1822 - val_loss: 676.1749
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 148.6553 - val_loss: 652.5816
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 147.2730 - val_loss: 637.6400
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 145.8297 - val_loss: 660.3088
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 144.5936 - val_loss: 635.6809
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 143.4173 - val_loss: 619.7396
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 142.3483 - val_loss: 639.1357
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 141.3301 - val_loss: 619.6053
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 140.3632 - val_loss: 614.3340
Epoch 00024: val_loss did not improve
training rlstm12 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 366.3254 - val_loss: 1161.0302
Epoch 00000: val_loss improved from inf to 1161.03018, saving model to rlstm12_weights.hdf5
Epoch 2/300
6s - loss: 243.6329 - val_loss: 1124.8567
Epoch 00001: val_loss improved from 1161.03018 to 1124.85674, saving model to rlstm12_weights.hdf5
Epoch 3/300
6s - loss: 219.1294 - val_loss: 787.3119
Epoch 00002: val_loss improved from 1124.85674 to 787.31195, saving model to rlstm12_weights.hdf5
Epoch 4/300
6s - loss: 200.1109 - val_loss: 673.8069
Epoch 00003: val_loss improved from 787.31195 to 673.80695, saving model to rlstm12_weights.hdf5
Epoch 5/300
6s - loss: 189.6056 - val_loss: 657.6090
Epoch 00004: val_loss improved from 673.80695 to 657.60898, saving model to rlstm12_weights.hdf5
Epoch 6/300
6s - loss: 182.4507 - val_loss: 640.9645
Epoch 00005: val_loss improved from 657.60898 to 640.96448, saving model to rlstm12_weights.hdf5
Epoch 7/300
6s - loss: 176.8321 - val_loss: 658.7604
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 171.3144 - val_loss: 654.1471
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 166.4363 - val_loss: 677.0475
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 162.7065 - val_loss: 694.5811
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 159.8519 - val_loss: 660.2227
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 157.3147 - val_loss: 663.6250
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 155.2488 - val_loss: 660.3042
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 153.3835 - val_loss: 693.2406
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 151.7090 - val_loss: 666.1437
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 150.1278 - val_loss: 668.6921
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 148.6913 - val_loss: 663.0517
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 147.3081 - val_loss: 648.5124
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 145.9961 - val_loss: 665.4943
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 144.5915 - val_loss: 667.3455
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 143.4735 - val_loss: 659.8893
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 142.2912 - val_loss: 669.7904
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 141.2117 - val_loss: 670.6770
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 140.1691 - val_loss: 662.1567
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 139.1280 - val_loss: 654.6143
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 138.0959 - val_loss: 657.2564
Epoch 00025: val_loss did not improve
Epoch 27/300
6s - loss: 137.2221 - val_loss: 667.7848
Epoch 00026: val_loss did not improve
training rlstm13 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 368.1770 - val_loss: 1152.3178
Epoch 00000: val_loss improved from inf to 1152.31784, saving model to rlstm13_weights.hdf5
Epoch 2/300
6s - loss: 243.9682 - val_loss: 1128.4628
Epoch 00001: val_loss improved from 1152.31784 to 1128.46278, saving model to rlstm13_weights.hdf5
Epoch 3/300
6s - loss: 220.3134 - val_loss: 762.0140
Epoch 00002: val_loss improved from 1128.46278 to 762.01402, saving model to rlstm13_weights.hdf5
Epoch 4/300
6s - loss: 199.7576 - val_loss: 644.4983
Epoch 00003: val_loss improved from 762.01402 to 644.49826, saving model to rlstm13_weights.hdf5
Epoch 5/300
6s - loss: 189.5149 - val_loss: 658.5853
Epoch 00004: val_loss did not improve
Epoch 6/300
6s - loss: 182.3205 - val_loss: 641.8703
Epoch 00005: val_loss improved from 644.49826 to 641.87032, saving model to rlstm13_weights.hdf5
Epoch 7/300
6s - loss: 176.6831 - val_loss: 653.4057
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 172.2819 - val_loss: 646.8227
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.5466 - val_loss: 677.4656
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 164.7466 - val_loss: 677.6195
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 161.3535 - val_loss: 724.5024
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 158.3080 - val_loss: 708.5885
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 155.8355 - val_loss: 704.5088
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 153.5683 - val_loss: 679.8205
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 151.4971 - val_loss: 679.3032
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 149.6901 - val_loss: 671.0656
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 148.0721 - val_loss: 673.6882
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 146.6305 - val_loss: 685.6797
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 145.1343 - val_loss: 662.4096
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 143.8849 - val_loss: 653.7674
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 142.6721 - val_loss: 675.4355
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 141.6423 - val_loss: 667.1860
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 140.5892 - val_loss: 678.1194
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 139.6455 - val_loss: 653.3048
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 138.7056 - val_loss: 658.9295
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 137.8538 - val_loss: 702.5924
Epoch 00025: val_loss did not improve
Epoch 27/300
6s - loss: 136.9720 - val_loss: 709.6938
Epoch 00026: val_loss did not improve
training rlstm14 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 365.7811 - val_loss: 1223.1421
Epoch 00000: val_loss improved from inf to 1223.14210, saving model to rlstm14_weights.hdf5
Epoch 2/300
6s - loss: 244.1395 - val_loss: 1130.5512
Epoch 00001: val_loss improved from 1223.14210 to 1130.55115, saving model to rlstm14_weights.hdf5
Epoch 3/300
6s - loss: 220.3252 - val_loss: 784.9740
Epoch 00002: val_loss improved from 1130.55115 to 784.97405, saving model to rlstm14_weights.hdf5
Epoch 4/300
6s - loss: 200.2223 - val_loss: 638.0915
Epoch 00003: val_loss improved from 784.97405 to 638.09152, saving model to rlstm14_weights.hdf5
Epoch 5/300
6s - loss: 189.9799 - val_loss: 612.8515
Epoch 00004: val_loss improved from 638.09152 to 612.85149, saving model to rlstm14_weights.hdf5
Epoch 6/300
6s - loss: 183.0670 - val_loss: 636.5919
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 177.4020 - val_loss: 649.6456
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 172.9007 - val_loss: 659.4491
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.3773 - val_loss: 689.2598
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 163.8817 - val_loss: 742.4496
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 159.9889 - val_loss: 725.2965
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 156.8832 - val_loss: 682.5196
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 154.3102 - val_loss: 674.2705
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 152.1157 - val_loss: 685.2829
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 150.2586 - val_loss: 671.9198
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 148.5709 - val_loss: 680.8344
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 147.0999 - val_loss: 679.6265
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 145.7672 - val_loss: 674.0452
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 144.6626 - val_loss: 674.9801
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 143.4320 - val_loss: 682.2705
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 142.4419 - val_loss: 683.2180
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 141.4823 - val_loss: 687.8735
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 140.5140 - val_loss: 681.7596
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 139.6245 - val_loss: 685.1776
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 138.8556 - val_loss: 676.1708
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 137.9774 - val_loss: 677.4898
Epoch 00025: val_loss did not improve
training rlstm15 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 369.3577 - val_loss: 1129.6276
Epoch 00000: val_loss improved from inf to 1129.62760, saving model to rlstm15_weights.hdf5
Epoch 2/300
6s - loss: 243.9850 - val_loss: 1160.5822
Epoch 00001: val_loss did not improve
Epoch 3/300
6s - loss: 218.6298 - val_loss: 731.8973
Epoch 00002: val_loss improved from 1129.62760 to 731.89730, saving model to rlstm15_weights.hdf5
Epoch 4/300
6s - loss: 198.2809 - val_loss: 648.1626
Epoch 00003: val_loss improved from 731.89730 to 648.16259, saving model to rlstm15_weights.hdf5
Epoch 5/300
6s - loss: 188.6000 - val_loss: 630.0766
Epoch 00004: val_loss improved from 648.16259 to 630.07656, saving model to rlstm15_weights.hdf5
Epoch 6/300
6s - loss: 181.6193 - val_loss: 629.9010
Epoch 00005: val_loss improved from 630.07656 to 629.90097, saving model to rlstm15_weights.hdf5
Epoch 7/300
6s - loss: 176.2461 - val_loss: 648.0210
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 171.9438 - val_loss: 651.2021
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.2616 - val_loss: 655.5806
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 164.4145 - val_loss: 699.4208
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 160.6628 - val_loss: 708.2773
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 157.2585 - val_loss: 725.4041
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 154.3966 - val_loss: 713.5306
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 152.0290 - val_loss: 730.9736
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 150.0661 - val_loss: 723.3033
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 148.3131 - val_loss: 720.3432
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 146.8719 - val_loss: 694.3418
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 145.4974 - val_loss: 693.8000
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 144.2060 - val_loss: 705.8449
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 143.1385 - val_loss: 700.4972
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 141.8928 - val_loss: 687.0813
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 140.7588 - val_loss: 707.8906
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 139.8800 - val_loss: 712.2618
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 139.0662 - val_loss: 689.1498
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 138.1386 - val_loss: 699.3315
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 137.2377 - val_loss: 695.2210
Epoch 00025: val_loss did not improve
Epoch 27/300
6s - loss: 136.5108 - val_loss: 687.6572
Epoch 00026: val_loss did not improve
training rlstm16 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 367.9447 - val_loss: 1135.0014
Epoch 00000: val_loss improved from inf to 1135.00140, saving model to rlstm16_weights.hdf5
Epoch 2/300
6s - loss: 243.8224 - val_loss: 1153.2726
Epoch 00001: val_loss did not improve
Epoch 3/300
6s - loss: 219.1146 - val_loss: 829.6050
Epoch 00002: val_loss improved from 1135.00140 to 829.60502, saving model to rlstm16_weights.hdf5
Epoch 4/300
6s - loss: 200.5589 - val_loss: 649.3013
Epoch 00003: val_loss improved from 829.60502 to 649.30127, saving model to rlstm16_weights.hdf5
Epoch 5/300
6s - loss: 189.7910 - val_loss: 633.3514
Epoch 00004: val_loss improved from 649.30127 to 633.35136, saving model to rlstm16_weights.hdf5
Epoch 6/300
6s - loss: 181.7245 - val_loss: 661.5198
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 174.2114 - val_loss: 659.2318
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 168.3471 - val_loss: 667.8166
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 164.1063 - val_loss: 677.8667
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 160.7738 - val_loss: 664.1515
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 158.1170 - val_loss: 668.0344
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 155.8340 - val_loss: 648.0342
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 153.5778 - val_loss: 666.9624
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 151.7461 - val_loss: 655.9952
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 150.1200 - val_loss: 672.0959
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 148.5655 - val_loss: 669.6260
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 147.1288 - val_loss: 658.2578
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 145.8816 - val_loss: 644.3606
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 144.5663 - val_loss: 656.5405
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 143.4185 - val_loss: 658.4427
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 142.3286 - val_loss: 658.7536
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 141.1984 - val_loss: 649.9393
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 140.1701 - val_loss: 652.3083
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 139.2504 - val_loss: 669.6768
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 138.2911 - val_loss: 655.2963
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 137.4314 - val_loss: 684.7461
Epoch 00025: val_loss did not improve
training rlstm17 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 366.7152 - val_loss: 1149.6902
Epoch 00000: val_loss improved from inf to 1149.69015, saving model to rlstm17_weights.hdf5
Epoch 2/300
6s - loss: 243.9831 - val_loss: 1111.3256
Epoch 00001: val_loss improved from 1149.69015 to 1111.32560, saving model to rlstm17_weights.hdf5
Epoch 3/300
6s - loss: 217.6270 - val_loss: 720.3482
Epoch 00002: val_loss improved from 1111.32560 to 720.34815, saving model to rlstm17_weights.hdf5
Epoch 4/300
6s - loss: 197.2185 - val_loss: 634.8488
Epoch 00003: val_loss improved from 720.34815 to 634.84876, saving model to rlstm17_weights.hdf5
Epoch 5/300
6s - loss: 188.0985 - val_loss: 622.0513
Epoch 00004: val_loss improved from 634.84876 to 622.05131, saving model to rlstm17_weights.hdf5
Epoch 6/300
6s - loss: 181.1163 - val_loss: 639.0578
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 176.0264 - val_loss: 661.8279
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 172.0683 - val_loss: 644.9831
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.5002 - val_loss: 656.3267
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 164.8238 - val_loss: 684.9887
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 161.3463 - val_loss: 664.5207
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 158.4462 - val_loss: 674.4849
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 156.1314 - val_loss: 680.4511
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 153.9831 - val_loss: 681.9422
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 152.1927 - val_loss: 670.5495
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 150.3923 - val_loss: 656.0285
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 148.7347 - val_loss: 678.3248
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 147.2967 - val_loss: 667.3129
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 145.7736 - val_loss: 679.1937
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 144.4389 - val_loss: 661.4787
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 143.3051 - val_loss: 673.0504
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 142.0727 - val_loss: 664.4725
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 141.1231 - val_loss: 652.4641
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 140.0252 - val_loss: 660.7360
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 139.1156 - val_loss: 673.1831
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 138.1855 - val_loss: 658.9228
Epoch 00025: val_loss did not improve
training rlstm18 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 367.2517 - val_loss: 1140.2306
Epoch 00000: val_loss improved from inf to 1140.23059, saving model to rlstm18_weights.hdf5
Epoch 2/300
6s - loss: 243.6762 - val_loss: 1128.5759
Epoch 00001: val_loss improved from 1140.23059 to 1128.57590, saving model to rlstm18_weights.hdf5
Epoch 3/300
6s - loss: 219.2449 - val_loss: 788.9951
Epoch 00002: val_loss improved from 1128.57590 to 788.99508, saving model to rlstm18_weights.hdf5
Epoch 4/300
6s - loss: 199.3039 - val_loss: 634.3780
Epoch 00003: val_loss improved from 788.99508 to 634.37800, saving model to rlstm18_weights.hdf5
Epoch 5/300
6s - loss: 187.8193 - val_loss: 635.3298
Epoch 00004: val_loss did not improve
Epoch 6/300
6s - loss: 180.1560 - val_loss: 650.8835
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 174.9239 - val_loss: 665.7649
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 170.6647 - val_loss: 680.1935
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 166.4317 - val_loss: 711.3617
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 162.5795 - val_loss: 703.5517
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 159.2750 - val_loss: 710.3565
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 156.4673 - val_loss: 685.7515
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 153.9052 - val_loss: 683.8078
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 151.7231 - val_loss: 681.4918
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 149.8128 - val_loss: 693.0395
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 148.1729 - val_loss: 654.1394
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 146.6587 - val_loss: 651.8717
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 145.3155 - val_loss: 650.3710
Epoch 00017: val_loss did not improve
Epoch 19/300
6s - loss: 144.0048 - val_loss: 652.2834
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 142.8912 - val_loss: 655.9858
Epoch 00019: val_loss did not improve
Epoch 21/300
6s - loss: 141.7827 - val_loss: 657.4189
Epoch 00020: val_loss did not improve
Epoch 22/300
6s - loss: 140.8218 - val_loss: 662.7324
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 139.9712 - val_loss: 660.6216
Epoch 00022: val_loss did not improve
Epoch 24/300
6s - loss: 139.0934 - val_loss: 644.9103
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 138.1862 - val_loss: 661.7570
Epoch 00024: val_loss did not improve
training rlstm19 batch_size = 256
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.9577034200413}
Epoch 1/300
6s - loss: 366.1511 - val_loss: 1164.5668
Epoch 00000: val_loss improved from inf to 1164.56678, saving model to rlstm19_weights.hdf5
Epoch 2/300
6s - loss: 244.3641 - val_loss: 1136.6731
Epoch 00001: val_loss improved from 1164.56678 to 1136.67307, saving model to rlstm19_weights.hdf5
Epoch 3/300
6s - loss: 219.7989 - val_loss: 753.0801
Epoch 00002: val_loss improved from 1136.67307 to 753.08009, saving model to rlstm19_weights.hdf5
Epoch 4/300
6s - loss: 199.0575 - val_loss: 626.9876
Epoch 00003: val_loss improved from 753.08009 to 626.98756, saving model to rlstm19_weights.hdf5
Epoch 5/300
6s - loss: 189.0930 - val_loss: 615.4081
Epoch 00004: val_loss improved from 626.98756 to 615.40812, saving model to rlstm19_weights.hdf5
Epoch 6/300
6s - loss: 182.1432 - val_loss: 630.5243
Epoch 00005: val_loss did not improve
Epoch 7/300
6s - loss: 176.7039 - val_loss: 630.9398
Epoch 00006: val_loss did not improve
Epoch 8/300
6s - loss: 172.2282 - val_loss: 643.1059
Epoch 00007: val_loss did not improve
Epoch 9/300
6s - loss: 168.3929 - val_loss: 654.4588
Epoch 00008: val_loss did not improve
Epoch 10/300
6s - loss: 164.6185 - val_loss: 706.7791
Epoch 00009: val_loss did not improve
Epoch 11/300
6s - loss: 160.8649 - val_loss: 682.9901
Epoch 00010: val_loss did not improve
Epoch 12/300
6s - loss: 157.3452 - val_loss: 683.6415
Epoch 00011: val_loss did not improve
Epoch 13/300
6s - loss: 154.3965 - val_loss: 678.2694
Epoch 00012: val_loss did not improve
Epoch 14/300
6s - loss: 152.1142 - val_loss: 645.2446
Epoch 00013: val_loss did not improve
Epoch 15/300
6s - loss: 150.1891 - val_loss: 634.8093
Epoch 00014: val_loss did not improve
Epoch 16/300
6s - loss: 148.5739 - val_loss: 627.4337
Epoch 00015: val_loss did not improve
Epoch 17/300
6s - loss: 146.8619 - val_loss: 616.4406
Epoch 00016: val_loss did not improve
Epoch 18/300
6s - loss: 145.2332 - val_loss: 612.3660
Epoch 00017: val_loss improved from 615.40812 to 612.36597, saving model to rlstm19_weights.hdf5
Epoch 19/300
6s - loss: 143.8470 - val_loss: 616.6818
Epoch 00018: val_loss did not improve
Epoch 20/300
6s - loss: 142.3811 - val_loss: 611.4321
Epoch 00019: val_loss improved from 612.36597 to 611.43213, saving model to rlstm19_weights.hdf5
Epoch 21/300
6s - loss: 141.1286 - val_loss: 600.1176
Epoch 00020: val_loss improved from 611.43213 to 600.11755, saving model to rlstm19_weights.hdf5
Epoch 22/300
6s - loss: 139.8986 - val_loss: 608.8987
Epoch 00021: val_loss did not improve
Epoch 23/300
6s - loss: 138.6324 - val_loss: 599.6750
Epoch 00022: val_loss improved from 600.11755 to 599.67499, saving model to rlstm19_weights.hdf5
Epoch 24/300
6s - loss: 137.5851 - val_loss: 612.5147
Epoch 00023: val_loss did not improve
Epoch 25/300
6s - loss: 136.5123 - val_loss: 608.3233
Epoch 00024: val_loss did not improve
Epoch 26/300
6s - loss: 135.5902 - val_loss: 595.8625
Epoch 00025: val_loss improved from 599.67499 to 595.86248, saving model to rlstm19_weights.hdf5
Epoch 27/300
6s - loss: 134.6012 - val_loss: 606.0831
Epoch 00026: val_loss did not improve
Epoch 28/300
6s - loss: 133.7215 - val_loss: 608.7949
Epoch 00027: val_loss did not improve
Epoch 29/300
6s - loss: 132.8942 - val_loss: 625.3787
Epoch 00028: val_loss did not improve
Epoch 30/300
6s - loss: 132.0926 - val_loss: 605.0090
Epoch 00029: val_loss did not improve
Epoch 31/300
6s - loss: 131.3953 - val_loss: 600.3959
Epoch 00030: val_loss did not improve
Epoch 32/300
6s - loss: 130.6977 - val_loss: 609.6434
Epoch 00031: val_loss did not improve
Epoch 33/300
6s - loss: 130.0924 - val_loss: 596.5156
Epoch 00032: val_loss did not improve
Epoch 34/300
6s - loss: 129.4213 - val_loss: 665.7089
Epoch 00033: val_loss did not improve
Epoch 35/300
6s - loss: 128.8663 - val_loss: 589.3248
Epoch 00034: val_loss improved from 595.86248 to 589.32482, saving model to rlstm19_weights.hdf5
Epoch 36/300
6s - loss: 128.3474 - val_loss: 622.7434
Epoch 00035: val_loss did not improve
Epoch 37/300
6s - loss: 127.7417 - val_loss: 624.4299
Epoch 00036: val_loss did not improve
Epoch 38/300
6s - loss: 127.2195 - val_loss: 642.3739
Epoch 00037: val_loss did not improve
Epoch 39/300
6s - loss: 126.7860 - val_loss: 607.6736
Epoch 00038: val_loss did not improve
Epoch 40/300
6s - loss: 126.2011 - val_loss: 586.1297
Epoch 00039: val_loss improved from 589.32482 to 586.12971, saving model to rlstm19_weights.hdf5
Epoch 41/300
6s - loss: 125.7275 - val_loss: 619.4647
Epoch 00040: val_loss did not improve
Epoch 42/300
6s - loss: 125.2682 - val_loss: 617.0501
Epoch 00041: val_loss did not improve
Epoch 43/300
6s - loss: 124.7680 - val_loss: 602.3325
Epoch 00042: val_loss did not improve
Epoch 44/300
6s - loss: 124.4658 - val_loss: 597.4736
Epoch 00043: val_loss did not improve
Epoch 45/300
6s - loss: 124.0735 - val_loss: 599.8757
Epoch 00044: val_loss did not improve
Epoch 46/300
6s - loss: 123.5988 - val_loss: 610.1303
Epoch 00045: val_loss did not improve
Epoch 47/300
6s - loss: 123.2392 - val_loss: 597.8892
Epoch 00046: val_loss did not improve
Epoch 48/300
6s - loss: 122.8008 - val_loss: 601.7345
Epoch 00047: val_loss did not improve
Epoch 49/300
6s - loss: 122.3906 - val_loss: 622.5818
Epoch 00048: val_loss did not improve
Epoch 50/300
6s - loss: 122.0486 - val_loss: 627.1765
Epoch 00049: val_loss did not improve
Epoch 51/300
6s - loss: 121.7037 - val_loss: 597.5422
Epoch 00050: val_loss did not improve
Epoch 52/300
6s - loss: 121.2678 - val_loss: 593.1569
Epoch 00051: val_loss did not improve
Epoch 53/300
6s - loss: 120.9745 - val_loss: 605.0210
Epoch 00052: val_loss did not improve
Epoch 54/300
6s - loss: 120.6496 - val_loss: 610.1225
Epoch 00053: val_loss did not improve
Epoch 55/300
6s - loss: 120.3581 - val_loss: 605.0322
Epoch 00054: val_loss did not improve
Epoch 56/300
6s - loss: 119.9946 - val_loss: 614.2913
Epoch 00055: val_loss did not improve
Epoch 57/300
6s - loss: 119.5982 - val_loss: 619.1313
Epoch 00056: val_loss did not improve
Epoch 58/300
6s - loss: 119.2835 - val_loss: 579.9044
Epoch 00057: val_loss improved from 586.12971 to 579.90445, saving model to rlstm19_weights.hdf5
Epoch 59/300
6s - loss: 119.0777 - val_loss: 608.0766
Epoch 00058: val_loss did not improve
Epoch 60/300
6s - loss: 118.7447 - val_loss: 593.4603
Epoch 00059: val_loss did not improve
Epoch 61/300
6s - loss: 118.4024 - val_loss: 591.2528
Epoch 00060: val_loss did not improve
Epoch 62/300
6s - loss: 118.2310 - val_loss: 591.7433
Epoch 00061: val_loss did not improve
Epoch 63/300
6s - loss: 118.0101 - val_loss: 589.1368
Epoch 00062: val_loss did not improve
Epoch 64/300
6s - loss: 117.6752 - val_loss: 584.5913
Epoch 00063: val_loss did not improve
Epoch 65/300
6s - loss: 117.4573 - val_loss: 596.2907
Epoch 00064: val_loss did not improve
Epoch 66/300
6s - loss: 117.1393 - val_loss: 569.9007
Epoch 00065: val_loss improved from 579.90445 to 569.90072, saving model to rlstm19_weights.hdf5
Epoch 67/300
6s - loss: 116.9092 - val_loss: 584.6932
Epoch 00066: val_loss did not improve
Epoch 68/300
6s - loss: 116.6826 - val_loss: 580.6251
Epoch 00067: val_loss did not improve
Epoch 69/300
6s - loss: 116.5349 - val_loss: 584.0742
Epoch 00068: val_loss did not improve
Epoch 70/300
6s - loss: 116.2696 - val_loss: 605.8905
Epoch 00069: val_loss did not improve
Epoch 71/300
6s - loss: 116.0306 - val_loss: 580.9769
Epoch 00070: val_loss did not improve
Epoch 72/300
6s - loss: 115.8502 - val_loss: 625.6417
Epoch 00071: val_loss did not improve
Epoch 73/300
6s - loss: 115.6634 - val_loss: 567.8460
Epoch 00072: val_loss improved from 569.90072 to 567.84603, saving model to rlstm19_weights.hdf5
Epoch 74/300
6s - loss: 115.3976 - val_loss: 599.2063
Epoch 00073: val_loss did not improve
Epoch 75/300
6s - loss: 115.2999 - val_loss: 594.6538
Epoch 00074: val_loss did not improve
Epoch 76/300
6s - loss: 115.0917 - val_loss: 587.2932
Epoch 00075: val_loss did not improve
Epoch 77/300
6s - loss: 114.7763 - val_loss: 592.4329
Epoch 00076: val_loss did not improve
Epoch 78/300
6s - loss: 114.5935 - val_loss: 593.6418
Epoch 00077: val_loss did not improve
Epoch 79/300
6s - loss: 114.3832 - val_loss: 579.3100
Epoch 00078: val_loss did not improve
Epoch 80/300
6s - loss: 114.2346 - val_loss: 575.6421
Epoch 00079: val_loss did not improve
Epoch 81/300
6s - loss: 114.0633 - val_loss: 577.9933
Epoch 00080: val_loss did not improve
Epoch 82/300
6s - loss: 113.8918 - val_loss: 570.4756
Epoch 00081: val_loss did not improve
Epoch 83/300
6s - loss: 113.6409 - val_loss: 575.9246
Epoch 00082: val_loss did not improve
Epoch 84/300
6s - loss: 113.4678 - val_loss: 584.1024
Epoch 00083: val_loss did not improve
Epoch 85/300
6s - loss: 113.3557 - val_loss: 571.9588
Epoch 00084: val_loss did not improve
Epoch 86/300
6s - loss: 113.0905 - val_loss: 556.8035
Epoch 00085: val_loss improved from 567.84603 to 556.80354, saving model to rlstm19_weights.hdf5
Epoch 87/300
6s - loss: 112.9519 - val_loss: 563.1241
Epoch 00086: val_loss did not improve
Epoch 88/300
6s - loss: 112.7752 - val_loss: 585.4360
Epoch 00087: val_loss did not improve
Epoch 89/300
6s - loss: 112.6856 - val_loss: 589.0402
Epoch 00088: val_loss did not improve
Epoch 90/300
6s - loss: 112.4645 - val_loss: 576.5131
Epoch 00089: val_loss did not improve
Epoch 91/300
6s - loss: 112.3523 - val_loss: 581.8823
Epoch 00090: val_loss did not improve
Epoch 92/300
6s - loss: 112.0908 - val_loss: 562.2232
Epoch 00091: val_loss did not improve
Epoch 93/300
6s - loss: 111.9249 - val_loss: 581.4315
Epoch 00092: val_loss did not improve
Epoch 94/300
6s - loss: 111.8579 - val_loss: 573.3946
Epoch 00093: val_loss did not improve
Epoch 95/300
6s - loss: 111.7354 - val_loss: 590.0313
Epoch 00094: val_loss did not improve
Epoch 96/300
6s - loss: 111.6023 - val_loss: 572.3387
Epoch 00095: val_loss did not improve
Epoch 97/300
6s - loss: 111.4751 - val_loss: 551.0492
Epoch 00096: val_loss improved from 556.80354 to 551.04918, saving model to rlstm19_weights.hdf5
Epoch 98/300
6s - loss: 111.2432 - val_loss: 572.9723
Epoch 00097: val_loss did not improve
Epoch 99/300
6s - loss: 111.0761 - val_loss: 565.4951
Epoch 00098: val_loss did not improve
Epoch 100/300
6s - loss: 110.9308 - val_loss: 592.7131
Epoch 00099: val_loss did not improve
Epoch 101/300
6s - loss: 110.8728 - val_loss: 571.8289
Epoch 00100: val_loss did not improve
Epoch 102/300
6s - loss: 110.6271 - val_loss: 578.4204
Epoch 00101: val_loss did not improve
Epoch 103/300
6s - loss: 110.6194 - val_loss: 573.5900
Epoch 00102: val_loss did not improve
Epoch 104/300
6s - loss: 110.4826 - val_loss: 565.4898
Epoch 00103: val_loss did not improve
Epoch 105/300
6s - loss: 110.3275 - val_loss: 574.1357
Epoch 00104: val_loss did not improve
Epoch 106/300
6s - loss: 110.1959 - val_loss: 576.9599
Epoch 00105: val_loss did not improve
Epoch 107/300
6s - loss: 110.0983 - val_loss: 591.2585
Epoch 00106: val_loss did not improve
Epoch 108/300
6s - loss: 109.8990 - val_loss: 580.3102
Epoch 00107: val_loss did not improve
Epoch 109/300
6s - loss: 109.7655 - val_loss: 577.3168
Epoch 00108: val_loss did not improve
Epoch 110/300
6s - loss: 109.6184 - val_loss: 567.0636
Epoch 00109: val_loss did not improve
Epoch 111/300
6s - loss: 109.4562 - val_loss: 581.8634
Epoch 00110: val_loss did not improve
Epoch 112/300
6s - loss: 109.4267 - val_loss: 569.0524
Epoch 00111: val_loss did not improve
Epoch 113/300
6s - loss: 109.2589 - val_loss: 564.6777
Epoch 00112: val_loss did not improve
Epoch 114/300
6s - loss: 109.0966 - val_loss: 580.6576
Epoch 00113: val_loss did not improve
Epoch 115/300
6s - loss: 109.0566 - val_loss: 558.0579
Epoch 00114: val_loss did not improve
Epoch 116/300
6s - loss: 108.8902 - val_loss: 580.8357
Epoch 00115: val_loss did not improve
Epoch 117/300
6s - loss: 108.7658 - val_loss: 581.1539
Epoch 00116: val_loss did not improve
Epoch 118/300
6s - loss: 108.6044 - val_loss: 583.0390
Epoch 00117: val_loss did not improve
