X_train[0].shape = (5742, 40, 23)

training nanjing0
Train on 5742 samples, validate on 1530 samples
Before training:
            nanjing0 3706.7746      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.12001 nan 3.12001
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            nanjing012639.5874      0.03  -nan  0.03      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.04997 nan 6.04997
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2245.0440 - val_loss: 4455.4786
Epoch 00000: val_loss improved from inf to 4455.47859, saving model to nanjing0_weights.hdf5
            nanjing0 1004.9233      0.32  0.43  0.26      0.32  0.42  0.26      0.32  0.39  0.27
            nanjing0 4455.4786      0.61  0.07  0.58      0.61  0.03  0.60      0.60  0.04  0.59
forget mean min: 0.93132 0.81201
incx.max(), incx.min(), incx.mean() 6.83433 0.482531 2.5352
fgtx.max(), fgtx.min(), fgtx.mean() 6.42142 0.372394 2.32722
abs_mean, abs_mean+, abs_mean-: 5.22495 3.40386 6.65078
U_c = [[-0.12346558]] U_f = [[ 0.]] b_c = [ 0.09150358] b_f = [ 1.09073067]
W_c max, min, mean, abs_mean: 0.120763 0.118896 0.120223 0.120223
W_f max, min, mean, abs_mean: 0.114663 0.11431 0.114495 0.114495
Epoch 2/300
1s - loss: 880.9804 - val_loss: 3161.1817
Epoch 00001: val_loss improved from 4455.47859 to 3161.18173, saving model to nanjing0_weights.hdf5
            nanjing0  821.5367      0.50  0.41  0.37      0.52  0.41  0.38      0.53  0.37  0.41
            nanjing0 3161.1817      0.88  0.15  0.77      0.89  0.11  0.80      0.90  0.11  0.81
forget mean min: 0.964272 0.851093
incx.max(), incx.min(), incx.mean() 8.58257 0.781382 3.63132
fgtx.max(), fgtx.min(), fgtx.mean() 8.06343 0.644835 3.355
abs_mean, abs_mean+, abs_mean-: 4.64921 4.30116 5.1917
U_c = [[-0.12256639]] U_f = [[ 0.]] b_c = [ 0.10330038] b_f = [ 1.09836125]
W_c max, min, mean, abs_mean: 0.142214 0.140304 0.141573 0.141573
W_f max, min, mean, abs_mean: 0.134925 0.134255 0.134632 0.134632
Epoch 3/300
1s - loss: 794.3969 - val_loss: 3058.6908
Epoch 00002: val_loss improved from 3161.18173 to 3058.69084, saving model to nanjing0_weights.hdf5
            nanjing0  769.1698      0.53  0.36  0.41      0.55  0.36  0.42      0.56  0.32  0.44
            nanjing0 3058.6908      0.90  0.15  0.77      0.90  0.12  0.80      0.90  0.11  0.81
forget mean min: 0.959385 0.811262
incx.max(), incx.min(), incx.mean() 8.69174 0.58936 3.87823
fgtx.max(), fgtx.min(), fgtx.mean() 7.12902 0.40762 3.13593
abs_mean, abs_mean+, abs_mean-: 4.80321 4.28909 5.63394
U_c = [[-0.10470588]] U_f = [[ 0.]] b_c = [ 0.09799477] b_f = [ 1.05060852]
W_c max, min, mean, abs_mean: 0.156747 0.154621 0.155975 0.155975
W_f max, min, mean, abs_mean: 0.129887 0.128692 0.129392 0.129392
Epoch 4/300
1s - loss: 756.4136 - val_loss: 3159.0528
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 723.8198 - val_loss: 3378.0987
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 695.7993 - val_loss: 3504.1590
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 674.1183 - val_loss: 3628.7202
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 654.5519 - val_loss: 3826.0593
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 640.0736 - val_loss: 3835.6049
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 626.3352 - val_loss: 3957.5979
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 616.0909 - val_loss: 4035.8871
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 605.7659 - val_loss: 4090.9463
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 595.1349 - val_loss: 4197.2434
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 585.0597 - val_loss: 4319.6394
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 575.9456 - val_loss: 4402.3811
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 567.4105 - val_loss: 4550.1160
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 558.8902 - val_loss: 4619.2561
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 548.9603 - val_loss: 4794.6370
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 543.5156 - val_loss: 4907.8009
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 535.7292 - val_loss: 5022.5232
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 529.4432 - val_loss: 5058.6330
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 523.3744 - val_loss: 5198.7613
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 517.2788 - val_loss: 4996.6303
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 511.1111 - val_loss: 5320.7888
Epoch 00023: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training shanghai0
Train on 5742 samples, validate on 1530 samples
Before training:
           shanghai0 3205.9772      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.00962 nan 3.00962
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           shanghai0 8940.5991      0.03  -nan  0.03      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.20786 nan 5.20786
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1906.7689 - val_loss: 2998.8131
Epoch 00000: val_loss improved from inf to 2998.81308, saving model to shanghai0_weights.hdf5
           shanghai0  879.2605      0.17  0.56  0.14      0.18  0.58  0.14      0.17  0.62  0.14
           shanghai0 2998.8131      0.56  0.33  0.44      0.56  0.32  0.45      0.55  0.29  0.45
forget mean min: 0.948873 0.802615
incx.max(), incx.min(), incx.mean() 5.84744 0.427645 2.52013
fgtx.max(), fgtx.min(), fgtx.mean() 5.40635 0.317057 2.28195
abs_mean, abs_mean+, abs_mean-: 3.101 2.32705 3.70806
U_c = [[-0.12181096]] U_f = [[ 0.]] b_c = [ 0.09001703] b_f = [ 1.08566463]
W_c max, min, mean, abs_mean: 0.119627 0.115345 0.118513 0.118513
W_f max, min, mean, abs_mean: 0.11193 0.108602 0.111292 0.111292
Epoch 2/300
1s - loss: 768.3872 - val_loss: 2200.6365
Epoch 00001: val_loss improved from 2998.81308 to 2200.63648, saving model to shanghai0_weights.hdf5
           shanghai0  683.6314      0.54  0.36  0.41      0.58  0.34  0.45      0.60  0.31  0.47
           shanghai0 2200.6365      0.78  0.30  0.58      0.77  0.29  0.59      0.74  0.27  0.58
forget mean min: 0.932428 0.777487
incx.max(), incx.min(), incx.mean() 9.8689 0.508819 4.34854
fgtx.max(), fgtx.min(), fgtx.mean() 4.74694 0.185441 2.05668
abs_mean, abs_mean+, abs_mean-: 4.80731 4.08208 5.68561
U_c = [[-0.11270972]] U_f = [[ 0.]] b_c = [ 0.12829661] b_f = [ 1.06564188]
W_c max, min, mean, abs_mean: 0.175903 0.171651 0.174835 0.174835
W_f max, min, mean, abs_mean: 0.0858827 0.0825695 0.0852043 0.0852043
Epoch 3/300
1s - loss: 647.0588 - val_loss: 2160.6200
Epoch 00002: val_loss improved from 2200.63648 to 2160.62003, saving model to shanghai0_weights.hdf5
           shanghai0  616.2796      0.52  0.34  0.41      0.57  0.29  0.46      0.62  0.24  0.52
           shanghai0 2160.6200      0.72  0.26  0.57      0.69  0.26  0.56      0.69  0.23  0.58
forget mean min: 0.908802 0.762444
incx.max(), incx.min(), incx.mean() 13.621 0.608005 5.6773
fgtx.max(), fgtx.min(), fgtx.mean() 3.80178 0.128194 1.55926
abs_mean, abs_mean+, abs_mean-: 5.52751 5.13208 5.87825
U_c = [[-0.09114492]] U_f = [[ 0.]] b_c = [ 0.15387303] b_f = [ 1.0379349]
W_c max, min, mean, abs_mean: 0.217132 0.212838 0.216108 0.216108
W_f max, min, mean, abs_mean: 0.0617439 0.0583333 0.0610068 0.0610068
Epoch 4/300
1s - loss: 603.8259 - val_loss: 2237.3719
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 577.0114 - val_loss: 2323.5512
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 556.5651 - val_loss: 2265.5852
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 539.4649 - val_loss: 2268.3342
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 524.9610 - val_loss: 2244.0283
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 514.5085 - val_loss: 2205.9995
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 504.4543 - val_loss: 2452.0928
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 496.6414 - val_loss: 2423.3600
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 485.9802 - val_loss: 2398.2439
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 477.9458 - val_loss: 2272.6046
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 468.9231 - val_loss: 2452.9061
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 460.7732 - val_loss: 2559.4037
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 453.7817 - val_loss: 2475.6132
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 445.5026 - val_loss: 2359.0438
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 439.0519 - val_loss: 2432.1032
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 432.7181 - val_loss: 2241.0195
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 426.1577 - val_loss: 2256.2470
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 419.8778 - val_loss: 2471.5509
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 415.5288 - val_loss: 2489.9289
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 409.4678 - val_loss: 2318.0755
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 406.2763 - val_loss: 2425.5501
Epoch 00023: val_loss did not improve
X_train[0].shape = (7018, 40, 23)

training hangzhou0
Train on 7018 samples, validate on 1870 samples
Before training:
           hangzhou0 3103.7821      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.08453 nan 3.08453
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           hangzhou010573.7763      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.56585 nan 5.56585
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1603.9510 - val_loss: 3154.7630
Epoch 00000: val_loss improved from inf to 3154.76298, saving model to hangzhou0_weights.hdf5
           hangzhou0  733.6023      0.33  0.32  0.29      0.39  0.27  0.33      0.42  0.22  0.37
           hangzhou0 3154.7630      0.68  0.21  0.57      0.69  0.17  0.61      0.70  0.15  0.63
forget mean min: 0.946333 0.794878
incx.max(), incx.min(), incx.mean() 5.88177 0.373414 2.55459
fgtx.max(), fgtx.min(), fgtx.mean() 5.4563 0.261521 2.31853
abs_mean, abs_mean+, abs_mean-: 3.43235 2.91592 3.77807
U_c = [[-0.13364232]] U_f = [[ 0.]] b_c = [ 0.09612073] b_f = [ 1.09306014]
W_c max, min, mean, abs_mean: 0.123933 0.120828 0.123467 0.123467
W_f max, min, mean, abs_mean: 0.11674 0.115552 0.116443 0.116443
Epoch 2/300
1s - loss: 679.5338 - val_loss: 2978.6226
Epoch 00001: val_loss improved from 3154.76298 to 2978.62260, saving model to hangzhou0_weights.hdf5
           hangzhou0  647.9794      0.39  0.33  0.33      0.45  0.29  0.38      0.49  0.24  0.42
           hangzhou0 2978.6226      0.76  0.21  0.63      0.78  0.17  0.67      0.80  0.13  0.72
forget mean min: 0.946733 0.787064
incx.max(), incx.min(), incx.mean() 6.97749 0.442238 3.24767
fgtx.max(), fgtx.min(), fgtx.mean() 4.74519 0.233998 2.17055
abs_mean, abs_mean+, abs_mean-: 3.44172 2.61513 4.287
U_c = [[-0.11681648]] U_f = [[ 0.]] b_c = [ 0.10326303] b_f = [ 1.07332146]
W_c max, min, mean, abs_mean: 0.157786 0.154529 0.157289 0.157289
W_f max, min, mean, abs_mean: 0.109298 0.107523 0.108577 0.108577
Epoch 3/300
1s - loss: 632.0185 - val_loss: 3174.1587
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 602.6577 - val_loss: 3299.0952
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 583.3761 - val_loss: 3454.0863
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 570.6530 - val_loss: 3420.6814
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 559.5732 - val_loss: 3554.2556
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 547.9438 - val_loss: 3740.4821
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 536.4695 - val_loss: 3772.3766
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 526.5065 - val_loss: 3707.1464
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 516.4964 - val_loss: 3957.5265
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 506.8845 - val_loss: 3973.5725
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 498.2417 - val_loss: 4028.6377
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 491.3484 - val_loss: 4097.0993
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 484.2207 - val_loss: 3941.3278
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 477.3993 - val_loss: 4084.1363
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 472.6617 - val_loss: 4106.3583
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 467.4802 - val_loss: 4141.9243
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 463.3200 - val_loss: 4104.6034
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 459.6194 - val_loss: 4033.9877
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 455.2775 - val_loss: 4101.0113
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 450.5572 - val_loss: 4206.3355
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 446.0566 - val_loss: 4067.9550
Epoch 00022: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training hefei0
Train on 5742 samples, validate on 1530 samples
Before training:
              hefei0 5877.2156      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.89839 nan 3.89839
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              hefei013884.8565      0.03  -nan  0.03      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.94627 nan 6.94627
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3728.9338 - val_loss: 4169.0789
Epoch 00000: val_loss improved from inf to 4169.07888, saving model to hefei0_weights.hdf5
              hefei0 1749.2817      0.38  0.44  0.29      0.42  0.40  0.33      0.43  0.36  0.35
              hefei0 4169.0789      0.88  0.24  0.69      0.88  0.19  0.73      0.88  0.15  0.76
forget mean min: 0.957443 0.827141
incx.max(), incx.min(), incx.mean() 5.49618 0.59522 2.54968
fgtx.max(), fgtx.min(), fgtx.mean() 5.13151 0.477599 2.33354
abs_mean, abs_mean+, abs_mean-: 2.91945 1.63133 3.87734
U_c = [[-0.12260444]] U_f = [[ 0.]] b_c = [ 0.09228495] b_f = [ 1.08789647]
W_c max, min, mean, abs_mean: 0.122713 0.119106 0.121905 0.121905
W_f max, min, mean, abs_mean: 0.116264 0.114628 0.115767 0.115767
Epoch 2/300
1s - loss: 1544.5289 - val_loss: 3466.2773
Epoch 00001: val_loss improved from 4169.07888 to 3466.27725, saving model to hefei0_weights.hdf5
              hefei0 1459.4732      0.61  0.44  0.42      0.66  0.42  0.44      0.67  0.39  0.47
              hefei0 3466.2772      0.97  0.22  0.76      0.97  0.18  0.80      0.97  0.15  0.83
forget mean min: 0.962941 0.784616
incx.max(), incx.min(), incx.mean() 7.89702 0.451468 4.23267
fgtx.max(), fgtx.min(), fgtx.mean() 5.41154 0.231028 2.86192
abs_mean, abs_mean+, abs_mean-: 4.42845 3.97526 5.15943
U_c = [[-0.11873984]] U_f = [[ 0.]] b_c = [ 0.11944125] b_f = [ 1.06174302]
W_c max, min, mean, abs_mean: 0.163428 0.159836 0.16261 0.16261
W_f max, min, mean, abs_mean: 0.113734 0.111935 0.113145 0.113145
Epoch 3/300
1s - loss: 1427.8019 - val_loss: 3433.4788
Epoch 00002: val_loss improved from 3466.27725 to 3433.47885, saving model to hefei0_weights.hdf5
              hefei0 1393.5513      0.66  0.44  0.43      0.70  0.43  0.46      0.72  0.39  0.49
              hefei0 3433.4788      0.95  0.21  0.76      0.96  0.16  0.81      0.96  0.13  0.83
forget mean min: 0.950754 0.760876
incx.max(), incx.min(), incx.mean() 10.0012 0.433911 5.18254
fgtx.max(), fgtx.min(), fgtx.mean() 4.78684 0.145919 2.4494
abs_mean, abs_mean+, abs_mean-: 5.16799 4.64735 5.88207
U_c = [[-0.10870524]] U_f = [[ 0.]] b_c = [ 0.13310462] b_f = [ 1.01157117]
W_c max, min, mean, abs_mean: 0.193175 0.189565 0.192349 0.192349
W_f max, min, mean, abs_mean: 0.0938698 0.0919577 0.0933068 0.0933068
Epoch 4/300
1s - loss: 1366.1578 - val_loss: 3546.4473
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1311.1795 - val_loss: 3675.3962
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1264.6746 - val_loss: 3822.9360
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1225.6650 - val_loss: 3968.9899
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1193.4497 - val_loss: 4096.2824
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1167.1651 - val_loss: 4051.2179
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1145.8827 - val_loss: 4265.8931
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1123.1540 - val_loss: 4158.8386
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1105.5829 - val_loss: 4534.4544
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1087.2427 - val_loss: 4449.7010
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1072.8285 - val_loss: 4519.4349
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1059.8092 - val_loss: 4483.5508
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1049.1202 - val_loss: 4697.2635
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1037.4199 - val_loss: 4686.8540
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1025.6735 - val_loss: 4737.7126
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1012.1900 - val_loss: 5005.3328
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1002.1615 - val_loss: 4915.2645
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 991.3715 - val_loss: 5026.8528
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 980.2998 - val_loss: 5126.0441
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 971.1989 - val_loss: 5198.1747
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 962.8065 - val_loss: 5177.6847
Epoch 00023: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training wuhan0
Train on 6380 samples, validate on 1700 samples
Before training:
              wuhan0 5192.1378      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.82209 nan 3.82209
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              wuhan015787.6871      0.03  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 7.06104 nan 7.06104
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3089.9448 - val_loss: 4791.7111
Epoch 00000: val_loss improved from inf to 4791.71108, saving model to wuhan0_weights.hdf5
              wuhan0 1620.3062      0.43  0.47  0.31      0.46  0.43  0.34      0.49  0.40  0.37
              wuhan0 4791.7110      0.75  0.12  0.68      0.76  0.07  0.72      0.77  0.03  0.75
forget mean min: 0.953265 0.849124
incx.max(), incx.min(), incx.mean() 6.63599 0.728382 2.6389
fgtx.max(), fgtx.min(), fgtx.mean() 6.52955 0.629858 2.53782
abs_mean, abs_mean+, abs_mean-: 4.22915 3.16933 4.91241
U_c = [[-0.13499448]] U_f = [[ 0.]] b_c = [ 0.09769826] b_f = [ 1.09788561]
W_c max, min, mean, abs_mean: 0.123046 0.120578 0.122565 0.122565
W_f max, min, mean, abs_mean: 0.122794 0.121583 0.122405 0.122405
Epoch 2/300
1s - loss: 1462.0243 - val_loss: 4252.9220
Epoch 00001: val_loss improved from 4791.71108 to 4252.92197, saving model to wuhan0_weights.hdf5
              wuhan0 1343.6057      0.58  0.44  0.40      0.61  0.42  0.42      0.62  0.41  0.43
              wuhan0 4252.9220      0.85  0.12  0.76      0.85  0.07  0.80      0.86  0.03  0.84
forget mean min: 0.968002 0.814317
incx.max(), incx.min(), incx.mean() 7.37185 0.511214 3.04378
fgtx.max(), fgtx.min(), fgtx.mean() 7.29734 0.399231 2.94561
abs_mean, abs_mean+, abs_mean-: 3.27849 2.69387 4.02159
U_c = [[-0.10077288]] U_f = [[ 0.]] b_c = [ 0.11415387] b_f = [ 1.07907724]
W_c max, min, mean, abs_mean: 0.137369 0.134744 0.136635 0.136635
W_f max, min, mean, abs_mean: 0.137806 0.136173 0.137383 0.137383
Epoch 3/300
1s - loss: 1264.4710 - val_loss: 4249.1312
Epoch 00002: val_loss improved from 4252.92197 to 4249.13118, saving model to wuhan0_weights.hdf5
              wuhan0 1189.7523      0.65  0.44  0.43      0.69  0.42  0.46      0.69  0.41  0.47
              wuhan0 4249.1312      0.87  0.12  0.78      0.87  0.06  0.82      0.88  0.03  0.86
forget mean min: 0.964705 0.775524
incx.max(), incx.min(), incx.mean() 8.39335 0.392233 3.55105
fgtx.max(), fgtx.min(), fgtx.mean() 6.70322 0.212806 2.77517
abs_mean, abs_mean+, abs_mean-: 3.42319 2.8357 4.17488
U_c = [[-0.04707486]] U_f = [[ 0.]] b_c = [ 0.12989263] b_f = [ 1.02696502]
W_c max, min, mean, abs_mean: 0.163727 0.160985 0.162857 0.162857
W_f max, min, mean, abs_mean: 0.132754 0.130623 0.132107 0.132107
Epoch 4/300
1s - loss: 1142.6048 - val_loss: 4718.2119
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1059.7130 - val_loss: 5114.5449
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 998.0678 - val_loss: 5424.9115
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 951.4129 - val_loss: 5779.0350
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 913.7723 - val_loss: 5818.6397
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 877.7782 - val_loss: 6145.8669
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 851.0029 - val_loss: 6015.8368
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 825.8787 - val_loss: 6156.5443
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 802.1578 - val_loss: 6994.9255
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 782.3585 - val_loss: 6510.8118
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 766.2044 - val_loss: 6648.8478
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 754.0169 - val_loss: 7143.9988
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 741.6730 - val_loss: 6976.5150
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 729.0389 - val_loss: 6789.4880
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 721.7529 - val_loss: 6884.6225
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 709.7962 - val_loss: 6778.7016
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 700.6812 - val_loss: 6805.0752
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 692.2754 - val_loss: 6821.0095
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 687.8281 - val_loss: 6847.6747
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 678.7485 - val_loss: 7339.8792
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 670.8652 - val_loss: 7254.2229
Epoch 00023: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training nanchang0
Train on 5742 samples, validate on 1530 samples
Before training:
           nanchang0 2569.3211      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 2.47571 nan 2.47571
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           nanchang0 6802.7534      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.44607 nan 4.44607
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1677.5811 - val_loss: 1937.1697
Epoch 00000: val_loss improved from inf to 1937.16967, saving model to nanchang0_weights.hdf5
           nanchang0  976.2913      0.24  0.49  0.19      0.27  0.45  0.22      0.28  0.42  0.23
           nanchang0 1937.1697      0.36  0.20  0.33      0.36  0.17  0.33      0.37  0.12  0.35
forget mean min: 0.941252 0.786385
incx.max(), incx.min(), incx.mean() 5.20428 0.318568 2.22563
fgtx.max(), fgtx.min(), fgtx.mean() 4.87028 0.220967 2.03578
abs_mean, abs_mean+, abs_mean-: 2.46243 1.76811 2.97907
U_c = [[-0.0981156]] U_f = [[ 0.]] b_c = [ 0.08638158] b_f = [ 1.08230543]
W_c max, min, mean, abs_mean: 0.115578 0.111406 0.11438 0.11438
W_f max, min, mean, abs_mean: 0.109681 0.105783 0.108851 0.108851
Epoch 2/300
1s - loss: 890.7901 - val_loss: 2036.8893
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 790.7207 - val_loss: 2222.5520
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 762.1858 - val_loss: 2431.2225
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 743.8210 - val_loss: 2464.4841
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 728.3267 - val_loss: 2535.7989
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 717.3946 - val_loss: 2572.4608
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 705.1907 - val_loss: 2545.4028
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 690.6870 - val_loss: 2607.3494
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 678.5622 - val_loss: 2702.2919
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 667.7158 - val_loss: 2751.7411
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 656.9613 - val_loss: 2717.5094
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 649.4593 - val_loss: 2735.6943
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 642.4477 - val_loss: 2890.2533
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 639.6995 - val_loss: 2733.8225
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 632.4001 - val_loss: 2818.4200
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 628.5839 - val_loss: 2742.9255
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 624.7620 - val_loss: 2842.9309
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 620.5710 - val_loss: 2894.3182
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 617.1079 - val_loss: 2760.9996
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 613.6925 - val_loss: 2848.6172
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 610.8170 - val_loss: 2988.7020
Epoch 00021: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training changsha0
Train on 6380 samples, validate on 1700 samples
Before training:
           changsha0 3303.9199      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.46565 nan 3.46565
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           changsha010459.2851      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.30799 nan 5.30799
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1742.8413 - val_loss: 3880.3488
Epoch 00000: val_loss improved from inf to 3880.34882, saving model to changsha0_weights.hdf5
           changsha0  875.5061      0.47  0.45  0.34      0.52  0.39  0.39      0.55  0.34  0.43
           changsha0 3880.3489      0.30  0.14  0.28      0.31  0.09  0.29      0.31  0.03  0.30
forget mean min: 0.928053 0.791667
incx.max(), incx.min(), incx.mean() 4.5152 0.315255 1.81256
fgtx.max(), fgtx.min(), fgtx.mean() 4.79247 0.246537 1.86714
abs_mean, abs_mean+, abs_mean-: 3.68295 2.0904 4.35165
U_c = [[-0.11544244]] U_f = [[ 0.]] b_c = [ 0.08750326] b_f = [ 1.08846736]
W_c max, min, mean, abs_mean: 0.102405 0.0984099 0.101333 0.101333
W_f max, min, mean, abs_mean: 0.110302 0.106137 0.109689 0.109689
Epoch 2/300
1s - loss: 773.3807 - val_loss: 3667.4027
Epoch 00001: val_loss improved from 3880.34882 to 3667.40270, saving model to changsha0_weights.hdf5
           changsha0  713.3671      0.61  0.40  0.44      0.68  0.32  0.51      0.72  0.27  0.57
           changsha0 3667.4027      0.37  0.19  0.35      0.38  0.15  0.36      0.38  0.09  0.37
forget mean min: 0.942513 0.820966
incx.max(), incx.min(), incx.mean() 4.00983 0.415521 1.71194
fgtx.max(), fgtx.min(), fgtx.mean() 5.73915 0.408821 2.33129
abs_mean, abs_mean+, abs_mean-: 3.33079 1.98678 4.27109
U_c = [[-0.09030151]] U_f = [[ 0.]] b_c = [ 0.13986818] b_f = [ 1.11408162]
W_c max, min, mean, abs_mean: 0.0990776 0.0944808 0.0975693 0.0975693
W_f max, min, mean, abs_mean: 0.145496 0.141403 0.1447 0.1447
Epoch 3/300
1s - loss: 694.6721 - val_loss: 3702.1416
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 673.0645 - val_loss: 3801.9909
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 646.6789 - val_loss: 3799.8196
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 620.8459 - val_loss: 3567.7757
Epoch 00005: val_loss improved from 3667.40270 to 3567.77570, saving model to changsha0_weights.hdf5
           changsha0  607.4198      0.64  0.32  0.49      0.70  0.24  0.57      0.73  0.17  0.63
           changsha0 3567.7757      0.31  0.13  0.29      0.31  0.08  0.30      0.32  0.03  0.31
forget mean min: 0.931552 0.790923
incx.max(), incx.min(), incx.mean() 7.8711 0.656706 2.8148
fgtx.max(), fgtx.min(), fgtx.mean() 6.3224 0.336095 2.12677
abs_mean, abs_mean+, abs_mean-: 4.20265 3.2977 4.76555
U_c = [[-0.05699299]] U_f = [[ 0.]] b_c = [ 0.25163761] b_f = [ 0.99440199]
W_c max, min, mean, abs_mean: 0.16761 0.162137 0.165483 0.165483
W_f max, min, mean, abs_mean: 0.138637 0.133501 0.137313 0.137313
Epoch 7/300
1s - loss: 599.5194 - val_loss: 3712.6601
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 581.7150 - val_loss: 3746.1214
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 567.0608 - val_loss: 3698.6368
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 554.4041 - val_loss: 3848.4538
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 539.0871 - val_loss: 3682.1340
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 525.4864 - val_loss: 3935.5376
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 516.9052 - val_loss: 3910.2348
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 505.6511 - val_loss: 3810.8319
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 497.7639 - val_loss: 3924.1540
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 490.4446 - val_loss: 4012.8474
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 483.6041 - val_loss: 4103.1161
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 479.1467 - val_loss: 4023.7219
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 475.9603 - val_loss: 3898.7550
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 471.0544 - val_loss: 4195.8497
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 465.8211 - val_loss: 4019.8844
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 460.3503 - val_loss: 4213.8934
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 457.4818 - val_loss: 4066.5809
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 452.7371 - val_loss: 4102.4128
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 446.4298 - val_loss: 4293.8910
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 443.9158 - val_loss: 4053.5805
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 440.4256 - val_loss: 3938.3552
Epoch 00026: val_loss did not improve

nanjing
            nanjing0  769.1698      0.53  0.36  0.41      0.55  0.36  0.42      0.56  0.32  0.44
            nanjing0 3058.6908      0.90  0.15  0.77      0.90  0.12  0.80      0.90  0.11  0.81
forget mean min: 0.959385 0.811262
incx.max(), incx.min(), incx.mean() 8.69174 0.58936 3.87823
fgtx.max(), fgtx.min(), fgtx.mean() 7.12902 0.40762 3.13593
abs_mean, abs_mean+, abs_mean-: 4.80321 4.28909 5.63394
U_c = [[-0.10470588]] U_f = [[ 0.]] b_c = [ 0.09799477] b_f = [ 1.05060852]
W_c max, min, mean, abs_mean: 0.156747 0.154621 0.155975 0.155975
W_f max, min, mean, abs_mean: 0.129887 0.128692 0.129392 0.129392

shanghai
           shanghai0  616.2796      0.52  0.34  0.41      0.57  0.29  0.46      0.62  0.24  0.52
           shanghai0 2160.6200      0.72  0.26  0.57      0.69  0.26  0.56      0.69  0.23  0.58
forget mean min: 0.908802 0.762444
incx.max(), incx.min(), incx.mean() 13.621 0.608005 5.6773
fgtx.max(), fgtx.min(), fgtx.mean() 3.80178 0.128194 1.55926
abs_mean, abs_mean+, abs_mean-: 5.52751 5.13208 5.87825
U_c = [[-0.09114492]] U_f = [[ 0.]] b_c = [ 0.15387303] b_f = [ 1.0379349]
W_c max, min, mean, abs_mean: 0.217132 0.212838 0.216108 0.216108
W_f max, min, mean, abs_mean: 0.0617439 0.0583333 0.0610068 0.0610068

hangzhou
           hangzhou0  647.9794      0.39  0.33  0.33      0.45  0.29  0.38      0.49  0.24  0.42
           hangzhou0 2978.6226      0.76  0.21  0.63      0.78  0.17  0.67      0.80  0.13  0.72
forget mean min: 0.946733 0.787064
incx.max(), incx.min(), incx.mean() 6.97749 0.442238 3.24767
fgtx.max(), fgtx.min(), fgtx.mean() 4.74519 0.233998 2.17055
abs_mean, abs_mean+, abs_mean-: 3.44172 2.61513 4.287
U_c = [[-0.11681648]] U_f = [[ 0.]] b_c = [ 0.10326303] b_f = [ 1.07332146]
W_c max, min, mean, abs_mean: 0.157786 0.154529 0.157289 0.157289
W_f max, min, mean, abs_mean: 0.109298 0.107523 0.108577 0.108577

hefei
              hefei0 1393.5513      0.66  0.44  0.43      0.70  0.43  0.46      0.72  0.39  0.49
              hefei0 3433.4788      0.95  0.21  0.76      0.96  0.16  0.81      0.96  0.13  0.83
forget mean min: 0.950754 0.760876
incx.max(), incx.min(), incx.mean() 10.0012 0.433911 5.18254
fgtx.max(), fgtx.min(), fgtx.mean() 4.78684 0.145919 2.4494
abs_mean, abs_mean+, abs_mean-: 5.16799 4.64735 5.88207
U_c = [[-0.10870524]] U_f = [[ 0.]] b_c = [ 0.13310462] b_f = [ 1.01157117]
W_c max, min, mean, abs_mean: 0.193175 0.189565 0.192349 0.192349
W_f max, min, mean, abs_mean: 0.0938698 0.0919577 0.0933068 0.0933068

wuhan
              wuhan0 1189.7523      0.65  0.44  0.43      0.69  0.42  0.46      0.69  0.41  0.47
              wuhan0 4249.1312      0.87  0.12  0.78      0.87  0.06  0.82      0.88  0.03  0.86
forget mean min: 0.964705 0.775524
incx.max(), incx.min(), incx.mean() 8.39335 0.392233 3.55105
fgtx.max(), fgtx.min(), fgtx.mean() 6.70322 0.212806 2.77517
abs_mean, abs_mean+, abs_mean-: 3.42319 2.8357 4.17488
U_c = [[-0.04707486]] U_f = [[ 0.]] b_c = [ 0.12989263] b_f = [ 1.02696502]
W_c max, min, mean, abs_mean: 0.163727 0.160985 0.162857 0.162857
W_f max, min, mean, abs_mean: 0.132754 0.130623 0.132107 0.132107

nanchang
           nanchang0  976.2913      0.24  0.49  0.19      0.27  0.45  0.22      0.28  0.42  0.23
           nanchang0 1937.1697      0.36  0.20  0.33      0.36  0.17  0.33      0.37  0.12  0.35
forget mean min: 0.941252 0.786385
incx.max(), incx.min(), incx.mean() 5.20428 0.318568 2.22563
fgtx.max(), fgtx.min(), fgtx.mean() 4.87028 0.220967 2.03578
abs_mean, abs_mean+, abs_mean-: 2.46243 1.76811 2.97907
U_c = [[-0.0981156]] U_f = [[ 0.]] b_c = [ 0.08638158] b_f = [ 1.08230543]
W_c max, min, mean, abs_mean: 0.115578 0.111406 0.11438 0.11438
W_f max, min, mean, abs_mean: 0.109681 0.105783 0.108851 0.108851

changsha
           changsha0  607.4198      0.64  0.32  0.49      0.70  0.24  0.57      0.73  0.17  0.63
           changsha0 3567.7757      0.31  0.13  0.29      0.31  0.08  0.30      0.32  0.03  0.31
forget mean min: 0.931552 0.790923
incx.max(), incx.min(), incx.mean() 7.8711 0.656706 2.8148
fgtx.max(), fgtx.min(), fgtx.mean() 6.3224 0.336095 2.12677
abs_mean, abs_mean+, abs_mean-: 4.20265 3.2977 4.76555
U_c = [[-0.05699299]] U_f = [[ 0.]] b_c = [ 0.25163761] b_f = [ 0.99440199]
W_c max, min, mean, abs_mean: 0.16761 0.162137 0.165483 0.165483
W_f max, min, mean, abs_mean: 0.138637 0.133501 0.137313 0.137313
