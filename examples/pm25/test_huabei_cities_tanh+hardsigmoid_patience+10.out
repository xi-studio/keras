X_train[0].shape = (7656, 40, 23)

training beijing0
Train on 7656 samples, validate on 2040 samples
Before training:
            beijing014863.8087      0.03  -nan  0.03      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.23986 nan 5.23986
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            beijing026233.5353      0.05  -nan  0.05      0.06  -nan  0.05      0.05  -nan  0.05
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 9.3916 nan 9.3916
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 8508.3012 - val_loss: 12511.1576
Epoch 00000: val_loss improved from inf to 12511.15758, saving model to beijing0_weights.hdf5
            beijing0 5094.5611      0.65  0.20  0.57      0.65  0.18  0.57      0.63  0.16  0.57
            beijing012511.1576      0.66  0.15  0.60      0.66  0.12  0.61      0.63  0.11  0.58
forget mean min: 0.77395 0.296546
incx.max(), incx.min(), incx.mean() 3.12215 -2.90664 0.930064
fgtx.max(), fgtx.min(), fgtx.mean() 1.98542 -2.01727 0.530029
abs_mean, abs_mean+, abs_mean-: 10.4049 2.76644 18.7346
U_c = [[-0.08281146]] U_f = [[ 0.]] b_c = [ 0.13174824] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.157894 -0.15814 -0.0311752 0.156106
W_f max, min, mean, abs_mean: 0.105146 -0.10524 -0.0204659 0.103643
Epoch 2/300
1s - loss: 3922.3816 - val_loss: 11806.0453
Epoch 00001: val_loss improved from 12511.15758 to 11806.04528, saving model to beijing0_weights.hdf5
            beijing0 3083.8517      0.86  0.21  0.69      0.86  0.19  0.72      0.86  0.17  0.73
            beijing011806.0453      0.81  0.23  0.65      0.82  0.19  0.69      0.81  0.18  0.69
forget mean min: 0.916473 0.334822
incx.max(), incx.min(), incx.mean() 5.58866 -5.09253 3.93965
fgtx.max(), fgtx.min(), fgtx.mean() 1.82944 -1.82589 1.26512
abs_mean, abs_mean+, abs_mean-: 9.41598 5.11555 22.171
U_c = [[-0.02379452]] U_f = [[ 0.]] b_c = [ 0.24287485] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.269733 -0.269989 -0.0535464 0.267936
W_f max, min, mean, abs_mean: 0.0932134 -0.0933532 -0.0180641 0.0916934
Epoch 3/300
1s - loss: 2834.8432 - val_loss: 9908.6193
Epoch 00002: val_loss improved from 11806.04528 to 9908.61928, saving model to beijing0_weights.hdf5
            beijing0 2641.3206      0.91  0.21  0.73      0.91  0.19  0.74      0.90  0.18  0.75
            beijing0 9908.6194      0.85  0.23  0.67      0.86  0.20  0.71      0.86  0.18  0.72
forget mean min: 0.915701 0.386654
incx.max(), incx.min(), incx.mean() 7.40923 -6.68354 5.2867
fgtx.max(), fgtx.min(), fgtx.mean() 1.58204 -1.56673 1.10781
abs_mean, abs_mean+, abs_mean-: 10.6757 6.48197 20.7015
U_c = [[-0.0245792]] U_f = [[ 0.]] b_c = [ 0.32857105] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.356428 -0.356688 -0.0708856 0.354624
W_f max, min, mean, abs_mean: 0.080742 -0.0808725 -0.0155699 0.0792342
Epoch 4/300
1s - loss: 2560.4286 - val_loss: 8812.9639
Epoch 00003: val_loss improved from 9908.61928 to 8812.96394, saving model to beijing0_weights.hdf5
            beijing0 2468.5134      0.92  0.22  0.73      0.92  0.20  0.75      0.92  0.18  0.77
            beijing0 8812.9640      0.86  0.23  0.69      0.86  0.20  0.71      0.86  0.19  0.72
forget mean min: 0.907281 0.383306
incx.max(), incx.min(), incx.mean() 8.66398 -7.77366 5.89859
fgtx.max(), fgtx.min(), fgtx.mean() 1.60677 -1.58347 1.07007
abs_mean, abs_mean+, abs_mean-: 11.9348 7.39897 21.7923
U_c = [[-0.0308079]] U_f = [[ 0.]] b_c = [ 0.38512662] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.416584 -0.41685 -0.0829166 0.414766
W_f max, min, mean, abs_mean: 0.0820054 -0.0821368 -0.0158246 0.0804985
Epoch 5/300
1s - loss: 2468.7092 - val_loss: 8608.0173
Epoch 00004: val_loss improved from 8812.96394 to 8608.01727, saving model to beijing0_weights.hdf5
            beijing0 2422.5757      0.92  0.19  0.75      0.92  0.17  0.77      0.91  0.15  0.79
            beijing0 8608.0173      0.85  0.21  0.69      0.86  0.18  0.72      0.86  0.17  0.73
forget mean min: 0.895966 0.385042
incx.max(), incx.min(), incx.mean() 9.36113 -8.41431 6.03587
fgtx.max(), fgtx.min(), fgtx.mean() 1.59623 -1.57479 1.00304
abs_mean, abs_mean+, abs_mean-: 12.3284 7.74589 21.0927
U_c = [[-0.03400894]] U_f = [[ 0.]] b_c = [ 0.41329336] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.450215 -0.450485 -0.0896431 0.448383
W_f max, min, mean, abs_mean: 0.0814923 -0.0816263 -0.0157245 0.0799885
Epoch 6/300
1s - loss: 2431.0192 - val_loss: 8601.7021
Epoch 00005: val_loss improved from 8608.01727 to 8601.70209, saving model to beijing0_weights.hdf5
            beijing0 2389.7877      0.92  0.21  0.74      0.93  0.19  0.77      0.93  0.16  0.79
            beijing0 8601.7021      0.85  0.21  0.69      0.85  0.18  0.72      0.86  0.17  0.73
forget mean min: 0.891726 0.365231
incx.max(), incx.min(), incx.mean() 9.88586 -8.89784 6.13471
fgtx.max(), fgtx.min(), fgtx.mean() 1.69566 -1.67384 1.02278
abs_mean, abs_mean+, abs_mean-: 13.1132 8.43255 22.0825
U_c = [[-0.03115134]] U_f = [[ 0.]] b_c = [ 0.43317452] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.475542 -0.475812 -0.0947092 0.473697
W_f max, min, mean, abs_mean: 0.0864717 -0.0866097 -0.0167232 0.0849738
Epoch 7/300
1s - loss: 2404.6161 - val_loss: 8641.5190
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 2391.7933 - val_loss: 8620.7099
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2375.3798 - val_loss: 8771.3123
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 2357.1701 - val_loss: 8798.9436
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 2348.4625 - val_loss: 8910.8922
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 2321.6987 - val_loss: 8974.7000
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 2286.3342 - val_loss: 8977.5960
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 2257.2037 - val_loss: 9035.1163
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 2215.6841 - val_loss: 9187.9865
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 2159.8724 - val_loss: 9328.3316
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 2108.7875 - val_loss: 9481.2136
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 2057.3745 - val_loss: 9738.7540
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 2016.0466 - val_loss: 9617.2743
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1984.1964 - val_loss: 9840.2649
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1960.8394 - val_loss: 9806.5966
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1930.3856 - val_loss: 9862.1848
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1914.9655 - val_loss: 9635.8855
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1891.7596 - val_loss: 9613.0783
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1878.2155 - val_loss: 9574.9042
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1859.8072 - val_loss: 9601.2560
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1842.2553 - val_loss: 9857.6557
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1817.2027 - val_loss: 9646.0872
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1800.9902 - val_loss: 9496.6856
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1781.8149 - val_loss: 9482.5596
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1777.4387 - val_loss: 9532.5338
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1758.1608 - val_loss: 9510.3511
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1754.9032 - val_loss: 9452.7291
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1738.7963 - val_loss: 9450.4368
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1729.2986 - val_loss: 9515.3145
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 1719.2583 - val_loss: 9355.6522
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 1713.0857 - val_loss: 9457.0934
Epoch 00036: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training tianjin0
Train on 6380 samples, validate on 1700 samples
Before training:
            tianjin0 8656.4532      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.28611 nan 4.28611
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            tianjin026647.8111      0.05  -nan  0.04      0.06  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.71034 nan 8.71034
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5398.6902 - val_loss: 10750.4685
Epoch 00000: val_loss improved from inf to 10750.46849, saving model to tianjin0_weights.hdf5
            tianjin0 2873.6457      0.53  0.14  0.48      0.53  0.10  0.50      0.52  0.07  0.50
            tianjin010750.4686      0.74  0.08  0.70      0.73  0.05  0.70      0.70  0.02  0.69
forget mean min: 0.813291 0.271004
incx.max(), incx.min(), incx.mean() 2.65317 -2.48026 1.02544
fgtx.max(), fgtx.min(), fgtx.mean() 2.10641 -2.14498 0.758358
abs_mean, abs_mean+, abs_mean-: 9.77092 2.28611 18.7336
U_c = [[-0.10635546]] U_f = [[ 0.]] b_c = [ 0.1097435] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.13617 -0.136777 -0.0264116 0.134769
W_f max, min, mean, abs_mean: 0.112846 -0.112893 -0.0219583 0.111613
Epoch 2/300
1s - loss: 2375.0615 - val_loss: 8794.6492
Epoch 00001: val_loss improved from 10750.46849 to 8794.64917, saving model to tianjin0_weights.hdf5
            tianjin0 2047.5507      0.78  0.22  0.64      0.80  0.17  0.69      0.80  0.14  0.71
            tianjin0 8794.6493      0.80  0.12  0.72      0.80  0.10  0.73      0.79  0.07  0.75
forget mean min: 0.86433 0.349266
incx.max(), incx.min(), incx.mean() 4.76158 -4.34748 2.5901
fgtx.max(), fgtx.min(), fgtx.mean() 1.75674 -1.75367 0.919904
abs_mean, abs_mean+, abs_mean-: 9.47774 4.27049 19.4357
U_c = [[-0.06188902]] U_f = [[ 0.]] b_c = [ 0.2030676] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.230299 -0.230908 -0.0452382 0.228888
W_f max, min, mean, abs_mean: 0.0894089 -0.0894418 -0.0172712 0.0882077
Epoch 3/300
1s - loss: 1948.9109 - val_loss: 7650.3934
Epoch 00002: val_loss improved from 8794.64917 to 7650.39342, saving model to tianjin0_weights.hdf5
            tianjin0 1878.2709      0.85  0.24  0.66      0.86  0.20  0.71      0.86  0.15  0.75
            tianjin0 7650.3934      0.86  0.16  0.74      0.86  0.14  0.75      0.86  0.12  0.77
forget mean min: 0.873319 0.371346
incx.max(), incx.min(), incx.mean() 6.33105 -5.76687 3.64311
fgtx.max(), fgtx.min(), fgtx.mean() 1.64429 -1.64327 0.913854
abs_mean, abs_mean+, abs_mean-: 10.8 5.59439 21.5087
U_c = [[-0.0738039]] U_f = [[ 0.]] b_c = [ 0.2802088] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.304588 -0.305197 -0.0600965 0.303175
W_f max, min, mean, abs_mean: 0.0836084 -0.0836412 -0.0161073 0.0823868
Epoch 4/300
1s - loss: 1854.7467 - val_loss: 7271.0099
Epoch 00003: val_loss improved from 7650.39342 to 7271.00992, saving model to tianjin0_weights.hdf5
            tianjin0 1828.5240      0.88  0.26  0.67      0.90  0.21  0.72      0.90  0.16  0.76
            tianjin0 7271.0099      0.87  0.13  0.77      0.87  0.12  0.78      0.87  0.10  0.79
forget mean min: 0.868607 0.36608
incx.max(), incx.min(), incx.mean() 7.40718 -6.72563 4.16097
fgtx.max(), fgtx.min(), fgtx.mean() 1.66974 -1.6696 0.902711
abs_mean, abs_mean+, abs_mean-: 12.0718 6.60871 22.908
U_c = [[-0.07878304]] U_f = [[ 0.]] b_c = [ 0.34047723] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.355399 -0.356008 -0.0702593 0.353987
W_f max, min, mean, abs_mean: 0.0848816 -0.0849237 -0.016355 0.083641
Epoch 5/300
1s - loss: 1811.7896 - val_loss: 7529.9893
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1786.2037 - val_loss: 7877.2769
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1757.2168 - val_loss: 8810.5190
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1706.5573 - val_loss: 9338.5066
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1687.9507 - val_loss: 9140.9691
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1678.3632 - val_loss: 9946.6425
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1666.1203 - val_loss: 10326.9989
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1664.7018 - val_loss: 9886.0254
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1662.9674 - val_loss: 9447.0625
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1658.0199 - val_loss: 9746.9171
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1655.5410 - val_loss: 9485.9821
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1657.0050 - val_loss: 9853.1784
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1649.4081 - val_loss: 10012.6996
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1650.5129 - val_loss: 9392.0480
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1649.0365 - val_loss: 9390.9556
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1638.8451 - val_loss: 9594.3054
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1623.0908 - val_loss: 9204.9781
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1602.8298 - val_loss: 9743.1711
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1567.6250 - val_loss: 9289.2650
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1546.8547 - val_loss: 9250.7180
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1525.1061 - val_loss: 9340.0708
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1496.4141 - val_loss: 9349.3487
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1482.5868 - val_loss: 8904.7728
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1468.6951 - val_loss: 8882.7072
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1450.1271 - val_loss: 9404.7976
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1436.5467 - val_loss: 8902.9108
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1415.1437 - val_loss: 9121.2618
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1390.0778 - val_loss: 8947.9447
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1379.9827 - val_loss: 8957.3412
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1355.7257 - val_loss: 8827.8175
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1337.1319 - val_loss: 8847.2250
Epoch 00034: val_loss did not improve
X_train[0].shape = (3828, 40, 23)

training tangshan0
Train on 3828 samples, validate on 1020 samples
Before training:
           tangshan010662.4372      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.77045 nan 4.77045
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           tangshan027029.8810      0.04  -nan  0.04      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 9.12279 nan 9.12279
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 8401.3744 - val_loss: 14642.9581
Epoch 00000: val_loss improved from inf to 14642.95814, saving model to tangshan0_weights.hdf5
           tangshan0 4723.8583      0.38  0.05  0.37      0.39  0.01  0.39      0.39  0.01  0.39
           tangshan014642.9578      0.49  0.03  0.48      0.47  0.00  0.47      0.46  0.00  0.46
forget mean min: 0.763257 0.36455
incx.max(), incx.min(), incx.mean() 1.83839 -1.60024 0.401716
fgtx.max(), fgtx.min(), fgtx.mean() 1.77221 -1.67725 0.331012
abs_mean, abs_mean+, abs_mean-: 11.3378 1.47429 13.4077
U_c = [[-0.11321439]] U_f = [[ 0.]] b_c = [ 0.07174432] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0966073 -0.096492 0.00032115 0.0960137
W_f max, min, mean, abs_mean: 0.0970312 -0.0969696 0.000189565 0.0963162
Epoch 2/300
0s - loss: 3630.3786 - val_loss: 9083.5296
Epoch 00001: val_loss improved from 14642.95814 to 9083.52961, saving model to tangshan0_weights.hdf5
           tangshan0 3024.0775      0.64  0.06  0.61      0.66  0.03  0.65      0.66  0.02  0.65
           tangshan0 9083.5294      0.80  0.07  0.76      0.80  0.03  0.78      0.80  0.03  0.78
forget mean min: 0.847149 0.251079
incx.max(), incx.min(), incx.mean() 3.18343 -2.86813 1.51892
fgtx.max(), fgtx.min(), fgtx.mean() 2.28475 -2.2446 1.03893
abs_mean, abs_mean+, abs_mean-: 9.18212 2.74718 19.9351
U_c = [[-0.09496844]] U_f = [[ 0.]] b_c = [ 0.13083145] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.158319 -0.158193 0.000320378 0.157715
W_f max, min, mean, abs_mean: 0.118757 -0.118691 0.000186611 0.118043
Epoch 3/300
0s - loss: 2618.6091 - val_loss: 6100.1023
Epoch 00002: val_loss improved from 9083.52961 to 6100.10228, saving model to tangshan0_weights.hdf5
           tangshan0 2277.3490      0.76  0.17  0.66      0.79  0.14  0.69      0.79  0.14  0.70
           tangshan0 6100.1023      0.94  0.16  0.80      0.95  0.12  0.84      0.96  0.10  0.86
forget mean min: 0.939379 0.313903
incx.max(), incx.min(), incx.mean() 4.42827 -3.89614 3.29639
fgtx.max(), fgtx.min(), fgtx.mean() 2.00447 -1.93049 1.46943
abs_mean, abs_mean+, abs_mean-: 7.56007 4.00592 21.0498
U_c = [[-0.05284229]] U_f = [[ 0.]] b_c = [ 0.18780962] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.215771 -0.215642 0.000320002 0.215162
W_f max, min, mean, abs_mean: 0.102375 -0.10234 0.00017525 0.101707
Epoch 4/300
0s - loss: 2129.6425 - val_loss: 5892.9730
Epoch 00003: val_loss improved from 6100.10228 to 5892.97298, saving model to tangshan0_weights.hdf5
           tangshan0 2006.8984      0.83  0.21  0.69      0.86  0.18  0.72      0.87  0.17  0.74
           tangshan0 5892.9729      0.97  0.22  0.76      0.97  0.19  0.79      0.98  0.19  0.79
forget mean min: 0.957543 0.384498
incx.max(), incx.min(), incx.mean() 5.49384 -4.72305 4.52551
fgtx.max(), fgtx.min(), fgtx.mean() 1.67148 -1.57751 1.36355
abs_mean, abs_mean+, abs_mean-: 7.58402 4.98048 17.8033
U_c = [[-0.05828704]] U_f = [[ 0.]] b_c = [ 0.23764929] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.265168 -0.265039 0.000319782 0.264557
W_f max, min, mean, abs_mean: 0.0847934 -0.0847672 0.000173678 0.0841297
Epoch 5/300
0s - loss: 1959.1563 - val_loss: 5539.2313
Epoch 00004: val_loss improved from 5892.97298 to 5539.23133, saving model to tangshan0_weights.hdf5
           tangshan0 1904.4558      0.86  0.22  0.69      0.89  0.19  0.73      0.89  0.18  0.74
           tangshan0 5539.2313      0.97  0.22  0.76      0.97  0.18  0.79      0.98  0.18  0.80
forget mean min: 0.951747 0.376394
incx.max(), incx.min(), incx.mean() 6.41663 -5.68304 5.17289
fgtx.max(), fgtx.min(), fgtx.mean() 1.66345 -1.61803 1.32614
abs_mean, abs_mean+, abs_mean-: 8.56861 5.69627 19.4949
U_c = [[-0.06106531]] U_f = [[ 0.]] b_c = [ 0.28306156] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.308465 -0.308335 0.000319603 0.307852
W_f max, min, mean, abs_mean: 0.084163 -0.0841377 0.000174979 0.083491
Epoch 6/300
0s - loss: 1879.0098 - val_loss: 5262.9373
Epoch 00005: val_loss improved from 5539.23133 to 5262.93726, saving model to tangshan0_weights.hdf5
           tangshan0 1843.9730      0.87  0.22  0.69      0.90  0.20  0.73      0.91  0.19  0.75
           tangshan0 5262.9372      0.97  0.21  0.77      0.97  0.18  0.80      0.98  0.18  0.81
forget mean min: 0.946322 0.366907
incx.max(), incx.min(), incx.mean() 7.18983 -6.4377 5.6639
fgtx.max(), fgtx.min(), fgtx.mean() 1.69104 -1.66546 1.31519
abs_mean, abs_mean+, abs_mean-: 9.45886 6.36756 20.7506
U_c = [[-0.06921239]] U_f = [[ 0.]] b_c = [ 0.3241502] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.344738 -0.344608 0.000319318 0.344125
W_f max, min, mean, abs_mean: 0.0854358 -0.0854132 0.000177351 0.084759
Epoch 7/300
0s - loss: 1829.4460 - val_loss: 4987.7864
Epoch 00006: val_loss improved from 5262.93726 to 4987.78642, saving model to tangshan0_weights.hdf5
           tangshan0 1796.8842      0.87  0.21  0.71      0.90  0.19  0.74      0.91  0.17  0.76
           tangshan0 4987.7864      0.96  0.19  0.79      0.97  0.15  0.82      0.98  0.15  0.83
forget mean min: 0.933325 0.360702
incx.max(), incx.min(), incx.mean() 7.71598 -6.94896 5.76741
fgtx.max(), fgtx.min(), fgtx.mean() 1.70937 -1.69649 1.25682
abs_mean, abs_mean+, abs_mean-: 10.3291 6.82585 21.0298
U_c = [[-0.075369]] U_f = [[ 0.]] b_c = [ 0.35577819] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.3692 -0.369071 0.000318924 0.368587
W_f max, min, mean, abs_mean: 0.0862832 -0.0862644 0.000180749 0.0856025
Epoch 8/300
0s - loss: 1794.1837 - val_loss: 4919.8456
Epoch 00007: val_loss improved from 4987.78642 to 4919.84564, saving model to tangshan0_weights.hdf5
           tangshan0 1760.4865      0.88  0.21  0.71      0.90  0.18  0.75      0.90  0.17  0.76
           tangshan0 4919.8456      0.96  0.18  0.79      0.97  0.14  0.83      0.98  0.13  0.85
forget mean min: 0.926315 0.359035
incx.max(), incx.min(), incx.mean() 8.12721 -7.32626 5.92588
fgtx.max(), fgtx.min(), fgtx.mean() 1.71195 -1.70483 1.22523
abs_mean, abs_mean+, abs_mean-: 10.9338 7.23217 21.7178
U_c = [[-0.07917482]] U_f = [[ 0.]] b_c = [ 0.38435796] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.38815 -0.388021 0.00031828 0.387537
W_f max, min, mean, abs_mean: 0.0863668 -0.0863519 0.000183498 0.0856849
Epoch 9/300
0s - loss: 1761.3083 - val_loss: 4922.8607
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 1731.8931 - val_loss: 4841.4701
Epoch 00009: val_loss improved from 4919.84564 to 4841.47005, saving model to tangshan0_weights.hdf5
           tangshan0 1710.8836      0.89  0.22  0.71      0.92  0.19  0.76      0.92  0.18  0.76
           tangshan0 4841.4701      0.95  0.18  0.79      0.96  0.13  0.84      0.98  0.12  0.87
forget mean min: 0.923231 0.343678
incx.max(), incx.min(), incx.mean() 8.74202 -7.80827 6.21825
fgtx.max(), fgtx.min(), fgtx.mean() 1.79452 -1.78161 1.24918
abs_mean, abs_mean+, abs_mean-: 11.6819 7.7381 23.3406
U_c = [[-0.07801635]] U_f = [[ 0.]] b_c = [ 0.43700942] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.416371 -0.416243 0.000316054 0.41576
W_f max, min, mean, abs_mean: 0.0905308 -0.0905284 0.000191658 0.0898359
Epoch 11/300
0s - loss: 1712.6755 - val_loss: 5027.8959
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 1699.4788 - val_loss: 4931.8417
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 1691.1522 - val_loss: 4888.0153
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 1685.4049 - val_loss: 5009.9031
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 1677.5020 - val_loss: 5033.3622
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 1674.9992 - val_loss: 5151.3231
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 1667.8121 - val_loss: 5009.0933
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 1667.1693 - val_loss: 4987.0810
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 1661.7163 - val_loss: 5068.7329
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 1658.2817 - val_loss: 5081.0337
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 1658.1540 - val_loss: 5056.4662
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 1658.0286 - val_loss: 5052.4958
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1653.7067 - val_loss: 5052.4954
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1655.1592 - val_loss: 5149.1169
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1649.4919 - val_loss: 5055.4792
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1647.5662 - val_loss: 5086.4732
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 1648.8725 - val_loss: 5094.0797
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 1644.3857 - val_loss: 5081.0158
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 1645.6826 - val_loss: 5062.4365
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 1647.4005 - val_loss: 5151.7638
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 1646.1674 - val_loss: 5164.8183
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 1646.4047 - val_loss: 5085.0129
Epoch 00031: val_loss did not improve
Epoch 33/300
0s - loss: 1647.3642 - val_loss: 5165.5488
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 1644.1350 - val_loss: 5088.2344
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 1645.2706 - val_loss: 5116.9072
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 1640.8015 - val_loss: 5213.4819
Epoch 00035: val_loss did not improve
Epoch 37/300
0s - loss: 1640.6289 - val_loss: 5141.8595
Epoch 00036: val_loss did not improve
Epoch 38/300
0s - loss: 1641.2847 - val_loss: 5119.2222
Epoch 00037: val_loss did not improve
Epoch 39/300
0s - loss: 1641.7395 - val_loss: 5134.8192
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 1625.2962 - val_loss: 5047.0150
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 1627.6618 - val_loss: 5070.2557
Epoch 00040: val_loss did not improve
X_train[0].shape = (3828, 40, 23)

training baoding0
Train on 3828 samples, validate on 1020 samples
Before training:
            baoding017045.0190      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.88974 nan 5.88974
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            baoding041691.4929      0.06  -nan  0.06      0.07  -nan  0.07      0.08  -nan  0.08
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 13.9341 nan 13.9341
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 14124.9970 - val_loss: 18436.0463
Epoch 00000: val_loss improved from inf to 18436.04626, saving model to baoding0_weights.hdf5
            baoding0 9148.1865      0.31  0.08  0.30      0.31  0.05  0.31      0.31  0.03  0.30
            baoding018436.0463      0.73  0.05  0.70      0.72  0.03  0.70      0.72  0.02  0.71
forget mean min: 0.839679 0.36017
incx.max(), incx.min(), incx.mean() 1.70624 -1.61178 0.766252
fgtx.max(), fgtx.min(), fgtx.mean() 1.65118 -1.69915 0.702039
abs_mean, abs_mean+, abs_mean-: 15.3209 1.21897 17.2024
U_c = [[-0.11379423]] U_f = [[ 0.]] b_c = [ 0.07098366] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0961474 -0.0960579 -0.0287644 0.0947113
W_f max, min, mean, abs_mean: 0.0974374 -0.0972262 -0.0280784 0.095634
Epoch 2/300
0s - loss: 7186.5593 - val_loss: 8999.6243
Epoch 00001: val_loss improved from 18436.04626 to 8999.62430, saving model to baoding0_weights.hdf5
            baoding0 5717.6347      0.71  0.16  0.62      0.71  0.12  0.65      0.70  0.11  0.65
            baoding0 8999.6242      0.95  0.10  0.86      0.95  0.07  0.89      0.97  0.04  0.93
forget mean min: 0.94935 0.22757
incx.max(), incx.min(), incx.mean() 3.08324 -2.67968 2.22832
fgtx.max(), fgtx.min(), fgtx.mean() 2.48408 -2.36215 1.76514
abs_mean, abs_mean+, abs_mean-: 7.86001 2.65482 31.9717
U_c = [[-0.11582071]] U_f = [[ 0.]] b_c = [ 0.12928444] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.157323 -0.157237 -0.0471173 0.155889
W_f max, min, mean, abs_mean: 0.132883 -0.132678 -0.0387164 0.131093
Epoch 3/300
0s - loss: 4877.3400 - val_loss: 10853.2599
Epoch 00002: val_loss did not improve
Epoch 4/300
0s - loss: 4086.5735 - val_loss: 10337.2618
Epoch 00003: val_loss did not improve
Epoch 5/300
0s - loss: 3833.5004 - val_loss: 9649.1004
Epoch 00004: val_loss did not improve
Epoch 6/300
0s - loss: 3603.1586 - val_loss: 8858.3909
Epoch 00005: val_loss improved from 8999.62430 to 8858.39090, saving model to baoding0_weights.hdf5
            baoding0 3446.5555      0.90  0.20  0.73      0.92  0.16  0.78      0.92  0.14  0.79
            baoding0 8858.3908      0.99  0.08  0.91      0.99  0.05  0.93      0.99  0.03  0.96
forget mean min: 0.966689 0.396902
incx.max(), incx.min(), incx.mean() 7.14959 -5.51154 5.98889
fgtx.max(), fgtx.min(), fgtx.mean() 1.77766 -1.51549 1.47574
abs_mean, abs_mean+, abs_mean-: 10.2291 6.51939 25.3426
U_c = [[-0.05026222]] U_f = [[ 0.]] b_c = [ 0.31508848] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.344125 -0.344037 -0.103154 0.342686
W_f max, min, mean, abs_mean: 0.0909363 -0.0906666 -0.0261387 0.0891329
Epoch 7/300
0s - loss: 3391.3793 - val_loss: 9076.4476
Epoch 00006: val_loss did not improve
Epoch 8/300
0s - loss: 3242.5086 - val_loss: 8557.1322
Epoch 00007: val_loss improved from 8858.39090 to 8557.13223, saving model to baoding0_weights.hdf5
            baoding0 3140.7950      0.88  0.18  0.74      0.91  0.14  0.79      0.91  0.12  0.81
            baoding0 8557.1323      0.98  0.08  0.90      0.99  0.06  0.93      0.99  0.03  0.96
forget mean min: 0.953372 0.382475
incx.max(), incx.min(), incx.mean() 8.58542 -6.73847 6.78052
fgtx.max(), fgtx.min(), fgtx.mean() 1.8289 -1.58763 1.42647
abs_mean, abs_mean+, abs_mean-: 12.942 7.65595 28.6253
U_c = [[-0.05020945]] U_f = [[ 0.]] b_c = [ 0.3824378] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.41189 -0.411799 -0.12348 0.410447
W_f max, min, mean, abs_mean: 0.0933186 -0.0930373 -0.0268557 0.0915115
Epoch 9/300
0s - loss: 3161.4446 - val_loss: 8644.5592
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 3110.1501 - val_loss: 8448.3031
Epoch 00009: val_loss improved from 8557.13223 to 8448.30311, saving model to baoding0_weights.hdf5
            baoding0 3030.2940      0.90  0.21  0.73      0.93  0.17  0.77      0.93  0.15  0.80
            baoding0 8448.3030      0.97  0.08  0.89      0.98  0.05  0.92      0.99  0.03  0.96
forget mean min: 0.948654 0.367509
incx.max(), incx.min(), incx.mean() 9.91333 -8.00325 7.70232
fgtx.max(), fgtx.min(), fgtx.mean() 1.86334 -1.66245 1.42822
abs_mean, abs_mean+, abs_mean-: 14.8904 8.73733 34.3961
U_c = [[-0.05100622]] U_f = [[ 0.]] b_c = [ 0.44467571] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.475028 -0.474935 -0.142417 0.47358
W_f max, min, mean, abs_mean: 0.0950098 -0.094723 -0.0273609 0.0931962
Epoch 11/300
0s - loss: 3076.1954 - val_loss: 8441.3789
Epoch 00010: val_loss improved from 8448.30311 to 8441.37888, saving model to baoding0_weights.hdf5
            baoding0 2967.5241      0.90  0.20  0.73      0.92  0.17  0.78      0.92  0.14  0.81
            baoding0 8441.3789      0.96  0.09  0.88      0.96  0.06  0.91      0.98  0.03  0.95
forget mean min: 0.942777 0.385161
incx.max(), incx.min(), incx.mean() 10.344 -8.1976 7.91286
fgtx.max(), fgtx.min(), fgtx.mean() 1.79543 -1.57419 1.3536
abs_mean, abs_mean+, abs_mean-: 15.4672 9.1672 31.345
U_c = [[-0.05286257]] U_f = [[ 0.]] b_c = [ 0.46456596] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.495576 -0.495482 -0.148579 0.494125
W_f max, min, mean, abs_mean: 0.0916147 -0.0913274 -0.026342 0.0897998
Epoch 12/300
0s - loss: 3040.6095 - val_loss: 8267.0344
Epoch 00011: val_loss improved from 8441.37888 to 8267.03437, saving model to baoding0_weights.hdf5
            baoding0 2942.1252      0.90  0.20  0.73      0.92  0.17  0.77      0.92  0.14  0.80
            baoding0 8267.0344      0.95  0.09  0.87      0.96  0.06  0.91      0.98  0.03  0.95
forget mean min: 0.940551 0.37744
incx.max(), incx.min(), incx.mean() 10.687 -8.55172 8.07275
fgtx.max(), fgtx.min(), fgtx.mean() 1.82252 -1.6128 1.35568
abs_mean, abs_mean+, abs_mean-: 16.143 9.53273 32.4314
U_c = [[-0.05448651]] U_f = [[ 0.]] b_c = [ 0.4805012] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.511935 -0.51184 -0.153484 0.510481
W_f max, min, mean, abs_mean: 0.0929744 -0.0926838 -0.0267469 0.0911532
Epoch 13/300
0s - loss: 3031.1794 - val_loss: 8479.9043
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 3016.7380 - val_loss: 8756.6005
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 3005.0490 - val_loss: 8400.2826
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 3005.5970 - val_loss: 8570.0311
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 2997.3758 - val_loss: 8348.7643
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 2983.8971 - val_loss: 8697.7286
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 2991.4429 - val_loss: 8219.3809
Epoch 00018: val_loss improved from 8267.03437 to 8219.38094, saving model to baoding0_weights.hdf5
            baoding0 2874.0498      0.90  0.23  0.71      0.93  0.19  0.76      0.93  0.16  0.79
            baoding0 8219.3811      0.96  0.10  0.87      0.96  0.07  0.90      0.98  0.04  0.94
forget mean min: 0.940781 0.361896
incx.max(), incx.min(), incx.mean() 11.7708 -9.19271 8.7345
fgtx.max(), fgtx.min(), fgtx.mean() 1.9547 -1.69052 1.42671
abs_mean, abs_mean+, abs_mean-: 17.5765 10.2564 38.657
U_c = [[-0.05640941]] U_f = [[ 0.]] b_c = [ 0.52946854] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.563807 -0.563705 -0.169027 0.562332
W_f max, min, mean, abs_mean: 0.0995963 -0.0993187 -0.0287377 0.0977808
Epoch 20/300
0s - loss: 2973.4663 - val_loss: 8337.5688
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 2963.9387 - val_loss: 8363.7160
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 2938.6564 - val_loss: 8016.1295
Epoch 00021: val_loss improved from 8219.38094 to 8016.12947, saving model to baoding0_weights.hdf5
            baoding0 2853.2146      0.91  0.23  0.71      0.93  0.20  0.76      0.93  0.17  0.79
            baoding0 8016.1294      0.96  0.09  0.88      0.97  0.06  0.91      0.98  0.04  0.95
forget mean min: 0.942356 0.350571
incx.max(), incx.min(), incx.mean() 11.8613 -9.22718 8.75421
fgtx.max(), fgtx.min(), fgtx.mean() 2.02815 -1.74714 1.47191
abs_mean, abs_mean+, abs_mean-: 17.6856 10.4913 38.1359
U_c = [[-0.05207889]] U_f = [[ 0.]] b_c = [ 0.53223711] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.56838 -0.568276 -0.170394 0.5669
W_f max, min, mean, abs_mean: 0.103305 -0.103034 -0.0298488 0.101488
Epoch 23/300
0s - loss: 2946.2780 - val_loss: 8261.2483
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 2943.5683 - val_loss: 8138.3077
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 2935.8804 - val_loss: 7977.5229
Epoch 00024: val_loss improved from 8016.12947 to 7977.52294, saving model to baoding0_weights.hdf5
            baoding0 2851.9544      0.90  0.24  0.70      0.93  0.21  0.74      0.94  0.18  0.78
            baoding0 7977.5230      0.98  0.09  0.89      0.99  0.06  0.92      0.99  0.04  0.95
forget mean min: 0.944947 0.343976
incx.max(), incx.min(), incx.mean() 11.8819 -9.09407 8.77623
fgtx.max(), fgtx.min(), fgtx.mean() 2.09914 -1.78012 1.52477
abs_mean, abs_mean+, abs_mean-: 17.6811 10.4057 40.3018
U_c = [[-0.0525231]] U_f = [[ 0.]] b_c = [ 0.53146005] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.569537 -0.569431 -0.170739 0.568054
W_f max, min, mean, abs_mean: 0.106872 -0.106609 -0.0309179 0.105055
Epoch 26/300
0s - loss: 2919.7281 - val_loss: 8117.3266
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 2929.1822 - val_loss: 7883.7905
Epoch 00026: val_loss improved from 7977.52294 to 7883.79051, saving model to baoding0_weights.hdf5
            baoding0 2789.4842      0.89  0.23  0.71      0.92  0.19  0.76      0.92  0.16  0.79
            baoding0 7883.7906      0.98  0.10  0.89      0.99  0.06  0.92      0.99  0.04  0.95
forget mean min: 0.94355 0.350251
incx.max(), incx.min(), incx.mean() 11.8 -8.9453 8.63974
fgtx.max(), fgtx.min(), fgtx.mean() 2.08144 -1.74875 1.49795
abs_mean, abs_mean+, abs_mean-: 17.6708 10.3885 38.7151
U_c = [[-0.05432049]] U_f = [[ 0.]] b_c = [ 0.52642077] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.565832 -0.565725 -0.169626 0.564347
W_f max, min, mean, abs_mean: 0.106014 -0.105755 -0.0306598 0.104195
Epoch 28/300
0s - loss: 2923.9652 - val_loss: 7947.6351
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 2917.9573 - val_loss: 7862.3204
Epoch 00028: val_loss improved from 7883.79051 to 7862.32040, saving model to baoding0_weights.hdf5
            baoding0 2798.7542      0.90  0.23  0.71      0.93  0.20  0.75      0.93  0.17  0.78
            baoding0 7862.3204      0.98  0.10  0.88      0.99  0.07  0.92      1.00  0.04  0.95
forget mean min: 0.945169 0.347843
incx.max(), incx.min(), incx.mean() 11.8588 -8.91413 8.69855
fgtx.max(), fgtx.min(), fgtx.mean() 2.11304 -1.76078 1.52369
abs_mean, abs_mean+, abs_mean-: 17.6002 10.3533 39.5645
U_c = [[-0.05418803]] U_f = [[ 0.]] b_c = [ 0.52791381] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.568782 -0.568674 -0.17051 0.567296
W_f max, min, mean, abs_mean: 0.107614 -0.107361 -0.0311372 0.105792
Epoch 30/300
0s - loss: 2925.5231 - val_loss: 7814.6065
Epoch 00029: val_loss improved from 7862.32040 to 7814.60653, saving model to baoding0_weights.hdf5
            baoding0 2784.8145      0.90  0.21  0.72      0.92  0.19  0.76      0.92  0.16  0.79
            baoding0 7814.6064      0.97  0.10  0.88      0.98  0.07  0.92      0.99  0.05  0.95
forget mean min: 0.942764 0.35797
incx.max(), incx.min(), incx.mean() 11.8408 -8.585 8.57379
fgtx.max(), fgtx.min(), fgtx.mean() 2.12359 -1.71015 1.5104
abs_mean, abs_mean+, abs_mean-: 17.7912 10.4484 38.1748
U_c = [[-0.05336955]] U_f = [[ 0.]] b_c = [ 0.52655596] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.568037 -0.567929 -0.170287 0.566551
W_f max, min, mean, abs_mean: 0.108161 -0.107908 -0.0313005 0.106337
Epoch 31/300
0s - loss: 2909.7441 - val_loss: 7811.0936
Epoch 00030: val_loss improved from 7814.60653 to 7811.09364, saving model to baoding0_weights.hdf5
            baoding0 2775.6144      0.89  0.22  0.72      0.92  0.19  0.76      0.92  0.16  0.79
            baoding0 7811.0935      0.98  0.10  0.88      0.99  0.07  0.92      0.99  0.05  0.95
forget mean min: 0.943358 0.370197
incx.max(), incx.min(), incx.mean() 11.8775 -8.42246 8.61929
fgtx.max(), fgtx.min(), fgtx.mean() 2.09119 -1.64902 1.49087
abs_mean, abs_mean+, abs_mean-: 17.6954 10.4458 37.6344
U_c = [[-0.05389512]] U_f = [[ 0.]] b_c = [ 0.52760041] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.569912 -0.569803 -0.170849 0.568426
W_f max, min, mean, abs_mean: 0.106557 -0.106309 -0.030817 0.104731
Epoch 32/300
0s - loss: 2930.7547 - val_loss: 7807.9895
Epoch 00031: val_loss improved from 7811.09364 to 7807.98947, saving model to baoding0_weights.hdf5
            baoding0 2779.9970      0.89  0.21  0.72      0.91  0.18  0.76      0.92  0.15  0.79
            baoding0 7807.9894      0.98  0.10  0.88      0.98  0.07  0.92      0.99  0.05  0.95
forget mean min: 0.942755 0.362407
incx.max(), incx.min(), incx.mean() 11.8828 -8.52909 8.58101
fgtx.max(), fgtx.min(), fgtx.mean() 2.11657 -1.68797 1.50116
abs_mean, abs_mean+, abs_mean-: 17.7852 10.3785 38.6656
U_c = [[-0.05578856]] U_f = [[ 0.]] b_c = [ 0.52709919] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.57017 -0.57006 -0.170926 0.568683
W_f max, min, mean, abs_mean: 0.107824 -0.107576 -0.0311966 0.105997
Epoch 33/300
0s - loss: 2920.4145 - val_loss: 7706.2161
Epoch 00032: val_loss improved from 7807.98947 to 7706.21608, saving model to baoding0_weights.hdf5
            baoding0 2811.0395      0.90  0.23  0.71      0.93  0.20  0.75      0.93  0.17  0.78
            baoding0 7706.2161      0.99  0.10  0.89      1.00  0.07  0.93      1.00  0.04  0.95
forget mean min: 0.948267 0.351838
incx.max(), incx.min(), incx.mean() 11.9511 -8.64034 8.82119
fgtx.max(), fgtx.min(), fgtx.mean() 2.16825 -1.74081 1.57407
abs_mean, abs_mean+, abs_mean-: 17.5292 10.4559 40.1922
U_c = [[-0.0515941]] U_f = [[ 0.]] b_c = [ 0.52960563] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.573442 -0.57333 -0.171908 0.571954
W_f max, min, mean, abs_mean: 0.11041 -0.110163 -0.0319707 0.10858
Epoch 34/300
0s - loss: 2922.0058 - val_loss: 7734.9608
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 2919.5931 - val_loss: 7747.8044
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 2897.3556 - val_loss: 8141.5378
Epoch 00035: val_loss did not improve
Epoch 37/300
0s - loss: 2902.5181 - val_loss: 7513.2030
Epoch 00036: val_loss improved from 7706.21608 to 7513.20297, saving model to baoding0_weights.hdf5
            baoding0 2810.8174      0.91  0.23  0.71      0.93  0.20  0.76      0.94  0.17  0.78
            baoding0 7513.2030      0.99  0.10  0.89      0.99  0.06  0.93      1.00  0.04  0.96
forget mean min: 0.94644 0.343219
incx.max(), incx.min(), incx.mean() 12.0509 -8.89038 8.76633
fgtx.max(), fgtx.min(), fgtx.mean() 2.18098 -1.78391 1.55909
abs_mean, abs_mean+, abs_mean-: 17.6158 10.4569 39.508
U_c = [[-0.05019792]] U_f = [[ 0.]] b_c = [ 0.53169298] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.57855 -0.578433 -0.17344 0.577062
W_f max, min, mean, abs_mean: 0.111106 -0.110842 -0.0321727 0.109257
Epoch 38/300
0s - loss: 2902.5670 - val_loss: 7672.9630
Epoch 00037: val_loss did not improve
Epoch 39/300
0s - loss: 2899.1884 - val_loss: 7833.7189
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 2892.6172 - val_loss: 7603.3298
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 2886.6320 - val_loss: 8165.3720
Epoch 00040: val_loss did not improve
Epoch 42/300
0s - loss: 2880.5907 - val_loss: 7633.4960
Epoch 00041: val_loss did not improve
Epoch 43/300
0s - loss: 2874.1577 - val_loss: 7613.0268
Epoch 00042: val_loss did not improve
Epoch 44/300
0s - loss: 2850.6782 - val_loss: 7447.4147
Epoch 00043: val_loss improved from 7513.20297 to 7447.41471, saving model to baoding0_weights.hdf5
            baoding0 2746.8411      0.91  0.23  0.71      0.93  0.20  0.76      0.94  0.17  0.79
            baoding0 7447.4147      0.99  0.10  0.89      0.99  0.07  0.92      1.00  0.05  0.95
forget mean min: 0.94794 0.341775
incx.max(), incx.min(), incx.mean() 12.227 -8.48844 8.72687
fgtx.max(), fgtx.min(), fgtx.mean() 2.32056 -1.79113 1.62584
abs_mean, abs_mean+, abs_mean-: 17.5073 10.4136 39.3997
U_c = [[-0.04766013]] U_f = [[ 0.]] b_c = [ 0.53562623] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.587994 -0.587803 -0.176265 0.586482
W_f max, min, mean, abs_mean: 0.118365 -0.117923 -0.0343415 0.116408
Epoch 45/300
0s - loss: 2838.7101 - val_loss: 8101.7235
Epoch 00044: val_loss did not improve
Epoch 46/300
0s - loss: 2824.4322 - val_loss: 7810.3983
Epoch 00045: val_loss did not improve
Epoch 47/300
0s - loss: 2820.4608 - val_loss: 7906.7731
Epoch 00046: val_loss did not improve
Epoch 48/300
0s - loss: 2790.6506 - val_loss: 7352.5609
Epoch 00047: val_loss improved from 7447.41471 to 7352.56087, saving model to baoding0_weights.hdf5
            baoding0 2688.2798      0.91  0.23  0.72      0.93  0.20  0.76      0.94  0.17  0.79
            baoding0 7352.5609      1.00  0.10  0.90      1.00  0.08  0.92      1.00  0.06  0.94
forget mean min: 0.950308 0.353245
incx.max(), incx.min(), incx.mean() 12.3658 -7.88817 8.70635
fgtx.max(), fgtx.min(), fgtx.mean() 2.43303 -1.73378 1.68017
abs_mean, abs_mean+, abs_mean-: 17.2734 10.2478 40.2505
U_c = [[-0.0486708]] U_f = [[ 0.]] b_c = [ 0.53942913] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.595767 -0.595531 -0.178572 0.594193
W_f max, min, mean, abs_mean: 0.124399 -0.12391 -0.0361083 0.122243
Epoch 49/300
0s - loss: 2781.5910 - val_loss: 7645.8536
Epoch 00048: val_loss did not improve
Epoch 50/300
0s - loss: 2778.2602 - val_loss: 7421.5215
Epoch 00049: val_loss did not improve
Epoch 51/300
0s - loss: 2759.5713 - val_loss: 7877.5918
Epoch 00050: val_loss did not improve
Epoch 52/300
0s - loss: 2736.1866 - val_loss: 7719.0903
Epoch 00051: val_loss did not improve
Epoch 53/300
0s - loss: 2701.2487 - val_loss: 7374.2570
Epoch 00052: val_loss did not improve
Epoch 54/300
0s - loss: 2704.9606 - val_loss: 7363.1429
Epoch 00053: val_loss did not improve
Epoch 55/300
0s - loss: 2630.9265 - val_loss: 7678.4344
Epoch 00054: val_loss did not improve
Epoch 56/300
0s - loss: 2624.5920 - val_loss: 7418.0247
Epoch 00055: val_loss did not improve
Epoch 57/300
0s - loss: 2576.3427 - val_loss: 7535.8498
Epoch 00056: val_loss did not improve
Epoch 58/300
0s - loss: 2546.2898 - val_loss: 7390.9640
Epoch 00057: val_loss did not improve
Epoch 59/300
0s - loss: 2517.7012 - val_loss: 7176.0892
Epoch 00058: val_loss improved from 7352.56087 to 7176.08923, saving model to baoding0_weights.hdf5
            baoding0 2363.8168      0.92  0.21  0.74      0.95  0.17  0.79      0.95  0.15  0.82
            baoding0 7176.0891      0.99  0.11  0.88      0.99  0.09  0.90      0.99  0.06  0.93
forget mean min: 0.947785 0.427008
incx.max(), incx.min(), incx.mean() 13.6672 -5.69553 8.73698
fgtx.max(), fgtx.min(), fgtx.mean() 2.84599 -1.36496 1.77379
abs_mean, abs_mean+, abs_mean-: 17.4725 10.5398 37.9458
U_c = [[-0.03829492]] U_f = [[ 0.]] b_c = [ 0.58061445] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.664894 -0.664508 -0.199109 0.662821
W_f max, min, mean, abs_mean: 0.14716 -0.146747 -0.0427901 0.144146
Epoch 60/300
0s - loss: 2483.0846 - val_loss: 7415.2249
Epoch 00059: val_loss did not improve
Epoch 61/300
0s - loss: 2435.5712 - val_loss: 7210.2975
Epoch 00060: val_loss did not improve
Epoch 62/300
0s - loss: 2420.5896 - val_loss: 7098.6541
Epoch 00061: val_loss improved from 7176.08923 to 7098.65407, saving model to baoding0_weights.hdf5
            baoding0 2268.7264      0.92  0.20  0.75      0.94  0.16  0.79      0.95  0.15  0.82
            baoding0 7098.6541      0.99  0.10  0.89      0.98  0.08  0.90      0.99  0.06  0.93
forget mean min: 0.945925 0.399567
incx.max(), incx.min(), incx.mean() 14.2662 -6.35767 8.82666
fgtx.max(), fgtx.min(), fgtx.mean() 2.95084 -1.50217 1.77638
abs_mean, abs_mean+, abs_mean-: 17.5502 10.7998 36.2752
U_c = [[-0.03547506]] U_f = [[ 0.]] b_c = [ 0.59919524] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.696796 -0.69636 -0.208617 0.694558
W_f max, min, mean, abs_mean: 0.153384 -0.153095 -0.0445825 0.149963
Epoch 63/300
0s - loss: 2375.9920 - val_loss: 7280.2367
Epoch 00062: val_loss did not improve
Epoch 64/300
0s - loss: 2359.5118 - val_loss: 7171.5637
Epoch 00063: val_loss did not improve
Epoch 65/300
0s - loss: 2333.3007 - val_loss: 7268.5197
Epoch 00064: val_loss did not improve
Epoch 66/300
0s - loss: 2320.6978 - val_loss: 7187.4791
Epoch 00065: val_loss did not improve
Epoch 67/300
0s - loss: 2295.0482 - val_loss: 7123.5076
Epoch 00066: val_loss did not improve
Epoch 68/300
0s - loss: 2268.8693 - val_loss: 6924.9638
Epoch 00067: val_loss improved from 7098.65407 to 6924.96382, saving model to baoding0_weights.hdf5
            baoding0 2197.6620      0.92  0.19  0.76      0.95  0.16  0.80      0.96  0.14  0.83
            baoding0 6924.9638      0.98  0.09  0.89      0.98  0.07  0.91      0.99  0.05  0.93
forget mean min: 0.944367 0.352887
incx.max(), incx.min(), incx.mean() 15.1578 -7.17412 8.9262
fgtx.max(), fgtx.min(), fgtx.mean() 3.23756 -1.73557 1.84981
abs_mean, abs_mean+, abs_mean-: 17.5183 10.8895 35.8717
U_c = [[-0.03671924]] U_f = [[ 0.]] b_c = [ 0.61913764] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.746231 -0.74565 -0.223328 0.743647
W_f max, min, mean, abs_mean: 0.170158 -0.170086 -0.0493755 0.165603
Epoch 69/300
0s - loss: 2255.9155 - val_loss: 7184.8591
Epoch 00068: val_loss did not improve
Epoch 70/300
0s - loss: 2239.7941 - val_loss: 7264.0666
Epoch 00069: val_loss did not improve
Epoch 71/300
0s - loss: 2228.1112 - val_loss: 6928.7676
Epoch 00070: val_loss did not improve
Epoch 72/300
0s - loss: 2212.9822 - val_loss: 7094.0564
Epoch 00071: val_loss did not improve
Epoch 73/300
0s - loss: 2197.7997 - val_loss: 7002.3124
Epoch 00072: val_loss did not improve
Epoch 74/300
0s - loss: 2184.5390 - val_loss: 6913.1341
Epoch 00073: val_loss improved from 6924.96382 to 6913.13412, saving model to baoding0_weights.hdf5
            baoding0 2061.2144      0.92  0.19  0.76      0.95  0.15  0.81      0.96  0.14  0.84
            baoding0 6913.1342      0.98  0.09  0.90      0.97  0.07  0.90      0.98  0.06  0.93
forget mean min: 0.941936 0.348655
incx.max(), incx.min(), incx.mean() 15.7499 -7.30029 8.92445
fgtx.max(), fgtx.min(), fgtx.mean() 3.35185 -1.75673 1.83897
abs_mean, abs_mean+, abs_mean-: 17.6453 11.0311 35.0785
U_c = [[-0.03774993]] U_f = [[ 0.]] b_c = [ 0.6263023] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.782392 -0.781661 -0.234124 0.779592
W_f max, min, mean, abs_mean: 0.178667 -0.179109 -0.0516154 0.172788
Epoch 75/300
0s - loss: 2161.7333 - val_loss: 7076.6366
Epoch 00074: val_loss did not improve
Epoch 76/300
0s - loss: 2145.7184 - val_loss: 7280.5274
Epoch 00075: val_loss did not improve
Epoch 77/300
0s - loss: 2133.3881 - val_loss: 6893.4660
Epoch 00076: val_loss improved from 6913.13412 to 6893.46600, saving model to baoding0_weights.hdf5
            baoding0 2061.9629      0.93  0.19  0.76      0.95  0.16  0.81      0.96  0.14  0.83
            baoding0 6893.4661      0.97  0.08  0.90      0.97  0.06  0.91      0.97  0.04  0.93
forget mean min: 0.94176 0.359364
incx.max(), incx.min(), incx.mean() 15.9958 -6.91714 8.99495
fgtx.max(), fgtx.min(), fgtx.mean() 3.47134 -1.70318 1.89004
abs_mean, abs_mean+, abs_mean-: 17.7602 11.1043 36.2022
U_c = [[-0.03631666]] U_f = [[ 0.]] b_c = [ 0.62524343] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.795256 -0.794458 -0.237965 0.79234
W_f max, min, mean, abs_mean: 0.185411 -0.185863 -0.0534943 0.178953
Epoch 78/300
0s - loss: 2115.6944 - val_loss: 7012.2430
Epoch 00077: val_loss did not improve
Epoch 79/300
0s - loss: 2115.8293 - val_loss: 6917.2454
Epoch 00078: val_loss did not improve
Epoch 80/300
0s - loss: 2097.0063 - val_loss: 7090.5093
Epoch 00079: val_loss did not improve
Epoch 81/300
0s - loss: 2082.9010 - val_loss: 7018.9698
Epoch 00080: val_loss did not improve
Epoch 82/300
0s - loss: 2061.0230 - val_loss: 7243.7865
Epoch 00081: val_loss did not improve
Epoch 83/300
0s - loss: 2053.4582 - val_loss: 7565.1691
Epoch 00082: val_loss did not improve
Epoch 84/300
0s - loss: 2036.0072 - val_loss: 7364.2573
Epoch 00083: val_loss did not improve
Epoch 85/300
0s - loss: 2023.3909 - val_loss: 7555.3792
Epoch 00084: val_loss did not improve
Epoch 86/300
0s - loss: 2021.4639 - val_loss: 7555.0295
Epoch 00085: val_loss did not improve
Epoch 87/300
0s - loss: 1979.1612 - val_loss: 7307.0969
Epoch 00086: val_loss did not improve
Epoch 88/300
0s - loss: 1978.4767 - val_loss: 7352.7684
Epoch 00087: val_loss did not improve
Epoch 89/300
0s - loss: 1958.6562 - val_loss: 7213.3208
Epoch 00088: val_loss did not improve
Epoch 90/300
0s - loss: 1949.8216 - val_loss: 7223.6670
Epoch 00089: val_loss did not improve
Epoch 91/300
0s - loss: 1933.6372 - val_loss: 7229.6413
Epoch 00090: val_loss did not improve
Epoch 92/300
0s - loss: 1905.0430 - val_loss: 7475.7008
Epoch 00091: val_loss did not improve
Epoch 93/300
0s - loss: 1905.3692 - val_loss: 7511.9188
Epoch 00092: val_loss did not improve
Epoch 94/300
0s - loss: 1888.4536 - val_loss: 7199.6772
Epoch 00093: val_loss did not improve
Epoch 95/300
0s - loss: 1882.2466 - val_loss: 7519.0334
Epoch 00094: val_loss did not improve
Epoch 96/300
0s - loss: 1864.1450 - val_loss: 7302.1774
Epoch 00095: val_loss did not improve
Epoch 97/300
0s - loss: 1860.9430 - val_loss: 7464.1459
Epoch 00096: val_loss did not improve
Epoch 98/300
0s - loss: 1854.3069 - val_loss: 7656.3089
Epoch 00097: val_loss did not improve
Epoch 99/300
0s - loss: 1831.9437 - val_loss: 7967.7097
Epoch 00098: val_loss did not improve
Epoch 100/300
0s - loss: 1832.4300 - val_loss: 7337.0986
Epoch 00099: val_loss did not improve
Epoch 101/300
0s - loss: 1804.7546 - val_loss: 7455.1864
Epoch 00100: val_loss did not improve
Epoch 102/300
0s - loss: 1796.6198 - val_loss: 7571.0222
Epoch 00101: val_loss did not improve
Epoch 103/300
0s - loss: 1766.9078 - val_loss: 7493.7885
Epoch 00102: val_loss did not improve
Epoch 104/300
0s - loss: 1739.1006 - val_loss: 8127.9249
Epoch 00103: val_loss did not improve
Epoch 105/300
0s - loss: 1729.1995 - val_loss: 7548.1089
Epoch 00104: val_loss did not improve
Epoch 106/300
0s - loss: 1687.2928 - val_loss: 7325.1775
Epoch 00105: val_loss did not improve
Epoch 107/300
0s - loss: 1683.4859 - val_loss: 7628.2389
Epoch 00106: val_loss did not improve
Epoch 108/300
0s - loss: 1678.7556 - val_loss: 7503.9454
Epoch 00107: val_loss did not improve
X_train[0].shape = (4466, 40, 23)

training shijiazhuang0
Train on 4466 samples, validate on 1190 samples
Before training:
       shijiazhuang012769.1938      0.03  -nan  0.03      0.03  -nan  0.03      0.03  -nan  0.03
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.54073 nan 4.54073
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
       shijiazhuang032969.4315      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.06
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 10.9447 nan 10.9447
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 9547.9246 - val_loss: 14940.1868
Epoch 00000: val_loss improved from inf to 14940.18675, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 5517.1569      0.45  0.04  0.44      0.46  0.03  0.45      0.45  0.02  0.45
       shijiazhuang014940.1866      0.66  0.17  0.58      0.65  0.13  0.59      0.63  0.10  0.58
forget mean min: 0.847607 0.327521
incx.max(), incx.min(), incx.mean() 1.9407 -1.86316 0.870659
fgtx.max(), fgtx.min(), fgtx.mean() 1.78108 -1.86239 0.756155
abs_mean, abs_mean+, abs_mean-: 10.4284 1.51071 12.9038
U_c = [[-0.11171544]] U_f = [[ 0.]] b_c = [ 0.08121776] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.10465 -0.104423 0.0304622 0.103081
W_f max, min, mean, abs_mean: 0.0990778 -0.0996978 0.0295474 0.0987353
Epoch 2/300
0s - loss: 4473.5951 - val_loss: 11935.8641
Epoch 00001: val_loss improved from 14940.18675 to 11935.86414, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 3530.1140      0.62  0.09  0.58      0.63  0.07  0.60      0.62  0.05  0.60
       shijiazhuang011935.8642      0.87  0.20  0.71      0.86  0.16  0.74      0.87  0.11  0.78
forget mean min: 0.926903 0.157365
incx.max(), incx.min(), incx.mean() 3.51973 -3.26695 2.4733
fgtx.max(), fgtx.min(), fgtx.mean() 2.67656 -2.71318 1.84552
abs_mean, abs_mean+, abs_mean-: 7.04186 3.10841 25.7675
U_c = [[-0.08091424]] U_f = [[ 0.]] b_c = [ 0.14944609] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.174461 -0.174239 0.0514029 0.172885
W_f max, min, mean, abs_mean: 0.137637 -0.138263 0.0411179 0.137299
Epoch 3/300
0s - loss: 3134.1514 - val_loss: 12794.2582
Epoch 00002: val_loss did not improve
Epoch 4/300
0s - loss: 2752.2954 - val_loss: 11356.3921
Epoch 00003: val_loss improved from 11935.86414 to 11356.39210, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2607.7554      0.82  0.22  0.66      0.84  0.21  0.69      0.83  0.19  0.70
       shijiazhuang011356.3920      0.88  0.19  0.73      0.87  0.15  0.76      0.88  0.10  0.80
forget mean min: 0.934357 0.339658
incx.max(), incx.min(), incx.mean() 6.0384 -5.51623 4.54139
fgtx.max(), fgtx.min(), fgtx.mean() 1.79896 -1.80171 1.33246
abs_mean, abs_mean+, abs_mean-: 9.49516 5.62207 23.6735
U_c = [[-0.06471168]] U_f = [[ 0.]] b_c = [ 0.26549184] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.291269 -0.291053 0.086443 0.289687
W_f max, min, mean, abs_mean: 0.0906618 -0.0912006 0.0270176 0.0902725
Epoch 5/300
0s - loss: 2542.2655 - val_loss: 10969.8212
Epoch 00004: val_loss improved from 11356.39210 to 10969.82124, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2446.1674      0.85  0.24  0.67      0.86  0.22  0.69      0.86  0.20  0.70
       shijiazhuang010969.8213      0.87  0.19  0.73      0.87  0.14  0.76      0.88  0.10  0.80
forget mean min: 0.931183 0.342122
incx.max(), incx.min(), incx.mean() 7.08256 -6.45533 5.22478
fgtx.max(), fgtx.min(), fgtx.mean() 1.78857 -1.78939 1.29758
abs_mean, abs_mean+, abs_mean-: 10.6584 6.35235 27.0063
U_c = [[-0.06288047]] U_f = [[ 0.]] b_c = [ 0.3151561] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.340655 -0.34044 0.101259 0.339072
W_f max, min, mean, abs_mean: 0.0900197 -0.0905543 0.0268194 0.0896142
Epoch 6/300
0s - loss: 2402.8501 - val_loss: 10611.4626
Epoch 00005: val_loss improved from 10969.82124 to 10611.46258, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2339.4223      0.87  0.26  0.67      0.89  0.24  0.69      0.89  0.22  0.71
       shijiazhuang010611.4625      0.89  0.18  0.74      0.88  0.14  0.77      0.89  0.10  0.81
forget mean min: 0.937123 0.33031
incx.max(), incx.min(), incx.mean() 7.9097 -7.17788 5.88352
fgtx.max(), fgtx.min(), fgtx.mean() 1.85392 -1.84845 1.3567
abs_mean, abs_mean+, abs_mean-: 11.2758 7.08469 26.563
U_c = [[-0.06360929]] U_f = [[ 0.]] b_c = [ 0.35477927] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.380028 -0.379815 0.113071 0.378445
W_f max, min, mean, abs_mean: 0.0932818 -0.0938114 0.0277951 0.0928674
Epoch 7/300
0s - loss: 2294.1745 - val_loss: 9787.0038
Epoch 00006: val_loss improved from 10611.46258 to 9787.00378, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2218.0758      0.87  0.25  0.67      0.89  0.23  0.70      0.88  0.21  0.71
       shijiazhuang0 9787.0038      0.91  0.19  0.75      0.90  0.15  0.78      0.90  0.11  0.81
forget mean min: 0.938224 0.336168
incx.max(), incx.min(), incx.mean() 8.5952 -7.46934 6.29266
fgtx.max(), fgtx.min(), fgtx.mean() 1.90067 -1.81916 1.3675
abs_mean, abs_mean+, abs_mean-: 11.8145 7.49597 24.808
U_c = [[-0.06515145]] U_f = [[ 0.]] b_c = [ 0.38693786] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.412849 -0.412639 0.122918 0.411267
W_f max, min, mean, abs_mean: 0.0956547 -0.096178 0.028504 0.0952311
Epoch 8/300
0s - loss: 2208.2890 - val_loss: 9419.1253
Epoch 00007: val_loss improved from 9787.00378 to 9419.12535, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2154.9489      0.87  0.25  0.67      0.88  0.23  0.70      0.87  0.21  0.71
       shijiazhuang0 9419.1254      0.90  0.20  0.74      0.90  0.15  0.77      0.91  0.11  0.82
forget mean min: 0.932377 0.314406
incx.max(), incx.min(), incx.mean() 9.15895 -8.06377 6.46976
fgtx.max(), fgtx.min(), fgtx.mean() 1.98985 -1.92797 1.37811
abs_mean, abs_mean+, abs_mean-: 12.9037 7.87463 27.0467
U_c = [[-0.06393303]] U_f = [[ 0.]] b_c = [ 0.41157779] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.440097 -0.439891 0.131093 0.438516
W_f max, min, mean, abs_mean: 0.100183 -0.100703 0.0298602 0.0997535
Epoch 9/300
0s - loss: 2180.3182 - val_loss: 9114.0479
Epoch 00008: val_loss improved from 9419.12535 to 9114.04795, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2142.8801      0.87  0.26  0.67      0.89  0.24  0.70      0.89  0.22  0.71
       shijiazhuang0 9114.0479      0.90  0.19  0.74      0.91  0.15  0.78      0.91  0.10  0.83
forget mean min: 0.931494 0.301952
incx.max(), incx.min(), incx.mean() 9.59329 -8.42951 6.72653
fgtx.max(), fgtx.min(), fgtx.mean() 2.05837 -1.99024 1.41439
abs_mean, abs_mean+, abs_mean-: 13.6342 8.26175 29.7734
U_c = [[-0.06272241]] U_f = [[ 0.]] b_c = [ 0.43023518] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.460957 -0.460755 0.137351 0.459377
W_f max, min, mean, abs_mean: 0.103625 -0.104144 0.030892 0.103194
Epoch 10/300
0s - loss: 2162.9330 - val_loss: 9113.0851
Epoch 00009: val_loss improved from 9114.04795 to 9113.08509, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2126.1081      0.87  0.26  0.67      0.89  0.24  0.69      0.89  0.22  0.71
       shijiazhuang0 9113.0852      0.90  0.19  0.74      0.91  0.15  0.78      0.92  0.10  0.83
forget mean min: 0.930278 0.293773
incx.max(), incx.min(), incx.mean() 9.94849 -8.6784 6.89501
fgtx.max(), fgtx.min(), fgtx.mean() 2.11572 -2.03114 1.43593
abs_mean, abs_mean+, abs_mean-: 14.219 8.52412 31.9714
U_c = [[-0.06390852]] U_f = [[ 0.]] b_c = [ 0.44507971] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.478087 -0.477889 0.142491 0.476508
W_f max, min, mean, abs_mean: 0.106517 -0.107034 0.0317591 0.106084
Epoch 11/300
0s - loss: 2150.1726 - val_loss: 9323.3682
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 2135.0096 - val_loss: 9128.1385
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 2127.0744 - val_loss: 9285.7096
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 2123.7552 - val_loss: 9454.2421
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 2118.4159 - val_loss: 9323.0049
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 2106.9615 - val_loss: 9525.9501
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 2106.4084 - val_loss: 9603.2106
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 2100.6314 - val_loss: 9550.9273
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 2095.0772 - val_loss: 9587.4855
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 2097.5183 - val_loss: 9621.9977
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 2104.4586 - val_loss: 9617.0080
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 2095.3089 - val_loss: 9751.6619
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 2092.8887 - val_loss: 9592.7825
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 2088.4263 - val_loss: 10030.3896
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 2093.0470 - val_loss: 9728.5207
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 2098.8516 - val_loss: 9852.6211
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 2092.3212 - val_loss: 9811.2420
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 2086.1383 - val_loss: 9783.2851
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 2087.2119 - val_loss: 9709.5960
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 2085.0551 - val_loss: 10047.6045
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 2092.2412 - val_loss: 10069.9089
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 2073.7098 - val_loss: 10062.1854
Epoch 00031: val_loss did not improve
Epoch 33/300
0s - loss: 2089.4715 - val_loss: 10237.9727
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 2075.5619 - val_loss: 9954.4456
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 2072.3471 - val_loss: 10182.2043
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 2073.0206 - val_loss: 10070.2428
Epoch 00035: val_loss did not improve
Epoch 37/300
0s - loss: 2069.1969 - val_loss: 10101.3732
Epoch 00036: val_loss did not improve
Epoch 38/300
0s - loss: 2065.8637 - val_loss: 10297.0404
Epoch 00037: val_loss did not improve
Epoch 39/300
0s - loss: 2063.0416 - val_loss: 10082.6419
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 2056.1017 - val_loss: 10005.3748
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 2052.3376 - val_loss: 10256.9167
Epoch 00040: val_loss did not improve
X_train[0].shape = (5104, 40, 23)

training xingtai+handan0
Train on 5104 samples, validate on 1360 samples
Before training:
     xingtai+handan012800.2606      0.02  -nan  0.02      0.02  -nan  0.02      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.24962 nan 5.24962
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
     xingtai+handan035415.5832      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.06
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 11.8751 nan 11.8751
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 9097.7511 - val_loss: 13123.5052
Epoch 00000: val_loss improved from inf to 13123.50524, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 5594.6028      0.37  0.09  0.36      0.38  0.05  0.37      0.36  0.04  0.36
     xingtai+handan013123.5051      0.76  0.10  0.70      0.76  0.06  0.72      0.75  0.04  0.72
forget mean min: 0.852702 0.303349
incx.max(), incx.min(), incx.mean() 2.12399 -2.07944 0.97043
fgtx.max(), fgtx.min(), fgtx.mean() 1.85955 -1.98326 0.804952
abs_mean, abs_mean+, abs_mean-: 11.7937 1.74522 16.7727
U_c = [[-0.12593573]] U_f = [[ 0.]] b_c = [ 0.08993741] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.115856 -0.115564 0.0346722 0.11426
W_f max, min, mean, abs_mean: 0.105481 -0.105507 0.0312131 0.104457
Epoch 2/300
0s - loss: 4400.2892 - val_loss: 9661.4835
Epoch 00001: val_loss improved from 13123.50524 to 9661.48347, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 3405.7873      0.71  0.22  0.59      0.72  0.18  0.63      0.69  0.16  0.62
     xingtai+handan0 9661.4835      0.92  0.14  0.80      0.91  0.11  0.82      0.90  0.08  0.84
forget mean min: 0.94683 0.127203
incx.max(), incx.min(), incx.mean() 3.77042 -3.58202 2.7345
fgtx.max(), fgtx.min(), fgtx.mean() 2.75426 -2.86399 1.96267
abs_mean, abs_mean+, abs_mean-: 6.61213 3.26524 23.0556
U_c = [[-0.09132233]] U_f = [[ 0.]] b_c = [ 0.16599816] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.194298 -0.194003 0.0582062 0.192706
W_f max, min, mean, abs_mean: 0.14828 -0.148362 0.0440443 0.147253
Epoch 3/300
0s - loss: 3085.1676 - val_loss: 8932.0125
Epoch 00002: val_loss improved from 9661.48347 to 8932.01253, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2875.3513      0.84  0.27  0.64      0.85  0.23  0.68      0.84  0.21  0.68
     xingtai+handan0 8932.0124      0.93  0.13  0.82      0.92  0.10  0.84      0.92  0.08  0.85
forget mean min: 0.952059 0.215875
incx.max(), incx.min(), incx.mean() 5.39746 -4.92918 4.09702
fgtx.max(), fgtx.min(), fgtx.mean() 2.42027 -2.42062 1.81065
abs_mean, abs_mean+, abs_mean-: 8.16373 4.79718 25.2964
U_c = [[-0.06707514]] U_f = [[ 0.]] b_c = [ 0.23451464] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.2632 -0.262902 0.0788771 0.261611
W_f max, min, mean, abs_mean: 0.123661 -0.123757 0.0366473 0.122637
Epoch 4/300
0s - loss: 2785.1334 - val_loss: 7458.2564
Epoch 00003: val_loss improved from 8932.01253 to 7458.25636, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2682.3186      0.86  0.27  0.65      0.88  0.23  0.69      0.87  0.21  0.71
     xingtai+handan0 7458.2563      0.94  0.13  0.82      0.93  0.10  0.84      0.93  0.08  0.86
forget mean min: 0.950483 0.257811
incx.max(), incx.min(), incx.mean() 6.66549 -6.03314 5.00664
fgtx.max(), fgtx.min(), fgtx.mean() 2.22663 -2.21094 1.64693
abs_mean, abs_mean+, abs_mean-: 9.98978 5.91067 27.5493
U_c = [[-0.06966607]] U_f = [[ 0.]] b_c = [ 0.29372981] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.321709 -0.32141 0.0964295 0.320122
W_f max, min, mean, abs_mean: 0.112879 -0.112943 0.0334193 0.111867
Epoch 5/300
0s - loss: 2642.8463 - val_loss: 6913.2796
Epoch 00004: val_loss improved from 7458.25636 to 6913.27960, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2588.7304      0.85  0.26  0.65      0.87  0.22  0.70      0.87  0.20  0.71
     xingtai+handan0 6913.2796      0.92  0.12  0.81      0.92  0.09  0.84      0.92  0.06  0.86
forget mean min: 0.938371 0.294989
incx.max(), incx.min(), incx.mean() 7.49987 -6.77331 5.41574
fgtx.max(), fgtx.min(), fgtx.mean() 2.04149 -2.02505 1.4477
abs_mean, abs_mean+, abs_mean-: 11.3962 6.62434 26.213
U_c = [[-0.0746973]] U_f = [[ 0.]] b_c = [ 0.3344374] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.360859 -0.360559 0.108174 0.359274
W_f max, min, mean, abs_mean: 0.103364 -0.103403 0.0305708 0.10236
Epoch 6/300
0s - loss: 2554.0980 - val_loss: 7165.2192
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 2365.0766 - val_loss: 7740.0173
Epoch 00006: val_loss did not improve
Epoch 8/300
0s - loss: 2275.3534 - val_loss: 8219.3710
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 2261.8459 - val_loss: 8187.3905
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 2254.6743 - val_loss: 8405.2214
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 2251.2127 - val_loss: 8315.2322
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 2249.4539 - val_loss: 8188.4657
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 2243.0208 - val_loss: 8321.0199
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 2242.4759 - val_loss: 8391.7247
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 2244.1624 - val_loss: 8332.8363
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 2256.0242 - val_loss: 8269.4485
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 2247.5278 - val_loss: 8332.6856
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 2240.9147 - val_loss: 8527.5504
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 2245.6213 - val_loss: 8301.4350
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 2247.3979 - val_loss: 8232.7607
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 2239.3807 - val_loss: 8361.7766
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 2247.5649 - val_loss: 8280.0059
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 2239.7626 - val_loss: 8249.8661
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 2246.0589 - val_loss: 8251.2742
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 2236.9781 - val_loss: 8313.4626
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 2221.5848 - val_loss: 8323.3262
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 2225.5317 - val_loss: 8393.1697
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 2221.5390 - val_loss: 8149.7494
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 2212.9242 - val_loss: 8183.9415
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 2194.2964 - val_loss: 8266.5202
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 2184.5937 - val_loss: 8130.0752
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 2157.7685 - val_loss: 8284.6109
Epoch 00031: val_loss did not improve
Epoch 33/300
0s - loss: 2136.1394 - val_loss: 8181.9384
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 2122.7150 - val_loss: 8246.9027
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 2107.7268 - val_loss: 8243.0694
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 2087.2551 - val_loss: 8241.0210
Epoch 00035: val_loss did not improve
X_train[0].shape = (3190, 40, 23)

training jinan0
Train on 3190 samples, validate on 850 samples
Before training:
              jinan012551.7119      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.82303 nan 5.82303
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              jinan030630.7377      0.04  -nan  0.04      0.05  -nan  0.04      0.04  -nan  0.04
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 10.3311 nan 10.3311
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 10758.8483 - val_loss: 21639.5503
Epoch 00000: val_loss improved from inf to 21639.55028, saving model to jinan0_weights.hdf5
              jinan0 7521.8482      0.20  0.10  0.20      0.20  0.07  0.20      0.20  0.03  0.20
              jinan021639.5503      0.24  0.01  0.24      0.23  0.00  0.23      0.22  0.00  0.22
forget mean min: 0.765292 0.434423
incx.max(), incx.min(), incx.mean() 1.44295 -1.20684 0.371715
fgtx.max(), fgtx.min(), fgtx.mean() 1.44914 -1.32789 0.326461
abs_mean, abs_mean+, abs_mean-: 13.5336 0.372317 13.5946
U_c = [[-0.10694647]] U_f = [[ 0.]] b_c = [ 0.06021168] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.084385 -0.0838264 0.0502882 0.08277
W_f max, min, mean, abs_mean: 0.0883124 -0.0876061 0.0523532 0.0867468
Epoch 2/300
0s - loss: 5532.4674 - val_loss: 10498.6433
Epoch 00001: val_loss improved from 21639.55028 to 10498.64326, saving model to jinan0_weights.hdf5
              jinan0 4300.7689      0.53  0.12  0.49      0.52  0.09  0.49      0.51  0.06  0.49
              jinan010498.6433      0.83  0.04  0.80      0.83  0.03  0.81      0.81  0.01  0.80
forget mean min: 0.902419 0.2869
incx.max(), incx.min(), incx.mean() 2.62543 -2.19979 1.37337
fgtx.max(), fgtx.min(), fgtx.mean() 2.25222 -2.0655 1.13183
abs_mean, abs_mean+, abs_mean-: 9.48208 1.95511 16.373
U_c = [[-0.14134169]] U_f = [[ 0.]] b_c = [ 0.10849451] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.1364 -0.135829 0.0814737 0.134761
W_f max, min, mean, abs_mean: 0.122172 -0.121453 0.0726503 0.120588
Epoch 3/300
0s - loss: 3810.4912 - val_loss: 7441.5187
Epoch 00002: val_loss improved from 10498.64326 to 7441.51873, saving model to jinan0_weights.hdf5
              jinan0 3394.3549      0.76  0.22  0.63      0.77  0.18  0.66      0.76  0.14  0.67
              jinan0 7441.5187      0.97  0.08  0.90      0.98  0.05  0.92      0.97  0.04  0.93
forget mean min: 0.95862 0.247478
incx.max(), incx.min(), incx.mean() 3.65336 -2.66042 2.38842
fgtx.max(), fgtx.min(), fgtx.mean() 2.81375 -2.26261 1.79671
abs_mean, abs_mean+, abs_mean-: 6.20252 2.79331 18.234
U_c = [[-0.14186257]] U_f = [[ 0.]] b_c = [ 0.15373556] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.182995 -0.18242 0.109422 0.181346
W_f max, min, mean, abs_mean: 0.147414 -0.146676 0.0877702 0.145806
Epoch 4/300
0s - loss: 3159.3019 - val_loss: 6979.1744
Epoch 00003: val_loss improved from 7441.51873 to 6979.17439, saving model to jinan0_weights.hdf5
              jinan0 2971.1811      0.87  0.28  0.65      0.88  0.23  0.70      0.88  0.20  0.72
              jinan0 6979.1745      0.98  0.09  0.90      0.98  0.07  0.92      0.98  0.04  0.93
forget mean min: 0.970679 0.265807
incx.max(), incx.min(), incx.mean() 4.63999 -3.40661 3.40838
fgtx.max(), fgtx.min(), fgtx.mean() 2.67408 -2.17096 1.93249
abs_mean, abs_mean+, abs_mean-: 5.94168 3.76945 21.2791
U_c = [[-0.1102633]] U_f = [[ 0.]] b_c = [ 0.19891784] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.22886 -0.228281 0.136934 0.227203
W_f max, min, mean, abs_mean: 0.138448 -0.137675 0.0823515 0.136805
Epoch 5/300
0s - loss: 2893.6627 - val_loss: 6751.4959
Epoch 00004: val_loss improved from 6979.17439 to 6751.49586, saving model to jinan0_weights.hdf5
              jinan0 2813.6274      0.89  0.29  0.65      0.90  0.24  0.70      0.90  0.22  0.72
              jinan0 6751.4959      0.98  0.09  0.90      0.99  0.07  0.92      0.98  0.04  0.94
forget mean min: 0.970029 0.369275
incx.max(), incx.min(), incx.mean() 5.55018 -4.07225 4.32451
fgtx.max(), fgtx.min(), fgtx.mean() 2.035 -1.65363 1.56515
abs_mean, abs_mean+, abs_mean-: 6.65875 4.65421 15.7164
U_c = [[-0.10253621]] U_f = [[ 0.]] b_c = [ 0.24153538] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.270861 -0.270281 0.162132 0.269203
W_f max, min, mean, abs_mean: 0.104836 -0.104062 0.0621855 0.103196
Epoch 6/300
0s - loss: 2789.0745 - val_loss: 6493.8194
Epoch 00005: val_loss improved from 6751.49586 to 6493.81940, saving model to jinan0_weights.hdf5
              jinan0 2750.8420      0.88  0.28  0.66      0.89  0.24  0.70      0.89  0.21  0.72
              jinan0 6493.8194      0.98  0.09  0.90      0.99  0.07  0.92      0.98  0.04  0.94
forget mean min: 0.961658 0.380416
incx.max(), incx.min(), incx.mean() 6.29432 -4.94487 4.93657
fgtx.max(), fgtx.min(), fgtx.mean() 1.84106 -1.59792 1.42561
abs_mean, abs_mean+, abs_mean-: 7.57006 5.34899 13.9972
U_c = [[-0.10263772]] U_f = [[ 0.]] b_c = [ 0.27742377] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.304908 -0.304329 0.182562 0.303253
W_f max, min, mean, abs_mean: 0.0944419 -0.0936609 0.055942 0.09279
Epoch 7/300
0s - loss: 2750.7947 - val_loss: 6440.1082
Epoch 00006: val_loss improved from 6493.81940 to 6440.10824, saving model to jinan0_weights.hdf5
              jinan0 2741.6660      0.86  0.27  0.65      0.88  0.23  0.69      0.88  0.21  0.71
              jinan0 6440.1082      0.98  0.08  0.90      0.98  0.07  0.92      0.98  0.04  0.93
forget mean min: 0.953761 0.370423
incx.max(), incx.min(), incx.mean() 6.86826 -5.76301 5.32385
fgtx.max(), fgtx.min(), fgtx.mean() 1.78052 -1.64789 1.36133
abs_mean, abs_mean+, abs_mean-: 8.49093 5.85686 15.2317
U_c = [[-0.10708279]] U_f = [[ 0.]] b_c = [ 0.3083052] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.331412 -0.330835 0.19847 0.329764
W_f max, min, mean, abs_mean: 0.0911764 -0.0903835 0.0539716 0.0895057
Epoch 8/300
0s - loss: 2736.3270 - val_loss: 6748.5751
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 2720.8937 - val_loss: 6647.8955
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 2717.7999 - val_loss: 6649.2752
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 2707.6295 - val_loss: 6522.3280
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 2706.1486 - val_loss: 6641.7882
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 2704.1007 - val_loss: 6634.0001
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 2702.1024 - val_loss: 6837.4331
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 2697.4238 - val_loss: 6501.5807
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 2691.9686 - val_loss: 6729.8152
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 2695.0876 - val_loss: 6584.8863
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 2692.7822 - val_loss: 6671.0777
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 2685.3616 - val_loss: 6720.5602
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 2691.0853 - val_loss: 6794.2135
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 2689.6915 - val_loss: 6623.6101
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 2685.6280 - val_loss: 6717.3376
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 2674.8460 - val_loss: 6600.1769
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 2679.8939 - val_loss: 6647.2904
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 2680.6781 - val_loss: 6628.9930
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 2675.9568 - val_loss: 6640.3429
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 2673.1555 - val_loss: 6713.8278
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 2669.7147 - val_loss: 6589.1062
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 2672.8069 - val_loss: 6429.1546
Epoch 00028: val_loss improved from 6440.10824 to 6429.15463, saving model to jinan0_weights.hdf5
              jinan0 2640.0745      0.89  0.28  0.66      0.90  0.24  0.70      0.90  0.22  0.72
              jinan0 6429.1547      0.98  0.08  0.90      0.99  0.07  0.92      0.98  0.04  0.94
forget mean min: 0.948237 0.370105
incx.max(), incx.min(), incx.mean() 8.29009 -6.66727 6.44911
fgtx.max(), fgtx.min(), fgtx.mean() 1.76309 -1.64947 1.34303
abs_mean, abs_mean+, abs_mean-: 10.6214 7.16809 21.2177
U_c = [[-0.11967255]] U_f = [[ 0.]] b_c = [ 0.56245208] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.38827 -0.387809 0.232768 0.386985
W_f max, min, mean, abs_mean: 0.0906225 -0.0894493 0.0533015 0.0882919
Epoch 30/300
0s - loss: 2666.5209 - val_loss: 6706.5394
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 2669.4544 - val_loss: 6544.8259
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 2660.1818 - val_loss: 6351.3217
Epoch 00031: val_loss improved from 6429.15463 to 6351.32165, saving model to jinan0_weights.hdf5
              jinan0 2625.4733      0.88  0.28  0.66      0.89  0.24  0.69      0.89  0.22  0.71
              jinan0 6351.3217      0.98  0.08  0.89      0.99  0.06  0.92      0.98  0.04  0.94
forget mean min: 0.944534 0.3732
incx.max(), incx.min(), incx.mean() 8.49801 -6.74299 6.49385
fgtx.max(), fgtx.min(), fgtx.mean() 1.75847 -1.634 1.31233
abs_mean, abs_mean+, abs_mean-: 10.8381 7.23453 20.6719
U_c = [[-0.12038463]] U_f = [[ 0.]] b_c = [ 0.59794736] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.397086 -0.396644 0.238079 0.395851
W_f max, min, mean, abs_mean: 0.0905835 -0.089327 0.0532078 0.0881122
Epoch 33/300
0s - loss: 2653.5696 - val_loss: 6332.9596
Epoch 00032: val_loss improved from 6351.32165 to 6332.95963, saving model to jinan0_weights.hdf5
              jinan0 2616.8587      0.89  0.28  0.66      0.90  0.24  0.70      0.91  0.22  0.72
              jinan0 6332.9596      0.97  0.08  0.89      0.98  0.06  0.92      0.98  0.04  0.94
forget mean min: 0.94423 0.372546
incx.max(), incx.min(), incx.mean() 8.71191 -6.85515 6.61852
fgtx.max(), fgtx.min(), fgtx.mean() 1.77423 -1.63727 1.31543
abs_mean, abs_mean+, abs_mean-: 10.9421 7.36312 20.8118
U_c = [[-0.11522777]] U_f = [[ 0.]] b_c = [ 0.61593276] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.407024 -0.406587 0.244047 0.405802
W_f max, min, mean, abs_mean: 0.0914728 -0.0901735 0.0537052 0.0889317
Epoch 34/300
0s - loss: 2645.6949 - val_loss: 6147.7722
Epoch 00033: val_loss improved from 6332.95963 to 6147.77225, saving model to jinan0_weights.hdf5
              jinan0 2609.8133      0.89  0.28  0.66      0.90  0.24  0.70      0.90  0.23  0.71
              jinan0 6147.7722      0.97  0.08  0.89      0.98  0.06  0.92      0.98  0.04  0.94
forget mean min: 0.944194 0.367562
incx.max(), incx.min(), incx.mean() 8.84152 -6.88429 6.65649
fgtx.max(), fgtx.min(), fgtx.mean() 1.81636 -1.66219 1.33298
abs_mean, abs_mean+, abs_mean-: 11.074 7.52761 20.5784
U_c = [[-0.11425326]] U_f = [[ 0.]] b_c = [ 0.63018632] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.413008 -0.412575 0.247641 0.411797
W_f max, min, mean, abs_mean: 0.0936909 -0.0923556 0.0550062 0.09109
Epoch 35/300
0s - loss: 2634.8221 - val_loss: 6098.6513
Epoch 00034: val_loss improved from 6147.77225 to 6098.65132, saving model to jinan0_weights.hdf5
              jinan0 2605.9876      0.89  0.28  0.66      0.89  0.24  0.70      0.90  0.22  0.71
              jinan0 6098.6512      0.98  0.08  0.90      0.99  0.07  0.92      0.98  0.04  0.94
forget mean min: 0.943043 0.377048
incx.max(), incx.min(), incx.mean() 8.96805 -6.89176 6.72482
fgtx.max(), fgtx.min(), fgtx.mean() 1.78421 -1.61476 1.30341
abs_mean, abs_mean+, abs_mean-: 10.884 7.45137 19.1751
U_c = [[-0.1126915]] U_f = [[ 0.]] b_c = [ 0.64287329] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.419087 -0.418657 0.25129 0.417884
W_f max, min, mean, abs_mean: 0.0922239 -0.0908469 0.0540911 0.0895588
Epoch 36/300
0s - loss: 2618.5066 - val_loss: 6032.8420
Epoch 00035: val_loss improved from 6098.65132 to 6032.84196, saving model to jinan0_weights.hdf5
              jinan0 2589.4934      0.87  0.27  0.66      0.88  0.24  0.69      0.88  0.22  0.70
              jinan0 6032.8419      0.97  0.08  0.89      0.98  0.06  0.92      0.98  0.04  0.94
forget mean min: 0.938127 0.384179
incx.max(), incx.min(), incx.mean() 9.20728 -7.03686 6.79732
fgtx.max(), fgtx.min(), fgtx.mean() 1.75286 -1.57911 1.25848
abs_mean, abs_mean+, abs_mean-: 11.0666 7.50501 18.76
U_c = [[-0.11004966]] U_f = [[ 0.]] b_c = [ 0.66173571] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.43082 -0.430391 0.258328 0.429617
W_f max, min, mean, abs_mean: 0.0908796 -0.0894436 0.0532346 0.0881234
Epoch 37/300
0s - loss: 2585.1693 - val_loss: 6113.9668
Epoch 00036: val_loss did not improve
Epoch 38/300
0s - loss: 2534.6658 - val_loss: 6898.9195
Epoch 00037: val_loss did not improve
Epoch 39/300
0s - loss: 2489.7482 - val_loss: 6245.8549
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 2446.6891 - val_loss: 6442.7222
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 2401.1416 - val_loss: 6197.8129
Epoch 00040: val_loss did not improve
Epoch 42/300
0s - loss: 2351.2020 - val_loss: 6126.4474
Epoch 00041: val_loss did not improve
Epoch 43/300
0s - loss: 2305.7937 - val_loss: 6552.0949
Epoch 00042: val_loss did not improve
Epoch 44/300
0s - loss: 2262.9612 - val_loss: 6242.8768
Epoch 00043: val_loss did not improve
Epoch 45/300
0s - loss: 2215.8170 - val_loss: 7024.6677
Epoch 00044: val_loss did not improve
Epoch 46/300
0s - loss: 2185.1093 - val_loss: 6471.0608
Epoch 00045: val_loss did not improve
Epoch 47/300
0s - loss: 2147.0688 - val_loss: 6462.9687
Epoch 00046: val_loss did not improve
Epoch 48/300
0s - loss: 2107.7368 - val_loss: 6515.8592
Epoch 00047: val_loss did not improve
Epoch 49/300
0s - loss: 2075.6936 - val_loss: 6524.9434
Epoch 00048: val_loss did not improve
Epoch 50/300
0s - loss: 2043.8635 - val_loss: 6719.9467
Epoch 00049: val_loss did not improve
Epoch 51/300
0s - loss: 2021.7270 - val_loss: 6322.8491
Epoch 00050: val_loss did not improve
Epoch 52/300
0s - loss: 1998.8448 - val_loss: 6857.1536
Epoch 00051: val_loss did not improve
Epoch 53/300
0s - loss: 1977.3762 - val_loss: 6863.1284
Epoch 00052: val_loss did not improve
Epoch 54/300
0s - loss: 1947.3207 - val_loss: 6622.3133
Epoch 00053: val_loss did not improve
Epoch 55/300
0s - loss: 1918.1300 - val_loss: 6320.2772
Epoch 00054: val_loss did not improve
Epoch 56/300
0s - loss: 1897.3165 - val_loss: 6893.5739
Epoch 00055: val_loss did not improve
Epoch 57/300
0s - loss: 1876.1124 - val_loss: 7313.3188
Epoch 00056: val_loss did not improve
Epoch 58/300
0s - loss: 1853.1914 - val_loss: 6466.7160
Epoch 00057: val_loss did not improve
Epoch 59/300
0s - loss: 1823.8441 - val_loss: 6399.6119
Epoch 00058: val_loss did not improve
Epoch 60/300
0s - loss: 1797.2647 - val_loss: 6902.1944
Epoch 00059: val_loss did not improve
Epoch 61/300
0s - loss: 1777.1456 - val_loss: 7201.3288
Epoch 00060: val_loss did not improve
Epoch 62/300
0s - loss: 1760.0133 - val_loss: 6903.1945
Epoch 00061: val_loss did not improve
Epoch 63/300
0s - loss: 1728.6992 - val_loss: 7470.2196
Epoch 00062: val_loss did not improve
Epoch 64/300
0s - loss: 1712.1627 - val_loss: 7354.7198
Epoch 00063: val_loss did not improve
Epoch 65/300
0s - loss: 1697.4656 - val_loss: 7363.0735
Epoch 00064: val_loss did not improve
Epoch 66/300
0s - loss: 1677.1303 - val_loss: 6795.8844
Epoch 00065: val_loss did not improve
Epoch 67/300
0s - loss: 1663.2110 - val_loss: 7537.5716
Epoch 00066: val_loss did not improve
X_train[0].shape = (7656, 40, 23)

training xian0
Train on 7656 samples, validate on 2040 samples
Before training:
               xian0 5638.0026      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.66588 nan 3.66588
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
               xian026930.1375      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.21846 nan 8.21846
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3433.8982 - val_loss: 9582.4361
Epoch 00000: val_loss improved from inf to 9582.43615, saving model to xian0_weights.hdf5
               xian0 1864.4105      0.42  0.31  0.35      0.44  0.30  0.37      0.44  0.28  0.38
               xian0 9582.4362      0.73  0.06  0.70      0.73  0.04  0.71      0.73  0.02  0.72
forget mean min: 0.866828 0.233148
incx.max(), incx.min(), incx.mean() 2.98842 -2.80263 1.55933
fgtx.max(), fgtx.min(), fgtx.mean() 2.28353 -2.33426 1.14397
abs_mean, abs_mean+, abs_mean-: 6.94927 2.54625 16.1293
U_c = [[-0.1072883]] U_f = [[ 0.]] b_c = [ 0.12470628] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.1525 -0.152342 -0.0152872 0.150446
W_f max, min, mean, abs_mean: 0.12169 -0.121627 -0.0121704 0.119966
Epoch 2/300
1s - loss: 1653.2346 - val_loss: 8034.1563
Epoch 00001: val_loss improved from 9582.43615 to 8034.15628, saving model to xian0_weights.hdf5
               xian0 1487.4861      0.66  0.34  0.50      0.70  0.32  0.52      0.71  0.31  0.54
               xian0 8034.1562      0.82  0.06  0.78      0.82  0.04  0.80      0.82  0.02  0.81
forget mean min: 0.914583 0.378123
incx.max(), incx.min(), incx.mean() 4.75605 -4.23683 3.22733
fgtx.max(), fgtx.min(), fgtx.mean() 1.64011 -1.60938 1.08771
abs_mean, abs_mean+, abs_mean-: 5.79587 3.56912 8.94575
U_c = [[-0.05605434]] U_f = [[ 0.]] b_c = [ 0.21710382] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.239466 -0.239318 -0.0239932 0.237444
W_f max, min, mean, abs_mean: 0.0874871 -0.087524 -0.00878234 0.0857993
Epoch 3/300
1s - loss: 1425.0603 - val_loss: 7229.3904
Epoch 00002: val_loss improved from 8034.15628 to 7229.39042, saving model to xian0_weights.hdf5
               xian0 1365.8274      0.74  0.37  0.52      0.78  0.35  0.54      0.79  0.36  0.55
               xian0 7229.3904      0.85  0.06  0.81      0.86  0.04  0.83      0.85  0.02  0.83
forget mean min: 0.928668 0.419195
incx.max(), incx.min(), incx.mean() 5.48206 -4.0859 3.86076
fgtx.max(), fgtx.min(), fgtx.mean() 1.68246 -1.40403 1.15942
abs_mean, abs_mean+, abs_mean-: 5.45985 3.69914 7.89339
U_c = [[-0.0352636]] U_f = [[ 0.]] b_c = [ 0.26658526] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.279875 -0.27974 -0.0280457 0.27789
W_f max, min, mean, abs_mean: 0.0913428 -0.0914071 -0.00917331 0.0896455
Epoch 4/300
1s - loss: 1354.7214 - val_loss: 6721.4821
Epoch 00003: val_loss improved from 7229.39042 to 6721.48210, saving model to xian0_weights.hdf5
               xian0 1344.7870      0.74  0.36  0.52      0.77  0.35  0.55      0.80  0.35  0.56
               xian0 6721.4821      0.87  0.06  0.82      0.87  0.04  0.84      0.87  0.02  0.85
forget mean min: 0.938167 0.472863
incx.max(), incx.min(), incx.mean() 5.72401 -3.26616 4.09975
fgtx.max(), fgtx.min(), fgtx.mean() 1.74016 -1.13568 1.22055
abs_mean, abs_mean+, abs_mean-: 5.45104 3.70559 8.16905
U_c = [[-0.0258964]] U_f = [[ 0.]] b_c = [ 0.28417507] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.294794 -0.294667 -0.0295441 0.292831
W_f max, min, mean, abs_mean: 0.095384 -0.0954631 -0.0095799 0.0936755
Epoch 5/300
1s - loss: 1331.7310 - val_loss: 7291.4048
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1319.1538 - val_loss: 6610.3514
Epoch 00005: val_loss improved from 6721.48210 to 6610.35141, saving model to xian0_weights.hdf5
               xian0 1322.9198      0.75  0.37  0.52      0.79  0.36  0.55      0.81  0.36  0.56
               xian0 6610.3514      0.88  0.06  0.83      0.88  0.04  0.85      0.88  0.02  0.86
forget mean min: 0.942542 0.544866
incx.max(), incx.min(), incx.mean() 6.16327 -2.13205 4.33116
fgtx.max(), fgtx.min(), fgtx.mean() 1.85768 -0.775668 1.27605
abs_mean, abs_mean+, abs_mean-: 6.14094 4.21148 9.21144
U_c = [[-0.01796928]] U_f = [[ 0.]] b_c = [ 0.31141961] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.319126 -0.319002 -0.0319825 0.317187
W_f max, min, mean, abs_mean: 0.102419 -0.102514 -0.010286 0.100693
Epoch 7/300
1s - loss: 1309.9300 - val_loss: 7210.7671
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1298.1858 - val_loss: 7363.5567
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1286.0988 - val_loss: 7384.4948
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1277.4674 - val_loss: 7498.9041
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1266.9853 - val_loss: 8156.7816
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1253.9303 - val_loss: 8341.7049
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1241.9077 - val_loss: 8854.0885
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1229.6639 - val_loss: 7467.9895
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1210.8903 - val_loss: 8034.5872
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1197.3368 - val_loss: 8119.6099
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1171.3877 - val_loss: 8095.6727
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1156.7921 - val_loss: 7660.0522
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1128.4427 - val_loss: 8754.5135
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1105.6578 - val_loss: 8085.4948
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1077.8231 - val_loss: 8847.5508
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1044.1879 - val_loss: 8666.2418
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1016.7677 - val_loss: 8886.6428
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 992.7700 - val_loss: 9173.3983
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 973.8961 - val_loss: 9032.0072
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 960.3844 - val_loss: 9025.7283
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 949.0849 - val_loss: 8954.2333
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 934.4484 - val_loss: 9343.4991
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 926.8026 - val_loss: 9795.9552
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 916.2930 - val_loss: 9344.2365
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 905.1604 - val_loss: 9640.0523
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 890.6203 - val_loss: 9681.8169
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 885.6433 - val_loss: 9916.0376
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 882.2138 - val_loss: 9631.1765
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 869.4713 - val_loss: 9950.5600
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 862.6359 - val_loss: 9259.0370
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 850.0591 - val_loss: 9634.3988
Epoch 00036: val_loss did not improve

beijing
            beijing0 2389.7877      0.92  0.21  0.74      0.93  0.19  0.77      0.93  0.16  0.79
            beijing0 8601.7021      0.85  0.21  0.69      0.85  0.18  0.72      0.86  0.17  0.73
forget mean min: 0.891726 0.365231
incx.max(), incx.min(), incx.mean() 9.88586 -8.89784 6.13471
fgtx.max(), fgtx.min(), fgtx.mean() 1.69566 -1.67384 1.02278
abs_mean, abs_mean+, abs_mean-: 13.1132 8.43255 22.0825
U_c = [[-0.03115134]] U_f = [[ 0.]] b_c = [ 0.43317452] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.475542 -0.475812 -0.0947092 0.473697
W_f max, min, mean, abs_mean: 0.0864717 -0.0866097 -0.0167232 0.0849738

tianjin
            tianjin0 1828.5240      0.88  0.26  0.67      0.90  0.21  0.72      0.90  0.16  0.76
            tianjin0 7271.0099      0.87  0.13  0.77      0.87  0.12  0.78      0.87  0.10  0.79
forget mean min: 0.868607 0.36608
incx.max(), incx.min(), incx.mean() 7.40718 -6.72563 4.16097
fgtx.max(), fgtx.min(), fgtx.mean() 1.66974 -1.6696 0.902711
abs_mean, abs_mean+, abs_mean-: 12.0718 6.60871 22.908
U_c = [[-0.07878304]] U_f = [[ 0.]] b_c = [ 0.34047723] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.355399 -0.356008 -0.0702593 0.353987
W_f max, min, mean, abs_mean: 0.0848816 -0.0849237 -0.016355 0.083641

tangshan
           tangshan0 1710.8836      0.89  0.22  0.71      0.92  0.19  0.76      0.92  0.18  0.76
           tangshan0 4841.4701      0.95  0.18  0.79      0.96  0.13  0.84      0.98  0.12  0.87
forget mean min: 0.923231 0.343678
incx.max(), incx.min(), incx.mean() 8.74202 -7.80827 6.21825
fgtx.max(), fgtx.min(), fgtx.mean() 1.79452 -1.78161 1.24918
abs_mean, abs_mean+, abs_mean-: 11.6819 7.7381 23.3406
U_c = [[-0.07801635]] U_f = [[ 0.]] b_c = [ 0.43700942] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.416371 -0.416243 0.000316054 0.41576
W_f max, min, mean, abs_mean: 0.0905308 -0.0905284 0.000191658 0.0898359

baoding
            baoding0 2061.9629      0.93  0.19  0.76      0.95  0.16  0.81      0.96  0.14  0.83
            baoding0 6893.4661      0.97  0.08  0.90      0.97  0.06  0.91      0.97  0.04  0.93
forget mean min: 0.94176 0.359364
incx.max(), incx.min(), incx.mean() 15.9958 -6.91714 8.99495
fgtx.max(), fgtx.min(), fgtx.mean() 3.47134 -1.70318 1.89004
abs_mean, abs_mean+, abs_mean-: 17.7602 11.1043 36.2022
U_c = [[-0.03631666]] U_f = [[ 0.]] b_c = [ 0.62524343] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.795256 -0.794458 -0.237965 0.79234
W_f max, min, mean, abs_mean: 0.185411 -0.185863 -0.0534943 0.178953

shijiazhuang
       shijiazhuang0 2126.1081      0.87  0.26  0.67      0.89  0.24  0.69      0.89  0.22  0.71
       shijiazhuang0 9113.0852      0.90  0.19  0.74      0.91  0.15  0.78      0.92  0.10  0.83
forget mean min: 0.930278 0.293773
incx.max(), incx.min(), incx.mean() 9.94849 -8.6784 6.89501
fgtx.max(), fgtx.min(), fgtx.mean() 2.11572 -2.03114 1.43593
abs_mean, abs_mean+, abs_mean-: 14.219 8.52412 31.9714
U_c = [[-0.06390852]] U_f = [[ 0.]] b_c = [ 0.44507971] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.478087 -0.477889 0.142491 0.476508
W_f max, min, mean, abs_mean: 0.106517 -0.107034 0.0317591 0.106084

xingtai+handan
     xingtai+handan0 2588.7304      0.85  0.26  0.65      0.87  0.22  0.70      0.87  0.20  0.71
     xingtai+handan0 6913.2796      0.92  0.12  0.81      0.92  0.09  0.84      0.92  0.06  0.86
forget mean min: 0.938371 0.294989
incx.max(), incx.min(), incx.mean() 7.49987 -6.77331 5.41574
fgtx.max(), fgtx.min(), fgtx.mean() 2.04149 -2.02505 1.4477
abs_mean, abs_mean+, abs_mean-: 11.3962 6.62434 26.213
U_c = [[-0.0746973]] U_f = [[ 0.]] b_c = [ 0.3344374] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.360859 -0.360559 0.108174 0.359274
W_f max, min, mean, abs_mean: 0.103364 -0.103403 0.0305708 0.10236

jinan
              jinan0 2589.4934      0.87  0.27  0.66      0.88  0.24  0.69      0.88  0.22  0.70
              jinan0 6032.8419      0.97  0.08  0.89      0.98  0.06  0.92      0.98  0.04  0.94
forget mean min: 0.938127 0.384179
incx.max(), incx.min(), incx.mean() 9.20728 -7.03686 6.79732
fgtx.max(), fgtx.min(), fgtx.mean() 1.75286 -1.57911 1.25848
abs_mean, abs_mean+, abs_mean-: 11.0666 7.50501 18.76
U_c = [[-0.11004966]] U_f = [[ 0.]] b_c = [ 0.66173571] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.43082 -0.430391 0.258328 0.429617
W_f max, min, mean, abs_mean: 0.0908796 -0.0894436 0.0532346 0.0881234

xian
               xian0 1322.9198      0.75  0.37  0.52      0.79  0.36  0.55      0.81  0.36  0.56
               xian0 6610.3514      0.88  0.06  0.83      0.88  0.04  0.85      0.88  0.02  0.86
forget mean min: 0.942542 0.544866
incx.max(), incx.min(), incx.mean() 6.16327 -2.13205 4.33116
fgtx.max(), fgtx.min(), fgtx.mean() 1.85768 -0.775668 1.27605
abs_mean, abs_mean+, abs_mean-: 6.14094 4.21148 9.21144
U_c = [[-0.01796928]] U_f = [[ 0.]] b_c = [ 0.31141961] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.319126 -0.319002 -0.0319825 0.317187
W_f max, min, mean, abs_mean: 0.102419 -0.102514 -0.010286 0.100693
