trainset.shape, testset.shape = (60075, 48, 11) (20025, 48, 11)

training rlstm2h0 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 320.5868 - val_loss: 1230.7967
Epoch 00000: val_loss improved from inf to 1230.79669, saving model to rlstm2h0_weights.hdf5
Epoch 2/300
10s - loss: 231.0573 - val_loss: 1156.2166
Epoch 00001: val_loss improved from 1230.79669 to 1156.21660, saving model to rlstm2h0_weights.hdf5
Epoch 3/300
10s - loss: 216.2234 - val_loss: 1145.2853
Epoch 00002: val_loss improved from 1156.21660 to 1145.28530, saving model to rlstm2h0_weights.hdf5
Epoch 4/300
10s - loss: 208.6491 - val_loss: 1119.6658
Epoch 00003: val_loss improved from 1145.28530 to 1119.66584, saving model to rlstm2h0_weights.hdf5
Epoch 5/300
10s - loss: 203.4269 - val_loss: 1042.2353
Epoch 00004: val_loss improved from 1119.66584 to 1042.23530, saving model to rlstm2h0_weights.hdf5
Epoch 6/300
10s - loss: 199.6717 - val_loss: 1048.4522
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 196.4386 - val_loss: 1067.7912
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 193.1703 - val_loss: 1098.8311
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 189.8822 - val_loss: 1039.9347
Epoch 00008: val_loss improved from 1042.23530 to 1039.93465, saving model to rlstm2h0_weights.hdf5
Epoch 10/300
10s - loss: 186.4511 - val_loss: 1111.2034
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 183.5731 - val_loss: 1318.5716
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 181.3396 - val_loss: 1385.2113
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 179.5907 - val_loss: 1120.1715
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 177.9641 - val_loss: 1328.6107
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 176.3990 - val_loss: 1258.5493
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 174.4127 - val_loss: 1566.1907
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 172.1142 - val_loss: 1396.4142
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 169.4580 - val_loss: 1552.1359
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 167.0369 - val_loss: 1432.2411
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 164.8959 - val_loss: 1667.6092
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 162.8337 - val_loss: 1409.3619
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 160.6968 - val_loss: 1755.9614
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 158.7101 - val_loss: 1404.2430
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 156.8703 - val_loss: 1061.7540
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 155.4055 - val_loss: 1066.8178
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 154.1705 - val_loss: 1143.6677
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 153.0568 - val_loss: 1131.3665
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 151.8802 - val_loss: 1100.2820
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 150.8366 - val_loss: 916.1839
Epoch 00028: val_loss improved from 1039.93465 to 916.18393, saving model to rlstm2h0_weights.hdf5
Epoch 30/300
10s - loss: 149.8581 - val_loss: 945.1152
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 148.9852 - val_loss: 1259.8607
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 148.3134 - val_loss: 1087.3420
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 147.6374 - val_loss: 1120.3669
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 147.0526 - val_loss: 1210.6423
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 146.3682 - val_loss: 1065.3951
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 145.7763 - val_loss: 1120.8326
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 145.1498 - val_loss: 1231.4150
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 144.4170 - val_loss: 1459.7770
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 143.7683 - val_loss: 1220.5499
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 143.1684 - val_loss: 1579.9494
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 142.6988 - val_loss: 1354.7894
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 142.1399 - val_loss: 1457.3176
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 141.5780 - val_loss: 1739.3905
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 141.0422 - val_loss: 1731.7018
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 140.6774 - val_loss: 1633.4659
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 140.2838 - val_loss: 1609.0410
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 139.8061 - val_loss: 1660.5736
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 139.3457 - val_loss: 1457.9695
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 139.0477 - val_loss: 2181.4279
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 138.6257 - val_loss: 1823.9448
Epoch 00049: val_loss did not improve

training rlstm2h1 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 321.6883 - val_loss: 1183.1403
Epoch 00000: val_loss improved from inf to 1183.14033, saving model to rlstm2h1_weights.hdf5
Epoch 2/300
11s - loss: 231.0275 - val_loss: 1136.1960
Epoch 00001: val_loss improved from 1183.14033 to 1136.19599, saving model to rlstm2h1_weights.hdf5
Epoch 3/300
11s - loss: 214.2976 - val_loss: 1097.1999
Epoch 00002: val_loss improved from 1136.19599 to 1097.19985, saving model to rlstm2h1_weights.hdf5
Epoch 4/300
11s - loss: 205.2221 - val_loss: 905.3852
Epoch 00003: val_loss improved from 1097.19985 to 905.38517, saving model to rlstm2h1_weights.hdf5
Epoch 5/300
11s - loss: 197.8529 - val_loss: 921.6884
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 191.7747 - val_loss: 922.6793
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 186.7037 - val_loss: 764.1708
Epoch 00006: val_loss improved from 905.38517 to 764.17082, saving model to rlstm2h1_weights.hdf5
Epoch 8/300
11s - loss: 183.0607 - val_loss: 964.5746
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 180.7515 - val_loss: 840.0192
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 179.0145 - val_loss: 885.0523
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 177.5803 - val_loss: 1125.9588
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 176.3301 - val_loss: 936.0127
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 175.1995 - val_loss: 1177.5204
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 174.0934 - val_loss: 1031.1716
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 172.8971 - val_loss: 1069.3522
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 171.6271 - val_loss: 1155.2007
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 170.5310 - val_loss: 1227.5655
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 169.4519 - val_loss: 1210.2524
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 168.4490 - val_loss: 1130.1202
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 167.2997 - val_loss: 1101.7652
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 166.3810 - val_loss: 1123.2616
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 165.2366 - val_loss: 1381.3772
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 164.3532 - val_loss: 1214.8773
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 163.2166 - val_loss: 1211.0180
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 162.4955 - val_loss: 1330.6153
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 161.4965 - val_loss: 1421.7016
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 160.6457 - val_loss: 1480.9385
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 159.8152 - val_loss: 1117.3207
Epoch 00027: val_loss did not improve

training rlstm2h2 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 319.8853 - val_loss: 1177.0885
Epoch 00000: val_loss improved from inf to 1177.08855, saving model to rlstm2h2_weights.hdf5
Epoch 2/300
11s - loss: 231.0604 - val_loss: 1254.2971
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 215.6795 - val_loss: 1136.7959
Epoch 00002: val_loss improved from 1177.08855 to 1136.79594, saving model to rlstm2h2_weights.hdf5
Epoch 4/300
11s - loss: 208.7702 - val_loss: 1056.5013
Epoch 00003: val_loss improved from 1136.79594 to 1056.50130, saving model to rlstm2h2_weights.hdf5
Epoch 5/300
11s - loss: 203.7693 - val_loss: 1002.1754
Epoch 00004: val_loss improved from 1056.50130 to 1002.17541, saving model to rlstm2h2_weights.hdf5
Epoch 6/300
11s - loss: 199.4393 - val_loss: 965.9090
Epoch 00005: val_loss improved from 1002.17541 to 965.90904, saving model to rlstm2h2_weights.hdf5
Epoch 7/300
10s - loss: 196.0609 - val_loss: 1098.4279
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 193.1123 - val_loss: 1033.7046
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 190.3924 - val_loss: 1060.9023
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 187.8752 - val_loss: 1020.2427
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 185.5248 - val_loss: 1000.3733
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 183.4034 - val_loss: 1244.3741
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 181.9248 - val_loss: 1181.5600
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 180.5929 - val_loss: 1190.8919
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 179.1324 - val_loss: 1092.3516
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 178.1317 - val_loss: 1323.0643
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 177.3441 - val_loss: 1363.9988
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 176.7721 - val_loss: 1251.3932
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 176.2313 - val_loss: 1326.9104
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 175.7718 - val_loss: 1352.4093
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 175.3950 - val_loss: 1334.5127
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 175.0325 - val_loss: 1462.4138
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 174.8190 - val_loss: 1277.2290
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 174.4897 - val_loss: 1396.0200
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 174.2470 - val_loss: 1287.6626
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 173.9965 - val_loss: 1265.2976
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 173.8431 - val_loss: 1438.4843
Epoch 00026: val_loss did not improve

training rlstm2h3 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 319.7200 - val_loss: 1274.0790
Epoch 00000: val_loss improved from inf to 1274.07899, saving model to rlstm2h3_weights.hdf5
Epoch 2/300
10s - loss: 232.3059 - val_loss: 1116.7530
Epoch 00001: val_loss improved from 1274.07899 to 1116.75305, saving model to rlstm2h3_weights.hdf5
Epoch 3/300
10s - loss: 216.2318 - val_loss: 1168.8226
Epoch 00002: val_loss did not improve
Epoch 4/300
10s - loss: 208.4881 - val_loss: 1037.1994
Epoch 00003: val_loss improved from 1116.75305 to 1037.19941, saving model to rlstm2h3_weights.hdf5
Epoch 5/300
10s - loss: 203.7185 - val_loss: 1115.6177
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 200.2384 - val_loss: 1209.8343
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 196.7588 - val_loss: 1017.3095
Epoch 00006: val_loss improved from 1037.19941 to 1017.30946, saving model to rlstm2h3_weights.hdf5
Epoch 8/300
10s - loss: 193.5329 - val_loss: 1082.6199
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 190.6461 - val_loss: 993.9164
Epoch 00008: val_loss improved from 1017.30946 to 993.91645, saving model to rlstm2h3_weights.hdf5
Epoch 10/300
10s - loss: 188.0179 - val_loss: 1136.9663
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 185.8470 - val_loss: 1181.4693
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 183.6121 - val_loss: 1127.0630
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 181.4431 - val_loss: 1205.5583
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 179.4698 - val_loss: 1282.1814
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 177.6383 - val_loss: 1213.5702
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 176.0724 - val_loss: 1537.2402
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 174.5153 - val_loss: 1503.9737
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 172.9759 - val_loss: 1738.9550
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 171.5548 - val_loss: 1762.4408
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 169.9546 - val_loss: 2050.3536
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 168.3637 - val_loss: 1736.8852
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 166.9409 - val_loss: 1634.4029
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 165.2070 - val_loss: 2104.3887
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 163.6357 - val_loss: 2110.3648
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 162.0975 - val_loss: 2126.7150
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 160.8107 - val_loss: 1636.2876
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 159.5144 - val_loss: 1746.9677
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 158.0659 - val_loss: 1797.8285
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 156.6661 - val_loss: 1715.7199
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 155.2161 - val_loss: 2158.7559
Epoch 00029: val_loss did not improve

training rlstm2h4 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 326.0957 - val_loss: 1228.1245
Epoch 00000: val_loss improved from inf to 1228.12454, saving model to rlstm2h4_weights.hdf5
Epoch 2/300
10s - loss: 233.7596 - val_loss: 1222.7357
Epoch 00001: val_loss improved from 1228.12454 to 1222.73571, saving model to rlstm2h4_weights.hdf5
Epoch 3/300
10s - loss: 218.1021 - val_loss: 1126.3196
Epoch 00002: val_loss improved from 1222.73571 to 1126.31961, saving model to rlstm2h4_weights.hdf5
Epoch 4/300
10s - loss: 210.4996 - val_loss: 1135.3484
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 205.8874 - val_loss: 1111.0003
Epoch 00004: val_loss improved from 1126.31961 to 1111.00026, saving model to rlstm2h4_weights.hdf5
Epoch 6/300
10s - loss: 202.5273 - val_loss: 1090.8195
Epoch 00005: val_loss improved from 1111.00026 to 1090.81955, saving model to rlstm2h4_weights.hdf5
Epoch 7/300
11s - loss: 199.5264 - val_loss: 1046.5822
Epoch 00006: val_loss improved from 1090.81955 to 1046.58223, saving model to rlstm2h4_weights.hdf5
Epoch 8/300
11s - loss: 196.6037 - val_loss: 1026.3495
Epoch 00007: val_loss improved from 1046.58223 to 1026.34949, saving model to rlstm2h4_weights.hdf5
Epoch 9/300
10s - loss: 194.0151 - val_loss: 1060.1452
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 191.2231 - val_loss: 938.1835
Epoch 00009: val_loss improved from 1026.34949 to 938.18354, saving model to rlstm2h4_weights.hdf5
Epoch 11/300
10s - loss: 188.1304 - val_loss: 886.5007
Epoch 00010: val_loss improved from 938.18354 to 886.50069, saving model to rlstm2h4_weights.hdf5
Epoch 12/300
10s - loss: 185.5050 - val_loss: 1011.0360
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 183.1379 - val_loss: 1109.0798
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 181.0420 - val_loss: 1109.7633
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 179.2214 - val_loss: 1232.4069
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 177.6626 - val_loss: 1063.3752
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 175.9987 - val_loss: 1194.1589
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 174.0427 - val_loss: 1226.6075
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 172.0820 - val_loss: 1173.7596
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 170.2448 - val_loss: 1244.8555
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 168.5597 - val_loss: 1401.1458
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 166.4179 - val_loss: 1177.4971
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 163.6756 - val_loss: 1118.1265
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 160.4604 - val_loss: 1178.1387
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 157.5366 - val_loss: 937.2996
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 155.1858 - val_loss: 1039.3044
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 153.0369 - val_loss: 1134.1090
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 151.2598 - val_loss: 893.0266
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 149.6006 - val_loss: 863.0736
Epoch 00028: val_loss improved from 886.50069 to 863.07356, saving model to rlstm2h4_weights.hdf5
Epoch 30/300
10s - loss: 148.2400 - val_loss: 896.4676
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 147.1133 - val_loss: 938.8920
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 146.1594 - val_loss: 862.4961
Epoch 00031: val_loss improved from 863.07356 to 862.49613, saving model to rlstm2h4_weights.hdf5
Epoch 33/300
10s - loss: 145.2279 - val_loss: 821.9287
Epoch 00032: val_loss improved from 862.49613 to 821.92872, saving model to rlstm2h4_weights.hdf5
Epoch 34/300
11s - loss: 144.5080 - val_loss: 870.9778
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 143.7773 - val_loss: 885.2729
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 143.0730 - val_loss: 956.1253
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 142.3356 - val_loss: 970.8363
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 141.6229 - val_loss: 879.6197
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 140.8642 - val_loss: 946.3907
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 140.1959 - val_loss: 901.5836
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 139.5660 - val_loss: 929.1614
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 138.9823 - val_loss: 912.2761
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 138.4688 - val_loss: 863.8438
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 137.8383 - val_loss: 818.6935
Epoch 00043: val_loss improved from 821.92872 to 818.69352, saving model to rlstm2h4_weights.hdf5
Epoch 45/300
10s - loss: 137.3342 - val_loss: 823.0238
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 136.7917 - val_loss: 860.7777
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 136.3104 - val_loss: 905.7510
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 135.7469 - val_loss: 923.4105
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 135.3059 - val_loss: 853.8319
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 134.8951 - val_loss: 833.1155
Epoch 00049: val_loss did not improve
Epoch 51/300
10s - loss: 134.4855 - val_loss: 828.7342
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 134.0909 - val_loss: 785.1674
Epoch 00051: val_loss improved from 818.69352 to 785.16745, saving model to rlstm2h4_weights.hdf5
Epoch 53/300
10s - loss: 133.7708 - val_loss: 832.6464
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 133.3333 - val_loss: 778.9584
Epoch 00053: val_loss improved from 785.16745 to 778.95836, saving model to rlstm2h4_weights.hdf5
Epoch 55/300
10s - loss: 133.0686 - val_loss: 794.8560
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 132.8008 - val_loss: 781.4014
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 132.5360 - val_loss: 783.9218
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 132.1916 - val_loss: 797.1693
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 131.8476 - val_loss: 805.2044
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 131.5965 - val_loss: 829.3506
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 131.3052 - val_loss: 768.0051
Epoch 00060: val_loss improved from 778.95836 to 768.00511, saving model to rlstm2h4_weights.hdf5
Epoch 62/300
10s - loss: 131.1120 - val_loss: 815.5860
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 130.7991 - val_loss: 797.3310
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 130.5922 - val_loss: 797.2099
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 130.4040 - val_loss: 757.1318
Epoch 00064: val_loss improved from 768.00511 to 757.13178, saving model to rlstm2h4_weights.hdf5
Epoch 66/300
10s - loss: 130.0413 - val_loss: 736.0605
Epoch 00065: val_loss improved from 757.13178 to 736.06047, saving model to rlstm2h4_weights.hdf5
Epoch 67/300
10s - loss: 129.8480 - val_loss: 777.1394
Epoch 00066: val_loss did not improve
Epoch 68/300
10s - loss: 129.6228 - val_loss: 797.6493
Epoch 00067: val_loss did not improve
Epoch 69/300
10s - loss: 129.4094 - val_loss: 779.6501
Epoch 00068: val_loss did not improve
Epoch 70/300
10s - loss: 129.1496 - val_loss: 804.3078
Epoch 00069: val_loss did not improve
Epoch 71/300
10s - loss: 128.9054 - val_loss: 860.7174
Epoch 00070: val_loss did not improve
Epoch 72/300
10s - loss: 128.7393 - val_loss: 736.8357
Epoch 00071: val_loss did not improve
Epoch 73/300
10s - loss: 128.4845 - val_loss: 731.8433
Epoch 00072: val_loss improved from 736.06047 to 731.84335, saving model to rlstm2h4_weights.hdf5
Epoch 74/300
10s - loss: 128.2577 - val_loss: 763.6927
Epoch 00073: val_loss did not improve
Epoch 75/300
10s - loss: 128.0853 - val_loss: 794.4623
Epoch 00074: val_loss did not improve
Epoch 76/300
10s - loss: 127.8625 - val_loss: 822.7657
Epoch 00075: val_loss did not improve
Epoch 77/300
10s - loss: 127.7409 - val_loss: 757.5258
Epoch 00076: val_loss did not improve
Epoch 78/300
10s - loss: 127.4725 - val_loss: 752.8118
Epoch 00077: val_loss did not improve
Epoch 79/300
10s - loss: 127.3924 - val_loss: 840.7821
Epoch 00078: val_loss did not improve
Epoch 80/300
10s - loss: 127.2507 - val_loss: 743.6222
Epoch 00079: val_loss did not improve
Epoch 81/300
10s - loss: 127.0852 - val_loss: 723.6277
Epoch 00080: val_loss improved from 731.84335 to 723.62767, saving model to rlstm2h4_weights.hdf5
Epoch 82/300
10s - loss: 126.8927 - val_loss: 729.3748
Epoch 00081: val_loss did not improve
Epoch 83/300
10s - loss: 126.8105 - val_loss: 763.1730
Epoch 00082: val_loss did not improve
Epoch 84/300
10s - loss: 126.6287 - val_loss: 738.0955
Epoch 00083: val_loss did not improve
Epoch 85/300
10s - loss: 126.4455 - val_loss: 727.1610
Epoch 00084: val_loss did not improve
Epoch 86/300
10s - loss: 126.2707 - val_loss: 757.0327
Epoch 00085: val_loss did not improve
Epoch 87/300
10s - loss: 126.1941 - val_loss: 734.3786
Epoch 00086: val_loss did not improve
Epoch 88/300
10s - loss: 126.0450 - val_loss: 733.2114
Epoch 00087: val_loss did not improve
Epoch 89/300
10s - loss: 125.8210 - val_loss: 751.9224
Epoch 00088: val_loss did not improve
Epoch 90/300
10s - loss: 125.7444 - val_loss: 731.3131
Epoch 00089: val_loss did not improve
Epoch 91/300
10s - loss: 125.7019 - val_loss: 753.2017
Epoch 00090: val_loss did not improve
Epoch 92/300
10s - loss: 125.4081 - val_loss: 771.4290
Epoch 00091: val_loss did not improve
Epoch 93/300
10s - loss: 125.3073 - val_loss: 809.8129
Epoch 00092: val_loss did not improve
Epoch 94/300
10s - loss: 125.2966 - val_loss: 761.9439
Epoch 00093: val_loss did not improve
Epoch 95/300
10s - loss: 125.1202 - val_loss: 731.1727
Epoch 00094: val_loss did not improve
Epoch 96/300
10s - loss: 124.9777 - val_loss: 725.2294
Epoch 00095: val_loss did not improve
Epoch 97/300
10s - loss: 124.8304 - val_loss: 798.3321
Epoch 00096: val_loss did not improve
Epoch 98/300
10s - loss: 124.7491 - val_loss: 780.5166
Epoch 00097: val_loss did not improve
Epoch 99/300
10s - loss: 124.6409 - val_loss: 739.2561
Epoch 00098: val_loss did not improve
Epoch 100/300
10s - loss: 124.4484 - val_loss: 766.3814
Epoch 00099: val_loss did not improve
Epoch 101/300
10s - loss: 124.3600 - val_loss: 791.6114
Epoch 00100: val_loss did not improve
Epoch 102/300
10s - loss: 124.2801 - val_loss: 766.7149
Epoch 00101: val_loss did not improve

training rlstm2h5 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 318.8934 - val_loss: 1213.5615
Epoch 00000: val_loss improved from inf to 1213.56151, saving model to rlstm2h5_weights.hdf5
Epoch 2/300
10s - loss: 232.2859 - val_loss: 1207.8130
Epoch 00001: val_loss improved from 1213.56151 to 1207.81299, saving model to rlstm2h5_weights.hdf5
Epoch 3/300
10s - loss: 216.7017 - val_loss: 1120.5793
Epoch 00002: val_loss improved from 1207.81299 to 1120.57930, saving model to rlstm2h5_weights.hdf5
Epoch 4/300
10s - loss: 209.5407 - val_loss: 1110.9376
Epoch 00003: val_loss improved from 1120.57930 to 1110.93763, saving model to rlstm2h5_weights.hdf5
Epoch 5/300
10s - loss: 205.0838 - val_loss: 1098.6483
Epoch 00004: val_loss improved from 1110.93763 to 1098.64834, saving model to rlstm2h5_weights.hdf5
Epoch 6/300
10s - loss: 201.4726 - val_loss: 1085.3121
Epoch 00005: val_loss improved from 1098.64834 to 1085.31212, saving model to rlstm2h5_weights.hdf5
Epoch 7/300
10s - loss: 198.2417 - val_loss: 1152.8403
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 194.8036 - val_loss: 1099.6066
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 190.8759 - val_loss: 1136.8572
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 186.8625 - val_loss: 1187.1517
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 182.6492 - val_loss: 1191.2184
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 178.4327 - val_loss: 1230.4515
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 174.6273 - val_loss: 1462.5984
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 170.1490 - val_loss: 1214.9053
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 165.6851 - val_loss: 1071.9035
Epoch 00014: val_loss improved from 1085.31212 to 1071.90346, saving model to rlstm2h5_weights.hdf5
Epoch 16/300
10s - loss: 162.5463 - val_loss: 1103.7736
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 160.3151 - val_loss: 989.6478
Epoch 00016: val_loss improved from 1071.90346 to 989.64777, saving model to rlstm2h5_weights.hdf5
Epoch 18/300
10s - loss: 158.5077 - val_loss: 1126.5060
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 156.7496 - val_loss: 1157.2863
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 155.2325 - val_loss: 1123.7606
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 154.2345 - val_loss: 1029.7583
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 153.0209 - val_loss: 1155.2189
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 152.0170 - val_loss: 1057.0931
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 150.8421 - val_loss: 1128.2903
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 149.9588 - val_loss: 1246.3065
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 149.2218 - val_loss: 1486.9067
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 148.5147 - val_loss: 1371.7126
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 147.9868 - val_loss: 1134.3359
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 147.3460 - val_loss: 1560.7817
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 146.9389 - val_loss: 1196.4556
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 146.4197 - val_loss: 1513.8827
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 145.9988 - val_loss: 1430.2163
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 145.5635 - val_loss: 1340.3032
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 145.1983 - val_loss: 1407.0986
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 144.6653 - val_loss: 1427.6909
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 144.3969 - val_loss: 1344.2912
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 143.8978 - val_loss: 1567.0952
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 143.5469 - val_loss: 1341.3212
Epoch 00037: val_loss did not improve

training rlstm2h6 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 323.3247 - val_loss: 1286.7764
Epoch 00000: val_loss improved from inf to 1286.77639, saving model to rlstm2h6_weights.hdf5
Epoch 2/300
11s - loss: 232.2040 - val_loss: 1150.9341
Epoch 00001: val_loss improved from 1286.77639 to 1150.93414, saving model to rlstm2h6_weights.hdf5
Epoch 3/300
10s - loss: 217.4664 - val_loss: 1208.0379
Epoch 00002: val_loss did not improve
Epoch 4/300
11s - loss: 209.3915 - val_loss: 1114.6053
Epoch 00003: val_loss improved from 1150.93414 to 1114.60531, saving model to rlstm2h6_weights.hdf5
Epoch 5/300
10s - loss: 203.4718 - val_loss: 989.4761
Epoch 00004: val_loss improved from 1114.60531 to 989.47611, saving model to rlstm2h6_weights.hdf5
Epoch 6/300
10s - loss: 198.3738 - val_loss: 943.1416
Epoch 00005: val_loss improved from 989.47611 to 943.14161, saving model to rlstm2h6_weights.hdf5
Epoch 7/300
11s - loss: 191.3187 - val_loss: 815.8099
Epoch 00006: val_loss improved from 943.14161 to 815.80987, saving model to rlstm2h6_weights.hdf5
Epoch 8/300
11s - loss: 185.0905 - val_loss: 837.8221
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 181.1620 - val_loss: 810.9994
Epoch 00008: val_loss improved from 815.80987 to 810.99945, saving model to rlstm2h6_weights.hdf5
Epoch 10/300
11s - loss: 178.1409 - val_loss: 992.6284
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 175.3288 - val_loss: 882.2383
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 172.9187 - val_loss: 993.0849
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 170.8992 - val_loss: 1001.4548
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 168.8376 - val_loss: 1084.3570
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 166.5052 - val_loss: 914.0878
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 163.8605 - val_loss: 855.2452
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 161.4959 - val_loss: 1008.7612
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 159.6314 - val_loss: 772.5046
Epoch 00017: val_loss improved from 810.99945 to 772.50456, saving model to rlstm2h6_weights.hdf5
Epoch 19/300
10s - loss: 158.0471 - val_loss: 737.1903
Epoch 00018: val_loss improved from 772.50456 to 737.19035, saving model to rlstm2h6_weights.hdf5
Epoch 20/300
10s - loss: 156.9722 - val_loss: 763.3651
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 155.8769 - val_loss: 788.6951
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 154.9934 - val_loss: 799.6558
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 154.2222 - val_loss: 862.8844
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 153.5199 - val_loss: 800.9494
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 152.9591 - val_loss: 770.0984
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 152.4348 - val_loss: 674.4474
Epoch 00025: val_loss improved from 737.19035 to 674.44745, saving model to rlstm2h6_weights.hdf5
Epoch 27/300
10s - loss: 152.0066 - val_loss: 678.8207
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 151.4023 - val_loss: 782.6547
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 150.9102 - val_loss: 658.2613
Epoch 00028: val_loss improved from 674.44745 to 658.26127, saving model to rlstm2h6_weights.hdf5
Epoch 30/300
11s - loss: 150.4406 - val_loss: 725.8799
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 150.0816 - val_loss: 724.0898
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 149.5829 - val_loss: 729.5118
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 149.0204 - val_loss: 723.8098
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 148.7035 - val_loss: 720.6433
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 148.2600 - val_loss: 785.6388
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 147.8177 - val_loss: 768.8317
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 147.3334 - val_loss: 689.4590
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 146.8244 - val_loss: 741.7575
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 146.2928 - val_loss: 748.9835
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 145.8896 - val_loss: 660.1094
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 145.4355 - val_loss: 739.7306
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 145.0200 - val_loss: 639.0305
Epoch 00041: val_loss improved from 658.26127 to 639.03051, saving model to rlstm2h6_weights.hdf5
Epoch 43/300
10s - loss: 144.5436 - val_loss: 666.6190
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 143.9620 - val_loss: 689.3341
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 143.4073 - val_loss: 661.1802
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 142.8777 - val_loss: 668.9719
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 142.3943 - val_loss: 703.7505
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 141.8767 - val_loss: 642.9798
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 141.2606 - val_loss: 653.7811
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 140.7849 - val_loss: 664.7013
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 140.3751 - val_loss: 624.7539
Epoch 00050: val_loss improved from 639.03051 to 624.75387, saving model to rlstm2h6_weights.hdf5
Epoch 52/300
10s - loss: 139.9121 - val_loss: 657.8405
Epoch 00051: val_loss did not improve
Epoch 53/300
10s - loss: 139.5299 - val_loss: 649.9174
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 139.0983 - val_loss: 622.4646
Epoch 00053: val_loss improved from 624.75387 to 622.46456, saving model to rlstm2h6_weights.hdf5
Epoch 55/300
10s - loss: 138.7021 - val_loss: 635.1508
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 138.3434 - val_loss: 639.7892
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 137.9364 - val_loss: 651.3874
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 137.6017 - val_loss: 640.0009
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 137.3101 - val_loss: 649.1156
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 136.9626 - val_loss: 669.9201
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 136.5803 - val_loss: 653.2244
Epoch 00060: val_loss did not improve
Epoch 62/300
10s - loss: 136.2494 - val_loss: 655.6859
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 135.8599 - val_loss: 646.1603
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 135.5647 - val_loss: 663.4445
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 135.2831 - val_loss: 704.9610
Epoch 00064: val_loss did not improve
Epoch 66/300
10s - loss: 134.9895 - val_loss: 666.4396
Epoch 00065: val_loss did not improve
Epoch 67/300
10s - loss: 134.7365 - val_loss: 663.6613
Epoch 00066: val_loss did not improve
Epoch 68/300
10s - loss: 134.3418 - val_loss: 671.8885
Epoch 00067: val_loss did not improve
Epoch 69/300
10s - loss: 134.1224 - val_loss: 665.4852
Epoch 00068: val_loss did not improve
Epoch 70/300
10s - loss: 133.8469 - val_loss: 720.1677
Epoch 00069: val_loss did not improve
Epoch 71/300
10s - loss: 133.6223 - val_loss: 669.0335
Epoch 00070: val_loss did not improve
Epoch 72/300
10s - loss: 133.3425 - val_loss: 681.4197
Epoch 00071: val_loss did not improve
Epoch 73/300
10s - loss: 132.9995 - val_loss: 688.7484
Epoch 00072: val_loss did not improve
Epoch 74/300
10s - loss: 132.6866 - val_loss: 684.9654
Epoch 00073: val_loss did not improve
Epoch 75/300
10s - loss: 132.4494 - val_loss: 678.8409
Epoch 00074: val_loss did not improve

training rlstm2h7 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 322.5006 - val_loss: 1246.5213
Epoch 00000: val_loss improved from inf to 1246.52128, saving model to rlstm2h7_weights.hdf5
Epoch 2/300
11s - loss: 231.0027 - val_loss: 1072.4668
Epoch 00001: val_loss improved from 1246.52128 to 1072.46685, saving model to rlstm2h7_weights.hdf5
Epoch 3/300
10s - loss: 215.6395 - val_loss: 1068.6498
Epoch 00002: val_loss improved from 1072.46685 to 1068.64982, saving model to rlstm2h7_weights.hdf5
Epoch 4/300
10s - loss: 208.1265 - val_loss: 1094.9430
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 203.0787 - val_loss: 1025.4990
Epoch 00004: val_loss improved from 1068.64982 to 1025.49896, saving model to rlstm2h7_weights.hdf5
Epoch 6/300
10s - loss: 199.4918 - val_loss: 1079.8413
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 196.2765 - val_loss: 970.2260
Epoch 00006: val_loss improved from 1025.49896 to 970.22597, saving model to rlstm2h7_weights.hdf5
Epoch 8/300
11s - loss: 192.8492 - val_loss: 989.1502
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 188.8709 - val_loss: 940.4997
Epoch 00008: val_loss improved from 970.22597 to 940.49968, saving model to rlstm2h7_weights.hdf5
Epoch 10/300
11s - loss: 185.3694 - val_loss: 1284.4466
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 182.4858 - val_loss: 1154.8086
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 180.2072 - val_loss: 1060.1060
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 177.8808 - val_loss: 1272.5865
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 175.5869 - val_loss: 1345.4806
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 173.4700 - val_loss: 1201.0062
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 171.8030 - val_loss: 1284.9557
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 170.2371 - val_loss: 1548.7424
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 168.9093 - val_loss: 1366.6867
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 167.3828 - val_loss: 1499.9434
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 165.7617 - val_loss: 1728.8391
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 164.1622 - val_loss: 1462.9117
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 162.7700 - val_loss: 1529.1737
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 161.4673 - val_loss: 1742.8496
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 160.2593 - val_loss: 1418.9661
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 159.0852 - val_loss: 1616.0654
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 158.1591 - val_loss: 1212.6950
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 157.0821 - val_loss: 1338.5905
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 155.9615 - val_loss: 1630.4287
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 154.6953 - val_loss: 1456.7511
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 153.6289 - val_loss: 1127.9463
Epoch 00029: val_loss did not improve

training rlstm2h8 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 320.6351 - val_loss: 1168.4750
Epoch 00000: val_loss improved from inf to 1168.47496, saving model to rlstm2h8_weights.hdf5
Epoch 2/300
10s - loss: 232.4068 - val_loss: 1122.3606
Epoch 00001: val_loss improved from 1168.47496 to 1122.36058, saving model to rlstm2h8_weights.hdf5
Epoch 3/300
10s - loss: 216.6991 - val_loss: 1103.1336
Epoch 00002: val_loss improved from 1122.36058 to 1103.13359, saving model to rlstm2h8_weights.hdf5
Epoch 4/300
10s - loss: 208.9809 - val_loss: 1077.1570
Epoch 00003: val_loss improved from 1103.13359 to 1077.15704, saving model to rlstm2h8_weights.hdf5
Epoch 5/300
10s - loss: 204.3490 - val_loss: 1044.5784
Epoch 00004: val_loss improved from 1077.15704 to 1044.57840, saving model to rlstm2h8_weights.hdf5
Epoch 6/300
10s - loss: 200.8299 - val_loss: 955.1582
Epoch 00005: val_loss improved from 1044.57840 to 955.15816, saving model to rlstm2h8_weights.hdf5
Epoch 7/300
10s - loss: 197.5188 - val_loss: 972.8675
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 194.3542 - val_loss: 1027.4913
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 191.6557 - val_loss: 1099.1637
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 189.1090 - val_loss: 1036.4699
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 186.9251 - val_loss: 1108.8644
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 184.9345 - val_loss: 1017.2076
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 183.3876 - val_loss: 1141.5545
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 181.9452 - val_loss: 1152.0575
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 180.6375 - val_loss: 1151.7727
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 179.2704 - val_loss: 1298.4636
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 177.8287 - val_loss: 1282.2083
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 176.2052 - val_loss: 1413.4802
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 174.4622 - val_loss: 1323.2673
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 172.7734 - val_loss: 1324.3257
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 171.2353 - val_loss: 1382.6343
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 169.5053 - val_loss: 1225.2294
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 167.6982 - val_loss: 1294.3358
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 166.0478 - val_loss: 1238.0429
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 164.5810 - val_loss: 1373.4572
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 163.2614 - val_loss: 1426.7262
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 161.8169 - val_loss: 1568.5189
Epoch 00026: val_loss did not improve

training rlstm2h9 dim = 20
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
10s - loss: 320.1326 - val_loss: 1240.2508
Epoch 00000: val_loss improved from inf to 1240.25075, saving model to rlstm2h9_weights.hdf5
Epoch 2/300
11s - loss: 230.4149 - val_loss: 1136.9841
Epoch 00001: val_loss improved from 1240.25075 to 1136.98410, saving model to rlstm2h9_weights.hdf5
Epoch 3/300
11s - loss: 215.6697 - val_loss: 1122.5593
Epoch 00002: val_loss improved from 1136.98410 to 1122.55934, saving model to rlstm2h9_weights.hdf5
Epoch 4/300
10s - loss: 209.0020 - val_loss: 1107.8629
Epoch 00003: val_loss improved from 1122.55934 to 1107.86289, saving model to rlstm2h9_weights.hdf5
Epoch 5/300
10s - loss: 205.0413 - val_loss: 1037.1878
Epoch 00004: val_loss improved from 1107.86289 to 1037.18784, saving model to rlstm2h9_weights.hdf5
Epoch 6/300
11s - loss: 202.0054 - val_loss: 1042.7534
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 199.3932 - val_loss: 984.2131
Epoch 00006: val_loss improved from 1037.18784 to 984.21306, saving model to rlstm2h9_weights.hdf5
Epoch 8/300
11s - loss: 196.7005 - val_loss: 936.6848
Epoch 00007: val_loss improved from 984.21306 to 936.68482, saving model to rlstm2h9_weights.hdf5
Epoch 9/300
11s - loss: 194.0423 - val_loss: 921.7503
Epoch 00008: val_loss improved from 936.68482 to 921.75030, saving model to rlstm2h9_weights.hdf5
Epoch 10/300
11s - loss: 191.4694 - val_loss: 904.9113
Epoch 00009: val_loss improved from 921.75030 to 904.91133, saving model to rlstm2h9_weights.hdf5
Epoch 11/300
11s - loss: 189.1376 - val_loss: 933.0666
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 186.9713 - val_loss: 911.2121
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 184.7454 - val_loss: 867.6155
Epoch 00012: val_loss improved from 904.91133 to 867.61553, saving model to rlstm2h9_weights.hdf5
Epoch 14/300
11s - loss: 182.4211 - val_loss: 944.5439
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 180.1225 - val_loss: 919.7487
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 178.0691 - val_loss: 998.2557
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 176.3583 - val_loss: 996.6355
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 174.7792 - val_loss: 1001.0411
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 173.1509 - val_loss: 985.9168
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 171.8433 - val_loss: 875.2339
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 170.8210 - val_loss: 1027.3782
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 170.0386 - val_loss: 1140.4765
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 169.2266 - val_loss: 1003.5200
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 168.4603 - val_loss: 1000.0781
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 167.8617 - val_loss: 1044.9202
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 167.1094 - val_loss: 1096.0218
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 166.1990 - val_loss: 1095.1676
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 165.4910 - val_loss: 1000.4456
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 164.4552 - val_loss: 933.6902
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 163.4672 - val_loss: 993.9290
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 162.5261 - val_loss: 836.6616
Epoch 00030: val_loss improved from 867.61553 to 836.66156, saving model to rlstm2h9_weights.hdf5
Epoch 32/300
10s - loss: 161.4681 - val_loss: 887.5448
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 160.4289 - val_loss: 835.6779
Epoch 00032: val_loss improved from 836.66156 to 835.67788, saving model to rlstm2h9_weights.hdf5
Epoch 34/300
10s - loss: 159.3737 - val_loss: 882.0475
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 158.3552 - val_loss: 795.1551
Epoch 00034: val_loss improved from 835.67788 to 795.15511, saving model to rlstm2h9_weights.hdf5
Epoch 36/300
11s - loss: 157.3190 - val_loss: 688.8848
Epoch 00035: val_loss improved from 795.15511 to 688.88479, saving model to rlstm2h9_weights.hdf5
Epoch 37/300
10s - loss: 156.3754 - val_loss: 700.2440
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 155.1052 - val_loss: 656.8767
Epoch 00037: val_loss improved from 688.88479 to 656.87670, saving model to rlstm2h9_weights.hdf5
Epoch 39/300
10s - loss: 153.5710 - val_loss: 618.0094
Epoch 00038: val_loss improved from 656.87670 to 618.00943, saving model to rlstm2h9_weights.hdf5
Epoch 40/300
10s - loss: 152.0881 - val_loss: 650.9015
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 150.7555 - val_loss: 662.4531
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 149.6616 - val_loss: 690.7826
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 148.7794 - val_loss: 743.2488
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 147.9890 - val_loss: 658.5327
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 147.2813 - val_loss: 708.6708
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 146.6331 - val_loss: 792.6144
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 146.1076 - val_loss: 810.0167
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 145.4843 - val_loss: 864.2652
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 144.9936 - val_loss: 737.3369
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 144.4850 - val_loss: 806.0931
Epoch 00049: val_loss did not improve
Epoch 51/300
10s - loss: 143.8672 - val_loss: 877.6374
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 143.4369 - val_loss: 891.0694
Epoch 00051: val_loss did not improve
Epoch 53/300
10s - loss: 143.0904 - val_loss: 929.5869
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 142.6191 - val_loss: 904.5923
Epoch 00053: val_loss did not improve
Epoch 55/300
10s - loss: 142.2640 - val_loss: 828.3478
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 141.8704 - val_loss: 1021.9193
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 141.2451 - val_loss: 906.2476
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 140.7492 - val_loss: 773.9142
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 140.3075 - val_loss: 905.0210
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 139.8289 - val_loss: 997.6841
Epoch 00059: val_loss did not improve

training rlstm2h10 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 292.1397 - val_loss: 1275.8492
Epoch 00000: val_loss improved from inf to 1275.84916, saving model to rlstm2h10_weights.hdf5
Epoch 2/300
11s - loss: 225.3807 - val_loss: 1160.3735
Epoch 00001: val_loss improved from 1275.84916 to 1160.37353, saving model to rlstm2h10_weights.hdf5
Epoch 3/300
11s - loss: 208.6673 - val_loss: 1070.1088
Epoch 00002: val_loss improved from 1160.37353 to 1070.10879, saving model to rlstm2h10_weights.hdf5
Epoch 4/300
11s - loss: 201.3588 - val_loss: 1184.1779
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 193.5414 - val_loss: 1161.9662
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 185.0634 - val_loss: 1159.4772
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 177.5925 - val_loss: 1142.3567
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 171.1561 - val_loss: 1140.7307
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 166.0505 - val_loss: 1024.3091
Epoch 00008: val_loss improved from 1070.10879 to 1024.30907, saving model to rlstm2h10_weights.hdf5
Epoch 10/300
11s - loss: 161.7519 - val_loss: 1299.4976
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 157.9769 - val_loss: 968.3428
Epoch 00010: val_loss improved from 1024.30907 to 968.34283, saving model to rlstm2h10_weights.hdf5
Epoch 12/300
11s - loss: 154.6544 - val_loss: 1196.0856
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 152.0707 - val_loss: 982.9423
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 149.4705 - val_loss: 936.6349
Epoch 00013: val_loss improved from 968.34283 to 936.63490, saving model to rlstm2h10_weights.hdf5
Epoch 15/300
11s - loss: 147.2355 - val_loss: 1175.8671
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 145.1067 - val_loss: 1443.6483
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 143.1991 - val_loss: 1689.3276
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 141.7461 - val_loss: 2032.9028
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 140.5632 - val_loss: 1490.0372
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 139.2552 - val_loss: 1754.4064
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 138.3231 - val_loss: 2003.9117
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 137.3832 - val_loss: 2154.8646
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 136.2973 - val_loss: 2262.6224
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 135.5703 - val_loss: 1721.4079
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 134.8488 - val_loss: 2553.9850
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 134.2770 - val_loss: 1961.0321
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 133.7376 - val_loss: 2213.5832
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 133.1015 - val_loss: 2351.7822
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 132.4453 - val_loss: 2488.7123
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 131.8936 - val_loss: 2282.8268
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 131.4678 - val_loss: 2689.4939
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 130.8635 - val_loss: 2754.5381
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 130.3567 - val_loss: 3433.4508
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 129.6323 - val_loss: 3099.9534
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 129.2817 - val_loss: 2673.8856
Epoch 00034: val_loss did not improve

training rlstm2h11 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 291.5915 - val_loss: 1223.4815
Epoch 00000: val_loss improved from inf to 1223.48152, saving model to rlstm2h11_weights.hdf5
Epoch 2/300
11s - loss: 228.1022 - val_loss: 1293.2419
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 209.7276 - val_loss: 1087.4361
Epoch 00002: val_loss improved from 1223.48152 to 1087.43615, saving model to rlstm2h11_weights.hdf5
Epoch 4/300
11s - loss: 200.9580 - val_loss: 998.7030
Epoch 00003: val_loss improved from 1087.43615 to 998.70300, saving model to rlstm2h11_weights.hdf5
Epoch 5/300
11s - loss: 195.3562 - val_loss: 1111.4039
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 189.5114 - val_loss: 1129.8434
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 184.5937 - val_loss: 1356.5266
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 180.0297 - val_loss: 1301.3353
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 175.5779 - val_loss: 1227.7055
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 171.0264 - val_loss: 1319.6772
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 165.9111 - val_loss: 1208.1771
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 160.2920 - val_loss: 1198.0475
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 155.1489 - val_loss: 1117.8847
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 150.7396 - val_loss: 1142.1203
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 146.8630 - val_loss: 1026.6124
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 144.0128 - val_loss: 877.5377
Epoch 00015: val_loss improved from 998.70300 to 877.53769, saving model to rlstm2h11_weights.hdf5
Epoch 17/300
11s - loss: 142.0316 - val_loss: 1146.2530
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 140.0462 - val_loss: 1213.9324
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 138.4008 - val_loss: 915.0772
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 136.9783 - val_loss: 730.6413
Epoch 00019: val_loss improved from 877.53769 to 730.64125, saving model to rlstm2h11_weights.hdf5
Epoch 21/300
11s - loss: 135.5836 - val_loss: 821.9274
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 134.3011 - val_loss: 1206.6481
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 133.1173 - val_loss: 804.7655
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 131.9843 - val_loss: 896.6483
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 131.0355 - val_loss: 784.1928
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 130.0317 - val_loss: 1115.9425
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 129.0995 - val_loss: 1011.6177
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 128.5520 - val_loss: 961.3539
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 127.8705 - val_loss: 793.3519
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 127.3840 - val_loss: 750.9068
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 126.8680 - val_loss: 729.1377
Epoch 00030: val_loss improved from 730.64125 to 729.13772, saving model to rlstm2h11_weights.hdf5
Epoch 32/300
11s - loss: 126.1465 - val_loss: 758.1175
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 125.5782 - val_loss: 756.7006
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 125.1923 - val_loss: 675.8137
Epoch 00033: val_loss improved from 729.13772 to 675.81372, saving model to rlstm2h11_weights.hdf5
Epoch 35/300
11s - loss: 124.6025 - val_loss: 707.5224
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 124.2179 - val_loss: 740.6451
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 123.7329 - val_loss: 793.2863
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 123.2553 - val_loss: 801.0404
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 122.9624 - val_loss: 795.4957
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 122.5317 - val_loss: 680.0060
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 122.1049 - val_loss: 782.5027
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 121.6135 - val_loss: 857.3860
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 121.1966 - val_loss: 838.3640
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 120.8721 - val_loss: 935.6936
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 120.3647 - val_loss: 708.6473
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 120.0204 - val_loss: 793.0972
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 119.6157 - val_loss: 765.5487
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 119.1818 - val_loss: 759.3394
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 119.0675 - val_loss: 804.5955
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 118.6171 - val_loss: 692.2952
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 118.1955 - val_loss: 835.5631
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 117.8825 - val_loss: 710.1882
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 117.6290 - val_loss: 639.0503
Epoch 00052: val_loss improved from 675.81372 to 639.05034, saving model to rlstm2h11_weights.hdf5
Epoch 54/300
11s - loss: 117.2524 - val_loss: 720.1608
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 116.7468 - val_loss: 806.5469
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 116.6444 - val_loss: 696.1327
Epoch 00055: val_loss did not improve
Epoch 57/300
11s - loss: 116.3749 - val_loss: 790.5215
Epoch 00056: val_loss did not improve
Epoch 58/300
11s - loss: 115.8984 - val_loss: 727.4424
Epoch 00057: val_loss did not improve
Epoch 59/300
11s - loss: 115.7414 - val_loss: 685.9695
Epoch 00058: val_loss did not improve
Epoch 60/300
11s - loss: 115.3730 - val_loss: 647.0216
Epoch 00059: val_loss did not improve
Epoch 61/300
11s - loss: 114.9949 - val_loss: 660.5456
Epoch 00060: val_loss did not improve
Epoch 62/300
11s - loss: 114.9158 - val_loss: 755.9943
Epoch 00061: val_loss did not improve
Epoch 63/300
11s - loss: 114.6946 - val_loss: 590.2411
Epoch 00062: val_loss improved from 639.05034 to 590.24106, saving model to rlstm2h11_weights.hdf5
Epoch 64/300
11s - loss: 114.4826 - val_loss: 680.0546
Epoch 00063: val_loss did not improve
Epoch 65/300
11s - loss: 114.1927 - val_loss: 844.0805
Epoch 00064: val_loss did not improve
Epoch 66/300
11s - loss: 113.8485 - val_loss: 656.8694
Epoch 00065: val_loss did not improve
Epoch 67/300
11s - loss: 113.4962 - val_loss: 706.5299
Epoch 00066: val_loss did not improve
Epoch 68/300
11s - loss: 113.2456 - val_loss: 700.4009
Epoch 00067: val_loss did not improve
Epoch 69/300
11s - loss: 112.9985 - val_loss: 856.9463
Epoch 00068: val_loss did not improve
Epoch 70/300
11s - loss: 112.7845 - val_loss: 686.1386
Epoch 00069: val_loss did not improve
Epoch 71/300
11s - loss: 112.2303 - val_loss: 831.2996
Epoch 00070: val_loss did not improve
Epoch 72/300
11s - loss: 112.1450 - val_loss: 734.6118
Epoch 00071: val_loss did not improve
Epoch 73/300
11s - loss: 111.7593 - val_loss: 661.8133
Epoch 00072: val_loss did not improve
Epoch 74/300
11s - loss: 111.5763 - val_loss: 680.9624
Epoch 00073: val_loss did not improve
Epoch 75/300
11s - loss: 111.4124 - val_loss: 862.7991
Epoch 00074: val_loss did not improve
Epoch 76/300
11s - loss: 111.1161 - val_loss: 666.6057
Epoch 00075: val_loss did not improve
Epoch 77/300
11s - loss: 110.9979 - val_loss: 728.3934
Epoch 00076: val_loss did not improve
Epoch 78/300
11s - loss: 110.5322 - val_loss: 708.7578
Epoch 00077: val_loss did not improve
Epoch 79/300
11s - loss: 110.3946 - val_loss: 678.5514
Epoch 00078: val_loss did not improve
Epoch 80/300
11s - loss: 110.0568 - val_loss: 875.0559
Epoch 00079: val_loss did not improve
Epoch 81/300
11s - loss: 109.8782 - val_loss: 754.6225
Epoch 00080: val_loss did not improve
Epoch 82/300
11s - loss: 109.6529 - val_loss: 680.6224
Epoch 00081: val_loss did not improve
Epoch 83/300
11s - loss: 109.3414 - val_loss: 660.7673
Epoch 00082: val_loss did not improve
Epoch 84/300
11s - loss: 109.0095 - val_loss: 631.7838
Epoch 00083: val_loss did not improve

training rlstm2h12 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 294.3517 - val_loss: 1238.8613
Epoch 00000: val_loss improved from inf to 1238.86131, saving model to rlstm2h12_weights.hdf5
Epoch 2/300
11s - loss: 226.4864 - val_loss: 1254.1453
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 208.1943 - val_loss: 1114.9381
Epoch 00002: val_loss improved from 1238.86131 to 1114.93815, saving model to rlstm2h12_weights.hdf5
Epoch 4/300
11s - loss: 199.5520 - val_loss: 1101.8252
Epoch 00003: val_loss improved from 1114.93815 to 1101.82519, saving model to rlstm2h12_weights.hdf5
Epoch 5/300
11s - loss: 192.8765 - val_loss: 1145.9023
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 183.7993 - val_loss: 925.7475
Epoch 00005: val_loss improved from 1101.82519 to 925.74745, saving model to rlstm2h12_weights.hdf5
Epoch 7/300
11s - loss: 173.0240 - val_loss: 807.7152
Epoch 00006: val_loss improved from 925.74745 to 807.71519, saving model to rlstm2h12_weights.hdf5
Epoch 8/300
11s - loss: 163.1048 - val_loss: 721.0222
Epoch 00007: val_loss improved from 807.71519 to 721.02220, saving model to rlstm2h12_weights.hdf5
Epoch 9/300
11s - loss: 156.8097 - val_loss: 687.5260
Epoch 00008: val_loss improved from 721.02220 to 687.52596, saving model to rlstm2h12_weights.hdf5
Epoch 10/300
11s - loss: 152.5228 - val_loss: 702.8357
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 149.3658 - val_loss: 706.8366
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 147.0957 - val_loss: 740.5364
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 145.3146 - val_loss: 748.9148
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 143.3972 - val_loss: 856.5526
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 141.8559 - val_loss: 821.3422
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 140.5668 - val_loss: 740.8749
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 139.2669 - val_loss: 747.5195
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 138.0650 - val_loss: 873.2408
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 136.8504 - val_loss: 785.7038
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 135.8152 - val_loss: 708.4924
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 134.8555 - val_loss: 812.3322
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 133.9414 - val_loss: 772.2414
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 133.0084 - val_loss: 867.1214
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 132.2004 - val_loss: 765.3944
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 131.3073 - val_loss: 691.9898
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 130.5923 - val_loss: 749.7304
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 129.7966 - val_loss: 820.4028
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 128.9161 - val_loss: 681.6134
Epoch 00027: val_loss improved from 687.52596 to 681.61342, saving model to rlstm2h12_weights.hdf5
Epoch 29/300
11s - loss: 128.3359 - val_loss: 765.8895
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 127.6673 - val_loss: 729.2456
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 126.8984 - val_loss: 898.3971
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 126.3493 - val_loss: 769.4791
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 125.7348 - val_loss: 1024.3951
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 125.1708 - val_loss: 837.5372
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 124.4905 - val_loss: 693.4874
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 124.1936 - val_loss: 877.8112
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 123.6635 - val_loss: 853.8500
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 122.8605 - val_loss: 1023.9836
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 122.3159 - val_loss: 825.1985
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 121.7410 - val_loss: 934.5938
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 121.3303 - val_loss: 1005.1363
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 120.7332 - val_loss: 961.6760
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 120.2405 - val_loss: 863.0421
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 119.7840 - val_loss: 728.3970
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 119.3742 - val_loss: 653.2892
Epoch 00044: val_loss improved from 681.61342 to 653.28923, saving model to rlstm2h12_weights.hdf5
Epoch 46/300
11s - loss: 118.9277 - val_loss: 1158.6878
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 118.4274 - val_loss: 1027.3622
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 118.0430 - val_loss: 793.9405
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 117.6370 - val_loss: 877.0826
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 117.2919 - val_loss: 943.5368
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 116.9075 - val_loss: 858.2622
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 116.4104 - val_loss: 768.1005
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 116.0698 - val_loss: 926.4692
Epoch 00052: val_loss did not improve
Epoch 54/300
11s - loss: 115.6738 - val_loss: 750.9534
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 115.4087 - val_loss: 805.1387
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 115.0551 - val_loss: 867.6644
Epoch 00055: val_loss did not improve
Epoch 57/300
11s - loss: 114.6810 - val_loss: 941.2223
Epoch 00056: val_loss did not improve
Epoch 58/300
11s - loss: 114.2589 - val_loss: 822.3496
Epoch 00057: val_loss did not improve
Epoch 59/300
11s - loss: 113.8194 - val_loss: 850.8688
Epoch 00058: val_loss did not improve
Epoch 60/300
11s - loss: 113.3776 - val_loss: 1144.5868
Epoch 00059: val_loss did not improve
Epoch 61/300
11s - loss: 113.0827 - val_loss: 758.5005
Epoch 00060: val_loss did not improve
Epoch 62/300
11s - loss: 112.7174 - val_loss: 1023.0348
Epoch 00061: val_loss did not improve
Epoch 63/300
11s - loss: 112.3875 - val_loss: 1054.2476
Epoch 00062: val_loss did not improve
Epoch 64/300
11s - loss: 111.9912 - val_loss: 1084.3082
Epoch 00063: val_loss did not improve
Epoch 65/300
11s - loss: 111.7885 - val_loss: 819.6182
Epoch 00064: val_loss did not improve
Epoch 66/300
11s - loss: 111.3682 - val_loss: 1049.2900
Epoch 00065: val_loss did not improve

training rlstm2h13 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 291.2667 - val_loss: 1300.5414
Epoch 00000: val_loss improved from inf to 1300.54139, saving model to rlstm2h13_weights.hdf5
Epoch 2/300
11s - loss: 227.2800 - val_loss: 1131.4365
Epoch 00001: val_loss improved from 1300.54139 to 1131.43653, saving model to rlstm2h13_weights.hdf5
Epoch 3/300
11s - loss: 209.3914 - val_loss: 1039.7164
Epoch 00002: val_loss improved from 1131.43653 to 1039.71637, saving model to rlstm2h13_weights.hdf5
Epoch 4/300
11s - loss: 200.7117 - val_loss: 1058.0744
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 194.9890 - val_loss: 994.1143
Epoch 00004: val_loss improved from 1039.71637 to 994.11433, saving model to rlstm2h13_weights.hdf5
Epoch 6/300
11s - loss: 189.8700 - val_loss: 999.4717
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 184.4859 - val_loss: 1118.3111
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 179.8513 - val_loss: 1020.0599
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 175.0903 - val_loss: 1189.8455
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 170.1754 - val_loss: 1196.2390
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 166.1667 - val_loss: 1078.7580
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 162.2570 - val_loss: 972.0661
Epoch 00011: val_loss improved from 994.11433 to 972.06607, saving model to rlstm2h13_weights.hdf5
Epoch 13/300
11s - loss: 158.2487 - val_loss: 966.8670
Epoch 00012: val_loss improved from 972.06607 to 966.86703, saving model to rlstm2h13_weights.hdf5
Epoch 14/300
11s - loss: 154.1644 - val_loss: 1100.8783
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 150.6273 - val_loss: 792.5058
Epoch 00014: val_loss improved from 966.86703 to 792.50584, saving model to rlstm2h13_weights.hdf5
Epoch 16/300
11s - loss: 147.8158 - val_loss: 1084.0734
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 145.7148 - val_loss: 1061.6310
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 143.4341 - val_loss: 893.2761
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 141.6020 - val_loss: 766.2259
Epoch 00018: val_loss improved from 792.50584 to 766.22590, saving model to rlstm2h13_weights.hdf5
Epoch 20/300
11s - loss: 139.9619 - val_loss: 1489.3184
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 138.4398 - val_loss: 847.5953
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 137.0425 - val_loss: 842.8090
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 135.5692 - val_loss: 757.6321
Epoch 00022: val_loss improved from 766.22590 to 757.63210, saving model to rlstm2h13_weights.hdf5
Epoch 24/300
11s - loss: 134.3838 - val_loss: 1050.9652
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 133.2470 - val_loss: 960.6695
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 132.2765 - val_loss: 1014.4940
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 131.2866 - val_loss: 918.4133
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 130.3681 - val_loss: 763.6642
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 129.8871 - val_loss: 900.8811
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 129.2726 - val_loss: 997.9273
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 128.4750 - val_loss: 829.0484
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 128.0345 - val_loss: 1163.5887
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 127.3759 - val_loss: 978.6584
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 126.7447 - val_loss: 1065.1022
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 126.1320 - val_loss: 872.3282
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 125.5886 - val_loss: 962.5099
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 125.0028 - val_loss: 1156.1658
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 124.6416 - val_loss: 940.2985
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 124.1799 - val_loss: 916.0287
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 123.7201 - val_loss: 878.0017
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 123.3712 - val_loss: 912.5492
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 123.0819 - val_loss: 1015.8026
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 122.6230 - val_loss: 958.4293
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 122.2988 - val_loss: 937.3717
Epoch 00043: val_loss did not improve

training rlstm2h14 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 291.4343 - val_loss: 1270.0571
Epoch 00000: val_loss improved from inf to 1270.05712, saving model to rlstm2h14_weights.hdf5
Epoch 2/300
11s - loss: 226.8202 - val_loss: 1175.2000
Epoch 00001: val_loss improved from 1270.05712 to 1175.19998, saving model to rlstm2h14_weights.hdf5
Epoch 3/300
11s - loss: 208.4192 - val_loss: 1078.4521
Epoch 00002: val_loss improved from 1175.19998 to 1078.45209, saving model to rlstm2h14_weights.hdf5
Epoch 4/300
11s - loss: 200.5267 - val_loss: 1163.7144
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 194.9050 - val_loss: 1169.3939
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 188.3098 - val_loss: 1110.8265
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 179.3793 - val_loss: 1039.5363
Epoch 00006: val_loss improved from 1078.45209 to 1039.53633, saving model to rlstm2h14_weights.hdf5
Epoch 8/300
11s - loss: 170.9948 - val_loss: 1017.9938
Epoch 00007: val_loss improved from 1039.53633 to 1017.99379, saving model to rlstm2h14_weights.hdf5
Epoch 9/300
11s - loss: 163.8372 - val_loss: 917.7438
Epoch 00008: val_loss improved from 1017.99379 to 917.74375, saving model to rlstm2h14_weights.hdf5
Epoch 10/300
11s - loss: 158.4493 - val_loss: 1090.1714
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 154.0117 - val_loss: 1008.1798
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 150.2434 - val_loss: 1264.5876
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 147.0415 - val_loss: 1061.0513
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 144.4508 - val_loss: 1096.5112
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 142.2608 - val_loss: 1561.3077
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 140.6051 - val_loss: 1305.1161
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 139.1518 - val_loss: 1665.5291
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 137.6135 - val_loss: 1716.6113
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 136.5614 - val_loss: 1303.0600
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 135.6538 - val_loss: 1536.3327
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 134.7267 - val_loss: 1320.8374
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 133.5645 - val_loss: 1256.2344
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 132.8577 - val_loss: 1364.1686
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 132.0714 - val_loss: 1298.4049
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 131.3871 - val_loss: 1528.2558
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 130.6554 - val_loss: 1227.2869
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 130.1651 - val_loss: 1585.9106
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 129.5619 - val_loss: 1747.2297
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 129.0499 - val_loss: 1229.8693
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 128.4170 - val_loss: 1554.6366
Epoch 00029: val_loss did not improve

training rlstm2h15 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 293.8307 - val_loss: 1184.7041
Epoch 00000: val_loss improved from inf to 1184.70407, saving model to rlstm2h15_weights.hdf5
Epoch 2/300
11s - loss: 226.8609 - val_loss: 1210.7340
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 208.5939 - val_loss: 1138.5834
Epoch 00002: val_loss improved from 1184.70407 to 1138.58336, saving model to rlstm2h15_weights.hdf5
Epoch 4/300
11s - loss: 200.9594 - val_loss: 1078.7358
Epoch 00003: val_loss improved from 1138.58336 to 1078.73584, saving model to rlstm2h15_weights.hdf5
Epoch 5/300
11s - loss: 195.1880 - val_loss: 1216.7909
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 189.4437 - val_loss: 1059.2243
Epoch 00005: val_loss improved from 1078.73584 to 1059.22430, saving model to rlstm2h15_weights.hdf5
Epoch 7/300
11s - loss: 181.8275 - val_loss: 852.3025
Epoch 00006: val_loss improved from 1059.22430 to 852.30252, saving model to rlstm2h15_weights.hdf5
Epoch 8/300
11s - loss: 170.7723 - val_loss: 815.0257
Epoch 00007: val_loss improved from 852.30252 to 815.02569, saving model to rlstm2h15_weights.hdf5
Epoch 9/300
11s - loss: 161.3670 - val_loss: 635.1434
Epoch 00008: val_loss improved from 815.02569 to 635.14339, saving model to rlstm2h15_weights.hdf5
Epoch 10/300
11s - loss: 155.5490 - val_loss: 784.8735
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 151.5665 - val_loss: 649.6058
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 148.4795 - val_loss: 744.9144
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 146.0712 - val_loss: 894.1773
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 144.1556 - val_loss: 687.8360
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 142.2582 - val_loss: 779.0020
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 140.8241 - val_loss: 732.5826
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 139.5036 - val_loss: 728.9576
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 138.2114 - val_loss: 847.2958
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 137.0184 - val_loss: 735.8496
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 135.7485 - val_loss: 733.9096
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 134.7912 - val_loss: 791.2218
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 133.5720 - val_loss: 746.6595
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 132.8771 - val_loss: 743.7223
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 131.9609 - val_loss: 724.2293
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 131.3643 - val_loss: 735.1416
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 130.5724 - val_loss: 732.4701
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 129.9405 - val_loss: 754.6153
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 129.3628 - val_loss: 743.4469
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 128.7075 - val_loss: 745.7129
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 128.2275 - val_loss: 765.4438
Epoch 00029: val_loss did not improve

training rlstm2h16 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 291.1313 - val_loss: 1204.1390
Epoch 00000: val_loss improved from inf to 1204.13898, saving model to rlstm2h16_weights.hdf5
Epoch 2/300
11s - loss: 226.9397 - val_loss: 1186.4029
Epoch 00001: val_loss improved from 1204.13898 to 1186.40294, saving model to rlstm2h16_weights.hdf5
Epoch 3/300
11s - loss: 208.9113 - val_loss: 1153.2655
Epoch 00002: val_loss improved from 1186.40294 to 1153.26552, saving model to rlstm2h16_weights.hdf5
Epoch 4/300
11s - loss: 200.1913 - val_loss: 1025.5886
Epoch 00003: val_loss improved from 1153.26552 to 1025.58858, saving model to rlstm2h16_weights.hdf5
Epoch 5/300
11s - loss: 194.0706 - val_loss: 1087.3977
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 189.1283 - val_loss: 1006.7982
Epoch 00005: val_loss improved from 1025.58858 to 1006.79824, saving model to rlstm2h16_weights.hdf5
Epoch 7/300
11s - loss: 184.2314 - val_loss: 967.5192
Epoch 00006: val_loss improved from 1006.79824 to 967.51925, saving model to rlstm2h16_weights.hdf5
Epoch 8/300
11s - loss: 178.1016 - val_loss: 864.1100
Epoch 00007: val_loss improved from 967.51925 to 864.11003, saving model to rlstm2h16_weights.hdf5
Epoch 9/300
11s - loss: 171.6214 - val_loss: 903.1820
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 165.0484 - val_loss: 960.8844
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 159.0107 - val_loss: 914.3976
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 154.1654 - val_loss: 911.1183
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 150.0286 - val_loss: 861.6404
Epoch 00012: val_loss improved from 864.11003 to 861.64040, saving model to rlstm2h16_weights.hdf5
Epoch 14/300
11s - loss: 147.0516 - val_loss: 891.9130
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 144.6348 - val_loss: 721.9678
Epoch 00014: val_loss improved from 861.64040 to 721.96784, saving model to rlstm2h16_weights.hdf5
Epoch 16/300
11s - loss: 142.3784 - val_loss: 673.7206
Epoch 00015: val_loss improved from 721.96784 to 673.72059, saving model to rlstm2h16_weights.hdf5
Epoch 17/300
11s - loss: 140.7561 - val_loss: 790.1549
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 138.9741 - val_loss: 603.4725
Epoch 00017: val_loss improved from 673.72059 to 603.47252, saving model to rlstm2h16_weights.hdf5
Epoch 19/300
11s - loss: 137.5874 - val_loss: 644.1487
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 136.3769 - val_loss: 679.0496
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 135.0533 - val_loss: 757.6424
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 133.8009 - val_loss: 660.7816
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 132.7382 - val_loss: 621.9143
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 131.6963 - val_loss: 714.5146
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 130.9598 - val_loss: 744.4259
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 130.0406 - val_loss: 589.3524
Epoch 00025: val_loss improved from 603.47252 to 589.35235, saving model to rlstm2h16_weights.hdf5
Epoch 27/300
11s - loss: 129.3059 - val_loss: 684.6710
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 128.7797 - val_loss: 604.0449
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 128.1769 - val_loss: 820.1681
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 127.2755 - val_loss: 712.7872
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 126.8106 - val_loss: 625.6464
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 126.2460 - val_loss: 614.3534
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 125.6777 - val_loss: 652.1966
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 125.2827 - val_loss: 718.6505
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 124.6522 - val_loss: 566.3051
Epoch 00034: val_loss improved from 589.35235 to 566.30506, saving model to rlstm2h16_weights.hdf5
Epoch 36/300
11s - loss: 124.3009 - val_loss: 824.4852
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 123.6696 - val_loss: 601.3972
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 123.2054 - val_loss: 629.7268
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 122.7148 - val_loss: 584.1334
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 122.2261 - val_loss: 589.7208
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 121.8358 - val_loss: 566.3699
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 121.3933 - val_loss: 604.6685
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 121.1480 - val_loss: 634.0798
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 120.6359 - val_loss: 658.0508
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 120.2440 - val_loss: 634.0284
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 120.0826 - val_loss: 600.7499
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 119.6410 - val_loss: 689.7779
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 119.4053 - val_loss: 594.6272
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 118.9789 - val_loss: 682.3507
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 118.8211 - val_loss: 767.4901
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 118.5986 - val_loss: 687.5542
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 118.3712 - val_loss: 606.5706
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 118.0249 - val_loss: 583.4457
Epoch 00052: val_loss did not improve
Epoch 54/300
11s - loss: 117.8222 - val_loss: 655.4082
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 117.6313 - val_loss: 775.4708
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 117.3058 - val_loss: 735.8434
Epoch 00055: val_loss did not improve

training rlstm2h17 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 292.1759 - val_loss: 1196.6299
Epoch 00000: val_loss improved from inf to 1196.62986, saving model to rlstm2h17_weights.hdf5
Epoch 2/300
11s - loss: 227.1092 - val_loss: 1149.1516
Epoch 00001: val_loss improved from 1196.62986 to 1149.15158, saving model to rlstm2h17_weights.hdf5
Epoch 3/300
11s - loss: 209.2879 - val_loss: 1164.5658
Epoch 00002: val_loss did not improve
Epoch 4/300
11s - loss: 200.7987 - val_loss: 1224.5567
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 194.6911 - val_loss: 1223.7479
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 189.2342 - val_loss: 1202.3068
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 185.2258 - val_loss: 1291.4540
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 181.3540 - val_loss: 1310.1930
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 175.4894 - val_loss: 1331.9237
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 167.9253 - val_loss: 1106.5652
Epoch 00009: val_loss improved from 1149.15158 to 1106.56515, saving model to rlstm2h17_weights.hdf5
Epoch 11/300
11s - loss: 161.7203 - val_loss: 1381.4428
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 157.0004 - val_loss: 1461.1663
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 153.2864 - val_loss: 1308.7633
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 150.4639 - val_loss: 1255.2840
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 147.9595 - val_loss: 1867.9201
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 145.8677 - val_loss: 1485.4075
Epoch 00015: val_loss did not improve
Epoch 17/300
12s - loss: 143.6954 - val_loss: 1568.8694
Epoch 00016: val_loss did not improve
Epoch 18/300
12s - loss: 141.7127 - val_loss: 1676.2650
Epoch 00017: val_loss did not improve
Epoch 19/300
12s - loss: 140.0038 - val_loss: 1898.7720
Epoch 00018: val_loss did not improve
Epoch 20/300
12s - loss: 138.3260 - val_loss: 2321.3096
Epoch 00019: val_loss did not improve
Epoch 21/300
12s - loss: 137.0201 - val_loss: 2430.6565
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 135.7996 - val_loss: 1866.3150
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 134.5390 - val_loss: 2171.8511
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 133.4535 - val_loss: 2522.4185
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 132.3928 - val_loss: 3022.4579
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 131.4146 - val_loss: 3139.7198
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 130.3251 - val_loss: 2989.8615
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 129.5591 - val_loss: 3630.1833
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 128.7721 - val_loss: 3656.5107
Epoch 00028: val_loss did not improve
Epoch 30/300
12s - loss: 128.0120 - val_loss: 3822.6137
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 127.3985 - val_loss: 3770.3928
Epoch 00030: val_loss did not improve

training rlstm2h18 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
12s - loss: 291.4215 - val_loss: 1251.8892
Epoch 00000: val_loss improved from inf to 1251.88920, saving model to rlstm2h18_weights.hdf5
Epoch 2/300
12s - loss: 226.7913 - val_loss: 1149.5636
Epoch 00001: val_loss improved from 1251.88920 to 1149.56364, saving model to rlstm2h18_weights.hdf5
Epoch 3/300
11s - loss: 208.5891 - val_loss: 1122.1206
Epoch 00002: val_loss improved from 1149.56364 to 1122.12062, saving model to rlstm2h18_weights.hdf5
Epoch 4/300
11s - loss: 199.8032 - val_loss: 1140.6883
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 190.9959 - val_loss: 881.6702
Epoch 00004: val_loss improved from 1122.12062 to 881.67016, saving model to rlstm2h18_weights.hdf5
Epoch 6/300
11s - loss: 179.3590 - val_loss: 1092.9343
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 172.0672 - val_loss: 1266.4258
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 166.6514 - val_loss: 915.1601
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 161.7194 - val_loss: 997.1497
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 157.6095 - val_loss: 1142.8128
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 154.0418 - val_loss: 1018.5105
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 151.0236 - val_loss: 1027.9932
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 148.4330 - val_loss: 915.6413
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 146.0797 - val_loss: 1101.1346
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 144.2863 - val_loss: 1057.7914
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 142.5190 - val_loss: 995.5652
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 140.9507 - val_loss: 799.0797
Epoch 00016: val_loss improved from 881.67016 to 799.07974, saving model to rlstm2h18_weights.hdf5
Epoch 18/300
11s - loss: 139.5596 - val_loss: 925.6161
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 138.2420 - val_loss: 883.1612
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 136.6539 - val_loss: 874.3854
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 135.0947 - val_loss: 866.1273
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 133.7598 - val_loss: 735.3428
Epoch 00021: val_loss improved from 799.07974 to 735.34282, saving model to rlstm2h18_weights.hdf5
Epoch 23/300
11s - loss: 132.6183 - val_loss: 694.6611
Epoch 00022: val_loss improved from 735.34282 to 694.66109, saving model to rlstm2h18_weights.hdf5
Epoch 24/300
11s - loss: 131.5362 - val_loss: 709.0052
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 130.6803 - val_loss: 706.8895
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 129.7298 - val_loss: 690.0327
Epoch 00025: val_loss improved from 694.66109 to 690.03269, saving model to rlstm2h18_weights.hdf5
Epoch 27/300
11s - loss: 128.9503 - val_loss: 743.1406
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 128.3155 - val_loss: 728.1651
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 127.5761 - val_loss: 707.5396
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 126.9003 - val_loss: 715.4180
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 126.2568 - val_loss: 706.7347
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 125.8941 - val_loss: 752.6121
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 125.3620 - val_loss: 801.7643
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 124.8579 - val_loss: 843.2487
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 124.3429 - val_loss: 773.5612
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 124.0747 - val_loss: 761.9289
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 123.4587 - val_loss: 700.3939
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 123.1817 - val_loss: 806.0971
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 122.5684 - val_loss: 788.4682
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 122.3165 - val_loss: 731.5659
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 121.8081 - val_loss: 784.1627
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 121.5929 - val_loss: 870.7677
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 121.1917 - val_loss: 903.9427
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 120.9169 - val_loss: 773.8284
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 120.5178 - val_loss: 814.8537
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 120.2496 - val_loss: 890.6567
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 119.9766 - val_loss: 760.1485
Epoch 00046: val_loss did not improve

training rlstm2h19 dim = 40
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 293.0459 - val_loss: 1310.1668
Epoch 00000: val_loss improved from inf to 1310.16677, saving model to rlstm2h19_weights.hdf5
Epoch 2/300
11s - loss: 227.8375 - val_loss: 1167.0565
Epoch 00001: val_loss improved from 1310.16677 to 1167.05653, saving model to rlstm2h19_weights.hdf5
Epoch 3/300
11s - loss: 208.4638 - val_loss: 1154.5234
Epoch 00002: val_loss improved from 1167.05653 to 1154.52341, saving model to rlstm2h19_weights.hdf5
Epoch 4/300
11s - loss: 199.7846 - val_loss: 1125.1198
Epoch 00003: val_loss improved from 1154.52341 to 1125.11976, saving model to rlstm2h19_weights.hdf5
Epoch 5/300
11s - loss: 192.6558 - val_loss: 1044.9992
Epoch 00004: val_loss improved from 1125.11976 to 1044.99923, saving model to rlstm2h19_weights.hdf5
Epoch 6/300
11s - loss: 181.5275 - val_loss: 1006.7411
Epoch 00005: val_loss improved from 1044.99923 to 1006.74112, saving model to rlstm2h19_weights.hdf5
Epoch 7/300
11s - loss: 171.1752 - val_loss: 1011.3077
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 165.2884 - val_loss: 892.3993
Epoch 00007: val_loss improved from 1006.74112 to 892.39929, saving model to rlstm2h19_weights.hdf5
Epoch 9/300
11s - loss: 161.1843 - val_loss: 980.6550
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 157.9739 - val_loss: 838.0547
Epoch 00009: val_loss improved from 892.39929 to 838.05473, saving model to rlstm2h19_weights.hdf5
Epoch 11/300
11s - loss: 155.1679 - val_loss: 845.9494
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 152.1596 - val_loss: 830.1325
Epoch 00011: val_loss improved from 838.05473 to 830.13251, saving model to rlstm2h19_weights.hdf5
Epoch 13/300
11s - loss: 149.6389 - val_loss: 1039.2700
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 147.2331 - val_loss: 786.4477
Epoch 00013: val_loss improved from 830.13251 to 786.44767, saving model to rlstm2h19_weights.hdf5
Epoch 15/300
11s - loss: 145.2520 - val_loss: 886.9021
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 143.4605 - val_loss: 855.7089
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 141.6285 - val_loss: 910.6996
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 140.0080 - val_loss: 913.6677
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 138.6983 - val_loss: 913.9373
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 137.4457 - val_loss: 958.2387
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 136.3778 - val_loss: 875.3808
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 135.3774 - val_loss: 980.9979
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 134.4329 - val_loss: 981.2986
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 133.7007 - val_loss: 1056.8779
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 132.6883 - val_loss: 1098.6407
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 131.8986 - val_loss: 1130.1048
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 131.3247 - val_loss: 1150.7173
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 130.5763 - val_loss: 1147.9153
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 129.8349 - val_loss: 1275.1550
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 129.0884 - val_loss: 1269.4022
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 128.5880 - val_loss: 1226.0265
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 128.0650 - val_loss: 1290.7695
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 127.3113 - val_loss: 1165.6325
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 126.6834 - val_loss: 1095.1883
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 126.0260 - val_loss: 1194.9978
Epoch 00034: val_loss did not improve

training rlstm2h20 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 280.4405 - val_loss: 1297.7375
Epoch 00000: val_loss improved from inf to 1297.73746, saving model to rlstm2h20_weights.hdf5
Epoch 2/300
11s - loss: 224.0267 - val_loss: 1211.8733
Epoch 00001: val_loss improved from 1297.73746 to 1211.87330, saving model to rlstm2h20_weights.hdf5
Epoch 3/300
11s - loss: 204.8491 - val_loss: 1022.0003
Epoch 00002: val_loss improved from 1211.87330 to 1022.00027, saving model to rlstm2h20_weights.hdf5
Epoch 4/300
11s - loss: 192.5845 - val_loss: 942.1117
Epoch 00003: val_loss improved from 1022.00027 to 942.11168, saving model to rlstm2h20_weights.hdf5
Epoch 5/300
11s - loss: 176.1579 - val_loss: 793.1552
Epoch 00004: val_loss improved from 942.11168 to 793.15515, saving model to rlstm2h20_weights.hdf5
Epoch 6/300
11s - loss: 165.1686 - val_loss: 1052.4977
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 158.4374 - val_loss: 926.8424
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 153.5206 - val_loss: 792.1478
Epoch 00007: val_loss improved from 793.15515 to 792.14781, saving model to rlstm2h20_weights.hdf5
Epoch 9/300
11s - loss: 150.0664 - val_loss: 854.9614
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 147.0953 - val_loss: 847.0693
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 144.8576 - val_loss: 751.2229
Epoch 00010: val_loss improved from 792.14781 to 751.22286, saving model to rlstm2h20_weights.hdf5
Epoch 12/300
11s - loss: 142.6899 - val_loss: 748.6711
Epoch 00011: val_loss improved from 751.22286 to 748.67110, saving model to rlstm2h20_weights.hdf5
Epoch 13/300
11s - loss: 140.3361 - val_loss: 1196.1632
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 138.6750 - val_loss: 784.1727
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 137.0911 - val_loss: 747.6692
Epoch 00014: val_loss improved from 748.67110 to 747.66923, saving model to rlstm2h20_weights.hdf5
Epoch 16/300
11s - loss: 135.3764 - val_loss: 861.3766
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 134.1583 - val_loss: 774.8168
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 132.8127 - val_loss: 1136.5712
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 131.2187 - val_loss: 790.8444
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 130.1128 - val_loss: 909.1122
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 129.0337 - val_loss: 1152.8464
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 128.1375 - val_loss: 1103.4709
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 127.3695 - val_loss: 942.4185
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 126.2122 - val_loss: 975.4996
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 125.7518 - val_loss: 892.4946
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 124.6480 - val_loss: 962.6957
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 124.0330 - val_loss: 934.4778
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 122.9563 - val_loss: 1368.9379
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 122.2702 - val_loss: 1000.0814
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 121.4326 - val_loss: 1123.1842
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 120.7712 - val_loss: 1335.6926
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 120.0357 - val_loss: 1320.5623
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 119.2479 - val_loss: 1104.2619
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 118.6515 - val_loss: 893.8098
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 118.1224 - val_loss: 1613.0366
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 117.6993 - val_loss: 1280.2788
Epoch 00035: val_loss did not improve

training rlstm2h21 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.7632 - val_loss: 1310.5841
Epoch 00000: val_loss improved from inf to 1310.58411, saving model to rlstm2h21_weights.hdf5
Epoch 2/300
11s - loss: 223.3902 - val_loss: 1210.9317
Epoch 00001: val_loss improved from 1310.58411 to 1210.93175, saving model to rlstm2h21_weights.hdf5
Epoch 3/300
11s - loss: 203.6281 - val_loss: 1079.6466
Epoch 00002: val_loss improved from 1210.93175 to 1079.64655, saving model to rlstm2h21_weights.hdf5
Epoch 4/300
11s - loss: 190.1499 - val_loss: 891.2043
Epoch 00003: val_loss improved from 1079.64655 to 891.20429, saving model to rlstm2h21_weights.hdf5
Epoch 5/300
11s - loss: 176.3554 - val_loss: 1056.8259
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 168.7500 - val_loss: 827.7449
Epoch 00005: val_loss improved from 891.20429 to 827.74487, saving model to rlstm2h21_weights.hdf5
Epoch 7/300
11s - loss: 163.7322 - val_loss: 1279.8430
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 159.8537 - val_loss: 1113.5280
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 156.6568 - val_loss: 950.2713
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 153.6321 - val_loss: 1169.7683
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 151.0397 - val_loss: 1088.1029
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 148.7177 - val_loss: 1200.9276
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 146.6748 - val_loss: 980.5216
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 144.7553 - val_loss: 1312.1450
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 143.3000 - val_loss: 975.4253
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 141.2874 - val_loss: 1017.5305
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 139.7432 - val_loss: 1060.0796
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 138.2446 - val_loss: 1017.3834
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 136.6569 - val_loss: 889.5590
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 135.3479 - val_loss: 1252.4602
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 133.7198 - val_loss: 896.8126
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 132.4844 - val_loss: 1021.3662
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 131.1300 - val_loss: 962.0618
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 129.8303 - val_loss: 856.9478
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 128.9508 - val_loss: 755.9206
Epoch 00024: val_loss improved from 827.74487 to 755.92057, saving model to rlstm2h21_weights.hdf5
Epoch 26/300
11s - loss: 127.8483 - val_loss: 879.7666
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 126.8695 - val_loss: 1025.4634
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 125.9378 - val_loss: 693.5971
Epoch 00027: val_loss improved from 755.92057 to 693.59710, saving model to rlstm2h21_weights.hdf5
Epoch 29/300
11s - loss: 124.7916 - val_loss: 991.1616
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 124.0668 - val_loss: 600.5165
Epoch 00029: val_loss improved from 693.59710 to 600.51651, saving model to rlstm2h21_weights.hdf5
Epoch 31/300
11s - loss: 123.0353 - val_loss: 615.3949
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 122.4139 - val_loss: 759.4183
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 121.7820 - val_loss: 783.7228
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 120.8178 - val_loss: 868.5352
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 120.3663 - val_loss: 711.0465
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 119.4938 - val_loss: 690.6273
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 118.8267 - val_loss: 636.4694
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 118.3728 - val_loss: 600.8373
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 117.6907 - val_loss: 570.1419
Epoch 00038: val_loss improved from 600.51651 to 570.14189, saving model to rlstm2h21_weights.hdf5
Epoch 40/300
11s - loss: 117.0301 - val_loss: 567.4867
Epoch 00039: val_loss improved from 570.14189 to 567.48670, saving model to rlstm2h21_weights.hdf5
Epoch 41/300
11s - loss: 116.1797 - val_loss: 591.7350
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 115.5646 - val_loss: 670.7032
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 115.0399 - val_loss: 701.4941
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 114.1996 - val_loss: 527.3262
Epoch 00043: val_loss improved from 567.48670 to 527.32620, saving model to rlstm2h21_weights.hdf5
Epoch 45/300
11s - loss: 113.7549 - val_loss: 580.2810
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 113.1994 - val_loss: 586.4696
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 112.5444 - val_loss: 504.8803
Epoch 00046: val_loss improved from 527.32620 to 504.88028, saving model to rlstm2h21_weights.hdf5
Epoch 48/300
11s - loss: 111.9840 - val_loss: 674.2127
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 111.3585 - val_loss: 722.3044
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 110.8715 - val_loss: 600.3589
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 110.4292 - val_loss: 591.9385
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 109.8769 - val_loss: 514.3376
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 109.2271 - val_loss: 599.1897
Epoch 00052: val_loss did not improve
Epoch 54/300
11s - loss: 108.8597 - val_loss: 741.1686
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 108.2759 - val_loss: 592.3844
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 107.8997 - val_loss: 546.6111
Epoch 00055: val_loss did not improve
Epoch 57/300
11s - loss: 107.6615 - val_loss: 556.2946
Epoch 00056: val_loss did not improve
Epoch 58/300
11s - loss: 107.1248 - val_loss: 622.7850
Epoch 00057: val_loss did not improve
Epoch 59/300
11s - loss: 106.6427 - val_loss: 574.7022
Epoch 00058: val_loss did not improve
Epoch 60/300
11s - loss: 106.1768 - val_loss: 589.3774
Epoch 00059: val_loss did not improve
Epoch 61/300
11s - loss: 105.8337 - val_loss: 594.5522
Epoch 00060: val_loss did not improve
Epoch 62/300
11s - loss: 105.3705 - val_loss: 590.9371
Epoch 00061: val_loss did not improve
Epoch 63/300
11s - loss: 104.9727 - val_loss: 539.1598
Epoch 00062: val_loss did not improve
Epoch 64/300
11s - loss: 104.6284 - val_loss: 542.9137
Epoch 00063: val_loss did not improve
Epoch 65/300
11s - loss: 104.1643 - val_loss: 583.6863
Epoch 00064: val_loss did not improve
Epoch 66/300
11s - loss: 103.8782 - val_loss: 583.8284
Epoch 00065: val_loss did not improve
Epoch 67/300
11s - loss: 103.3707 - val_loss: 550.4189
Epoch 00066: val_loss did not improve
Epoch 68/300
11s - loss: 103.1668 - val_loss: 634.1409
Epoch 00067: val_loss did not improve

training rlstm2h22 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.5149 - val_loss: 1184.7285
Epoch 00000: val_loss improved from inf to 1184.72849, saving model to rlstm2h22_weights.hdf5
Epoch 2/300
12s - loss: 224.0427 - val_loss: 1090.1785
Epoch 00001: val_loss improved from 1184.72849 to 1090.17855, saving model to rlstm2h22_weights.hdf5
Epoch 3/300
11s - loss: 205.0373 - val_loss: 1115.9476
Epoch 00002: val_loss did not improve
Epoch 4/300
11s - loss: 192.0575 - val_loss: 929.9449
Epoch 00003: val_loss improved from 1090.17855 to 929.94485, saving model to rlstm2h22_weights.hdf5
Epoch 5/300
11s - loss: 176.5316 - val_loss: 971.1785
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 166.2886 - val_loss: 977.0457
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 158.8601 - val_loss: 837.3799
Epoch 00006: val_loss improved from 929.94485 to 837.37994, saving model to rlstm2h22_weights.hdf5
Epoch 8/300
11s - loss: 153.3509 - val_loss: 814.6738
Epoch 00007: val_loss improved from 837.37994 to 814.67384, saving model to rlstm2h22_weights.hdf5
Epoch 9/300
11s - loss: 148.9694 - val_loss: 958.4269
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 145.4720 - val_loss: 1245.0850
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 142.7357 - val_loss: 987.3690
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 140.6542 - val_loss: 989.5286
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 138.9960 - val_loss: 746.1719
Epoch 00012: val_loss improved from 814.67384 to 746.17194, saving model to rlstm2h22_weights.hdf5
Epoch 14/300
11s - loss: 137.3284 - val_loss: 775.8888
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 135.9620 - val_loss: 803.5720
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 134.5067 - val_loss: 1086.9390
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 133.2739 - val_loss: 900.2072
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 132.2659 - val_loss: 775.3087
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 131.0698 - val_loss: 1246.8733
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 129.9631 - val_loss: 754.6281
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 128.8988 - val_loss: 1072.9604
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 127.8828 - val_loss: 906.6887
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 126.9563 - val_loss: 1229.0786
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 126.0357 - val_loss: 1079.2826
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 125.0479 - val_loss: 834.9583
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 124.5469 - val_loss: 873.7113
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 123.7947 - val_loss: 1099.7238
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 123.1138 - val_loss: 947.4394
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 122.4185 - val_loss: 903.1217
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 121.8763 - val_loss: 963.4323
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 121.3361 - val_loss: 1145.6225
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 120.6734 - val_loss: 997.2307
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 120.0099 - val_loss: 890.4212
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 119.1947 - val_loss: 1311.5577
Epoch 00033: val_loss did not improve

training rlstm2h23 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 278.3253 - val_loss: 1227.4852
Epoch 00000: val_loss improved from inf to 1227.48518, saving model to rlstm2h23_weights.hdf5
Epoch 2/300
11s - loss: 222.9465 - val_loss: 1169.6225
Epoch 00001: val_loss improved from 1227.48518 to 1169.62247, saving model to rlstm2h23_weights.hdf5
Epoch 3/300
11s - loss: 204.3491 - val_loss: 1254.5908
Epoch 00002: val_loss did not improve
Epoch 4/300
11s - loss: 194.0099 - val_loss: 1024.2190
Epoch 00003: val_loss improved from 1169.62247 to 1024.21900, saving model to rlstm2h23_weights.hdf5
Epoch 5/300
11s - loss: 182.7484 - val_loss: 1069.3494
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 171.1631 - val_loss: 985.9623
Epoch 00005: val_loss improved from 1024.21900 to 985.96234, saving model to rlstm2h23_weights.hdf5
Epoch 7/300
11s - loss: 162.0636 - val_loss: 858.7112
Epoch 00006: val_loss improved from 985.96234 to 858.71116, saving model to rlstm2h23_weights.hdf5
Epoch 8/300
11s - loss: 155.6995 - val_loss: 852.9615
Epoch 00007: val_loss improved from 858.71116 to 852.96148, saving model to rlstm2h23_weights.hdf5
Epoch 9/300
11s - loss: 150.5400 - val_loss: 984.5604
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 146.8248 - val_loss: 712.1431
Epoch 00009: val_loss improved from 852.96148 to 712.14311, saving model to rlstm2h23_weights.hdf5
Epoch 11/300
11s - loss: 143.7771 - val_loss: 937.2770
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 141.1418 - val_loss: 1088.4749
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 139.0847 - val_loss: 722.4165
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 137.1302 - val_loss: 1273.3283
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 135.5756 - val_loss: 835.7612
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 133.9077 - val_loss: 960.1385
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 132.6432 - val_loss: 1111.6696
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 131.4341 - val_loss: 1084.1190
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 130.4146 - val_loss: 1358.4310
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 129.5120 - val_loss: 1503.4849
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 128.5477 - val_loss: 1176.3676
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 127.4947 - val_loss: 1131.4660
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 126.6282 - val_loss: 978.3506
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 125.7166 - val_loss: 1248.9450
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 124.8796 - val_loss: 1060.7171
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 124.2752 - val_loss: 1215.6151
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 123.4744 - val_loss: 1020.2998
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 122.7586 - val_loss: 1972.9370
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 121.8849 - val_loss: 1026.8753
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 121.6848 - val_loss: 1570.0539
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 120.8232 - val_loss: 1411.0493
Epoch 00030: val_loss did not improve

training rlstm2h24 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.3182 - val_loss: 1239.2348
Epoch 00000: val_loss improved from inf to 1239.23482, saving model to rlstm2h24_weights.hdf5
Epoch 2/300
11s - loss: 223.2772 - val_loss: 1231.4047
Epoch 00001: val_loss improved from 1239.23482 to 1231.40472, saving model to rlstm2h24_weights.hdf5
Epoch 3/300
11s - loss: 204.6920 - val_loss: 1247.6177
Epoch 00002: val_loss did not improve
Epoch 4/300
11s - loss: 192.1523 - val_loss: 886.6415
Epoch 00003: val_loss improved from 1231.40472 to 886.64148, saving model to rlstm2h24_weights.hdf5
Epoch 5/300
11s - loss: 176.7314 - val_loss: 784.7377
Epoch 00004: val_loss improved from 886.64148 to 784.73773, saving model to rlstm2h24_weights.hdf5
Epoch 6/300
11s - loss: 164.4829 - val_loss: 799.2295
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 156.9861 - val_loss: 743.7236
Epoch 00006: val_loss improved from 784.73773 to 743.72364, saving model to rlstm2h24_weights.hdf5
Epoch 8/300
11s - loss: 151.7424 - val_loss: 681.5519
Epoch 00007: val_loss improved from 743.72364 to 681.55194, saving model to rlstm2h24_weights.hdf5
Epoch 9/300
11s - loss: 147.4889 - val_loss: 743.9193
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 143.6095 - val_loss: 790.1425
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 140.6838 - val_loss: 1078.5669
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 138.7809 - val_loss: 1019.3024
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 136.7686 - val_loss: 971.8798
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 134.9147 - val_loss: 960.9486
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 133.2312 - val_loss: 909.0734
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 131.7531 - val_loss: 748.4054
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 130.4235 - val_loss: 779.9465
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 129.1397 - val_loss: 996.7109
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 128.1203 - val_loss: 796.5030
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 127.2408 - val_loss: 701.0055
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 125.9939 - val_loss: 852.1777
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 125.1660 - val_loss: 893.2762
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 124.4804 - val_loss: 967.4306
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 123.6264 - val_loss: 923.5558
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 122.8845 - val_loss: 746.4655
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 122.0786 - val_loss: 939.7179
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 121.4030 - val_loss: 1012.6197
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 120.8680 - val_loss: 725.9915
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 120.0998 - val_loss: 881.9916
Epoch 00028: val_loss did not improve

training rlstm2h25 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.5766 - val_loss: 1194.9395
Epoch 00000: val_loss improved from inf to 1194.93950, saving model to rlstm2h25_weights.hdf5
Epoch 2/300
11s - loss: 221.4870 - val_loss: 1353.6264
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 197.2580 - val_loss: 1098.5610
Epoch 00002: val_loss improved from 1194.93950 to 1098.56099, saving model to rlstm2h25_weights.hdf5
Epoch 4/300
11s - loss: 181.5298 - val_loss: 1084.4764
Epoch 00003: val_loss improved from 1098.56099 to 1084.47637, saving model to rlstm2h25_weights.hdf5
Epoch 5/300
11s - loss: 171.4194 - val_loss: 935.8812
Epoch 00004: val_loss improved from 1084.47637 to 935.88122, saving model to rlstm2h25_weights.hdf5
Epoch 6/300
11s - loss: 166.2448 - val_loss: 1174.5968
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 162.6804 - val_loss: 760.4351
Epoch 00006: val_loss improved from 935.88122 to 760.43509, saving model to rlstm2h25_weights.hdf5
Epoch 8/300
11s - loss: 159.2367 - val_loss: 895.8606
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 156.1673 - val_loss: 789.4046
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 153.3493 - val_loss: 865.6326
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 150.4633 - val_loss: 696.8731
Epoch 00010: val_loss improved from 760.43509 to 696.87306, saving model to rlstm2h25_weights.hdf5
Epoch 12/300
11s - loss: 148.3286 - val_loss: 796.8842
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 145.8474 - val_loss: 714.4609
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 143.7039 - val_loss: 687.2411
Epoch 00013: val_loss improved from 696.87306 to 687.24113, saving model to rlstm2h25_weights.hdf5
Epoch 15/300
11s - loss: 141.7181 - val_loss: 673.0021
Epoch 00014: val_loss improved from 687.24113 to 673.00212, saving model to rlstm2h25_weights.hdf5
Epoch 16/300
11s - loss: 139.8879 - val_loss: 823.9673
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 138.2313 - val_loss: 677.7622
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 136.8696 - val_loss: 636.5185
Epoch 00017: val_loss improved from 673.00212 to 636.51852, saving model to rlstm2h25_weights.hdf5
Epoch 19/300
11s - loss: 135.3356 - val_loss: 705.6089
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 133.7793 - val_loss: 634.2725
Epoch 00019: val_loss improved from 636.51852 to 634.27251, saving model to rlstm2h25_weights.hdf5
Epoch 21/300
11s - loss: 132.5535 - val_loss: 643.9359
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 131.2891 - val_loss: 643.2811
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 129.9375 - val_loss: 705.2497
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 128.9115 - val_loss: 689.8143
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 127.5893 - val_loss: 670.8164
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 126.4464 - val_loss: 663.9494
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 125.5513 - val_loss: 666.2323
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 124.7119 - val_loss: 657.3945
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 123.6615 - val_loss: 739.3229
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 123.1732 - val_loss: 707.7035
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 122.3130 - val_loss: 665.8064
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 121.5828 - val_loss: 684.0723
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 120.7629 - val_loss: 697.6048
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 120.0964 - val_loss: 829.7889
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 119.7097 - val_loss: 720.0322
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 119.0131 - val_loss: 746.7004
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 118.3445 - val_loss: 753.2383
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 118.0020 - val_loss: 671.1934
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 117.3636 - val_loss: 699.7672
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 116.5772 - val_loss: 718.7624
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 115.9662 - val_loss: 886.7180
Epoch 00040: val_loss did not improve

training rlstm2h26 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.2151 - val_loss: 1348.3391
Epoch 00000: val_loss improved from inf to 1348.33909, saving model to rlstm2h26_weights.hdf5
Epoch 2/300
11s - loss: 223.9129 - val_loss: 1166.7935
Epoch 00001: val_loss improved from 1348.33909 to 1166.79346, saving model to rlstm2h26_weights.hdf5
Epoch 3/300
11s - loss: 205.5805 - val_loss: 1022.1578
Epoch 00002: val_loss improved from 1166.79346 to 1022.15781, saving model to rlstm2h26_weights.hdf5
Epoch 4/300
11s - loss: 196.3156 - val_loss: 1176.9119
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 189.2651 - val_loss: 1084.7564
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 183.6519 - val_loss: 957.5158
Epoch 00005: val_loss improved from 1022.15781 to 957.51575, saving model to rlstm2h26_weights.hdf5
Epoch 7/300
11s - loss: 178.3270 - val_loss: 873.3780
Epoch 00006: val_loss improved from 957.51575 to 873.37798, saving model to rlstm2h26_weights.hdf5
Epoch 8/300
11s - loss: 171.1100 - val_loss: 991.9183
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 163.0224 - val_loss: 951.7255
Epoch 00008: val_loss did not improve
Epoch 10/300
12s - loss: 155.8437 - val_loss: 873.0311
Epoch 00009: val_loss improved from 873.37798 to 873.03109, saving model to rlstm2h26_weights.hdf5
Epoch 11/300
11s - loss: 149.7756 - val_loss: 902.6759
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 144.3558 - val_loss: 706.5058
Epoch 00011: val_loss improved from 873.03109 to 706.50579, saving model to rlstm2h26_weights.hdf5
Epoch 13/300
11s - loss: 139.9555 - val_loss: 742.3084
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 136.8506 - val_loss: 644.4143
Epoch 00013: val_loss improved from 706.50579 to 644.41434, saving model to rlstm2h26_weights.hdf5
Epoch 15/300
11s - loss: 134.5784 - val_loss: 792.5546
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 132.6043 - val_loss: 1092.3838
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 130.6118 - val_loss: 567.7826
Epoch 00016: val_loss improved from 644.41434 to 567.78265, saving model to rlstm2h26_weights.hdf5
Epoch 18/300
11s - loss: 128.9895 - val_loss: 702.8930
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 127.6989 - val_loss: 788.8069
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 126.5329 - val_loss: 824.0910
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 125.5509 - val_loss: 659.9479
Epoch 00020: val_loss did not improve
Epoch 22/300
12s - loss: 124.4898 - val_loss: 705.7579
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 123.7781 - val_loss: 706.3150
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 123.1177 - val_loss: 605.9400
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 122.3137 - val_loss: 571.6199
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 121.7608 - val_loss: 600.6919
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 121.1072 - val_loss: 723.9055
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 120.3631 - val_loss: 591.9895
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 119.7991 - val_loss: 614.0499
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 119.1991 - val_loss: 853.5227
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 118.8402 - val_loss: 751.6377
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 117.8336 - val_loss: 625.6612
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 117.3872 - val_loss: 609.6728
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 116.7219 - val_loss: 584.8036
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 116.3586 - val_loss: 688.4087
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 115.8305 - val_loss: 613.3717
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 115.1857 - val_loss: 730.3862
Epoch 00036: val_loss did not improve
Epoch 38/300
12s - loss: 114.8582 - val_loss: 625.4652
Epoch 00037: val_loss did not improve

training rlstm2h27 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 280.4313 - val_loss: 1178.0825
Epoch 00000: val_loss improved from inf to 1178.08254, saving model to rlstm2h27_weights.hdf5
Epoch 2/300
11s - loss: 223.2727 - val_loss: 1169.9745
Epoch 00001: val_loss improved from 1178.08254 to 1169.97445, saving model to rlstm2h27_weights.hdf5
Epoch 3/300
11s - loss: 204.4716 - val_loss: 1015.7396
Epoch 00002: val_loss improved from 1169.97445 to 1015.73957, saving model to rlstm2h27_weights.hdf5
Epoch 4/300
11s - loss: 191.1041 - val_loss: 982.7517
Epoch 00003: val_loss improved from 1015.73957 to 982.75172, saving model to rlstm2h27_weights.hdf5
Epoch 5/300
11s - loss: 177.2141 - val_loss: 954.0104
Epoch 00004: val_loss improved from 982.75172 to 954.01045, saving model to rlstm2h27_weights.hdf5
Epoch 6/300
11s - loss: 169.5027 - val_loss: 1041.8484
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 165.0289 - val_loss: 916.6948
Epoch 00006: val_loss improved from 954.01045 to 916.69477, saving model to rlstm2h27_weights.hdf5
Epoch 8/300
11s - loss: 161.0523 - val_loss: 1075.3349
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 157.4625 - val_loss: 810.5074
Epoch 00008: val_loss improved from 916.69477 to 810.50744, saving model to rlstm2h27_weights.hdf5
Epoch 10/300
11s - loss: 153.9549 - val_loss: 1089.7307
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 150.7835 - val_loss: 897.7461
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 147.8531 - val_loss: 920.1244
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 144.7758 - val_loss: 701.5858
Epoch 00012: val_loss improved from 810.50744 to 701.58584, saving model to rlstm2h27_weights.hdf5
Epoch 14/300
11s - loss: 142.0787 - val_loss: 986.9154
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 139.7657 - val_loss: 628.0500
Epoch 00014: val_loss improved from 701.58584 to 628.05002, saving model to rlstm2h27_weights.hdf5
Epoch 16/300
11s - loss: 137.5930 - val_loss: 709.9861
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 135.5385 - val_loss: 969.4812
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 134.0079 - val_loss: 744.4238
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 132.6007 - val_loss: 668.4409
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 131.5845 - val_loss: 770.2347
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 130.1360 - val_loss: 811.1473
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 129.2714 - val_loss: 629.4326
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 128.2330 - val_loss: 745.6523
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 127.5820 - val_loss: 771.3684
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 126.8230 - val_loss: 719.9058
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 125.7314 - val_loss: 866.6193
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 124.8829 - val_loss: 761.4797
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 123.9500 - val_loss: 666.2248
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 122.8133 - val_loss: 895.8039
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 121.7907 - val_loss: 640.0974
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 121.1698 - val_loss: 886.9129
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 120.4530 - val_loss: 715.7391
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 119.6318 - val_loss: 790.3171
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 118.7518 - val_loss: 918.0244
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 118.2792 - val_loss: 649.0060
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 117.7240 - val_loss: 832.3775
Epoch 00035: val_loss did not improve

training rlstm2h28 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 279.4423 - val_loss: 1296.4487
Epoch 00000: val_loss improved from inf to 1296.44870, saving model to rlstm2h28_weights.hdf5
Epoch 2/300
11s - loss: 222.0410 - val_loss: 1162.9859
Epoch 00001: val_loss improved from 1296.44870 to 1162.98595, saving model to rlstm2h28_weights.hdf5
Epoch 3/300
11s - loss: 203.1858 - val_loss: 1125.4706
Epoch 00002: val_loss improved from 1162.98595 to 1125.47055, saving model to rlstm2h28_weights.hdf5
Epoch 4/300
11s - loss: 188.8593 - val_loss: 1037.9878
Epoch 00003: val_loss improved from 1125.47055 to 1037.98778, saving model to rlstm2h28_weights.hdf5
Epoch 5/300
11s - loss: 174.9197 - val_loss: 1059.9677
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 167.8615 - val_loss: 1179.1671
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 162.4467 - val_loss: 973.3021
Epoch 00006: val_loss improved from 1037.98778 to 973.30214, saving model to rlstm2h28_weights.hdf5
Epoch 8/300
11s - loss: 157.3601 - val_loss: 1337.2102
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 152.6991 - val_loss: 964.6949
Epoch 00008: val_loss improved from 973.30214 to 964.69492, saving model to rlstm2h28_weights.hdf5
Epoch 10/300
11s - loss: 149.1409 - val_loss: 775.2504
Epoch 00009: val_loss improved from 964.69492 to 775.25041, saving model to rlstm2h28_weights.hdf5
Epoch 11/300
11s - loss: 146.3457 - val_loss: 806.7937
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 144.0650 - val_loss: 788.9666
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 141.7330 - val_loss: 652.2024
Epoch 00012: val_loss improved from 775.25041 to 652.20239, saving model to rlstm2h28_weights.hdf5
Epoch 14/300
11s - loss: 139.6609 - val_loss: 760.6186
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 137.5964 - val_loss: 842.0237
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 136.1021 - val_loss: 776.1769
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 134.5686 - val_loss: 784.5271
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 133.1650 - val_loss: 876.1367
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 131.8847 - val_loss: 940.0810
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 130.9304 - val_loss: 711.2515
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 129.7607 - val_loss: 698.2904
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 128.9194 - val_loss: 875.8321
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 127.7038 - val_loss: 767.9796
Epoch 00022: val_loss did not improve
Epoch 24/300
12s - loss: 126.8807 - val_loss: 818.4604
Epoch 00023: val_loss did not improve
Epoch 25/300
12s - loss: 126.2238 - val_loss: 756.1030
Epoch 00024: val_loss did not improve
Epoch 26/300
12s - loss: 125.3098 - val_loss: 687.6089
Epoch 00025: val_loss did not improve
Epoch 27/300
12s - loss: 124.7792 - val_loss: 871.1316
Epoch 00026: val_loss did not improve
Epoch 28/300
12s - loss: 124.0974 - val_loss: 922.9179
Epoch 00027: val_loss did not improve
Epoch 29/300
12s - loss: 123.1820 - val_loss: 1203.9210
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 122.6658 - val_loss: 881.8174
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 121.9063 - val_loss: 805.6596
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 121.2311 - val_loss: 863.6707
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 120.5302 - val_loss: 825.2633
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 120.0194 - val_loss: 1206.7455
Epoch 00033: val_loss did not improve

training rlstm2h29 dim = 60
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
12s - loss: 280.4977 - val_loss: 1223.9681
Epoch 00000: val_loss improved from inf to 1223.96813, saving model to rlstm2h29_weights.hdf5
Epoch 2/300
12s - loss: 223.2392 - val_loss: 1149.1527
Epoch 00001: val_loss improved from 1223.96813 to 1149.15269, saving model to rlstm2h29_weights.hdf5
Epoch 3/300
12s - loss: 204.4147 - val_loss: 1082.3685
Epoch 00002: val_loss improved from 1149.15269 to 1082.36854, saving model to rlstm2h29_weights.hdf5
Epoch 4/300
12s - loss: 191.2861 - val_loss: 1163.5663
Epoch 00003: val_loss did not improve
Epoch 5/300
12s - loss: 177.2267 - val_loss: 989.6982
Epoch 00004: val_loss improved from 1082.36854 to 989.69822, saving model to rlstm2h29_weights.hdf5
Epoch 6/300
12s - loss: 167.5170 - val_loss: 878.9336
Epoch 00005: val_loss improved from 989.69822 to 878.93363, saving model to rlstm2h29_weights.hdf5
Epoch 7/300
12s - loss: 160.4387 - val_loss: 1047.4135
Epoch 00006: val_loss did not improve
Epoch 8/300
12s - loss: 154.9651 - val_loss: 1247.6960
Epoch 00007: val_loss did not improve
Epoch 9/300
12s - loss: 150.5396 - val_loss: 919.6569
Epoch 00008: val_loss did not improve
Epoch 10/300
12s - loss: 146.6047 - val_loss: 913.2031
Epoch 00009: val_loss did not improve
Epoch 11/300
12s - loss: 143.2034 - val_loss: 1347.9140
Epoch 00010: val_loss did not improve
Epoch 12/300
12s - loss: 140.3250 - val_loss: 697.6579
Epoch 00011: val_loss improved from 878.93363 to 697.65786, saving model to rlstm2h29_weights.hdf5
Epoch 13/300
12s - loss: 137.8914 - val_loss: 805.4700
Epoch 00012: val_loss did not improve
Epoch 14/300
12s - loss: 135.5378 - val_loss: 788.7874
Epoch 00013: val_loss did not improve
Epoch 15/300
12s - loss: 133.8432 - val_loss: 756.3219
Epoch 00014: val_loss did not improve
Epoch 16/300
12s - loss: 132.0620 - val_loss: 663.9092
Epoch 00015: val_loss improved from 697.65786 to 663.90917, saving model to rlstm2h29_weights.hdf5
Epoch 17/300
12s - loss: 130.6797 - val_loss: 837.5422
Epoch 00016: val_loss did not improve
Epoch 18/300
12s - loss: 129.3356 - val_loss: 881.3563
Epoch 00017: val_loss did not improve
Epoch 19/300
12s - loss: 128.2469 - val_loss: 734.7648
Epoch 00018: val_loss did not improve
Epoch 20/300
12s - loss: 127.1478 - val_loss: 760.8931
Epoch 00019: val_loss did not improve
Epoch 21/300
12s - loss: 126.0529 - val_loss: 718.9652
Epoch 00020: val_loss did not improve
Epoch 22/300
12s - loss: 124.8368 - val_loss: 885.5902
Epoch 00021: val_loss did not improve
Epoch 23/300
12s - loss: 124.0055 - val_loss: 728.3641
Epoch 00022: val_loss did not improve
Epoch 24/300
12s - loss: 122.8615 - val_loss: 807.1156
Epoch 00023: val_loss did not improve
Epoch 25/300
12s - loss: 121.8976 - val_loss: 779.5609
Epoch 00024: val_loss did not improve
Epoch 26/300
12s - loss: 121.2349 - val_loss: 733.3956
Epoch 00025: val_loss did not improve
Epoch 27/300
12s - loss: 120.3633 - val_loss: 760.6401
Epoch 00026: val_loss did not improve
Epoch 28/300
12s - loss: 119.4198 - val_loss: 756.0178
Epoch 00027: val_loss did not improve
Epoch 29/300
12s - loss: 118.5657 - val_loss: 733.3301
Epoch 00028: val_loss did not improve
Epoch 30/300
12s - loss: 117.9737 - val_loss: 719.0164
Epoch 00029: val_loss did not improve
Epoch 31/300
12s - loss: 117.0720 - val_loss: 729.6365
Epoch 00030: val_loss did not improve
Epoch 32/300
12s - loss: 116.4151 - val_loss: 765.2592
Epoch 00031: val_loss did not improve
Epoch 33/300
12s - loss: 115.6330 - val_loss: 724.6989
Epoch 00032: val_loss did not improve
Epoch 34/300
12s - loss: 115.0684 - val_loss: 834.6417
Epoch 00033: val_loss did not improve
Epoch 35/300
12s - loss: 114.1737 - val_loss: 867.3732
Epoch 00034: val_loss did not improve
Epoch 36/300
12s - loss: 113.8276 - val_loss: 713.6220
Epoch 00035: val_loss did not improve
Epoch 37/300
12s - loss: 113.1730 - val_loss: 723.9749
Epoch 00036: val_loss did not improve

training rlstm2h30 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
12s - loss: 272.1521 - val_loss: 1151.2051
Epoch 00000: val_loss improved from inf to 1151.20513, saving model to rlstm2h30_weights.hdf5
Epoch 2/300
12s - loss: 220.1708 - val_loss: 1066.4901
Epoch 00001: val_loss improved from 1151.20513 to 1066.49012, saving model to rlstm2h30_weights.hdf5
Epoch 3/300
12s - loss: 199.9194 - val_loss: 1052.2450
Epoch 00002: val_loss improved from 1066.49012 to 1052.24498, saving model to rlstm2h30_weights.hdf5
Epoch 4/300
12s - loss: 184.4482 - val_loss: 936.9905
Epoch 00003: val_loss improved from 1052.24498 to 936.99048, saving model to rlstm2h30_weights.hdf5
Epoch 5/300
12s - loss: 170.9911 - val_loss: 828.0003
Epoch 00004: val_loss improved from 936.99048 to 828.00027, saving model to rlstm2h30_weights.hdf5
Epoch 6/300
12s - loss: 162.5368 - val_loss: 734.7925
Epoch 00005: val_loss improved from 828.00027 to 734.79246, saving model to rlstm2h30_weights.hdf5
Epoch 7/300
12s - loss: 155.7269 - val_loss: 755.1780
Epoch 00006: val_loss did not improve
Epoch 8/300
12s - loss: 150.2176 - val_loss: 714.5742
Epoch 00007: val_loss improved from 734.79246 to 714.57417, saving model to rlstm2h30_weights.hdf5
Epoch 9/300
12s - loss: 145.0106 - val_loss: 716.0302
Epoch 00008: val_loss did not improve
Epoch 10/300
12s - loss: 140.4739 - val_loss: 716.7710
Epoch 00009: val_loss did not improve
Epoch 11/300
12s - loss: 136.8733 - val_loss: 622.0204
Epoch 00010: val_loss improved from 714.57417 to 622.02042, saving model to rlstm2h30_weights.hdf5
Epoch 12/300
12s - loss: 133.9670 - val_loss: 739.0886
Epoch 00011: val_loss did not improve
Epoch 13/300
12s - loss: 131.5192 - val_loss: 662.7142
Epoch 00012: val_loss did not improve
Epoch 14/300
12s - loss: 129.2838 - val_loss: 752.7087
Epoch 00013: val_loss did not improve
Epoch 15/300
12s - loss: 127.3272 - val_loss: 755.7970
Epoch 00014: val_loss did not improve
Epoch 16/300
12s - loss: 125.3676 - val_loss: 1021.7645
Epoch 00015: val_loss did not improve
Epoch 17/300
12s - loss: 123.6697 - val_loss: 822.1169
Epoch 00016: val_loss did not improve
Epoch 18/300
12s - loss: 122.0108 - val_loss: 836.9491
Epoch 00017: val_loss did not improve
Epoch 19/300
12s - loss: 120.6736 - val_loss: 1117.4404
Epoch 00018: val_loss did not improve
Epoch 20/300
12s - loss: 119.3641 - val_loss: 978.4637
Epoch 00019: val_loss did not improve
Epoch 21/300
12s - loss: 118.4095 - val_loss: 1098.9137
Epoch 00020: val_loss did not improve
Epoch 22/300
12s - loss: 117.1619 - val_loss: 1231.0450
Epoch 00021: val_loss did not improve
Epoch 23/300
12s - loss: 115.9733 - val_loss: 1504.4233
Epoch 00022: val_loss did not improve
Epoch 24/300
12s - loss: 115.0034 - val_loss: 1286.5241
Epoch 00023: val_loss did not improve
Epoch 25/300
12s - loss: 114.0345 - val_loss: 1985.1352
Epoch 00024: val_loss did not improve
Epoch 26/300
12s - loss: 113.0832 - val_loss: 1232.8941
Epoch 00025: val_loss did not improve
Epoch 27/300
12s - loss: 112.2175 - val_loss: 1151.2068
Epoch 00026: val_loss did not improve
Epoch 28/300
12s - loss: 111.1943 - val_loss: 874.3044
Epoch 00027: val_loss did not improve
Epoch 29/300
12s - loss: 110.4960 - val_loss: 1629.0142
Epoch 00028: val_loss did not improve
Epoch 30/300
12s - loss: 109.6793 - val_loss: 1175.7747
Epoch 00029: val_loss did not improve
Epoch 31/300
12s - loss: 108.9629 - val_loss: 1204.5088
Epoch 00030: val_loss did not improve
Epoch 32/300
12s - loss: 108.2239 - val_loss: 1110.0394
Epoch 00031: val_loss did not improve

training rlstm2h31 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
12s - loss: 270.5099 - val_loss: 1152.7664
Epoch 00000: val_loss improved from inf to 1152.76643, saving model to rlstm2h31_weights.hdf5
Epoch 2/300
12s - loss: 222.1107 - val_loss: 1203.5756
Epoch 00001: val_loss did not improve
Epoch 3/300
12s - loss: 203.1600 - val_loss: 1004.5209
Epoch 00002: val_loss improved from 1152.76643 to 1004.52091, saving model to rlstm2h31_weights.hdf5
Epoch 4/300
12s - loss: 188.8790 - val_loss: 969.2493
Epoch 00003: val_loss improved from 1004.52091 to 969.24925, saving model to rlstm2h31_weights.hdf5
Epoch 5/300
12s - loss: 173.0057 - val_loss: 846.1494
Epoch 00004: val_loss improved from 969.24925 to 846.14940, saving model to rlstm2h31_weights.hdf5
Epoch 6/300
12s - loss: 162.6430 - val_loss: 921.2008
Epoch 00005: val_loss did not improve
Epoch 7/300
12s - loss: 154.8967 - val_loss: 1077.1505
Epoch 00006: val_loss did not improve
Epoch 8/300
12s - loss: 149.2033 - val_loss: 717.2530
Epoch 00007: val_loss improved from 846.14940 to 717.25296, saving model to rlstm2h31_weights.hdf5
Epoch 9/300
12s - loss: 144.7932 - val_loss: 904.9818
Epoch 00008: val_loss did not improve
Epoch 10/300
12s - loss: 141.0681 - val_loss: 942.4413
Epoch 00009: val_loss did not improve
Epoch 11/300
12s - loss: 137.2865 - val_loss: 1145.7046
Epoch 00010: val_loss did not improve
Epoch 12/300
12s - loss: 134.1553 - val_loss: 757.6559
Epoch 00011: val_loss did not improve
Epoch 13/300
12s - loss: 131.3164 - val_loss: 803.3911
Epoch 00012: val_loss did not improve
Epoch 14/300
12s - loss: 129.1550 - val_loss: 680.3193
Epoch 00013: val_loss improved from 717.25296 to 680.31935, saving model to rlstm2h31_weights.hdf5
Epoch 15/300
12s - loss: 127.2528 - val_loss: 674.3737
Epoch 00014: val_loss improved from 680.31935 to 674.37371, saving model to rlstm2h31_weights.hdf5
Epoch 16/300
12s - loss: 125.5800 - val_loss: 823.9945
Epoch 00015: val_loss did not improve
Epoch 17/300
12s - loss: 124.1693 - val_loss: 892.2830
Epoch 00016: val_loss did not improve
Epoch 18/300
12s - loss: 122.8543 - val_loss: 1155.3591
Epoch 00017: val_loss did not improve
Epoch 19/300
12s - loss: 121.7932 - val_loss: 785.4800
Epoch 00018: val_loss did not improve
Epoch 20/300
12s - loss: 120.5804 - val_loss: 756.1100
Epoch 00019: val_loss did not improve
Epoch 21/300
12s - loss: 119.3494 - val_loss: 667.6689
Epoch 00020: val_loss improved from 674.37371 to 667.66887, saving model to rlstm2h31_weights.hdf5
Epoch 22/300
12s - loss: 118.2786 - val_loss: 802.4628
Epoch 00021: val_loss did not improve
Epoch 23/300
12s - loss: 117.4097 - val_loss: 679.8815
Epoch 00022: val_loss did not improve
Epoch 24/300
12s - loss: 116.6048 - val_loss: 691.3260
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 115.7532 - val_loss: 815.5132
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 115.0926 - val_loss: 841.9251
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 114.2810 - val_loss: 645.8461
Epoch 00026: val_loss improved from 667.66887 to 645.84606, saving model to rlstm2h31_weights.hdf5
Epoch 28/300
11s - loss: 113.4777 - val_loss: 820.3006
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 112.4894 - val_loss: 734.5180
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 111.7832 - val_loss: 1150.1888
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 111.2691 - val_loss: 921.7176
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 110.5558 - val_loss: 793.1902
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 109.8083 - val_loss: 999.0132
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 109.1769 - val_loss: 888.6823
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 108.6942 - val_loss: 688.4924
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 108.2216 - val_loss: 774.3727
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 107.4068 - val_loss: 747.9359
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 106.9871 - val_loss: 682.2832
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 106.5503 - val_loss: 805.7782
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 105.8657 - val_loss: 725.6667
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 105.4894 - val_loss: 748.5824
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 104.9242 - val_loss: 781.0083
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 104.5813 - val_loss: 766.1731
Epoch 00042: val_loss did not improve
Epoch 44/300
12s - loss: 103.9080 - val_loss: 804.8951
Epoch 00043: val_loss did not improve
Epoch 45/300
13s - loss: 103.4065 - val_loss: 781.0503
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 103.0190 - val_loss: 991.7651
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 102.6171 - val_loss: 798.1257
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 102.1799 - val_loss: 799.9324
Epoch 00047: val_loss did not improve

training rlstm2h32 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 276.6102 - val_loss: 1294.8720
Epoch 00000: val_loss improved from inf to 1294.87202, saving model to rlstm2h32_weights.hdf5
Epoch 2/300
12s - loss: 223.1978 - val_loss: 1134.4017
Epoch 00001: val_loss improved from 1294.87202 to 1134.40171, saving model to rlstm2h32_weights.hdf5
Epoch 3/300
13s - loss: 198.0579 - val_loss: 895.1835
Epoch 00002: val_loss improved from 1134.40171 to 895.18348, saving model to rlstm2h32_weights.hdf5
Epoch 4/300
11s - loss: 182.4728 - val_loss: 953.1304
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 171.4445 - val_loss: 1263.3397
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 163.2134 - val_loss: 891.8068
Epoch 00005: val_loss improved from 895.18348 to 891.80682, saving model to rlstm2h32_weights.hdf5
Epoch 7/300
11s - loss: 157.4364 - val_loss: 870.1911
Epoch 00006: val_loss improved from 891.80682 to 870.19108, saving model to rlstm2h32_weights.hdf5
Epoch 8/300
11s - loss: 152.4387 - val_loss: 1117.0637
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 147.7092 - val_loss: 929.0718
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 144.3896 - val_loss: 853.0191
Epoch 00009: val_loss improved from 870.19108 to 853.01912, saving model to rlstm2h32_weights.hdf5
Epoch 11/300
11s - loss: 141.2650 - val_loss: 757.2779
Epoch 00010: val_loss improved from 853.01912 to 757.27788, saving model to rlstm2h32_weights.hdf5
Epoch 12/300
11s - loss: 139.0040 - val_loss: 895.9585
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 137.0008 - val_loss: 1055.7365
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 135.1769 - val_loss: 842.9683
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 133.3094 - val_loss: 723.4458
Epoch 00014: val_loss improved from 757.27788 to 723.44578, saving model to rlstm2h32_weights.hdf5
Epoch 16/300
11s - loss: 131.8696 - val_loss: 1036.7863
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 130.3796 - val_loss: 955.4848
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 128.9309 - val_loss: 1163.4837
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 127.6915 - val_loss: 811.6401
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 126.4612 - val_loss: 1142.2253
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 125.5696 - val_loss: 1058.4255
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 124.4668 - val_loss: 1153.7902
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 123.6386 - val_loss: 1072.7292
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 122.7765 - val_loss: 970.8908
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 121.6217 - val_loss: 873.5622
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 121.1361 - val_loss: 879.8306
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 119.9311 - val_loss: 931.6213
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 119.0432 - val_loss: 945.5180
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 118.0905 - val_loss: 972.7126
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 117.0809 - val_loss: 800.3694
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 116.4159 - val_loss: 928.1676
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 115.6534 - val_loss: 1213.8118
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 114.9424 - val_loss: 1018.3839
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 114.1620 - val_loss: 820.8380
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 113.3824 - val_loss: 1158.8717
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 112.7390 - val_loss: 1526.6309
Epoch 00035: val_loss did not improve

training rlstm2h33 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 270.8928 - val_loss: 1282.2646
Epoch 00000: val_loss improved from inf to 1282.26464, saving model to rlstm2h33_weights.hdf5
Epoch 2/300
11s - loss: 221.3350 - val_loss: 1158.1245
Epoch 00001: val_loss improved from 1282.26464 to 1158.12452, saving model to rlstm2h33_weights.hdf5
Epoch 3/300
11s - loss: 200.6501 - val_loss: 1085.9358
Epoch 00002: val_loss improved from 1158.12452 to 1085.93576, saving model to rlstm2h33_weights.hdf5
Epoch 4/300
11s - loss: 186.1949 - val_loss: 1016.1650
Epoch 00003: val_loss improved from 1085.93576 to 1016.16504, saving model to rlstm2h33_weights.hdf5
Epoch 5/300
11s - loss: 172.5640 - val_loss: 899.8575
Epoch 00004: val_loss improved from 1016.16504 to 899.85754, saving model to rlstm2h33_weights.hdf5
Epoch 6/300
11s - loss: 160.1924 - val_loss: 983.8572
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 152.3454 - val_loss: 1152.4020
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 146.9230 - val_loss: 794.4722
Epoch 00007: val_loss improved from 899.85754 to 794.47222, saving model to rlstm2h33_weights.hdf5
Epoch 9/300
11s - loss: 143.0279 - val_loss: 822.6280
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 139.4108 - val_loss: 864.7049
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 136.5844 - val_loss: 687.9608
Epoch 00010: val_loss improved from 794.47222 to 687.96083, saving model to rlstm2h33_weights.hdf5
Epoch 12/300
11s - loss: 133.9711 - val_loss: 654.1227
Epoch 00011: val_loss improved from 687.96083 to 654.12271, saving model to rlstm2h33_weights.hdf5
Epoch 13/300
11s - loss: 131.5445 - val_loss: 926.6932
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 129.6695 - val_loss: 678.0805
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 127.8763 - val_loss: 663.7658
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 126.3024 - val_loss: 673.8507
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 124.9862 - val_loss: 585.2600
Epoch 00016: val_loss improved from 654.12271 to 585.25998, saving model to rlstm2h33_weights.hdf5
Epoch 18/300
11s - loss: 123.7162 - val_loss: 662.0088
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 122.7205 - val_loss: 677.4017
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 121.2805 - val_loss: 635.0929
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 120.7881 - val_loss: 690.6770
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 119.7533 - val_loss: 606.5512
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 119.0403 - val_loss: 619.2307
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 117.9768 - val_loss: 671.9663
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 117.0735 - val_loss: 667.5587
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 116.2549 - val_loss: 665.5680
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 115.8257 - val_loss: 638.3756
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 114.9010 - val_loss: 727.6807
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 114.2662 - val_loss: 774.1477
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 113.5558 - val_loss: 606.2652
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 112.9766 - val_loss: 827.3506
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 112.3749 - val_loss: 631.1985
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 111.6345 - val_loss: 695.6514
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 111.1056 - val_loss: 619.2688
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 110.4019 - val_loss: 631.4327
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 109.9250 - val_loss: 793.2064
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 109.3199 - val_loss: 677.6031
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 108.7226 - val_loss: 741.9002
Epoch 00037: val_loss did not improve

training rlstm2h34 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 274.3156 - val_loss: 1340.6578
Epoch 00000: val_loss improved from inf to 1340.65778, saving model to rlstm2h34_weights.hdf5
Epoch 2/300
11s - loss: 223.5213 - val_loss: 1150.4050
Epoch 00001: val_loss improved from 1340.65778 to 1150.40502, saving model to rlstm2h34_weights.hdf5
Epoch 3/300
11s - loss: 203.6586 - val_loss: 1130.2591
Epoch 00002: val_loss improved from 1150.40502 to 1130.25910, saving model to rlstm2h34_weights.hdf5
Epoch 4/300
11s - loss: 186.1168 - val_loss: 965.2597
Epoch 00003: val_loss improved from 1130.25910 to 965.25972, saving model to rlstm2h34_weights.hdf5
Epoch 5/300
11s - loss: 171.9256 - val_loss: 836.5311
Epoch 00004: val_loss improved from 965.25972 to 836.53106, saving model to rlstm2h34_weights.hdf5
Epoch 6/300
11s - loss: 164.0160 - val_loss: 762.0458
Epoch 00005: val_loss improved from 836.53106 to 762.04584, saving model to rlstm2h34_weights.hdf5
Epoch 7/300
11s - loss: 157.9719 - val_loss: 812.8051
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 153.2698 - val_loss: 913.0874
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 148.8677 - val_loss: 869.1493
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 145.5886 - val_loss: 1038.1177
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 142.2309 - val_loss: 842.5098
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 139.8330 - val_loss: 1110.1124
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 137.7349 - val_loss: 864.0036
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 135.5305 - val_loss: 741.7097
Epoch 00013: val_loss improved from 762.04584 to 741.70975, saving model to rlstm2h34_weights.hdf5
Epoch 15/300
11s - loss: 133.6362 - val_loss: 891.4215
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 131.5740 - val_loss: 923.4272
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 129.7388 - val_loss: 695.5520
Epoch 00016: val_loss improved from 741.70975 to 695.55195, saving model to rlstm2h34_weights.hdf5
Epoch 18/300
11s - loss: 128.2962 - val_loss: 886.4968
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 126.7445 - val_loss: 883.4379
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 125.4859 - val_loss: 914.2691
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 124.3598 - val_loss: 1080.0359
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 123.3354 - val_loss: 813.1291
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 122.2007 - val_loss: 805.1076
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 121.5965 - val_loss: 916.2973
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 120.1748 - val_loss: 1182.7277
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 119.6703 - val_loss: 1023.6021
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 118.6027 - val_loss: 1058.8008
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 117.8302 - val_loss: 681.9693
Epoch 00027: val_loss improved from 695.55195 to 681.96927, saving model to rlstm2h34_weights.hdf5
Epoch 29/300
11s - loss: 117.1404 - val_loss: 670.0231
Epoch 00028: val_loss improved from 681.96927 to 670.02311, saving model to rlstm2h34_weights.hdf5
Epoch 30/300
11s - loss: 116.4342 - val_loss: 865.0155
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 115.7556 - val_loss: 1167.5546
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 115.4028 - val_loss: 756.0698
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 114.7625 - val_loss: 931.4123
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 113.9974 - val_loss: 1066.5431
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 113.5341 - val_loss: 1065.1345
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 112.8240 - val_loss: 915.8468
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 112.5393 - val_loss: 908.3322
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 111.8968 - val_loss: 846.3073
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 111.3638 - val_loss: 854.7097
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 111.0267 - val_loss: 768.0433
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 110.5269 - val_loss: 937.0420
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 110.0674 - val_loss: 966.9218
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 109.7171 - val_loss: 867.9275
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 109.1088 - val_loss: 1264.1489
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 108.5718 - val_loss: 825.5880
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 108.1848 - val_loss: 834.3741
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 107.8561 - val_loss: 909.1269
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 107.3648 - val_loss: 1119.8902
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 106.9765 - val_loss: 1394.0201
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 106.7263 - val_loss: 902.4887
Epoch 00049: val_loss did not improve

training rlstm2h35 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 271.2408 - val_loss: 1385.3168
Epoch 00000: val_loss improved from inf to 1385.31677, saving model to rlstm2h35_weights.hdf5
Epoch 2/300
11s - loss: 221.3727 - val_loss: 1139.3752
Epoch 00001: val_loss improved from 1385.31677 to 1139.37522, saving model to rlstm2h35_weights.hdf5
Epoch 3/300
11s - loss: 202.1007 - val_loss: 1131.2208
Epoch 00002: val_loss improved from 1139.37522 to 1131.22081, saving model to rlstm2h35_weights.hdf5
Epoch 4/300
11s - loss: 188.8063 - val_loss: 988.7622
Epoch 00003: val_loss improved from 1131.22081 to 988.76221, saving model to rlstm2h35_weights.hdf5
Epoch 5/300
11s - loss: 173.5650 - val_loss: 864.2350
Epoch 00004: val_loss improved from 988.76221 to 864.23505, saving model to rlstm2h35_weights.hdf5
Epoch 6/300
11s - loss: 163.8351 - val_loss: 757.6132
Epoch 00005: val_loss improved from 864.23505 to 757.61323, saving model to rlstm2h35_weights.hdf5
Epoch 7/300
11s - loss: 156.7104 - val_loss: 812.7734
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 151.6115 - val_loss: 882.1311
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 147.1221 - val_loss: 942.6772
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 143.2989 - val_loss: 995.2228
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 139.6690 - val_loss: 768.3794
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 136.8111 - val_loss: 740.1938
Epoch 00011: val_loss improved from 757.61323 to 740.19380, saving model to rlstm2h35_weights.hdf5
Epoch 13/300
11s - loss: 134.1131 - val_loss: 718.5076
Epoch 00012: val_loss improved from 740.19380 to 718.50758, saving model to rlstm2h35_weights.hdf5
Epoch 14/300
11s - loss: 132.1145 - val_loss: 682.8800
Epoch 00013: val_loss improved from 718.50758 to 682.87997, saving model to rlstm2h35_weights.hdf5
Epoch 15/300
11s - loss: 129.9401 - val_loss: 664.0653
Epoch 00014: val_loss improved from 682.87997 to 664.06525, saving model to rlstm2h35_weights.hdf5
Epoch 16/300
11s - loss: 127.8260 - val_loss: 710.0123
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 126.2113 - val_loss: 702.6160
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 124.7839 - val_loss: 745.5530
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 123.3001 - val_loss: 715.6115
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 122.1278 - val_loss: 714.3948
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 121.0021 - val_loss: 651.6090
Epoch 00020: val_loss improved from 664.06525 to 651.60902, saving model to rlstm2h35_weights.hdf5
Epoch 22/300
14s - loss: 119.7228 - val_loss: 810.8982
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 118.8483 - val_loss: 733.7939
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 117.8839 - val_loss: 680.8765
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 116.6899 - val_loss: 702.8716
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 115.7561 - val_loss: 767.5107
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 115.0692 - val_loss: 693.4511
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 114.0595 - val_loss: 711.3286
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 113.2532 - val_loss: 708.9509
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 112.4856 - val_loss: 669.6517
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 111.5245 - val_loss: 675.7293
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 110.9291 - val_loss: 710.6365
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 110.3412 - val_loss: 693.6035
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 109.6287 - val_loss: 755.9415
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 109.0934 - val_loss: 700.8557
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 108.5848 - val_loss: 745.1094
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 108.1996 - val_loss: 762.4748
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 107.3558 - val_loss: 707.5522
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 106.9659 - val_loss: 788.7765
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 106.4967 - val_loss: 709.7962
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 105.8520 - val_loss: 708.3146
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 105.4520 - val_loss: 713.2964
Epoch 00041: val_loss did not improve

training rlstm2h36 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 272.3781 - val_loss: 1103.1470
Epoch 00000: val_loss improved from inf to 1103.14704, saving model to rlstm2h36_weights.hdf5
Epoch 2/300
11s - loss: 222.4914 - val_loss: 1160.1578
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 203.8711 - val_loss: 961.9033
Epoch 00002: val_loss improved from 1103.14704 to 961.90326, saving model to rlstm2h36_weights.hdf5
Epoch 4/300
11s - loss: 188.5755 - val_loss: 804.3686
Epoch 00003: val_loss improved from 961.90326 to 804.36861, saving model to rlstm2h36_weights.hdf5
Epoch 5/300
11s - loss: 172.5385 - val_loss: 746.1810
Epoch 00004: val_loss improved from 804.36861 to 746.18096, saving model to rlstm2h36_weights.hdf5
Epoch 6/300
11s - loss: 162.5515 - val_loss: 1102.8288
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 155.7547 - val_loss: 946.8143
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 150.3434 - val_loss: 1202.9245
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 145.9526 - val_loss: 786.0374
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 141.9159 - val_loss: 858.3370
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 138.1115 - val_loss: 945.7355
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 134.7243 - val_loss: 873.7998
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 131.5446 - val_loss: 904.9375
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 128.9887 - val_loss: 740.4883
Epoch 00013: val_loss improved from 746.18096 to 740.48832, saving model to rlstm2h36_weights.hdf5
Epoch 15/300
11s - loss: 126.8869 - val_loss: 805.9338
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 124.9835 - val_loss: 936.3696
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 123.4795 - val_loss: 727.7689
Epoch 00016: val_loss improved from 740.48832 to 727.76893, saving model to rlstm2h36_weights.hdf5
Epoch 18/300
11s - loss: 121.9323 - val_loss: 784.0620
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 120.5944 - val_loss: 971.5286
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 119.3189 - val_loss: 1009.0080
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 118.3889 - val_loss: 974.4750
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 117.1566 - val_loss: 818.8015
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 116.3752 - val_loss: 925.4197
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 115.1857 - val_loss: 1098.7176
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 114.5408 - val_loss: 1021.1875
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 113.4885 - val_loss: 918.1530
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 112.7810 - val_loss: 803.3559
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 111.7748 - val_loss: 866.4460
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 110.9620 - val_loss: 897.5145
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 110.1902 - val_loss: 1197.0292
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 109.6069 - val_loss: 890.9609
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 108.8720 - val_loss: 1052.3288
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 107.9514 - val_loss: 814.5153
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 107.2507 - val_loss: 805.3062
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 106.6184 - val_loss: 944.6355
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 106.2479 - val_loss: 919.2388
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 105.5125 - val_loss: 944.8815
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 104.8806 - val_loss: 876.9769
Epoch 00037: val_loss did not improve

training rlstm2h37 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 278.8971 - val_loss: 1343.8082
Epoch 00000: val_loss improved from inf to 1343.80822, saving model to rlstm2h37_weights.hdf5
Epoch 2/300
12s - loss: 225.2176 - val_loss: 1183.0733
Epoch 00001: val_loss improved from 1343.80822 to 1183.07333, saving model to rlstm2h37_weights.hdf5
Epoch 3/300
11s - loss: 205.8788 - val_loss: 1024.3959
Epoch 00002: val_loss improved from 1183.07333 to 1024.39588, saving model to rlstm2h37_weights.hdf5
Epoch 4/300
11s - loss: 188.4132 - val_loss: 920.3260
Epoch 00003: val_loss improved from 1024.39588 to 920.32597, saving model to rlstm2h37_weights.hdf5
Epoch 5/300
11s - loss: 172.2320 - val_loss: 987.9926
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 162.6759 - val_loss: 1057.7906
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 155.9387 - val_loss: 1273.6287
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 150.4189 - val_loss: 1219.9775
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 145.4594 - val_loss: 969.0447
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 141.4603 - val_loss: 1054.4777
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 138.4893 - val_loss: 896.2435
Epoch 00010: val_loss improved from 920.32597 to 896.24349, saving model to rlstm2h37_weights.hdf5
Epoch 12/300
11s - loss: 136.1089 - val_loss: 782.0669
Epoch 00011: val_loss improved from 896.24349 to 782.06690, saving model to rlstm2h37_weights.hdf5
Epoch 13/300
11s - loss: 134.1445 - val_loss: 683.7663
Epoch 00012: val_loss improved from 782.06690 to 683.76626, saving model to rlstm2h37_weights.hdf5
Epoch 14/300
11s - loss: 132.3603 - val_loss: 883.5473
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 130.3152 - val_loss: 746.7722
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 128.6285 - val_loss: 1167.3760
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 126.7973 - val_loss: 736.3005
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 125.2451 - val_loss: 691.5967
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 123.6939 - val_loss: 819.0804
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 122.4850 - val_loss: 851.7625
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 120.8719 - val_loss: 958.0859
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 119.6366 - val_loss: 676.8028
Epoch 00021: val_loss improved from 683.76626 to 676.80285, saving model to rlstm2h37_weights.hdf5
Epoch 23/300
11s - loss: 118.4051 - val_loss: 868.9057
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 117.4847 - val_loss: 803.0538
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 116.1895 - val_loss: 689.1884
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 115.3219 - val_loss: 700.7409
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 114.2598 - val_loss: 675.3789
Epoch 00026: val_loss improved from 676.80285 to 675.37893, saving model to rlstm2h37_weights.hdf5
Epoch 28/300
11s - loss: 113.3033 - val_loss: 608.5243
Epoch 00027: val_loss improved from 675.37893 to 608.52434, saving model to rlstm2h37_weights.hdf5
Epoch 29/300
11s - loss: 112.5022 - val_loss: 609.3976
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 111.5499 - val_loss: 601.0007
Epoch 00029: val_loss improved from 608.52434 to 601.00068, saving model to rlstm2h37_weights.hdf5
Epoch 31/300
11s - loss: 110.8854 - val_loss: 954.0888
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 110.2332 - val_loss: 564.4806
Epoch 00031: val_loss improved from 601.00068 to 564.48063, saving model to rlstm2h37_weights.hdf5
Epoch 33/300
11s - loss: 109.4107 - val_loss: 591.0316
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 108.8622 - val_loss: 797.2517
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 108.2078 - val_loss: 720.0657
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 107.7384 - val_loss: 711.8996
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 107.2725 - val_loss: 682.1605
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 106.5623 - val_loss: 605.0490
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 106.0710 - val_loss: 635.4759
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 105.4603 - val_loss: 757.7274
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 105.0219 - val_loss: 558.2682
Epoch 00040: val_loss improved from 564.48063 to 558.26815, saving model to rlstm2h37_weights.hdf5
Epoch 42/300
11s - loss: 104.4109 - val_loss: 571.7736
Epoch 00041: val_loss did not improve
Epoch 43/300
11s - loss: 103.6985 - val_loss: 845.3676
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 103.3698 - val_loss: 715.4494
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 103.1031 - val_loss: 689.2415
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 102.4691 - val_loss: 644.4532
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 102.1350 - val_loss: 854.2013
Epoch 00046: val_loss did not improve
Epoch 48/300
11s - loss: 101.5601 - val_loss: 927.3562
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 101.2148 - val_loss: 612.8171
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 100.7082 - val_loss: 578.4622
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 100.5465 - val_loss: 656.8756
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 99.8510 - val_loss: 687.2018
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 99.7383 - val_loss: 716.3714
Epoch 00052: val_loss did not improve
Epoch 54/300
11s - loss: 99.1991 - val_loss: 706.0812
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 98.6536 - val_loss: 669.2089
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 98.6018 - val_loss: 639.5536
Epoch 00055: val_loss did not improve
Epoch 57/300
11s - loss: 98.0681 - val_loss: 602.2636
Epoch 00056: val_loss did not improve
Epoch 58/300
11s - loss: 97.6712 - val_loss: 601.0015
Epoch 00057: val_loss did not improve
Epoch 59/300
11s - loss: 97.3640 - val_loss: 679.3973
Epoch 00058: val_loss did not improve
Epoch 60/300
11s - loss: 97.1870 - val_loss: 660.0460
Epoch 00059: val_loss did not improve
Epoch 61/300
11s - loss: 96.6620 - val_loss: 707.6203
Epoch 00060: val_loss did not improve
Epoch 62/300
11s - loss: 96.5067 - val_loss: 627.1017
Epoch 00061: val_loss did not improve

training rlstm2h38 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 271.3381 - val_loss: 1227.1828
Epoch 00000: val_loss improved from inf to 1227.18279, saving model to rlstm2h38_weights.hdf5
Epoch 2/300
11s - loss: 221.7205 - val_loss: 1231.6266
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 201.6701 - val_loss: 1072.4311
Epoch 00002: val_loss improved from 1227.18279 to 1072.43106, saving model to rlstm2h38_weights.hdf5
Epoch 4/300
11s - loss: 183.3370 - val_loss: 901.1365
Epoch 00003: val_loss improved from 1072.43106 to 901.13655, saving model to rlstm2h38_weights.hdf5
Epoch 5/300
11s - loss: 167.6499 - val_loss: 740.4748
Epoch 00004: val_loss improved from 901.13655 to 740.47480, saving model to rlstm2h38_weights.hdf5
Epoch 6/300
11s - loss: 159.7569 - val_loss: 731.4523
Epoch 00005: val_loss improved from 740.47480 to 731.45228, saving model to rlstm2h38_weights.hdf5
Epoch 7/300
11s - loss: 154.9500 - val_loss: 728.7482
Epoch 00006: val_loss improved from 731.45228 to 728.74824, saving model to rlstm2h38_weights.hdf5
Epoch 8/300
11s - loss: 150.7396 - val_loss: 690.6082
Epoch 00007: val_loss improved from 728.74824 to 690.60817, saving model to rlstm2h38_weights.hdf5
Epoch 9/300
11s - loss: 147.2937 - val_loss: 875.0586
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 143.6513 - val_loss: 740.5759
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 140.8925 - val_loss: 672.7207
Epoch 00010: val_loss improved from 690.60817 to 672.72071, saving model to rlstm2h38_weights.hdf5
Epoch 12/300
11s - loss: 138.3753 - val_loss: 818.1533
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 136.0891 - val_loss: 688.0361
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 133.7696 - val_loss: 735.3511
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 131.8598 - val_loss: 740.4391
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 130.1595 - val_loss: 961.5321
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 128.7811 - val_loss: 869.8141
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 127.3106 - val_loss: 675.9117
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 126.2510 - val_loss: 848.0316
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 124.4682 - val_loss: 847.3219
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 123.1679 - val_loss: 774.0322
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 121.9208 - val_loss: 885.1677
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 120.4868 - val_loss: 1315.2653
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 119.4301 - val_loss: 903.0778
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 118.5776 - val_loss: 955.9943
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 117.1916 - val_loss: 1208.8362
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 116.4526 - val_loss: 1060.7954
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 114.8610 - val_loss: 906.8903
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 114.1689 - val_loss: 1010.2735
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 113.0615 - val_loss: 1215.2641
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 112.2178 - val_loss: 1428.0182
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 111.6423 - val_loss: 1089.7256
Epoch 00031: val_loss did not improve

training rlstm2h39 dim = 80
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 894.95770146935467}
Epoch 1/300
11s - loss: 272.8100 - val_loss: 1207.7702
Epoch 00000: val_loss improved from inf to 1207.77021, saving model to rlstm2h39_weights.hdf5
Epoch 2/300
11s - loss: 220.4239 - val_loss: 1217.6159
Epoch 00001: val_loss did not improve
Epoch 3/300
11s - loss: 200.3704 - val_loss: 1174.1901
Epoch 00002: val_loss improved from 1207.77021 to 1174.19010, saving model to rlstm2h39_weights.hdf5
Epoch 4/300
11s - loss: 188.5070 - val_loss: 1029.2602
Epoch 00003: val_loss improved from 1174.19010 to 1029.26016, saving model to rlstm2h39_weights.hdf5
Epoch 5/300
11s - loss: 176.3968 - val_loss: 871.7191
Epoch 00004: val_loss improved from 1029.26016 to 871.71915, saving model to rlstm2h39_weights.hdf5
Epoch 6/300
11s - loss: 165.3796 - val_loss: 898.1805
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 157.0100 - val_loss: 1148.0989
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 150.5766 - val_loss: 1019.6895
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 146.1230 - val_loss: 896.0305
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 142.5353 - val_loss: 1022.9440
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 139.4931 - val_loss: 1097.7289
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 136.8923 - val_loss: 1352.6498
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 134.8130 - val_loss: 1065.3843
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 132.9122 - val_loss: 961.5375
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 131.4044 - val_loss: 1119.5564
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 129.9791 - val_loss: 1827.8279
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 128.6090 - val_loss: 1703.6708
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 127.5107 - val_loss: 1062.8975
Epoch 00017: val_loss did not improve
Epoch 19/300
11s - loss: 126.5880 - val_loss: 1014.0368
Epoch 00018: val_loss did not improve
Epoch 20/300
11s - loss: 125.4342 - val_loss: 1092.2135
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 124.6881 - val_loss: 1507.6504
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 123.5711 - val_loss: 975.3229
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 122.7198 - val_loss: 1329.7603
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 121.9135 - val_loss: 918.2382
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 121.4704 - val_loss: 1026.4774
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 120.5982 - val_loss: 804.3624
Epoch 00025: val_loss improved from 871.71915 to 804.36235, saving model to rlstm2h39_weights.hdf5
Epoch 27/300
11s - loss: 119.6523 - val_loss: 1095.7888
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 119.0450 - val_loss: 820.8816
Epoch 00027: val_loss did not improve
Epoch 29/300
11s - loss: 118.2780 - val_loss: 975.6459
Epoch 00028: val_loss did not improve
Epoch 30/300
11s - loss: 117.7550 - val_loss: 924.7110
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 117.1580 - val_loss: 860.8304
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 116.3953 - val_loss: 1238.9785
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 115.7013 - val_loss: 835.9208
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 115.1970 - val_loss: 903.9478
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 114.5144 - val_loss: 1249.3791
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 114.0483 - val_loss: 970.7583
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 113.5045 - val_loss: 910.3004
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 112.9545 - val_loss: 1046.0640
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 112.3868 - val_loss: 1052.5252
Epoch 00038: val_loss did not improve
Epoch 40/300
11s - loss: 111.9780 - val_loss: 933.1982
Epoch 00039: val_loss did not improve
Epoch 41/300
11s - loss: 111.3164 - val_loss: 909.0460
Epoch 00040: val_loss did not improve
Epoch 42/300
11s - loss: 110.7525 - val_loss: 753.9205
Epoch 00041: val_loss improved from 804.36235 to 753.92052, saving model to rlstm2h39_weights.hdf5
Epoch 43/300
11s - loss: 110.4758 - val_loss: 894.5712
Epoch 00042: val_loss did not improve
Epoch 44/300
11s - loss: 109.7410 - val_loss: 1208.3084
Epoch 00043: val_loss did not improve
Epoch 45/300
11s - loss: 109.3060 - val_loss: 861.4505
Epoch 00044: val_loss did not improve
Epoch 46/300
11s - loss: 108.6917 - val_loss: 986.2585
Epoch 00045: val_loss did not improve
Epoch 47/300
11s - loss: 108.2174 - val_loss: 659.6805
Epoch 00046: val_loss improved from 753.92052 to 659.68052, saving model to rlstm2h39_weights.hdf5
Epoch 48/300
11s - loss: 107.9244 - val_loss: 885.5572
Epoch 00047: val_loss did not improve
Epoch 49/300
11s - loss: 107.5029 - val_loss: 882.5191
Epoch 00048: val_loss did not improve
Epoch 50/300
11s - loss: 106.8955 - val_loss: 914.3638
Epoch 00049: val_loss did not improve
Epoch 51/300
11s - loss: 106.4824 - val_loss: 767.5112
Epoch 00050: val_loss did not improve
Epoch 52/300
11s - loss: 106.0808 - val_loss: 696.1518
Epoch 00051: val_loss did not improve
Epoch 53/300
11s - loss: 105.6394 - val_loss: 1147.7182
Epoch 00052: val_loss did not improve
Epoch 54/300
11s - loss: 105.3272 - val_loss: 1067.1469
Epoch 00053: val_loss did not improve
Epoch 55/300
11s - loss: 104.7319 - val_loss: 874.9739
Epoch 00054: val_loss did not improve
Epoch 56/300
11s - loss: 104.4963 - val_loss: 874.3532
Epoch 00055: val_loss did not improve
Epoch 57/300
11s - loss: 103.8548 - val_loss: 864.7103
Epoch 00056: val_loss did not improve
Epoch 58/300
11s - loss: 103.5680 - val_loss: 1067.8941
Epoch 00057: val_loss did not improve
Epoch 59/300
11s - loss: 103.2497 - val_loss: 695.6839
Epoch 00058: val_loss did not improve
Epoch 60/300
11s - loss: 102.7946 - val_loss: 883.7440
Epoch 00059: val_loss did not improve
Epoch 61/300
11s - loss: 102.5682 - val_loss: 782.2131
Epoch 00060: val_loss did not improve
Epoch 62/300
11s - loss: 102.2126 - val_loss: 954.5725
Epoch 00061: val_loss did not improve
Epoch 63/300
11s - loss: 101.5261 - val_loss: 987.5033
Epoch 00062: val_loss did not improve
Epoch 64/300
11s - loss: 101.3683 - val_loss: 814.4834
Epoch 00063: val_loss did not improve
Epoch 65/300
11s - loss: 100.8964 - val_loss: 810.9861
Epoch 00064: val_loss did not improve
Epoch 66/300
11s - loss: 100.4973 - val_loss: 738.5318
Epoch 00065: val_loss did not improve
Epoch 67/300
11s - loss: 100.3453 - val_loss: 849.3438
Epoch 00066: val_loss did not improve
Epoch 68/300
11s - loss: 99.9049 - val_loss: 815.1948
Epoch 00067: val_loss did not improve
