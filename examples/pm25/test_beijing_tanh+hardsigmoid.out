X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid0
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid0 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid029822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5905.8557 - val_loss: 9831.5963
Epoch 00000: val_loss improved from inf to 9831.59634, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 3289.1251      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.811865 0.315844
delta_x = 4.40475 delta_h = 2.18849
U_c = [[-0.06091996]] U_f = [[ 0.]] b_c = [ 0.12306906] b_f = [ 1.09371161]
incx.max(), incx.min(), incx.mean() 2.91441 -2.75512 1.10629
fgtx.max(), fgtx.min(), fgtx.mean() 1.95369 -2.01449 0.688166
delta mean, abs_mean, abs_mean+, abs_mean-: -1.21847 4.40475 2.57162 7.3894
W_c max, min, mean, abs_mean: 0.150003 -0.149704 -0.0150062 0.147575
W_f max, min, mean, abs_mean: 0.105164 -0.105311 -0.00991494 0.103291
beijing_tanh+hardsigmoid0 9831.5964      0.78  0.09  0.73      0.78  0.05  0.75      0.79  0.03  0.77
forget mean min: 0.843674 0.316468
delta_x = 6.56176 delta_h = 4.042
U_c = [[-0.06091996]] U_f = [[ 0.]] b_c = [ 0.12306906] b_f = [ 1.09371161]
incx.max(), incx.min(), incx.mean() 2.91699 -2.75067 1.33625
fgtx.max(), fgtx.min(), fgtx.mean() 1.9555 -2.01137 0.849113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.37563 6.56176 2.61952 12.6802
W_c max, min, mean, abs_mean: 0.150003 -0.149704 -0.0150062 0.147575
W_f max, min, mean, abs_mean: 0.105164 -0.105311 -0.00991494 0.103291
Epoch 2/300
1s - loss: 2452.6062 - val_loss: 10432.2998
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1863.9007 - val_loss: 9590.5383
Epoch 00002: val_loss improved from 9831.59634 to 9590.53830, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1770.5840      0.83  0.23  0.67      0.84  0.21  0.69      0.85  0.18  0.72
forget mean min: 0.851706 0.422939
delta_x = 6.58132 delta_h = 0.624
U_c = [[-0.01232447]] U_f = [[ 0.]] b_c = [ 0.27294642] b_f = [ 1.10694385]
incx.max(), incx.min(), incx.mean() 6.1924 -5.65861 2.95773
fgtx.max(), fgtx.min(), fgtx.mean() 1.4892 -1.49225 0.675423
delta mean, abs_mean, abs_mean+, abs_mean-: 0.122491 6.58132 5.10565 9.40176
W_c max, min, mean, abs_mean: 0.299478 -0.299186 -0.0299495 0.29705
W_f max, min, mean, abs_mean: 0.0766622 -0.0767666 -0.0070496 0.0747312
beijing_tanh+hardsigmoid0 9590.5382      0.77  0.14  0.69      0.77  0.11  0.71      0.80  0.08  0.75
forget mean min: 0.904622 0.42366
delta_x = 8.31187 delta_h = 1.02441
U_c = [[-0.01232447]] U_f = [[ 0.]] b_c = [ 0.27294642] b_f = [ 1.10694385]
incx.max(), incx.min(), incx.mean() 6.18793 -5.64428 4.0069
fgtx.max(), fgtx.min(), fgtx.mean() 1.48808 -1.48864 0.93937
delta mean, abs_mean, abs_mean+, abs_mean-: -1.31291 8.31187 5.09815 15.3467
W_c max, min, mean, abs_mean: 0.299478 -0.299186 -0.0299495 0.29705
W_f max, min, mean, abs_mean: 0.0766622 -0.0767666 -0.0070496 0.0747312
Epoch 4/300
1s - loss: 1725.4312 - val_loss: 8696.9738
Epoch 00003: val_loss improved from 9590.53830 to 8696.97383, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1678.9132      0.88  0.25  0.68      0.88  0.23  0.70      0.88  0.20  0.72
forget mean min: 0.853887 0.379075
delta_x = 7.56356 delta_h = 0.878863
U_c = [[-0.01631707]] U_f = [[ 0.]] b_c = [ 0.30253467] b_f = [ 1.10914803]
incx.max(), incx.min(), incx.mean() 6.81106 -6.2181 3.30185
fgtx.max(), fgtx.min(), fgtx.mean() 1.71059 -1.71377 0.78828
delta mean, abs_mean, abs_mean+, abs_mean-: 0.425127 7.56356 5.84976 11.253
W_c max, min, mean, abs_mean: 0.328793 -0.328501 -0.0328785 0.326362
W_f max, min, mean, abs_mean: 0.0877244 -0.0878214 -0.00814914 0.0857757
beijing_tanh+hardsigmoid0 8696.9738      0.84  0.15  0.73      0.84  0.12  0.75      0.87  0.09  0.80
forget mean min: 0.912659 0.379663
delta_x = 9.91768 delta_h = 1.44674
U_c = [[-0.01631707]] U_f = [[ 0.]] b_c = [ 0.30253467] b_f = [ 1.10914803]
incx.max(), incx.min(), incx.mean() 6.80825 -6.2069 4.50104
fgtx.max(), fgtx.min(), fgtx.mean() 1.70985 -1.71083 1.10345
delta mean, abs_mean, abs_mean+, abs_mean-: -0.628623 9.91768 6.01777 23.1079
W_c max, min, mean, abs_mean: 0.328793 -0.328501 -0.0328785 0.326362
W_f max, min, mean, abs_mean: 0.0877244 -0.0878214 -0.00814914 0.0857757
Epoch 5/300
1s - loss: 1660.6369 - val_loss: 8017.0533
Epoch 00004: val_loss improved from 8696.97383 to 8017.05334, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1614.5447      0.88  0.24  0.69      0.88  0.22  0.71      0.88  0.18  0.73
forget mean min: 0.851509 0.343951
delta_x = 7.94154 delta_h = 1.03161
U_c = [[-0.01949632]] U_f = [[ 0.]] b_c = [ 0.31394699] b_f = [ 1.10215831]
incx.max(), incx.min(), incx.mean() 7.06734 -6.45367 3.40371
fgtx.max(), fgtx.min(), fgtx.mean() 1.87845 -1.8824 0.859405
delta mean, abs_mean, abs_mean+, abs_mean-: 0.391978 7.94154 6.0562 12.0993
W_c max, min, mean, abs_mean: 0.341115 -0.340824 -0.0341073 0.338681
W_f max, min, mean, abs_mean: 0.0961783 -0.0962631 -0.00898401 0.0942037
beijing_tanh+hardsigmoid0 8017.0533      0.85  0.15  0.74      0.85  0.12  0.77      0.88  0.09  0.81
forget mean min: 0.911755 0.344532
delta_x = 10.1878 delta_h = 1.68376
U_c = [[-0.01949632]] U_f = [[ 0.]] b_c = [ 0.31394699] b_f = [ 1.10215831]
incx.max(), incx.min(), incx.mean() 7.06364 -6.44323 4.60505
fgtx.max(), fgtx.min(), fgtx.mean() 1.87742 -1.8795 1.19355
delta mean, abs_mean, abs_mean+, abs_mean-: -0.568594 10.1878 6.17887 24.2692
W_c max, min, mean, abs_mean: 0.341115 -0.340824 -0.0341073 0.338681
W_f max, min, mean, abs_mean: 0.0961783 -0.0962631 -0.00898401 0.0942037
Epoch 6/300
1s - loss: 1637.2228 - val_loss: 7706.0953
Epoch 00005: val_loss improved from 8017.05334 to 7706.09531, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1598.6782      0.88  0.23  0.69      0.88  0.21  0.71      0.88  0.18  0.74
forget mean min: 0.84595 0.313322
delta_x = 8.17648 delta_h = 1.03918
U_c = [[-0.0193785]] U_f = [[ 0.]] b_c = [ 0.32293963] b_f = [ 1.09545624]
incx.max(), incx.min(), incx.mean() 7.2747 -6.64178 3.42809
fgtx.max(), fgtx.min(), fgtx.mean() 2.02507 -2.02885 0.904532
delta mean, abs_mean, abs_mean+, abs_mean-: 0.393396 8.17648 6.20204 12.5896
W_c max, min, mean, abs_mean: 0.350993 -0.350701 -0.0350914 0.348555
W_f max, min, mean, abs_mean: 0.103538 -0.103611 -0.00970835 0.101535
beijing_tanh+hardsigmoid0 7706.0952      0.85  0.14  0.75      0.85  0.11  0.77      0.88  0.08  0.81
forget mean min: 0.906473 0.313935
delta_x = 10.4721 delta_h = 1.6935
U_c = [[-0.0193785]] U_f = [[ 0.]] b_c = [ 0.32293963] b_f = [ 1.09545624]
incx.max(), incx.min(), incx.mean() 7.26292 -6.63126 4.60804
fgtx.max(), fgtx.min(), fgtx.mean() 2.02164 -2.02578 1.24825
delta mean, abs_mean, abs_mean+, abs_mean-: -0.627593 10.4721 6.3185 25.1151
W_c max, min, mean, abs_mean: 0.350993 -0.350701 -0.0350914 0.348555
W_f max, min, mean, abs_mean: 0.103538 -0.103611 -0.00970835 0.101535
Epoch 7/300
1s - loss: 1623.8045 - val_loss: 7769.2827
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1618.8312 - val_loss: 7247.9327
Epoch 00007: val_loss improved from 7706.09531 to 7247.93266, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1575.2385      0.89  0.25  0.69      0.89  0.23  0.71      0.90  0.20  0.73
forget mean min: 0.845708 0.287324
delta_x = 8.27176 delta_h = 1.00078
U_c = [[-0.0186028]] U_f = [[ 0.]] b_c = [ 0.33363375] b_f = [ 1.08922088]
incx.max(), incx.min(), incx.mean() 7.50358 -6.86234 3.50954
fgtx.max(), fgtx.min(), fgtx.mean() 2.14481 -2.1526 0.95003
delta mean, abs_mean, abs_mean+, abs_mean-: 0.431348 8.27176 6.28966 12.7221
W_c max, min, mean, abs_mean: 0.362739 -0.362444 -0.03626 0.360293
W_f max, min, mean, abs_mean: 0.109819 -0.109874 -0.0103219 0.107778
beijing_tanh+hardsigmoid0 7247.9326      0.85  0.13  0.75      0.85  0.10  0.77      0.88  0.07  0.82
forget mean min: 0.905421 0.288302
delta_x = 10.3719 delta_h = 1.58439
U_c = [[-0.0186028]] U_f = [[ 0.]] b_c = [ 0.33363375] b_f = [ 1.08922088]
incx.max(), incx.min(), incx.mean() 7.47199 -6.84599 4.58216
fgtx.max(), fgtx.min(), fgtx.mean() 2.13536 -2.14771 1.27089
delta mean, abs_mean, abs_mean+, abs_mean-: -0.745288 10.3719 6.29015 23.6749
W_c max, min, mean, abs_mean: 0.362739 -0.362444 -0.03626 0.360293
W_f max, min, mean, abs_mean: 0.109819 -0.109874 -0.0103219 0.107778
Epoch 9/300
1s - loss: 1604.6779 - val_loss: 7246.6718
Epoch 00008: val_loss improved from 7247.93266 to 7246.67184, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1562.8489      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.18  0.74
forget mean min: 0.84419 0.265171
delta_x = 8.1874 delta_h = 0.948856
U_c = [[-0.01777591]] U_f = [[ 0.]] b_c = [ 0.33512327] b_f = [ 1.08913326]
incx.max(), incx.min(), incx.mean() 7.53426 -6.89999 3.46463
fgtx.max(), fgtx.min(), fgtx.mean() 2.25202 -2.26328 0.978961
delta mean, abs_mean, abs_mean+, abs_mean-: 0.380908 8.1874 6.20969 12.5876
W_c max, min, mean, abs_mean: 0.364849 -0.364552 -0.0364682 0.362398
W_f max, min, mean, abs_mean: 0.115427 -0.115473 -0.0108745 0.113365
beijing_tanh+hardsigmoid0 7246.6718      0.84  0.13  0.75      0.84  0.10  0.77      0.87  0.07  0.82
forget mean min: 0.906086 0.266547
delta_x = 10.269 delta_h = 1.50868
U_c = [[-0.01777591]] U_f = [[ 0.]] b_c = [ 0.33512327] b_f = [ 1.08913326]
incx.max(), incx.min(), incx.mean() 7.50185 -6.87799 4.51635
fgtx.max(), fgtx.min(), fgtx.mean() 2.24188 -2.2564 1.30796
delta mean, abs_mean, abs_mean+, abs_mean-: -0.822163 10.269 6.15106 23.8937
W_c max, min, mean, abs_mean: 0.364849 -0.364552 -0.0364682 0.362398
W_f max, min, mean, abs_mean: 0.115427 -0.115473 -0.0108745 0.113365
Epoch 10/300
1s - loss: 1598.1161 - val_loss: 7127.3854
Epoch 00009: val_loss improved from 7246.67184 to 7127.38542, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1563.2512      0.88  0.23  0.70      0.88  0.21  0.72      0.89  0.18  0.74
forget mean min: 0.841745 0.256441
delta_x = 8.08952 delta_h = 1.04097
U_c = [[-0.01960177]] U_f = [[ 0.]] b_c = [ 0.3388671] b_f = [ 1.09069419]
incx.max(), incx.min(), incx.mean() 7.60441 -6.96789 3.42136
fgtx.max(), fgtx.min(), fgtx.mean() 2.29547 -2.30849 0.973874
delta mean, abs_mean, abs_mean+, abs_mean-: 0.387689 8.08952 6.18517 12.2362
W_c max, min, mean, abs_mean: 0.368623 -0.368321 -0.0368433 0.366166
W_f max, min, mean, abs_mean: 0.117762 -0.117806 -0.0111038 0.115686
beijing_tanh+hardsigmoid0 7127.3854      0.84  0.13  0.75      0.85  0.10  0.78      0.87  0.07  0.82
forget mean min: 0.904208 0.258114
delta_x = 10.296 delta_h = 1.6845
U_c = [[-0.01960177]] U_f = [[ 0.]] b_c = [ 0.3388671] b_f = [ 1.09069419]
incx.max(), incx.min(), incx.mean() 7.57462 -6.94142 4.49776
fgtx.max(), fgtx.min(), fgtx.mean() 2.28606 -2.30013 1.31395
delta mean, abs_mean, abs_mean+, abs_mean-: -0.773624 10.296 6.17682 24.15
W_c max, min, mean, abs_mean: 0.368623 -0.368321 -0.0368433 0.366166
W_f max, min, mean, abs_mean: 0.117762 -0.117806 -0.0111038 0.115686
Epoch 11/300
1s - loss: 1599.3815 - val_loss: 7111.0830
Epoch 00010: val_loss improved from 7127.38542 to 7111.08302, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1551.9342      0.88  0.23  0.70      0.89  0.20  0.72      0.89  0.18  0.75
forget mean min: 0.844988 0.257122
delta_x = 8.07424 delta_h = 0.902369
U_c = [[-0.01708072]] U_f = [[ 0.]] b_c = [ 0.34375271] b_f = [ 1.09183991]
incx.max(), incx.min(), incx.mean() 7.69157 -7.0606 3.46187
fgtx.max(), fgtx.min(), fgtx.mean() 2.28862 -2.30623 0.97119
delta mean, abs_mean, abs_mean+, abs_mean-: 0.353514 8.07424 6.1671 12.1887
W_c max, min, mean, abs_mean: 0.373684 -0.373379 -0.0373476 0.371222
W_f max, min, mean, abs_mean: 0.117711 -0.117753 -0.0110962 0.115624
beijing_tanh+hardsigmoid0 7111.0830      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.83
forget mean min: 0.908465 0.259224
delta_x = 10.0671 delta_h = 1.44244
U_c = [[-0.01708072]] U_f = [[ 0.]] b_c = [ 0.34375271] b_f = [ 1.09183991]
incx.max(), incx.min(), incx.mean() 7.66613 -7.02685 4.50647
fgtx.max(), fgtx.min(), fgtx.mean() 2.28069 -2.29572 1.29655
delta mean, abs_mean, abs_mean+, abs_mean-: -0.834617 10.0671 6.06942 22.7669
W_c max, min, mean, abs_mean: 0.373684 -0.373379 -0.0373476 0.371222
W_f max, min, mean, abs_mean: 0.117711 -0.117753 -0.0110962 0.115624
Epoch 12/300
1s - loss: 1589.8271 - val_loss: 6931.5788
Epoch 00011: val_loss improved from 7111.08302 to 6931.57876, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1561.0642      0.87  0.22  0.70      0.88  0.20  0.72      0.88  0.17  0.75
forget mean min: 0.844407 0.25047
delta_x = 8.03703 delta_h = 0.933198
U_c = [[-0.01806736]] U_f = [[ 0.]] b_c = [ 0.3488957] b_f = [ 1.09113479]
incx.max(), incx.min(), incx.mean() 7.79641 -7.16152 3.44722
fgtx.max(), fgtx.min(), fgtx.mean() 2.3192 -2.33879 0.96483
delta mean, abs_mean, abs_mean+, abs_mean-: 0.292255 8.03703 6.17547 11.8925
W_c max, min, mean, abs_mean: 0.379112 -0.378806 -0.0378884 0.376645
W_f max, min, mean, abs_mean: 0.11939 -0.119425 -0.0112582 0.117289
beijing_tanh+hardsigmoid0 6931.5788      0.85  0.12  0.76      0.85  0.09  0.78      0.88  0.06  0.83
forget mean min: 0.910346 0.253078
delta_x = 9.82865 delta_h = 1.48211
U_c = [[-0.01806736]] U_f = [[ 0.]] b_c = [ 0.3488957] b_f = [ 1.09113479]
incx.max(), incx.min(), incx.mean() 7.77511 -7.11964 4.51202
fgtx.max(), fgtx.min(), fgtx.mean() 2.31256 -2.32574 1.29641
delta mean, abs_mean, abs_mean+, abs_mean-: -0.882844 9.82865 6.06421 20.4098
W_c max, min, mean, abs_mean: 0.379112 -0.378806 -0.0378884 0.376645
W_f max, min, mean, abs_mean: 0.11939 -0.119425 -0.0112582 0.117289
Epoch 13/300
1s - loss: 1585.4990 - val_loss: 7081.5543
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1572.7536 - val_loss: 6852.1235
Epoch 00013: val_loss improved from 6931.57876 to 6852.12348, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1532.2600      0.89  0.23  0.70      0.90  0.21  0.72      0.90  0.18  0.75
forget mean min: 0.846291 0.253426
delta_x = 8.26497 delta_h = 0.70235
U_c = [[-0.01300977]] U_f = [[ 0.]] b_c = [ 0.36819929] b_f = [ 1.09338391]
incx.max(), incx.min(), incx.mean() 8.20838 -7.52219 3.62124
fgtx.max(), fgtx.min(), fgtx.mean() 2.31145 -2.32625 0.959056
delta mean, abs_mean, abs_mean+, abs_mean-: 0.411449 8.26497 6.39244 12.2195
W_c max, min, mean, abs_mean: 0.398267 -0.397958 -0.0398001 0.39579
W_f max, min, mean, abs_mean: 0.118812 -0.118862 -0.0111991 0.116687
beijing_tanh+hardsigmoid0 6852.1234      0.85  0.11  0.77      0.85  0.09  0.79      0.88  0.06  0.83
forget mean min: 0.906464 0.256106
delta_x = 10.201 delta_h = 1.13208
U_c = [[-0.01300977]] U_f = [[ 0.]] b_c = [ 0.36819929] b_f = [ 1.09338391]
incx.max(), incx.min(), incx.mean() 8.17727 -7.47674 4.63081
fgtx.max(), fgtx.min(), fgtx.mean() 2.30228 -2.31285 1.2567
delta mean, abs_mean, abs_mean+, abs_mean-: -0.858884 10.201 6.26001 21.7864
W_c max, min, mean, abs_mean: 0.398267 -0.397958 -0.0398001 0.39579
W_f max, min, mean, abs_mean: 0.118812 -0.118862 -0.0111991 0.116687
Epoch 15/300
1s - loss: 1562.9135 - val_loss: 7016.6336
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1557.0569 - val_loss: 7002.1985
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1551.4310 - val_loss: 7123.5935
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1544.7596 - val_loss: 7270.8539
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1531.1495 - val_loss: 7295.4840
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1532.3270 - val_loss: 7174.5017
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1515.1412 - val_loss: 7280.4563
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1502.3612 - val_loss: 7191.5138
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1485.7317 - val_loss: 7087.1728
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1475.2753 - val_loss: 7228.2281
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1459.4863 - val_loss: 7232.4005
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1441.7138 - val_loss: 6882.5650
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1416.3724 - val_loss: 6937.9567
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1389.6923 - val_loss: 6852.7407
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1363.4541 - val_loss: 6797.2194
Epoch 00028: val_loss improved from 6852.12348 to 6797.21939, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1283.2446      0.87  0.20  0.72      0.89  0.16  0.75      0.90  0.13  0.79
forget mean min: 0.85464 0.123349
delta_x = 8.74119 delta_h = 0.246653
U_c = [[-0.00469986]] U_f = [[ 0.]] b_c = [ 0.48409957] b_f = [ 1.07581437]
incx.max(), incx.min(), incx.mean() 10.2028 -9.3446 4.113
fgtx.max(), fgtx.min(), fgtx.mean() 2.92594 -2.95907 1.09245
delta mean, abs_mean, abs_mean+, abs_mean-: 0.222575 8.74119 6.71119 12.8224
W_c max, min, mean, abs_mean: 0.500478 -0.499942 -0.0498999 0.497664
W_f max, min, mean, abs_mean: 0.155035 -0.155728 -0.014321 0.149831
beijing_tanh+hardsigmoid0 6797.2193      0.84  0.09  0.78      0.84  0.07  0.80      0.86  0.04  0.83
forget mean min: 0.911227 0.166472
delta_x = 10.3033 delta_h = 0.399564
U_c = [[-0.00469986]] U_f = [[ 0.]] b_c = [ 0.48409957] b_f = [ 1.07581437]
incx.max(), incx.min(), incx.mean() 10.0929 -8.62886 5.07559
fgtx.max(), fgtx.min(), fgtx.mean() 2.89282 -2.74346 1.38202
delta mean, abs_mean, abs_mean+, abs_mean-: -1.16096 10.3033 6.71318 17.965
W_c max, min, mean, abs_mean: 0.500478 -0.499942 -0.0498999 0.497664
W_f max, min, mean, abs_mean: 0.155035 -0.155728 -0.014321 0.149831
Epoch 30/300
1s - loss: 1331.8284 - val_loss: 6559.6079
Epoch 00029: val_loss improved from 6797.21939 to 6559.60787, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1284.8064      0.89  0.21  0.72      0.90  0.18  0.75      0.91  0.15  0.78
forget mean min: 0.851324 0.104949
delta_x = 8.94396 delta_h = 0.238483
U_c = [[-0.00432849]] U_f = [[ 0.]] b_c = [ 0.50292617] b_f = [ 1.07056081]
incx.max(), incx.min(), incx.mean() 10.5763 -9.68741 4.21318
fgtx.max(), fgtx.min(), fgtx.mean() 3.01082 -3.04582 1.10886
delta mean, abs_mean, abs_mean+, abs_mean-: 0.340486 8.94396 6.94903 12.9586
W_c max, min, mean, abs_mean: 0.51892 -0.518501 -0.0517044 0.515933
W_f max, min, mean, abs_mean: 0.15962 -0.160285 -0.0147473 0.154211
beijing_tanh+hardsigmoid0 6559.6079      0.86  0.09  0.79      0.86  0.06  0.81      0.88  0.04  0.84
forget mean min: 0.907758 0.160413
delta_x = 10.5795 delta_h = 0.379876
U_c = [[-0.00432849]] U_f = [[ 0.]] b_c = [ 0.50292617] b_f = [ 1.07056081]
incx.max(), incx.min(), incx.mean() 10.4615 -8.76014 5.17929
fgtx.max(), fgtx.min(), fgtx.mean() 2.97651 -2.7685 1.39736
delta mean, abs_mean, abs_mean+, abs_mean-: -1.06057 10.5795 6.93666 18.5432
W_c max, min, mean, abs_mean: 0.51892 -0.518501 -0.0517044 0.515933
W_f max, min, mean, abs_mean: 0.15962 -0.160285 -0.0147473 0.154211
Epoch 31/300
1s - loss: 1290.7783 - val_loss: 7494.7332
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1243.4135 - val_loss: 6726.8829
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1199.9422 - val_loss: 6518.6474
Epoch 00032: val_loss improved from 6559.60787 to 6518.64735, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1160.5013      0.89  0.20  0.73      0.91  0.17  0.76      0.92  0.14  0.79
forget mean min: 0.845568 0.0685073
delta_x = 9.25892 delta_h = 0.271984
U_c = [[-0.00489575]] U_f = [[ 0.]] b_c = [ 0.57298911] b_f = [ 1.04237247]
incx.max(), incx.min(), incx.mean() 12.0572 -11.0163 4.47523
fgtx.max(), fgtx.min(), fgtx.mean() 3.1708 -3.19984 1.07714
delta mean, abs_mean, abs_mean+, abs_mean-: 0.349237 9.25892 7.41738 12.6443
W_c max, min, mean, abs_mean: 0.594408 -0.594863 -0.0590539 0.590512
W_f max, min, mean, abs_mean: 0.169774 -0.170948 -0.0155522 0.163048
beijing_tanh+hardsigmoid0 6518.6473      0.87  0.07  0.81      0.86  0.05  0.82      0.88  0.04  0.85
forget mean min: 0.892627 0.16587
delta_x = 10.7597 delta_h = 0.420647
U_c = [[-0.00489575]] U_f = [[ 0.]] b_c = [ 0.57298911] b_f = [ 1.04237247]
incx.max(), incx.min(), incx.mean() 11.8738 -9.25427 5.35541
fgtx.max(), fgtx.min(), fgtx.mean() 3.12019 -2.71302 1.31967
delta mean, abs_mean, abs_mean+, abs_mean-: -1.17974 10.7597 7.50777 16.4911
W_c max, min, mean, abs_mean: 0.594408 -0.594863 -0.0590539 0.590512
W_f max, min, mean, abs_mean: 0.169774 -0.170948 -0.0155522 0.163048
Epoch 34/300
1s - loss: 1162.7543 - val_loss: 6771.4728
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1144.9691 - val_loss: 6983.6159
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 1125.0984 - val_loss: 6112.5629
Epoch 00035: val_loss improved from 6518.64735 to 6112.56285, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1063.2360      0.89  0.18  0.74      0.90  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.843986 0.0219885
delta_x = 9.44965 delta_h = 0.585473
U_c = [[-0.01082413]] U_f = [[ 0.]] b_c = [ 0.62905419] b_f = [ 1.02127397]
incx.max(), incx.min(), incx.mean() 13.2717 -12.029 4.70969
fgtx.max(), fgtx.min(), fgtx.mean() 3.4071 -3.41133 1.09926
delta mean, abs_mean, abs_mean+, abs_mean-: 0.31796 9.44965 7.73764 12.3794
W_c max, min, mean, abs_mean: 0.656543 -0.657531 -0.0651105 0.6519
W_f max, min, mean, abs_mean: 0.183887 -0.185704 -0.0167314 0.175697
beijing_tanh+hardsigmoid0 6112.5629      0.88  0.07  0.82      0.88  0.04  0.84      0.90  0.04  0.87
forget mean min: 0.895348 0.141299
delta_x = 11.0199 delta_h = 0.870696
U_c = [[-0.01082413]] U_f = [[ 0.]] b_c = [ 0.62905419] b_f = [ 1.02127397]
incx.max(), incx.min(), incx.mean() 13.033 -9.81691 5.71138
fgtx.max(), fgtx.min(), fgtx.mean() 3.34269 -2.81478 1.36843
delta mean, abs_mean, abs_mean+, abs_mean-: -1.20365 11.0199 7.84692 16.3192
W_c max, min, mean, abs_mean: 0.656543 -0.657531 -0.0651105 0.6519
W_f max, min, mean, abs_mean: 0.183887 -0.185704 -0.0167314 0.175697
Epoch 37/300
1s - loss: 1114.4348 - val_loss: 7391.6552
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 1099.4560 - val_loss: 5792.8835
Epoch 00037: val_loss improved from 6112.56285 to 5792.88347, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1041.0846      0.89  0.18  0.75      0.91  0.15  0.79      0.92  0.11  0.82
forget mean min: 0.842759 0.000925915
delta_x = 9.59192 delta_h = 0.656064
U_c = [[-0.01194264]] U_f = [[ 0.]] b_c = [ 0.65474105] b_f = [ 1.01243103]
incx.max(), incx.min(), incx.mean() 13.7966 -12.4031 4.84019
fgtx.max(), fgtx.min(), fgtx.mean() 3.53026 -3.5078 1.12373
delta mean, abs_mean, abs_mean+, abs_mean-: 0.372843 9.59192 7.98735 12.2524
W_c max, min, mean, abs_mean: 0.683713 -0.684926 -0.0677402 0.678723
W_f max, min, mean, abs_mean: 0.191651 -0.194139 -0.017313 0.182342
beijing_tanh+hardsigmoid0 5792.8835      0.89  0.07  0.83      0.89  0.05  0.85      0.91  0.04  0.88
forget mean min: 0.89339 0.116658
delta_x = 11.2577 delta_h = 0.967236
U_c = [[-0.01194264]] U_f = [[ 0.]] b_c = [ 0.65474105] b_f = [ 1.01243103]
incx.max(), incx.min(), incx.mean() 13.5245 -10.2508 5.83422
fgtx.max(), fgtx.min(), fgtx.mean() 3.45704 -2.92914 1.38977
delta mean, abs_mean, abs_mean+, abs_mean-: -1.10037 11.2577 8.03485 16.7943
W_c max, min, mean, abs_mean: 0.683713 -0.684926 -0.0677402 0.678723
W_f max, min, mean, abs_mean: 0.191651 -0.194139 -0.017313 0.182342
Epoch 39/300
1s - loss: 1094.1746 - val_loss: 6217.2874
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 1082.6380 - val_loss: 5659.2296
Epoch 00039: val_loss improved from 5792.88347 to 5659.22965, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1041.0323      0.89  0.18  0.75      0.91  0.14  0.79      0.92  0.11  0.83
forget mean min: 0.84357 0.0
delta_x = 9.74514 delta_h = 0.542794
U_c = [[-0.00966481]] U_f = [[ 0.]] b_c = [ 0.6739518] b_f = [ 1.00627053]
incx.max(), incx.min(), incx.mean() 14.2168 -12.6602 4.95848
fgtx.max(), fgtx.min(), fgtx.mean() 3.683 -3.62636 1.16448
delta mean, abs_mean, abs_mean+, abs_mean-: 0.37572 9.74514 8.09996 12.4842
W_c max, min, mean, abs_mean: 0.703831 -0.704706 -0.0697026 0.698705
W_f max, min, mean, abs_mean: 0.200094 -0.202937 -0.018024 0.190035
beijing_tanh+hardsigmoid0 5659.2296      0.89  0.08  0.83      0.89  0.05  0.85      0.91  0.04  0.88
forget mean min: 0.898589 0.0873621
delta_x = 11.516 delta_h = 0.800846
U_c = [[-0.00966481]] U_f = [[ 0.]] b_c = [ 0.6739518] b_f = [ 1.00627053]
incx.max(), incx.min(), incx.mean() 13.9312 -10.6144 6.04115
fgtx.max(), fgtx.min(), fgtx.mean() 3.60518 -3.06946 1.4578
delta mean, abs_mean, abs_mean+, abs_mean-: -1.03167 11.516 8.02539 18.0905
W_c max, min, mean, abs_mean: 0.703831 -0.704706 -0.0697026 0.698705
W_f max, min, mean, abs_mean: 0.200094 -0.202937 -0.018024 0.190035
Epoch 41/300
1s - loss: 1083.2734 - val_loss: 5340.4171
Epoch 00040: val_loss improved from 5659.22965 to 5340.41710, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1020.3050      0.89  0.17  0.75      0.91  0.13  0.80      0.91  0.10  0.82
forget mean min: 0.845294 0.0
delta_x = 9.59853 delta_h = 0.800494
U_c = [[-0.0147258]] U_f = [[ 0.]] b_c = [ 0.68073189] b_f = [ 1.00356817]
incx.max(), incx.min(), incx.mean() 14.2858 -12.5984 4.97062
fgtx.max(), fgtx.min(), fgtx.mean() 3.7074 -3.6188 1.16819
delta mean, abs_mean, abs_mean+, abs_mean-: 0.385935 9.59853 8.08665 12.0376
W_c max, min, mean, abs_mean: 0.709244 -0.710172 -0.0701949 0.703985
W_f max, min, mean, abs_mean: 0.202704 -0.205967 -0.0181612 0.191865
beijing_tanh+hardsigmoid0 5340.4171      0.90  0.08  0.84      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.899316 0.086138
delta_x = 11.5102 delta_h = 1.20752
U_c = [[-0.0147258]] U_f = [[ 0.]] b_c = [ 0.68073189] b_f = [ 1.00356817]
incx.max(), incx.min(), incx.mean() 13.9704 -10.5974 6.04577
fgtx.max(), fgtx.min(), fgtx.mean() 3.62157 -3.07288 1.45989
delta mean, abs_mean, abs_mean+, abs_mean-: -0.921019 11.5102 8.17855 17.6269
W_c max, min, mean, abs_mean: 0.709244 -0.710172 -0.0701949 0.703985
W_f max, min, mean, abs_mean: 0.202704 -0.205967 -0.0181612 0.191865
Epoch 42/300
1s - loss: 1066.9005 - val_loss: 5372.3474
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 1066.0489 - val_loss: 5549.9728
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 1059.0576 - val_loss: 5277.0855
Epoch 00043: val_loss improved from 5340.41710 to 5277.08555, saving model to beijing_tanh+hardsigmoid0_weights.hdf5
beijing_tanh+hardsigmoid0 1036.6225      0.90  0.18  0.75      0.92  0.15  0.80      0.92  0.12  0.82
forget mean min: 0.845161 0.0
delta_x = 9.78095 delta_h = 0.688563
U_c = [[-0.01210496]] U_f = [[ 0.]] b_c = [ 0.70613426] b_f = [ 0.99408478]
incx.max(), incx.min(), incx.mean() 14.7289 -12.7167 5.10866
fgtx.max(), fgtx.min(), fgtx.mean() 3.89895 -3.73274 1.22294
delta mean, abs_mean, abs_mean+, abs_mean-: 0.454598 9.78095 8.2162 12.3655
W_c max, min, mean, abs_mean: 0.730843 -0.730262 -0.0723608 0.725802
W_f max, min, mean, abs_mean: 0.214743 -0.219015 -0.0190546 0.201844
beijing_tanh+hardsigmoid0 5277.0856      0.90  0.08  0.84      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.898084 0.0484894
delta_x = 11.6624 delta_h = 1.03153
U_c = [[-0.01210496]] U_f = [[ 0.]] b_c = [ 0.70613426] b_f = [ 0.99408478]
incx.max(), incx.min(), incx.mean() 14.3855 -10.9905 6.12549
fgtx.max(), fgtx.min(), fgtx.mean() 3.80329 -3.25164 1.50403
delta mean, abs_mean, abs_mean+, abs_mean-: -0.881061 11.6624 8.26482 18.035
W_c max, min, mean, abs_mean: 0.730843 -0.730262 -0.0723608 0.725802
W_f max, min, mean, abs_mean: 0.214743 -0.219015 -0.0190546 0.201844
Epoch 45/300
1s - loss: 1049.6312 - val_loss: 6379.4400
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 1051.0644 - val_loss: 5868.9625
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 1045.6704 - val_loss: 5820.6769
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 1037.6193 - val_loss: 5906.3371
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 1027.6473 - val_loss: 5608.2988
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 1027.0074 - val_loss: 6572.8364
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 1017.3841 - val_loss: 6206.8248
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 1013.3942 - val_loss: 6424.5656
Epoch 00051: val_loss did not improve
Epoch 53/300
1s - loss: 1012.4497 - val_loss: 5960.6125
Epoch 00052: val_loss did not improve
Epoch 54/300
1s - loss: 1000.8038 - val_loss: 5891.3959
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 997.9424 - val_loss: 6740.1528
Epoch 00054: val_loss did not improve
Epoch 56/300
1s - loss: 990.9730 - val_loss: 6702.4311
Epoch 00055: val_loss did not improve
Epoch 57/300
1s - loss: 983.6399 - val_loss: 6879.7924
Epoch 00056: val_loss did not improve
Epoch 58/300
1s - loss: 976.5770 - val_loss: 6912.3373
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 974.4880 - val_loss: 6560.2130
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 968.8928 - val_loss: 7139.7322
Epoch 00059: val_loss did not improve
Epoch 61/300
1s - loss: 960.4781 - val_loss: 7762.8083
Epoch 00060: val_loss did not improve
Epoch 62/300
1s - loss: 956.1146 - val_loss: 7314.8146
Epoch 00061: val_loss did not improve
Epoch 63/300
1s - loss: 950.1736 - val_loss: 7068.1115
Epoch 00062: val_loss did not improve
Epoch 64/300
1s - loss: 944.8331 - val_loss: 7708.3852
Epoch 00063: val_loss did not improve
Epoch 65/300
1s - loss: 937.9162 - val_loss: 8135.8870
Epoch 00064: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid1
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid1 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid129822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5869.3177 - val_loss: 9563.5605
Epoch 00000: val_loss improved from inf to 9563.56050, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 3319.2023      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.812993 0.319669
delta_x = 4.41522 delta_h = 2.25629
U_c = [[-0.06336537]] U_f = [[ 0.]] b_c = [ 0.12280082] b_f = [ 1.09519553]
incx.max(), incx.min(), incx.mean() 2.91715 -2.74951 1.10499
fgtx.max(), fgtx.min(), fgtx.mean() 1.94264 -1.99685 0.682817
delta mean, abs_mean, abs_mean+, abs_mean-: -1.24975 4.41522 2.56602 7.39177
W_c max, min, mean, abs_mean: 0.149191 -0.148793 0.0442177 0.14731
W_f max, min, mean, abs_mean: 0.104249 -0.104354 0.0305343 0.102412
beijing_tanh+hardsigmoid1 9563.5605      0.80  0.09  0.74      0.80  0.05  0.76      0.81  0.03  0.79
forget mean min: 0.846345 0.320352
delta_x = 6.54127 delta_h = 4.18455
U_c = [[-0.06336537]] U_f = [[ 0.]] b_c = [ 0.12280082] b_f = [ 1.09519553]
incx.max(), incx.min(), incx.mean() 2.91494 -2.74459 1.36097
fgtx.max(), fgtx.min(), fgtx.mean() 1.94111 -1.99343 0.86078
delta mean, abs_mean, abs_mean+, abs_mean-: -3.27864 6.54127 2.59511 13.2205
W_c max, min, mean, abs_mean: 0.149191 -0.148793 0.0442177 0.14731
W_f max, min, mean, abs_mean: 0.104249 -0.104354 0.0305343 0.102412
Epoch 2/300
1s - loss: 2435.1819 - val_loss: 11442.4344
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1848.3942 - val_loss: 9482.2243
Epoch 00002: val_loss improved from 9563.56050 to 9482.22431, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1758.2919      0.85  0.24  0.67      0.86  0.22  0.69      0.86  0.18  0.72
forget mean min: 0.854811 0.417258
delta_x = 6.77868 delta_h = 0.771796
U_c = [[-0.01516966]] U_f = [[ 0.]] b_c = [ 0.27665681] b_f = [ 1.11055493]
incx.max(), incx.min(), incx.mean() 6.27733 -5.73725 3.04624
fgtx.max(), fgtx.min(), fgtx.mean() 1.52091 -1.52426 0.701955
delta mean, abs_mean, abs_mean+, abs_mean-: 0.210788 6.77868 5.26566 9.76446
W_c max, min, mean, abs_mean: 0.302999 -0.302608 0.0903619 0.301118
W_f max, min, mean, abs_mean: 0.0782425 -0.0783663 0.0227034 0.0763203
beijing_tanh+hardsigmoid1 9482.2244      0.79  0.15  0.69      0.79  0.12  0.72      0.82  0.09  0.76
forget mean min: 0.911431 0.418139
delta_x = 8.53341 delta_h = 1.24809
U_c = [[-0.01516966]] U_f = [[ 0.]] b_c = [ 0.27665681] b_f = [ 1.11055493]
incx.max(), incx.min(), incx.mean() 6.273 -5.71988 4.16262
fgtx.max(), fgtx.min(), fgtx.mean() 1.51981 -1.51986 0.984906
delta mean, abs_mean, abs_mean+, abs_mean-: -1.09459 8.53341 5.26856 16.3721
W_c max, min, mean, abs_mean: 0.302999 -0.302608 0.0903619 0.301118
W_f max, min, mean, abs_mean: 0.0782425 -0.0783663 0.0227034 0.0763203
Epoch 4/300
1s - loss: 1713.2751 - val_loss: 8613.0344
Epoch 00003: val_loss improved from 9482.22431 to 8613.03441, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1655.0944      0.87  0.24  0.68      0.87  0.21  0.70      0.87  0.18  0.73
forget mean min: 0.854281 0.386668
delta_x = 7.48992 delta_h = 0.929312
U_c = [[-0.01770812]] U_f = [[ 0.]] b_c = [ 0.30272245] b_f = [ 1.10734487]
incx.max(), incx.min(), incx.mean() 6.83677 -6.24407 3.30343
fgtx.max(), fgtx.min(), fgtx.mean() 1.67075 -1.67401 0.767265
delta mean, abs_mean, abs_mean+, abs_mean-: 0.353178 7.48992 5.81991 10.9397
W_c max, min, mean, abs_mean: 0.329559 -0.329167 0.0983291 0.327676
W_f max, min, mean, abs_mean: 0.0857233 -0.0858552 0.0249429 0.0837864
beijing_tanh+hardsigmoid1 8613.0345      0.83  0.15  0.72      0.84  0.12  0.75      0.86  0.09  0.79
forget mean min: 0.91205 0.387262
delta_x = 9.77194 delta_h = 1.5405
U_c = [[-0.01770812]] U_f = [[ 0.]] b_c = [ 0.30272245] b_f = [ 1.10734487]
incx.max(), incx.min(), incx.mean() 6.83316 -6.23246 4.4979
fgtx.max(), fgtx.min(), fgtx.mean() 1.66982 -1.67104 1.07269
delta mean, abs_mean, abs_mean+, abs_mean-: -0.679328 9.77194 5.98195 21.7738
W_c max, min, mean, abs_mean: 0.329559 -0.329167 0.0983291 0.327676
W_f max, min, mean, abs_mean: 0.0857233 -0.0858552 0.0249429 0.0837864
Epoch 5/300
1s - loss: 1658.2718 - val_loss: 8081.2097
Epoch 00004: val_loss improved from 8613.03441 to 8081.20968, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1623.4866      0.89  0.25  0.68      0.89  0.23  0.70      0.89  0.20  0.73
forget mean min: 0.851549 0.345919
delta_x = 8.04495 delta_h = 0.915472
U_c = [[-0.0168376]] U_f = [[ 0.]] b_c = [ 0.31640759] b_f = [ 1.09924936]
incx.max(), incx.min(), incx.mean() 7.14426 -6.52654 3.45542
fgtx.max(), fgtx.min(), fgtx.mean() 1.86553 -1.86965 0.85764
delta mean, abs_mean, abs_mean+, abs_mean-: 0.448192 8.04495 6.13909 12.3215
W_c max, min, mean, abs_mean: 0.344308 -0.343915 0.102753 0.342422
W_f max, min, mean, abs_mean: 0.0955117 -0.0956548 0.0278738 0.0935579
beijing_tanh+hardsigmoid1 8081.2097      0.84  0.14  0.74      0.85  0.11  0.76      0.87  0.09  0.81
forget mean min: 0.908274 0.346428
delta_x = 10.3005 delta_h = 1.48147
U_c = [[-0.0168376]] U_f = [[ 0.]] b_c = [ 0.31640759] b_f = [ 1.09924936]
incx.max(), incx.min(), incx.mean() 7.13963 -6.51723 4.58773
fgtx.max(), fgtx.min(), fgtx.mean() 1.86427 -1.86711 1.16701
delta mean, abs_mean, abs_mean+, abs_mean-: -0.656114 10.3005 6.25711 23.8884
W_c max, min, mean, abs_mean: 0.344308 -0.343915 0.102753 0.342422
W_f max, min, mean, abs_mean: 0.0955117 -0.0956548 0.0278738 0.0935579
Epoch 6/300
1s - loss: 1635.9996 - val_loss: 7780.3978
Epoch 00005: val_loss improved from 8081.20968 to 7780.39779, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1601.1781      0.88  0.24  0.69      0.89  0.23  0.70      0.89  0.19  0.73
forget mean min: 0.847256 0.320904
delta_x = 8.16415 delta_h = 0.991576
U_c = [[-0.0183114]] U_f = [[ 0.]] b_c = [ 0.32344565] b_f = [ 1.09028137]
incx.max(), incx.min(), incx.mean() 7.29987 -6.66909 3.46458
fgtx.max(), fgtx.min(), fgtx.mean() 1.98118 -1.98576 0.892019
delta mean, abs_mean, abs_mean+, abs_mean-: 0.440204 8.16415 6.24315 12.4221
W_c max, min, mean, abs_mean: 0.35182 -0.351426 0.105005 0.349932
W_f max, min, mean, abs_mean: 0.10135 -0.101503 0.0296183 0.0993748
beijing_tanh+hardsigmoid1 7780.3978      0.84  0.14  0.75      0.85  0.11  0.77      0.87  0.08  0.81
forget mean min: 0.905289 0.321488
delta_x = 10.4597 delta_h = 1.61033
U_c = [[-0.0183114]] U_f = [[ 0.]] b_c = [ 0.32344565] b_f = [ 1.09028137]
incx.max(), incx.min(), incx.mean() 7.28991 -6.65881 4.60961
fgtx.max(), fgtx.min(), fgtx.mean() 1.97836 -1.98284 1.21718
delta mean, abs_mean, abs_mean+, abs_mean-: -0.637328 10.4597 6.33772 24.6501
W_c max, min, mean, abs_mean: 0.35182 -0.351426 0.105005 0.349932
W_f max, min, mean, abs_mean: 0.10135 -0.101503 0.0296183 0.0993748
Epoch 7/300
1s - loss: 1623.0043 - val_loss: 7270.7591
Epoch 00006: val_loss improved from 7780.39779 to 7270.75910, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1599.9844      0.89  0.25  0.68      0.89  0.23  0.70      0.90  0.20  0.73
forget mean min: 0.845317 0.297459
delta_x = 8.22879 delta_h = 1.11502
U_c = [[-0.02059653]] U_f = [[ 0.]] b_c = [ 0.32746762] b_f = [ 1.08690989]
incx.max(), incx.min(), incx.mean() 7.38015 -6.74155 3.48976
fgtx.max(), fgtx.min(), fgtx.mean() 2.09476 -2.09961 0.939244
delta mean, abs_mean, abs_mean+, abs_mean-: 0.494684 8.22879 6.27632 12.6769
W_c max, min, mean, abs_mean: 0.355706 -0.355311 0.10617 0.353816
W_f max, min, mean, abs_mean: 0.107081 -0.107242 0.0313321 0.105089
beijing_tanh+hardsigmoid1 7270.7591      0.85  0.13  0.76      0.86  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.902299 0.298111
delta_x = 10.5196 delta_h = 1.79678
U_c = [[-0.02059653]] U_f = [[ 0.]] b_c = [ 0.32746762] b_f = [ 1.08690989]
incx.max(), incx.min(), incx.mean() 7.35937 -6.73058 4.57545
fgtx.max(), fgtx.min(), fgtx.mean() 2.08859 -2.09635 1.26171
delta mean, abs_mean, abs_mean+, abs_mean-: -0.629229 10.5196 6.35234 25.1649
W_c max, min, mean, abs_mean: 0.355706 -0.355311 0.10617 0.353816
W_f max, min, mean, abs_mean: 0.107081 -0.107242 0.0313321 0.105089
Epoch 8/300
1s - loss: 1613.4216 - val_loss: 7300.5644
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1608.0742 - val_loss: 7112.0996
Epoch 00008: val_loss improved from 7270.75910 to 7112.09957, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1566.8885      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.841291 0.265859
delta_x = 8.20235 delta_h = 1.04908
U_c = [[-0.01956861]] U_f = [[ 0.]] b_c = [ 0.33485153] b_f = [ 1.08292139]
incx.max(), incx.min(), incx.mean() 7.52441 -6.88312 3.45066
fgtx.max(), fgtx.min(), fgtx.mean() 2.24475 -2.25362 0.972821
delta mean, abs_mean, abs_mean+, abs_mean-: 0.411937 8.20235 6.24643 12.5464
W_c max, min, mean, abs_mean: 0.363342 -0.362944 0.108459 0.361446
W_f max, min, mean, abs_mean: 0.114867 -0.115043 0.0336606 0.112852
beijing_tanh+hardsigmoid1 7112.0995      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.903381 0.266983
delta_x = 10.3925 delta_h = 1.6811
U_c = [[-0.01956861]] U_f = [[ 0.]] b_c = [ 0.33485153] b_f = [ 1.08292139]
incx.max(), incx.min(), incx.mean() 7.49358 -6.86513 4.53366
fgtx.max(), fgtx.min(), fgtx.mean() 2.23513 -2.24801 1.31096
delta mean, abs_mean, abs_mean+, abs_mean-: -0.746115 10.3925 6.23906 24.5408
W_c max, min, mean, abs_mean: 0.363342 -0.362944 0.108459 0.361446
W_f max, min, mean, abs_mean: 0.114867 -0.115043 0.0336606 0.112852
Epoch 10/300
1s - loss: 1602.1501 - val_loss: 7089.2350
Epoch 00009: val_loss improved from 7112.09957 to 7089.23498, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1563.8618      0.88  0.23  0.70      0.88  0.21  0.72      0.89  0.18  0.74
forget mean min: 0.843809 0.26377
delta_x = 8.09686 delta_h = 1.08189
U_c = [[-0.02068588]] U_f = [[ 0.]] b_c = [ 0.3385295] b_f = [ 1.08551645]
incx.max(), incx.min(), incx.mean() 7.58546 -6.94616 3.44505
fgtx.max(), fgtx.min(), fgtx.mean() 2.25491 -2.26667 0.9666
delta mean, abs_mean, abs_mean+, abs_mean-: 0.365982 8.09686 6.17895 12.2639
W_c max, min, mean, abs_mean: 0.36689 -0.366491 0.109523 0.364992
W_f max, min, mean, abs_mean: 0.115593 -0.115769 0.0338749 0.113569
beijing_tanh+hardsigmoid1 7089.2349      0.85  0.13  0.75      0.85  0.10  0.78      0.87  0.07  0.82
forget mean min: 0.90677 0.265493
delta_x = 10.1501 delta_h = 1.7271
U_c = [[-0.02068588]] U_f = [[ 0.]] b_c = [ 0.3385295] b_f = [ 1.08551645]
incx.max(), incx.min(), incx.mean() 7.55053 -6.91849 4.50759
fgtx.max(), fgtx.min(), fgtx.mean() 2.24405 -2.25805 1.29721
delta mean, abs_mean, abs_mean+, abs_mean-: -0.793924 10.1501 6.12855 23.1205
W_c max, min, mean, abs_mean: 0.36689 -0.366491 0.109523 0.364992
W_f max, min, mean, abs_mean: 0.115593 -0.115769 0.0338749 0.113569
Epoch 11/300
1s - loss: 1597.5129 - val_loss: 7163.7382
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1594.3995 - val_loss: 6968.5462
Epoch 00011: val_loss improved from 7089.23498 to 6968.54623, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1547.4727      0.88  0.23  0.70      0.89  0.21  0.72      0.89  0.18  0.75
forget mean min: 0.841073 0.246135
delta_x = 8.11489 delta_h = 0.924566
U_c = [[-0.01739135]] U_f = [[ 0.]] b_c = [ 0.3479476] b_f = [ 1.08557248]
incx.max(), incx.min(), incx.mean() 7.76974 -7.13012 3.44989
fgtx.max(), fgtx.min(), fgtx.mean() 2.33718 -2.3549 0.976817
delta mean, abs_mean, abs_mean+, abs_mean-: 0.360068 8.11489 6.23972 12.0834
W_c max, min, mean, abs_mean: 0.376756 -0.376352 0.112481 0.374851
W_f max, min, mean, abs_mean: 0.120073 -0.120256 0.0352169 0.118043
beijing_tanh+hardsigmoid1 6968.5463      0.85  0.12  0.76      0.85  0.09  0.79      0.88  0.06  0.83
forget mean min: 0.90597 0.24812
delta_x = 10.0952 delta_h = 1.48438
U_c = [[-0.01739135]] U_f = [[ 0.]] b_c = [ 0.3479476] b_f = [ 1.08557248]
incx.max(), incx.min(), incx.mean() 7.74986 -7.0986 4.50838
fgtx.max(), fgtx.min(), fgtx.mean() 2.33092 -2.34497 1.31014
delta mean, abs_mean, abs_mean+, abs_mean-: -0.820331 10.0952 6.12389 22.4854
W_c max, min, mean, abs_mean: 0.376756 -0.376352 0.112481 0.374851
W_f max, min, mean, abs_mean: 0.120073 -0.120256 0.0352169 0.118043
Epoch 13/300
1s - loss: 1590.6503 - val_loss: 6999.5511
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1581.9525 - val_loss: 6887.7821
Epoch 00013: val_loss improved from 6968.54623 to 6887.78206, saving model to beijing_tanh+hardsigmoid1_weights.hdf5
beijing_tanh+hardsigmoid1 1530.3418      0.87  0.21  0.71      0.88  0.19  0.73      0.88  0.16  0.76
forget mean min: 0.847968 0.26583
delta_x = 8.05093 delta_h = 0.655908
U_c = [[-0.01271261]] U_f = [[ 0.]] b_c = [ 0.36305773] b_f = [ 1.08765352]
incx.max(), incx.min(), incx.mean() 8.08803 -7.42192 3.53392
fgtx.max(), fgtx.min(), fgtx.mean() 2.24109 -2.2585 0.919892
delta mean, abs_mean, abs_mean+, abs_mean-: 0.235506 8.05093 6.22362 11.6901
W_c max, min, mean, abs_mean: 0.392436 -0.392032 0.117182 0.390523
W_f max, min, mean, abs_mean: 0.115332 -0.115509 0.0337914 0.113295
beijing_tanh+hardsigmoid1 6887.7820      0.85  0.12  0.76      0.85  0.08  0.79      0.87  0.06  0.83
forget mean min: 0.911801 0.269108
delta_x = 9.7412 delta_h = 1.05338
U_c = [[-0.01271261]] U_f = [[ 0.]] b_c = [ 0.36305773] b_f = [ 1.08765352]
incx.max(), incx.min(), incx.mean() 8.06175 -7.36543 4.6219
fgtx.max(), fgtx.min(), fgtx.mean() 2.23347 -2.24211 1.23552
delta mean, abs_mean, abs_mean+, abs_mean-: -0.987991 9.7412 6.01435 19.7006
W_c max, min, mean, abs_mean: 0.392436 -0.392032 0.117182 0.390523
W_f max, min, mean, abs_mean: 0.115332 -0.115509 0.0337914 0.113295
Epoch 15/300
1s - loss: 1569.4800 - val_loss: 6969.8185
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1564.3021 - val_loss: 7095.3117
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1556.0543 - val_loss: 7091.0151
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1549.2788 - val_loss: 7013.3625
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1538.5038 - val_loss: 7111.6954
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1542.6241 - val_loss: 7272.0149
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1536.3309 - val_loss: 7588.2253
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1532.7070 - val_loss: 7577.7974
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1529.0550 - val_loss: 7310.2211
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1518.9007 - val_loss: 7262.3575
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1506.2605 - val_loss: 7189.6417
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1490.1680 - val_loss: 7077.0087
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1463.2456 - val_loss: 7464.1470
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1434.3128 - val_loss: 7091.6556
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1388.6030 - val_loss: 7005.5142
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1364.4007 - val_loss: 7147.9313
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1326.9626 - val_loss: 7644.4292
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1294.3829 - val_loss: 7807.0239
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1264.8265 - val_loss: 8583.6558
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1242.7100 - val_loss: 8014.2749
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1217.8334 - val_loss: 8165.3571
Epoch 00034: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid2
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid2 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid229822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5906.5249 - val_loss: 10029.8433
Epoch 00000: val_loss improved from inf to 10029.84325, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 3251.3002      0.56  0.22  0.49      0.56  0.20  0.50      0.54  0.18  0.49
forget mean min: 0.815241 0.312928
delta_x = 4.37172 delta_h = 2.15245
U_c = [[-0.06013236]] U_f = [[ 0.]] b_c = [ 0.12283099] b_f = [ 1.09538031]
incx.max(), incx.min(), incx.mean() 2.92577 -2.77841 1.13021
fgtx.max(), fgtx.min(), fgtx.mean() 1.96193 -2.03074 0.705116
delta mean, abs_mean, abs_mean+, abs_mean-: -1.16556 4.37172 2.56278 7.39335
W_c max, min, mean, abs_mean: 0.150448 -0.150368 0.0148115 0.14874
W_f max, min, mean, abs_mean: 0.105505 -0.105577 0.0106276 0.104112
beijing_tanh+hardsigmoid210029.8432      0.78  0.09  0.72      0.78  0.05  0.74      0.79  0.03  0.77
forget mean min: 0.845756 0.313719
delta_x = 6.54711 delta_h = 3.97634
U_c = [[-0.06013236]] U_f = [[ 0.]] b_c = [ 0.12283099] b_f = [ 1.09538031]
incx.max(), incx.min(), incx.mean() 2.92643 -2.77276 1.34066
fgtx.max(), fgtx.min(), fgtx.mean() 1.96239 -2.02679 0.852424
delta mean, abs_mean, abs_mean+, abs_mean-: -3.4078 6.54711 2.60052 12.5564
W_c max, min, mean, abs_mean: 0.150448 -0.150368 0.0148115 0.14874
W_f max, min, mean, abs_mean: 0.105505 -0.105577 0.0106276 0.104112
Epoch 2/300
1s - loss: 2405.3320 - val_loss: 11346.0074
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1841.8972 - val_loss: 9598.1994
Epoch 00002: val_loss improved from 10029.84325 to 9598.19938, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1738.3447      0.86  0.25  0.67      0.87  0.23  0.69      0.87  0.20  0.72
forget mean min: 0.854915 0.407387
delta_x = 6.9094 delta_h = 0.587295
U_c = [[-0.01112028]] U_f = [[ 0.]] b_c = [ 0.27477086] b_f = [ 1.10600078]
incx.max(), incx.min(), incx.mean() 6.26853 -5.73097 3.05406
fgtx.max(), fgtx.min(), fgtx.mean() 1.56593 -1.56907 0.726112
delta mean, abs_mean, abs_mean+, abs_mean-: 0.271381 6.9094 5.31893 10.213
W_c max, min, mean, abs_mean: 0.302358 -0.302281 0.0300055 0.300651
W_f max, min, mean, abs_mean: 0.0799179 -0.0800017 0.00807286 0.0785483
beijing_tanh+hardsigmoid2 9598.1994      0.79  0.15  0.70      0.79  0.12  0.72      0.81  0.09  0.76
forget mean min: 0.909883 0.408139
delta_x = 8.86431 delta_h = 0.955808
U_c = [[-0.01112028]] U_f = [[ 0.]] b_c = [ 0.27477086] b_f = [ 1.10600078]
incx.max(), incx.min(), incx.mean() 6.26352 -5.71658 4.1128
fgtx.max(), fgtx.min(), fgtx.mean() 1.56463 -1.56531 1.00272
delta mean, abs_mean, abs_mean+, abs_mean-: -1.10121 8.86431 5.37597 17.9248
W_c max, min, mean, abs_mean: 0.302358 -0.302281 0.0300055 0.300651
W_f max, min, mean, abs_mean: 0.0799179 -0.0800017 0.00807286 0.0785483
Epoch 4/300
1s - loss: 1708.2182 - val_loss: 8358.3156
Epoch 00003: val_loss improved from 9598.19938 to 8358.31563, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1657.4056      0.87  0.24  0.68      0.87  0.22  0.70      0.88  0.19  0.73
forget mean min: 0.853162 0.375324
delta_x = 7.51745 delta_h = 0.94914
U_c = [[-0.01799779]] U_f = [[ 0.]] b_c = [ 0.29804575] b_f = [ 1.10347676]
incx.max(), incx.min(), incx.mean() 6.76337 -6.17978 3.26882
fgtx.max(), fgtx.min(), fgtx.mean() 1.72352 -1.72686 0.791941
delta mean, abs_mean, abs_mean+, abs_mean-: 0.382598 7.51745 5.79608 11.2007
W_c max, min, mean, abs_mean: 0.325892 -0.325817 0.0323599 0.324183
W_f max, min, mean, abs_mean: 0.087799 -0.0878788 0.00886186 0.0864206
beijing_tanh+hardsigmoid2 8358.3157      0.83  0.14  0.73      0.84  0.12  0.76      0.86  0.09  0.80
forget mean min: 0.909312 0.375848
delta_x = 9.84265 delta_h = 1.57049
U_c = [[-0.01799779]] U_f = [[ 0.]] b_c = [ 0.29804575] b_f = [ 1.10347676]
incx.max(), incx.min(), incx.mean() 6.75936 -6.16995 4.39934
fgtx.max(), fgtx.min(), fgtx.mean() 1.72246 -1.72424 1.09331
delta mean, abs_mean, abs_mean+, abs_mean-: -0.714217 9.84265 5.97291 22.3807
W_c max, min, mean, abs_mean: 0.325892 -0.325817 0.0323599 0.324183
W_f max, min, mean, abs_mean: 0.087799 -0.0878788 0.00886186 0.0864206
Epoch 5/300
1s - loss: 1655.5529 - val_loss: 7988.0272
Epoch 00004: val_loss improved from 8358.31563 to 7988.02725, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1629.7852      0.88  0.25  0.68      0.89  0.23  0.70      0.89  0.20  0.73
forget mean min: 0.851544 0.341853
delta_x = 7.93787 delta_h = 0.962891
U_c = [[-0.01782358]] U_f = [[ 0.]] b_c = [ 0.31057662] b_f = [ 1.09821844]
incx.max(), incx.min(), incx.mean() 7.04391 -6.43794 3.41259
fgtx.max(), fgtx.min(), fgtx.mean() 1.8847 -1.88895 0.868266
delta mean, abs_mean, abs_mean+, abs_mean-: 0.455351 7.93787 6.05388 12.1948
W_c max, min, mean, abs_mean: 0.339402 -0.339328 0.033712 0.337689
W_f max, min, mean, abs_mean: 0.095911 -0.0959894 0.00967432 0.0945214
beijing_tanh+hardsigmoid2 7988.0274      0.85  0.14  0.74      0.85  0.11  0.77      0.88  0.08  0.81
forget mean min: 0.908319 0.34238
delta_x = 10.2685 delta_h = 1.57599
U_c = [[-0.01782358]] U_f = [[ 0.]] b_c = [ 0.31057662] b_f = [ 1.09821844]
incx.max(), incx.min(), incx.mean() 7.03937 -6.42853 4.54651
fgtx.max(), fgtx.min(), fgtx.mean() 1.88343 -1.88632 1.18566
delta mean, abs_mean, abs_mean+, abs_mean-: -0.610321 10.2685 6.19279 24.7017
W_c max, min, mean, abs_mean: 0.339402 -0.339328 0.033712 0.337689
W_f max, min, mean, abs_mean: 0.095911 -0.0959894 0.00967432 0.0945214
Epoch 6/300
1s - loss: 1636.4026 - val_loss: 7741.7210
Epoch 00005: val_loss improved from 7988.02725 to 7741.72100, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1594.3673      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.849261 0.319935
delta_x = 8.12256 delta_h = 1.02692
U_c = [[-0.01926408]] U_f = [[ 0.]] b_c = [ 0.31791088] b_f = [ 1.09096301]
incx.max(), incx.min(), incx.mean() 7.21468 -6.59351 3.45486
fgtx.max(), fgtx.min(), fgtx.mean() 1.98707 -1.99129 0.903798
delta mean, abs_mean, abs_mean+, abs_mean-: 0.41107 8.12256 6.14989 12.5924
W_c max, min, mean, abs_mean: 0.347582 -0.34751 0.0345313 0.345866
W_f max, min, mean, abs_mean: 0.101051 -0.101128 0.0101895 0.0996495
beijing_tanh+hardsigmoid2 7741.7210      0.84  0.14  0.74      0.85  0.11  0.76      0.87  0.08  0.81
forget mean min: 0.908881 0.320646
delta_x = 10.3006 delta_h = 1.65449
U_c = [[-0.01926408]] U_f = [[ 0.]] b_c = [ 0.31791088] b_f = [ 1.09096301]
incx.max(), incx.min(), incx.mean() 7.19901 -6.58118 4.58439
fgtx.max(), fgtx.min(), fgtx.mean() 1.98255 -1.98773 1.22923
delta mean, abs_mean, abs_mean+, abs_mean-: -0.672594 10.3006 6.22159 24.2514
W_c max, min, mean, abs_mean: 0.347582 -0.34751 0.0345313 0.345866
W_f max, min, mean, abs_mean: 0.101051 -0.101128 0.0101895 0.0996495
Epoch 7/300
1s - loss: 1623.2620 - val_loss: 7491.8090
Epoch 00006: val_loss improved from 7741.72100 to 7491.80899, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1608.9505      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.845029 0.294617
delta_x = 8.27536 delta_h = 0.888375
U_c = [[-0.01606737]] U_f = [[ 0.]] b_c = [ 0.32550538] b_f = [ 1.08852136]
incx.max(), incx.min(), incx.mean() 7.38366 -6.74934 3.48921
fgtx.max(), fgtx.min(), fgtx.mean() 2.11045 -2.11544 0.945967
delta mean, abs_mean, abs_mean+, abs_mean-: 0.451615 8.27536 6.27794 12.828
W_c max, min, mean, abs_mean: 0.355783 -0.355713 0.0353527 0.354065
W_f max, min, mean, abs_mean: 0.10728 -0.107355 0.0108137 0.105868
beijing_tanh+hardsigmoid2 7491.8089      0.85  0.14  0.75      0.86  0.11  0.78      0.88  0.08  0.82
forget mean min: 0.906437 0.295284
delta_x = 10.6555 delta_h = 1.4454
U_c = [[-0.01606737]] U_f = [[ 0.]] b_c = [ 0.32550538] b_f = [ 1.08852136]
incx.max(), incx.min(), incx.mean() 7.36505 -6.73819 4.66406
fgtx.max(), fgtx.min(), fgtx.mean() 2.10488 -2.1121 1.29726
delta mean, abs_mean, abs_mean+, abs_mean-: -0.615931 10.6555 6.3975 26.1692
W_c max, min, mean, abs_mean: 0.355783 -0.355713 0.0353527 0.354065
W_f max, min, mean, abs_mean: 0.10728 -0.107355 0.0108137 0.105868
Epoch 8/300
1s - loss: 1613.0936 - val_loss: 7315.3628
Epoch 00007: val_loss improved from 7491.80899 to 7315.36284, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1569.1758      0.88  0.23  0.70      0.88  0.21  0.72      0.89  0.18  0.74
forget mean min: 0.845783 0.290908
delta_x = 8.08272 delta_h = 1.04055
U_c = [[-0.01986604]] U_f = [[ 0.]] b_c = [ 0.32627645] b_f = [ 1.08288014]
incx.max(), incx.min(), incx.mean() 7.39437 -6.76711 3.43159
fgtx.max(), fgtx.min(), fgtx.mean() 2.12075 -2.12834 0.931729
delta mean, abs_mean, abs_mean+, abs_mean-: 0.353951 8.08272 6.15378 12.2869
W_c max, min, mean, abs_mean: 0.356878 -0.356809 0.0354635 0.355157
W_f max, min, mean, abs_mean: 0.107979 -0.108059 0.0108857 0.106563
beijing_tanh+hardsigmoid2 7315.3628      0.84  0.13  0.75      0.84  0.10  0.77      0.87  0.07  0.82
forget mean min: 0.905587 0.29201
delta_x = 10.1359 delta_h = 1.66878
U_c = [[-0.01986604]] U_f = [[ 0.]] b_c = [ 0.32627645] b_f = [ 1.08288014]
incx.max(), incx.min(), incx.mean() 7.36349 -6.74875 4.48714
fgtx.max(), fgtx.min(), fgtx.mean() 2.11148 -2.12283 1.24844
delta mean, abs_mean, abs_mean+, abs_mean-: -0.817014 10.1359 6.11668 22.9876
W_c max, min, mean, abs_mean: 0.356878 -0.356809 0.0354635 0.355157
W_f max, min, mean, abs_mean: 0.107979 -0.108059 0.0108857 0.106563
Epoch 9/300
1s - loss: 1602.5177 - val_loss: 7204.8822
Epoch 00008: val_loss improved from 7315.36284 to 7204.88219, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1556.6676      0.88  0.23  0.70      0.89  0.21  0.72      0.89  0.18  0.75
forget mean min: 0.84776 0.276052
delta_x = 8.04838 delta_h = 0.925188
U_c = [[-0.01765543]] U_f = [[ 0.]] b_c = [ 0.33071879] b_f = [ 1.08204341]
incx.max(), incx.min(), incx.mean() 7.48112 -6.8548 3.46427
fgtx.max(), fgtx.min(), fgtx.mean() 2.19102 -2.20178 0.960175
delta mean, abs_mean, abs_mean+, abs_mean-: 0.351025 8.04838 6.10935 12.3127
W_c max, min, mean, abs_mean: 0.361626 -0.361558 0.0359396 0.359902
W_f max, min, mean, abs_mean: 0.111703 -0.111784 0.0112588 0.110281
beijing_tanh+hardsigmoid2 7204.8823      0.84  0.13  0.75      0.85  0.10  0.78      0.87  0.07  0.82
forget mean min: 0.908994 0.277595
delta_x = 10.0297 delta_h = 1.48533
U_c = [[-0.01765543]] U_f = [[ 0.]] b_c = [ 0.33071879] b_f = [ 1.08204341]
incx.max(), incx.min(), incx.mean() 7.45006 -6.82963 4.49777
fgtx.max(), fgtx.min(), fgtx.mean() 2.1815 -2.19407 1.27686
delta mean, abs_mean, abs_mean+, abs_mean-: -0.832142 10.0297 6.04671 22.6801
W_c max, min, mean, abs_mean: 0.361626 -0.361558 0.0359396 0.359902
W_f max, min, mean, abs_mean: 0.111703 -0.111784 0.0112588 0.110281
Epoch 10/300
1s - loss: 1598.9226 - val_loss: 7266.6591
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1587.5386 - val_loss: 6955.3818
Epoch 00010: val_loss improved from 7204.88219 to 6955.38179, saving model to beijing_tanh+hardsigmoid2_weights.hdf5
beijing_tanh+hardsigmoid2 1539.6709      0.88  0.23  0.70      0.89  0.21  0.72      0.89  0.18  0.75
forget mean min: 0.848934 0.274444
delta_x = 8.09516 delta_h = 0.72371
U_c = [[-0.01374162]] U_f = [[ 0.]] b_c = [ 0.34594199] b_f = [ 1.08208239]
incx.max(), incx.min(), incx.mean() 7.80302 -7.15316 3.54768
fgtx.max(), fgtx.min(), fgtx.mean() 2.19748 -2.20986 0.943494
delta mean, abs_mean, abs_mean+, abs_mean-: 0.330909 8.09516 6.22952 11.993
W_c max, min, mean, abs_mean: 0.377506 -0.377443 0.0375298 0.375779
W_f max, min, mean, abs_mean: 0.112159 -0.112244 0.0113058 0.110736
beijing_tanh+hardsigmoid2 6955.3819      0.85  0.12  0.76      0.85  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.911134 0.276592
delta_x = 9.83388 delta_h = 1.15126
U_c = [[-0.01374162]] U_f = [[ 0.]] b_c = [ 0.34594199] b_f = [ 1.08208239]
incx.max(), incx.min(), incx.mean() 7.77574 -7.11672 4.59044
fgtx.max(), fgtx.min(), fgtx.mean() 2.18944 -2.19912 1.25078
delta mean, abs_mean, abs_mean+, abs_mean-: -0.907863 9.83388 6.04815 20.4927
W_c max, min, mean, abs_mean: 0.377506 -0.377443 0.0375298 0.375779
W_f max, min, mean, abs_mean: 0.112159 -0.112244 0.0113058 0.110736
Epoch 12/300
1s - loss: 1580.4458 - val_loss: 7070.6430
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1566.4412 - val_loss: 7044.1627
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1553.0938 - val_loss: 7035.8326
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1547.5063 - val_loss: 7118.3271
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1543.8160 - val_loss: 7365.7200
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1542.3068 - val_loss: 7340.2549
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1532.6669 - val_loss: 7447.0149
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1532.0447 - val_loss: 7392.2289
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1512.3888 - val_loss: 7564.4862
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1511.1169 - val_loss: 7570.2678
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1487.5698 - val_loss: 7465.4122
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1460.4371 - val_loss: 7588.5809
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1436.1597 - val_loss: 7457.2183
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1398.0320 - val_loss: 7687.6116
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1372.0886 - val_loss: 8158.0424
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1331.7964 - val_loss: 8506.2305
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1292.3946 - val_loss: 8787.9984
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1248.7559 - val_loss: 8806.5204
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1220.4289 - val_loss: 8283.9622
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1194.5888 - val_loss: 8106.5290
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1172.2905 - val_loss: 8177.6240
Epoch 00031: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid3
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid3 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid329822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5925.3252 - val_loss: 9612.3757
Epoch 00000: val_loss improved from inf to 9612.37565, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 3315.1115      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.19  0.48
forget mean min: 0.811793 0.312897
delta_x = 4.43377 delta_h = 2.2721
U_c = [[-0.06384084]] U_f = [[ 0.]] b_c = [ 0.12289225] b_f = [ 1.09472156]
incx.max(), incx.min(), incx.mean() 2.93191 -2.76729 1.1106
fgtx.max(), fgtx.min(), fgtx.mean() 1.97322 -2.03024 0.693826
delta mean, abs_mean, abs_mean+, abs_mean-: -1.23491 4.43377 2.58028 7.45616
W_c max, min, mean, abs_mean: 0.149498 -0.149843 -0.0155602 0.148238
W_f max, min, mean, abs_mean: 0.104905 -0.10472 -0.0105394 0.104132
beijing_tanh+hardsigmoid3 9612.3757      0.80  0.09  0.74      0.79  0.05  0.76      0.80  0.03  0.78
forget mean min: 0.843792 0.313511
delta_x = 6.56826 delta_h = 4.20769
U_c = [[-0.06384084]] U_f = [[ 0.]] b_c = [ 0.12289225] b_f = [ 1.09472156]
incx.max(), incx.min(), incx.mean() 2.93156 -2.76292 1.3484
fgtx.max(), fgtx.min(), fgtx.mean() 1.97298 -2.02716 0.860866
delta mean, abs_mean, abs_mean+, abs_mean-: -3.32636 6.56826 2.60882 13.0652
W_c max, min, mean, abs_mean: 0.149498 -0.149843 -0.0155602 0.148238
W_f max, min, mean, abs_mean: 0.104905 -0.10472 -0.0105394 0.104132
Epoch 2/300
1s - loss: 2417.9586 - val_loss: 10822.1687
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1842.6768 - val_loss: 9341.6417
Epoch 00002: val_loss improved from 9612.37565 to 9341.64169, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1747.7908      0.84  0.23  0.67      0.85  0.20  0.69      0.85  0.17  0.72
forget mean min: 0.852281 0.417126
delta_x = 6.73186 delta_h = 0.738351
U_c = [[-0.0145936]] U_f = [[ 0.]] b_c = [ 0.27663478] b_f = [ 1.1100527]
incx.max(), incx.min(), incx.mean() 6.29164 -5.75094 2.99922
fgtx.max(), fgtx.min(), fgtx.mean() 1.52124 -1.52442 0.688563
delta mean, abs_mean, abs_mean+, abs_mean-: 0.150325 6.73186 5.23647 9.59795
W_c max, min, mean, abs_mean: 0.303045 -0.303428 -0.0309179 0.30182
W_f max, min, mean, abs_mean: 0.0771488 -0.0768984 -0.00775382 0.0763328
beijing_tanh+hardsigmoid3 9341.6417      0.79  0.15  0.70      0.79  0.12  0.72      0.82  0.09  0.76
forget mean min: 0.909049 0.417896
delta_x = 8.62552 delta_h = 1.21895
U_c = [[-0.0145936]] U_f = [[ 0.]] b_c = [ 0.27663478] b_f = [ 1.1100527]
incx.max(), incx.min(), incx.mean() 6.28789 -5.73571 4.12767
fgtx.max(), fgtx.min(), fgtx.mean() 1.5203 -1.52057 0.973957
delta mean, abs_mean, abs_mean+, abs_mean-: -1.13244 8.62552 5.2828 16.7775
W_c max, min, mean, abs_mean: 0.303045 -0.303428 -0.0309179 0.30182
W_f max, min, mean, abs_mean: 0.0771488 -0.0768984 -0.00775382 0.0763328
Epoch 4/300
1s - loss: 1707.6174 - val_loss: 8752.7703
Epoch 00003: val_loss improved from 9341.64169 to 8752.77035, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1652.6091      0.88  0.25  0.68      0.88  0.23  0.70      0.88  0.19  0.73
forget mean min: 0.853424 0.373972
delta_x = 7.66659 delta_h = 0.825639
U_c = [[-0.01533198]] U_f = [[ 0.]] b_c = [ 0.30565599] b_f = [ 1.10985231]
incx.max(), incx.min(), incx.mean() 6.90809 -6.30879 3.33362
fgtx.max(), fgtx.min(), fgtx.mean() 1.73684 -1.73999 0.796535
delta mean, abs_mean, abs_mean+, abs_mean-: 0.392331 7.66659 5.92833 11.3553
W_c max, min, mean, abs_mean: 0.332247 -0.332637 -0.0338383 0.331029
W_f max, min, mean, abs_mean: 0.0879033 -0.0876535 -0.00882818 0.0870803
beijing_tanh+hardsigmoid3 8752.7704      0.84  0.16  0.72      0.84  0.12  0.75      0.87  0.09  0.80
forget mean min: 0.913262 0.374563
delta_x = 9.99308 delta_h = 1.35922
U_c = [[-0.01533198]] U_f = [[ 0.]] b_c = [ 0.30565599] b_f = [ 1.10985231]
incx.max(), incx.min(), incx.mean() 6.90531 -6.29755 4.55796
fgtx.max(), fgtx.min(), fgtx.mean() 1.7361 -1.73704 1.11861
delta mean, abs_mean, abs_mean+, abs_mean-: -0.635031 9.99308 6.07674 23.1035
W_c max, min, mean, abs_mean: 0.332247 -0.332637 -0.0338383 0.331029
W_f max, min, mean, abs_mean: 0.0879033 -0.0876535 -0.00882818 0.0870803
Epoch 5/300
1s - loss: 1655.2338 - val_loss: 7960.5305
Epoch 00004: val_loss improved from 8752.77035 to 7960.53046, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1629.1476      0.87  0.22  0.70      0.87  0.20  0.71      0.87  0.17  0.74
forget mean min: 0.850312 0.351622
delta_x = 7.88048 delta_h = 1.03544
U_c = [[-0.02008202]] U_f = [[ 0.]] b_c = [ 0.31343162] b_f = [ 1.10076714]
incx.max(), incx.min(), incx.mean() 7.08537 -6.47439 3.35577
fgtx.max(), fgtx.min(), fgtx.mean() 1.83835 -1.84266 0.825888
delta mean, abs_mean, abs_mean+, abs_mean-: 0.278593 7.88048 6.01323 11.8199
W_c max, min, mean, abs_mean: 0.34093 -0.341328 -0.0347068 0.339718
W_f max, min, mean, abs_mean: 0.0930516 -0.0928041 -0.00934205 0.0922216
beijing_tanh+hardsigmoid3 7960.5304      0.84  0.15  0.73      0.84  0.11  0.76      0.87  0.08  0.80
forget mean min: 0.910627 0.352264
delta_x = 9.99515 delta_h = 1.68272
U_c = [[-0.02008202]] U_f = [[ 0.]] b_c = [ 0.31343162] b_f = [ 1.10076714]
incx.max(), incx.min(), incx.mean() 7.08037 -6.46255 4.55135
fgtx.max(), fgtx.min(), fgtx.mean() 1.83699 -1.83945 1.15045
delta mean, abs_mean, abs_mean+, abs_mean-: -0.722445 9.99515 6.12098 22.0939
W_c max, min, mean, abs_mean: 0.34093 -0.341328 -0.0347068 0.339718
W_f max, min, mean, abs_mean: 0.0930516 -0.0928041 -0.00934205 0.0922216
Epoch 6/300
1s - loss: 1634.4101 - val_loss: 7590.0834
Epoch 00005: val_loss improved from 7960.53046 to 7590.08339, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1598.0466      0.89  0.25  0.68      0.89  0.23  0.70      0.89  0.20  0.73
forget mean min: 0.8487 0.313655
delta_x = 8.18053 delta_h = 1.0189
U_c = [[-0.01886058]] U_f = [[ 0.]] b_c = [ 0.32137597] b_f = [ 1.09888864]
incx.max(), incx.min(), incx.mean() 7.2531 -6.62772 3.47271
fgtx.max(), fgtx.min(), fgtx.mean() 2.02554 -2.03061 0.920857
delta mean, abs_mean, abs_mean+, abs_mean-: 0.454401 8.18053 6.20788 12.6858
W_c max, min, mean, abs_mean: 0.348996 -0.349401 -0.0355135 0.347789
W_f max, min, mean, abs_mean: 0.102468 -0.102217 -0.0102825 0.101628
beijing_tanh+hardsigmoid3 7590.0833      0.85  0.14  0.75      0.86  0.11  0.78      0.88  0.08  0.82
forget mean min: 0.907149 0.314267
delta_x = 10.4477 delta_h = 1.64827
U_c = [[-0.01886058]] U_f = [[ 0.]] b_c = [ 0.32137597] b_f = [ 1.09888864]
incx.max(), incx.min(), incx.mean() 7.24357 -6.61724 4.60366
fgtx.max(), fgtx.min(), fgtx.mean() 2.02275 -2.02755 1.25134
delta mean, abs_mean, abs_mean+, abs_mean-: -0.600612 10.4477 6.29675 25.3301
W_c max, min, mean, abs_mean: 0.348996 -0.349401 -0.0355135 0.347789
W_f max, min, mean, abs_mean: 0.102468 -0.102217 -0.0102825 0.101628
Epoch 7/300
1s - loss: 1614.9257 - val_loss: 7273.5474
Epoch 00006: val_loss improved from 7590.08339 to 7273.54745, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1590.7962      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.73
forget mean min: 0.844645 0.298451
delta_x = 8.18007 delta_h = 1.07888
U_c = [[-0.02003974]] U_f = [[ 0.]] b_c = [ 0.32613838] b_f = [ 1.0938133]
incx.max(), incx.min(), incx.mean() 7.36332 -6.73029 3.44334
fgtx.max(), fgtx.min(), fgtx.mean() 2.09583 -2.10156 0.928368
delta mean, abs_mean, abs_mean+, abs_mean-: 0.447134 8.18007 6.23676 12.5389
W_c max, min, mean, abs_mean: 0.354454 -0.354865 -0.0360594 0.353253
W_f max, min, mean, abs_mean: 0.106055 -0.105801 -0.01064 0.105206
beijing_tanh+hardsigmoid3 7273.5475      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.900953 0.299124
delta_x = 10.4685 delta_h = 1.74965
U_c = [[-0.02003974]] U_f = [[ 0.]] b_c = [ 0.32613838] b_f = [ 1.0938133]
incx.max(), incx.min(), incx.mean() 7.34415 -6.71899 4.51509
fgtx.max(), fgtx.min(), fgtx.mean() 2.09012 -2.09819 1.24756
delta mean, abs_mean, abs_mean+, abs_mean-: -0.690332 10.4685 6.29478 24.9849
W_c max, min, mean, abs_mean: 0.354454 -0.354865 -0.0360594 0.353253
W_f max, min, mean, abs_mean: 0.106055 -0.105801 -0.01064 0.105206
Epoch 8/300
1s - loss: 1610.9354 - val_loss: 7291.4532
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1609.8816 - val_loss: 7144.0602
Epoch 00008: val_loss improved from 7273.54745 to 7144.06022, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1569.7606      0.88  0.23  0.69      0.89  0.22  0.71      0.89  0.18  0.74
forget mean min: 0.844311 0.274831
delta_x = 8.10981 delta_h = 1.0948
U_c = [[-0.02095337]] U_f = [[ 0.]] b_c = [ 0.33405852] b_f = [ 1.08746064]
incx.max(), incx.min(), incx.mean() 7.51201 -6.88093 3.43836
fgtx.max(), fgtx.min(), fgtx.mean() 2.20194 -2.2133 0.952288
delta mean, abs_mean, abs_mean+, abs_mean-: 0.364702 8.10981 6.179 12.3232
W_c max, min, mean, abs_mean: 0.36263 -0.363053 -0.0368772 0.361438
W_f max, min, mean, abs_mean: 0.111743 -0.111476 -0.0112064 0.110876
beijing_tanh+hardsigmoid3 7144.0601      0.84  0.13  0.75      0.85  0.10  0.78      0.87  0.07  0.82
forget mean min: 0.904911 0.2762
delta_x = 10.1074 delta_h = 1.73509
U_c = [[-0.02095337]] U_f = [[ 0.]] b_c = [ 0.33405852] b_f = [ 1.08746064]
incx.max(), incx.min(), incx.mean() 7.4819 -6.85863 4.47142
fgtx.max(), fgtx.min(), fgtx.mean() 2.1927 -2.20646 1.26919
delta mean, abs_mean, abs_mean+, abs_mean-: -0.846809 10.1074 6.10543 22.6689
W_c max, min, mean, abs_mean: 0.36263 -0.363053 -0.0368772 0.361438
W_f max, min, mean, abs_mean: 0.111743 -0.111476 -0.0112064 0.110876
Epoch 10/300
1s - loss: 1601.2306 - val_loss: 7097.0161
Epoch 00009: val_loss improved from 7144.06022 to 7097.01608, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1557.4627      0.88  0.23  0.69      0.89  0.21  0.72      0.89  0.18  0.74
forget mean min: 0.844969 0.274032
delta_x = 8.07961 delta_h = 0.978994
U_c = [[-0.01863097]] U_f = [[ 0.]] b_c = [ 0.34056768] b_f = [ 1.08718908]
incx.max(), incx.min(), incx.mean() 7.6436 -7.00403 3.45802
fgtx.max(), fgtx.min(), fgtx.mean() 2.20448 -2.21703 0.94103
delta mean, abs_mean, abs_mean+, abs_mean-: 0.362583 8.07961 6.18903 12.1348
W_c max, min, mean, abs_mean: 0.369286 -0.369716 -0.0375431 0.368101
W_f max, min, mean, abs_mean: 0.111992 -0.111713 -0.0112296 0.111114
beijing_tanh+hardsigmoid3 7097.0161      0.84  0.12  0.75      0.84  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.903915 0.275685
delta_x = 9.97609 delta_h = 1.5532
U_c = [[-0.01863097]] U_f = [[ 0.]] b_c = [ 0.34056768] b_f = [ 1.08718908]
incx.max(), incx.min(), incx.mean() 7.60871 -6.97664 4.44419
fgtx.max(), fgtx.min(), fgtx.mean() 2.19395 -2.20876 1.23871
delta mean, abs_mean, abs_mean+, abs_mean-: -0.911718 9.97609 6.07463 21.4398
W_c max, min, mean, abs_mean: 0.369286 -0.369716 -0.0375431 0.368101
W_f max, min, mean, abs_mean: 0.111992 -0.111713 -0.0112296 0.111114
Epoch 11/300
1s - loss: 1600.1615 - val_loss: 7041.7955
Epoch 00010: val_loss improved from 7097.01608 to 7041.79554, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1551.4077      0.89  0.24  0.69      0.89  0.22  0.71      0.90  0.19  0.74
forget mean min: 0.844271 0.259835
delta_x = 8.1884 delta_h = 0.889768
U_c = [[-0.01655853]] U_f = [[ 0.]] b_c = [ 0.34887111] b_f = [ 1.089329]
incx.max(), incx.min(), incx.mean() 7.80803 -7.16021 3.52157
fgtx.max(), fgtx.min(), fgtx.mean() 2.27493 -2.29016 0.967625
delta mean, abs_mean, abs_mean+, abs_mean-: 0.411189 8.1884 6.29785 12.2568
W_c max, min, mean, abs_mean: 0.377589 -0.378025 -0.0383737 0.376409
W_f max, min, mean, abs_mean: 0.115681 -0.115397 -0.0115984 0.114799
beijing_tanh+hardsigmoid3 7041.7955      0.85  0.12  0.76      0.85  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.906531 0.261766
delta_x = 10.1277 delta_h = 1.4146
U_c = [[-0.01655853]] U_f = [[ 0.]] b_c = [ 0.34887111] b_f = [ 1.089329]
incx.max(), incx.min(), incx.mean() 7.78328 -7.12855 4.55818
fgtx.max(), fgtx.min(), fgtx.mean() 2.26738 -2.2805 1.28378
delta mean, abs_mean, abs_mean+, abs_mean-: -0.810101 10.1277 6.17757 22.2448
W_c max, min, mean, abs_mean: 0.377589 -0.378025 -0.0383737 0.376409
W_f max, min, mean, abs_mean: 0.115681 -0.115397 -0.0115984 0.114799
Epoch 12/300
1s - loss: 1592.1697 - val_loss: 6971.3833
Epoch 00011: val_loss improved from 7041.79554 to 6971.38326, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1567.4828      0.90  0.25  0.69      0.90  0.23  0.71      0.91  0.20  0.74
forget mean min: 0.843525 0.243062
delta_x = 8.24787 delta_h = 0.876578
U_c = [[-0.01597172]] U_f = [[ 0.]] b_c = [ 0.35385606] b_f = [ 1.09382105]
incx.max(), incx.min(), incx.mean() 7.91409 -7.25084 3.56582
fgtx.max(), fgtx.min(), fgtx.mean() 2.3646 -2.37851 1.0046
delta mean, abs_mean, abs_mean+, abs_mean-: 0.495504 8.24787 6.33951 12.4875
W_c max, min, mean, abs_mean: 0.382453 -0.382895 -0.0388606 0.381279
W_f max, min, mean, abs_mean: 0.120139 -0.119849 -0.0120434 0.119252
beijing_tanh+hardsigmoid3 6971.3832      0.85  0.12  0.76      0.86  0.09  0.79      0.88  0.07  0.83
forget mean min: 0.905217 0.245124
delta_x = 10.3234 delta_h = 1.4066
U_c = [[-0.01597172]] U_f = [[ 0.]] b_c = [ 0.35385606] b_f = [ 1.09382105]
incx.max(), incx.min(), incx.mean() 7.88668 -7.21788 4.58806
fgtx.max(), fgtx.min(), fgtx.mean() 2.35603 -2.3682 1.32432
delta mean, abs_mean, abs_mean+, abs_mean-: -0.718259 10.3234 6.27715 23.5015
W_c max, min, mean, abs_mean: 0.382453 -0.382895 -0.0388606 0.381279
W_f max, min, mean, abs_mean: 0.120139 -0.119849 -0.0120434 0.119252
Epoch 13/300
1s - loss: 1580.8548 - val_loss: 7044.9714
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1568.2121 - val_loss: 7174.9737
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1564.7746 - val_loss: 6994.6992
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1556.5474 - val_loss: 7049.9532
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1548.1662 - val_loss: 7333.8831
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1547.9424 - val_loss: 7130.8154
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1541.6265 - val_loss: 7177.4095
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1537.7696 - val_loss: 7122.3555
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1528.2956 - val_loss: 7192.6402
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1518.5594 - val_loss: 7278.5623
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1505.4877 - val_loss: 7044.7142
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1486.8601 - val_loss: 6999.9079
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1468.4508 - val_loss: 7191.2124
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1433.4986 - val_loss: 7202.5479
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1413.2893 - val_loss: 6884.4034
Epoch 00026: val_loss improved from 6971.38326 to 6884.40343, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1328.7224      0.88  0.21  0.71      0.89  0.18  0.75      0.90  0.15  0.78
forget mean min: 0.84859 0.140965
delta_x = 8.67001 delta_h = 0.302333
U_c = [[-0.00566563]] U_f = [[ 0.]] b_c = [ 0.45348597] b_f = [ 1.10004497]
incx.max(), incx.min(), incx.mean() 9.75694 -8.93407 3.91344
fgtx.max(), fgtx.min(), fgtx.mean() 2.86928 -2.89522 1.06708
delta mean, abs_mean, abs_mean+, abs_mean-: 0.259905 8.67001 6.67817 12.6884
W_c max, min, mean, abs_mean: 0.476628 -0.476999 -0.0482845 0.475385
W_f max, min, mean, abs_mean: 0.149169 -0.149051 -0.0146217 0.146614
beijing_tanh+hardsigmoid3 6884.4035      0.84  0.10  0.77      0.84  0.08  0.79      0.87  0.05  0.83
forget mean min: 0.914934 0.166487
delta_x = 10.326 delta_h = 0.500506
U_c = [[-0.00566563]] U_f = [[ 0.]] b_c = [ 0.45348597] b_f = [ 1.10004497]
incx.max(), incx.min(), incx.mean() 9.64588 -8.52039 4.97544
fgtx.max(), fgtx.min(), fgtx.mean() 2.83502 -2.76761 1.39454
delta mean, abs_mean, abs_mean+, abs_mean-: -1.00787 10.326 6.47923 20.1722
W_c max, min, mean, abs_mean: 0.476628 -0.476999 -0.0482845 0.475385
W_f max, min, mean, abs_mean: 0.149169 -0.149051 -0.0146217 0.146614
Epoch 28/300
1s - loss: 1374.2943 - val_loss: 7054.1048
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1340.5616 - val_loss: 6778.9024
Epoch 00028: val_loss improved from 6884.40343 to 6778.90241, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1277.2908      0.88  0.21  0.71      0.89  0.18  0.74      0.90  0.15  0.77
forget mean min: 0.845109 0.112121
delta_x = 8.65948 delta_h = 0.376442
U_c = [[-0.00707321]] U_f = [[ 0.]] b_c = [ 0.49114001] b_f = [ 1.08539307]
incx.max(), incx.min(), incx.mean() 10.5105 -9.62609 3.97702
fgtx.max(), fgtx.min(), fgtx.mean() 2.99553 -3.02479 1.04215
delta mean, abs_mean, abs_mean+, abs_mean-: 0.276805 8.65948 6.78551 12.2727
W_c max, min, mean, abs_mean: 0.516718 -0.517171 -0.0522488 0.515316
W_f max, min, mean, abs_mean: 0.157578 -0.157636 -0.0152688 0.154068
beijing_tanh+hardsigmoid3 6778.9025      0.85  0.09  0.79      0.85  0.06  0.80      0.87  0.04  0.84
forget mean min: 0.904517 0.150662
delta_x = 10.5137 delta_h = 0.626102
U_c = [[-0.00707321]] U_f = [[ 0.]] b_c = [ 0.49114001] b_f = [ 1.08539307]
incx.max(), incx.min(), incx.mean() 10.351 -8.98176 4.97636
fgtx.max(), fgtx.min(), fgtx.mean() 2.94782 -2.83208 1.34076
delta mean, abs_mean, abs_mean+, abs_mean-: -1.05926 10.5137 6.76203 19.2296
W_c max, min, mean, abs_mean: 0.516718 -0.517171 -0.0522488 0.515316
W_f max, min, mean, abs_mean: 0.157578 -0.157636 -0.0152688 0.154068
Epoch 30/300
1s - loss: 1292.3366 - val_loss: 6878.6986
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1240.2802 - val_loss: 6652.7779
Epoch 00030: val_loss improved from 6778.90241 to 6652.77793, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1160.6345      0.88  0.19  0.73      0.89  0.16  0.76      0.89  0.13  0.79
forget mean min: 0.844131 0.0729085
delta_x = 8.98777 delta_h = 0.258956
U_c = [[-0.00480144]] U_f = [[ 0.]] b_c = [ 0.54301834] b_f = [ 1.06509626]
incx.max(), incx.min(), incx.mean() 11.6422 -10.6609 4.22235
fgtx.max(), fgtx.min(), fgtx.mean() 3.17062 -3.20055 1.05095
delta mean, abs_mean, abs_mean+, abs_mean-: 0.224682 8.98777 7.10141 12.47
W_c max, min, mean, abs_mean: 0.573682 -0.574192 -0.0579174 0.572111
W_f max, min, mean, abs_mean: 0.167942 -0.168123 -0.0161092 0.163435
beijing_tanh+hardsigmoid3 6652.7778      0.86  0.08  0.80      0.86  0.06  0.82      0.88  0.04  0.85
forget mean min: 0.906025 0.127761
delta_x = 10.8401 delta_h = 0.42239
U_c = [[-0.00480144]] U_f = [[ 0.]] b_c = [ 0.54301834] b_f = [ 1.06509626]
incx.max(), incx.min(), incx.mean() 11.4455 -9.70116 5.34242
fgtx.max(), fgtx.min(), fgtx.mean() 3.11441 -2.92629 1.37061
delta mean, abs_mean, abs_mean+, abs_mean-: -1.06328 10.8401 7.1399 18.8741
W_c max, min, mean, abs_mean: 0.573682 -0.574192 -0.0579174 0.572111
W_f max, min, mean, abs_mean: 0.167942 -0.168123 -0.0161092 0.163435
Epoch 32/300
1s - loss: 1203.1721 - val_loss: 6725.5411
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1175.2192 - val_loss: 6371.5706
Epoch 00032: val_loss improved from 6652.77793 to 6371.57063, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1099.4584      0.88  0.19  0.74      0.90  0.16  0.77      0.91  0.13  0.80
forget mean min: 0.845542 0.0414203
delta_x = 9.26532 delta_h = 0.320184
U_c = [[-0.00591308]] U_f = [[ 0.]] b_c = [ 0.58496666] b_f = [ 1.05245149]
incx.max(), incx.min(), incx.mean() 12.572 -11.5016 4.47891
fgtx.max(), fgtx.min(), fgtx.mean() 3.31779 -3.34535 1.07759
delta mean, abs_mean, abs_mean+, abs_mean-: 0.268627 9.26532 7.43317 12.5411
W_c max, min, mean, abs_mean: 0.620946 -0.621401 -0.0625928 0.619074
W_f max, min, mean, abs_mean: 0.177001 -0.17737 -0.016796 0.171355
beijing_tanh+hardsigmoid3 6371.5706      0.87  0.08  0.81      0.87  0.05  0.83      0.88  0.04  0.85
forget mean min: 0.903534 0.116506
delta_x = 10.9445 delta_h = 0.506539
U_c = [[-0.00591308]] U_f = [[ 0.]] b_c = [ 0.58496666] b_f = [ 1.05245149]
incx.max(), incx.min(), incx.mean() 12.3333 -10.1457 5.55305
fgtx.max(), fgtx.min(), fgtx.mean() 3.25169 -2.96992 1.37442
delta mean, abs_mean, abs_mean+, abs_mean-: -1.04821 10.9445 7.40867 18.0553
W_c max, min, mean, abs_mean: 0.620946 -0.621401 -0.0625928 0.619074
W_f max, min, mean, abs_mean: 0.177001 -0.17737 -0.016796 0.171355
Epoch 34/300
1s - loss: 1152.1597 - val_loss: 5885.9312
Epoch 00033: val_loss improved from 6371.57063 to 5885.93117, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1086.0802      0.89  0.18  0.74      0.90  0.15  0.78      0.90  0.13  0.80
forget mean min: 0.845044 0.0263588
delta_x = 9.30514 delta_h = 0.526417
U_c = [[-0.00967689]] U_f = [[ 0.]] b_c = [ 0.60037869] b_f = [ 1.04890621]
incx.max(), incx.min(), incx.mean() 12.8888 -11.7788 4.5424
fgtx.max(), fgtx.min(), fgtx.mean() 3.39205 -3.41711 1.08793
delta mean, abs_mean, abs_mean+, abs_mean-: 0.322357 9.30514 7.51085 12.5076
W_c max, min, mean, abs_mean: 0.638062 -0.638527 -0.0642937 0.636108
W_f max, min, mean, abs_mean: 0.181612 -0.182066 -0.0171808 0.175597
beijing_tanh+hardsigmoid3 5885.9311      0.89  0.08  0.82      0.89  0.05  0.85      0.91  0.04  0.87
forget mean min: 0.903933 0.110375
delta_x = 11.0486 delta_h = 0.831715
U_c = [[-0.00967689]] U_f = [[ 0.]] b_c = [ 0.60037869] b_f = [ 1.04890621]
incx.max(), incx.min(), incx.mean() 12.64 -10.2574 5.6704
fgtx.max(), fgtx.min(), fgtx.mean() 3.32332 -2.99703 1.39877
delta mean, abs_mean, abs_mean+, abs_mean-: -0.905841 11.0486 7.61341 17.9017
W_c max, min, mean, abs_mean: 0.638062 -0.638527 -0.0642937 0.636108
W_f max, min, mean, abs_mean: 0.181612 -0.182066 -0.0171808 0.175597
Epoch 35/300
1s - loss: 1135.3257 - val_loss: 6014.9054
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 1120.8740 - val_loss: 5680.0521
Epoch 00035: val_loss improved from 5885.93117 to 5680.05211, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1119.7889      0.89  0.20  0.73      0.91  0.17  0.77      0.91  0.15  0.79
forget mean min: 0.84398 0.0
delta_x = 9.60161 delta_h = 0.516817
U_c = [[-0.00907175]] U_f = [[ 0.]] b_c = [ 0.62674719] b_f = [ 1.04522932]
incx.max(), incx.min(), incx.mean() 13.4651 -12.2545 4.70759
fgtx.max(), fgtx.min(), fgtx.mean() 3.57153 -3.58347 1.135
delta mean, abs_mean, abs_mean+, abs_mean-: 0.422995 9.60161 7.77987 12.9009
W_c max, min, mean, abs_mean: 0.667845 -0.668267 -0.0672332 0.665611
W_f max, min, mean, abs_mean: 0.191803 -0.192393 -0.0180705 0.185178
beijing_tanh+hardsigmoid3 5680.0521      0.89  0.09  0.82      0.90  0.06  0.85      0.92  0.04  0.88
forget mean min: 0.903104 0.0893177
delta_x = 11.4147 delta_h = 0.820496
U_c = [[-0.00907175]] U_f = [[ 0.]] b_c = [ 0.62674719] b_f = [ 1.04522932]
incx.max(), incx.min(), incx.mean() 13.1999 -10.5122 5.84357
fgtx.max(), fgtx.min(), fgtx.mean() 3.49771 -3.09864 1.45043
delta mean, abs_mean, abs_mean+, abs_mean-: -0.730686 11.4147 7.82745 19.1249
W_c max, min, mean, abs_mean: 0.667845 -0.668267 -0.0672332 0.665611
W_f max, min, mean, abs_mean: 0.191803 -0.192393 -0.0180705 0.185178
Epoch 37/300
1s - loss: 1107.6181 - val_loss: 5666.7037
Epoch 00036: val_loss improved from 5680.05211 to 5666.70370, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1044.0238      0.88  0.17  0.75      0.90  0.13  0.79      0.90  0.10  0.81
forget mean min: 0.846248 0.0
delta_x = 9.42853 delta_h = 0.613322
U_c = [[-0.01146284]] U_f = [[ 0.]] b_c = [ 0.63646519] b_f = [ 1.04099488]
incx.max(), incx.min(), incx.mean() 13.6874 -12.38 4.71222
fgtx.max(), fgtx.min(), fgtx.mean() 3.55905 -3.54963 1.11122
delta mean, abs_mean, abs_mean+, abs_mean-: 0.288442 9.42853 7.71377 12.3463
W_c max, min, mean, abs_mean: 0.678996 -0.679517 -0.0683571 0.676741
W_f max, min, mean, abs_mean: 0.191266 -0.191886 -0.0179966 0.18456
beijing_tanh+hardsigmoid3 5666.7037      0.89  0.08  0.83      0.90  0.05  0.85      0.91  0.04  0.88
forget mean min: 0.904553 0.103807
delta_x = 11.2121 delta_h = 0.947406
U_c = [[-0.01146284]] U_f = [[ 0.]] b_c = [ 0.63646519] b_f = [ 1.04099488]
incx.max(), incx.min(), incx.mean() 13.3959 -10.4455 5.83796
fgtx.max(), fgtx.min(), fgtx.mean() 3.47949 -3.02196 1.41761
delta mean, abs_mean, abs_mean+, abs_mean-: -0.943775 11.2121 7.78026 17.8708
W_c max, min, mean, abs_mean: 0.678996 -0.679517 -0.0683571 0.676741
W_f max, min, mean, abs_mean: 0.191266 -0.191886 -0.0179966 0.18456
Epoch 38/300
1s - loss: 1099.8316 - val_loss: 5465.3398
Epoch 00037: val_loss improved from 5666.70370 to 5465.33983, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1047.3132      0.89  0.18  0.74      0.91  0.15  0.79      0.91  0.12  0.81
forget mean min: 0.847646 0.0
delta_x = 9.61098 delta_h = 0.506928
U_c = [[-0.00916985]] U_f = [[ 0.]] b_c = [ 0.64870489] b_f = [ 1.0401926]
incx.max(), incx.min(), incx.mean() 13.9466 -12.5387 4.8334
fgtx.max(), fgtx.min(), fgtx.mean() 3.62846 -3.59828 1.14157
delta mean, abs_mean, abs_mean+, abs_mean-: 0.354486 9.61098 7.84967 12.6721
W_c max, min, mean, abs_mean: 0.691692 -0.69229 -0.0696295 0.689379
W_f max, min, mean, abs_mean: 0.195071 -0.195753 -0.0183306 0.188115
beijing_tanh+hardsigmoid3 5465.3399      0.90  0.08  0.83      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.90521 0.0958564
delta_x = 11.463 delta_h = 0.794094
U_c = [[-0.00916985]] U_f = [[ 0.]] b_c = [ 0.64870489] b_f = [ 1.0401926]
incx.max(), incx.min(), incx.mean() 13.6524 -10.5698 5.97141
fgtx.max(), fgtx.min(), fgtx.mean() 3.54813 -3.06091 1.45148
delta mean, abs_mean, abs_mean+, abs_mean-: -0.818915 11.463 7.95244 18.5659
W_c max, min, mean, abs_mean: 0.691692 -0.69229 -0.0696295 0.689379
W_f max, min, mean, abs_mean: 0.195071 -0.195753 -0.0183306 0.188115
Epoch 39/300
1s - loss: 1093.5341 - val_loss: 5308.5548
Epoch 00038: val_loss improved from 5465.33983 to 5308.55478, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1059.6627      0.90  0.19  0.74      0.92  0.16  0.78      0.92  0.13  0.81
forget mean min: 0.849537 0.0
delta_x = 9.75949 delta_h = 0.572141
U_c = [[-0.0101731]] U_f = [[ 0.]] b_c = [ 0.65659243] b_f = [ 1.04057014]
incx.max(), incx.min(), incx.mean() 14.1245 -12.6861 4.92711
fgtx.max(), fgtx.min(), fgtx.mean() 3.75116 -3.71626 1.18918
delta mean, abs_mean, abs_mean+, abs_mean-: 0.431965 9.75949 7.93937 13.0211
W_c max, min, mean, abs_mean: 0.700013 -0.700808 -0.07049 0.697765
W_f max, min, mean, abs_mean: 0.20143 -0.20214 -0.0189305 0.194357
beijing_tanh+hardsigmoid3 5308.5548      0.90  0.08  0.84      0.91  0.05  0.86      0.93  0.04  0.89
forget mean min: 0.909751 0.0752619
delta_x = 11.5977 delta_h = 0.898401
U_c = [[-0.0101731]] U_f = [[ 0.]] b_c = [ 0.65659243] b_f = [ 1.04057014]
incx.max(), incx.min(), incx.mean() 13.815 -10.7048 6.09339
fgtx.max(), fgtx.min(), fgtx.mean() 3.66491 -3.16426 1.51341
delta mean, abs_mean, abs_mean+, abs_mean-: -0.658548 11.5977 7.95535 19.6123
W_c max, min, mean, abs_mean: 0.700013 -0.700808 -0.07049 0.697765
W_f max, min, mean, abs_mean: 0.20143 -0.20214 -0.0189305 0.194357
Epoch 40/300
1s - loss: 1090.2694 - val_loss: 5265.6113
Epoch 00039: val_loss improved from 5308.55478 to 5265.61132, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1063.0005      0.90  0.19  0.74      0.91  0.15  0.78      0.91  0.13  0.80
forget mean min: 0.847043 0.0
delta_x = 9.67146 delta_h = 0.539389
U_c = [[-0.00955479]] U_f = [[ 0.]] b_c = [ 0.66288137] b_f = [ 1.03753746]
incx.max(), incx.min(), incx.mean() 14.2247 -12.6994 4.88757
fgtx.max(), fgtx.min(), fgtx.mean() 3.75204 -3.69678 1.16852
delta mean, abs_mean, abs_mean+, abs_mean-: 0.400912 9.67146 7.92975 12.7029
W_c max, min, mean, abs_mean: 0.706497 -0.707398 -0.0711478 0.704201
W_f max, min, mean, abs_mean: 0.202147 -0.202934 -0.0189605 0.194838
beijing_tanh+hardsigmoid3 5265.6114      0.90  0.08  0.84      0.91  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.903438 0.0737718
delta_x = 11.6168 delta_h = 0.867504
U_c = [[-0.00955479]] U_f = [[ 0.]] b_c = [ 0.66288137] b_f = [ 1.03753746]
incx.max(), incx.min(), incx.mean() 13.9059 -10.7911 6.03659
fgtx.max(), fgtx.min(), fgtx.mean() 3.66376 -3.16868 1.48577
delta mean, abs_mean, abs_mean+, abs_mean-: -0.675536 11.6168 8.04598 19.202
W_c max, min, mean, abs_mean: 0.706497 -0.707398 -0.0711478 0.704201
W_f max, min, mean, abs_mean: 0.202147 -0.202934 -0.0189605 0.194838
Epoch 41/300
1s - loss: 1083.7808 - val_loss: 5345.5637
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 1073.4637 - val_loss: 5329.3918
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 1069.7038 - val_loss: 5163.5158
Epoch 00042: val_loss improved from 5265.61132 to 5163.51583, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1008.4728      0.89  0.18  0.75      0.91  0.14  0.80      0.91  0.11  0.82
forget mean min: 0.851495 0.0
delta_x = 9.60645 delta_h = 0.752906
U_c = [[-0.01397287]] U_f = [[ 0.]] b_c = [ 0.68148488] b_f = [ 1.03186381]
incx.max(), incx.min(), incx.mean() 14.5749 -12.8184 4.98257
fgtx.max(), fgtx.min(), fgtx.mean() 3.91098 -3.80012 1.21043
delta mean, abs_mean, abs_mean+, abs_mean-: 0.379344 9.60645 7.92834 12.4608
W_c max, min, mean, abs_mean: 0.723531 -0.725083 -0.0729509 0.721406
W_f max, min, mean, abs_mean: 0.211011 -0.212077 -0.0197009 0.20309
beijing_tanh+hardsigmoid3 5163.5158      0.91  0.08  0.84      0.91  0.05  0.87      0.93  0.04  0.90
forget mean min: 0.904424 0.0523884
delta_x = 11.5236 delta_h = 1.20299
U_c = [[-0.01397287]] U_f = [[ 0.]] b_c = [ 0.68148488] b_f = [ 1.03186381]
incx.max(), incx.min(), incx.mean() 14.2014 -10.9357 6.03547
fgtx.max(), fgtx.min(), fgtx.mean() 3.80577 -3.26992 1.50615
delta mean, abs_mean, abs_mean+, abs_mean-: -0.717811 11.5236 7.98007 18.9523
W_c max, min, mean, abs_mean: 0.723531 -0.725083 -0.0729509 0.721406
W_f max, min, mean, abs_mean: 0.211011 -0.212077 -0.0197009 0.20309
Epoch 44/300
1s - loss: 1059.2530 - val_loss: 4946.6796
Epoch 00043: val_loss improved from 5163.51583 to 4946.67957, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3 1023.1375      0.89  0.18  0.75      0.91  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.851794 0.0
delta_x = 9.66406 delta_h = 0.638026
U_c = [[-0.01142797]] U_f = [[ 0.]] b_c = [ 0.68824446] b_f = [ 1.03002822]
incx.max(), incx.min(), incx.mean() 14.7137 -12.8486 5.01797
fgtx.max(), fgtx.min(), fgtx.mean() 3.97442 -3.83588 1.22661
delta mean, abs_mean, abs_mean+, abs_mean-: 0.400212 9.66406 7.9287 12.6789
W_c max, min, mean, abs_mean: 0.730614 -0.732249 -0.0736824 0.728366
W_f max, min, mean, abs_mean: 0.214598 -0.215776 -0.0199999 0.206414
beijing_tanh+hardsigmoid3 4946.6795      0.91  0.08  0.84      0.91  0.05  0.87      0.93  0.04  0.90
forget mean min: 0.906031 0.0371799
delta_x = 11.6975 delta_h = 1.04551
U_c = [[-0.01142797]] U_f = [[ 0.]] b_c = [ 0.68824446] b_f = [ 1.03002822]
incx.max(), incx.min(), incx.mean() 14.3497 -11.1141 6.13888
fgtx.max(), fgtx.min(), fgtx.mean() 3.87122 -3.34413 1.54355
delta mean, abs_mean, abs_mean+, abs_mean-: -0.590449 11.6975 8.04321 19.849
W_c max, min, mean, abs_mean: 0.730614 -0.732249 -0.0736824 0.728366
W_f max, min, mean, abs_mean: 0.214598 -0.215776 -0.0199999 0.206414
Epoch 45/300
1s - loss: 1051.5924 - val_loss: 5114.8155
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 1045.3986 - val_loss: 5092.5345
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 1040.0375 - val_loss: 5123.5401
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 1039.2453 - val_loss: 5268.4886
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 1037.4831 - val_loss: 4911.6801
Epoch 00048: val_loss improved from 4946.67957 to 4911.68005, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3  994.4012      0.90  0.17  0.76      0.92  0.14  0.80      0.92  0.12  0.82
forget mean min: 0.854676 0.0
delta_x = 9.65884 delta_h = 0.850243
U_c = [[-0.01536518]] U_f = [[ 0.]] b_c = [ 0.71598148] b_f = [ 1.02526367]
incx.max(), incx.min(), incx.mean() 15.2248 -12.8769 5.13673
fgtx.max(), fgtx.min(), fgtx.mean() 4.23468 -3.96731 1.28993
delta mean, abs_mean, abs_mean+, abs_mean-: 0.464477 9.65884 8.0158 12.474
W_c max, min, mean, abs_mean: 0.758823 -0.760501 -0.0765847 0.755404
W_f max, min, mean, abs_mean: 0.230167 -0.232251 -0.0211281 0.220498
beijing_tanh+hardsigmoid3 4911.6800      0.91  0.08  0.85      0.92  0.05  0.87      0.94  0.04  0.90
forget mean min: 0.903034 0.000156586
delta_x = 11.7466 delta_h = 1.40699
U_c = [[-0.01536518]] U_f = [[ 0.]] b_c = [ 0.71598148] b_f = [ 1.02526367]
incx.max(), incx.min(), incx.mean() 14.7773 -11.3613 6.13793
fgtx.max(), fgtx.min(), fgtx.mean() 4.10405 -3.52448 1.58136
delta mean, abs_mean, abs_mean+, abs_mean-: -0.50007 11.7466 8.20714 19.4493
W_c max, min, mean, abs_mean: 0.758823 -0.760501 -0.0765847 0.755404
W_f max, min, mean, abs_mean: 0.230167 -0.232251 -0.0211281 0.220498
Epoch 50/300
1s - loss: 1031.7119 - val_loss: 5006.7719
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 1029.6428 - val_loss: 4988.0380
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 1019.0020 - val_loss: 5414.2371
Epoch 00051: val_loss did not improve
Epoch 53/300
1s - loss: 1016.0490 - val_loss: 4829.1968
Epoch 00052: val_loss improved from 4911.68005 to 4829.19676, saving model to beijing_tanh+hardsigmoid3_weights.hdf5
beijing_tanh+hardsigmoid3  968.5221      0.89  0.16  0.76      0.92  0.12  0.81      0.92  0.10  0.83
forget mean min: 0.857604 0.0
delta_x = 9.56246 delta_h = 0.836902
U_c = [[-0.01539795]] U_f = [[ 0.]] b_c = [ 0.73995489] b_f = [ 1.01567221]
incx.max(), incx.min(), incx.mean() 15.6574 -13.0328 5.19909
fgtx.max(), fgtx.min(), fgtx.mean() 4.33459 -4.002 1.29542
delta mean, abs_mean, abs_mean+, abs_mean-: 0.423248 9.56246 7.95517 12.2715
W_c max, min, mean, abs_mean: 0.782927 -0.784481 -0.0791044 0.778293
W_f max, min, mean, abs_mean: 0.237631 -0.240552 -0.0213952 0.22617
beijing_tanh+hardsigmoid3 4829.1967      0.91  0.08  0.84      0.92  0.05  0.87      0.94  0.04  0.90
forget mean min: 0.903281 0.0
delta_x = 11.6937 delta_h = 1.36943
U_c = [[-0.01539795]] U_f = [[ 0.]] b_c = [ 0.73995489] b_f = [ 1.01567221]
incx.max(), incx.min(), incx.mean() 15.1444 -11.6875 6.16929
fgtx.max(), fgtx.min(), fgtx.mean() 4.18558 -3.61054 1.57643
delta mean, abs_mean, abs_mean+, abs_mean-: -0.60506 11.6937 8.31871 18.4382
W_c max, min, mean, abs_mean: 0.782927 -0.784481 -0.0791044 0.778293
W_f max, min, mean, abs_mean: 0.237631 -0.240552 -0.0213952 0.22617
Epoch 54/300
1s - loss: 1015.2248 - val_loss: 5070.4230
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 1009.3878 - val_loss: 4863.9103
Epoch 00054: val_loss did not improve
Epoch 56/300
1s - loss: 999.4421 - val_loss: 4950.3060
Epoch 00055: val_loss did not improve
Epoch 57/300
1s - loss: 997.7554 - val_loss: 5023.8405
Epoch 00056: val_loss did not improve
Epoch 58/300
1s - loss: 995.1465 - val_loss: 5247.3045
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 985.0468 - val_loss: 5285.3065
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 981.1648 - val_loss: 5286.2606
Epoch 00059: val_loss did not improve
Epoch 61/300
1s - loss: 973.6121 - val_loss: 5153.5833
Epoch 00060: val_loss did not improve
Epoch 62/300
1s - loss: 973.8763 - val_loss: 5101.3324
Epoch 00061: val_loss did not improve
Epoch 63/300
1s - loss: 965.4594 - val_loss: 5304.7819
Epoch 00062: val_loss did not improve
Epoch 64/300
1s - loss: 964.5559 - val_loss: 5185.4688
Epoch 00063: val_loss did not improve
Epoch 65/300
1s - loss: 958.9361 - val_loss: 4966.6942
Epoch 00064: val_loss did not improve
Epoch 66/300
1s - loss: 958.8150 - val_loss: 4839.4670
Epoch 00065: val_loss did not improve
Epoch 67/300
1s - loss: 950.9154 - val_loss: 4922.9123
Epoch 00066: val_loss did not improve
Epoch 68/300
1s - loss: 950.0990 - val_loss: 5115.9666
Epoch 00067: val_loss did not improve
Epoch 69/300
1s - loss: 937.4530 - val_loss: 5605.3385
Epoch 00068: val_loss did not improve
Epoch 70/300
1s - loss: 935.6374 - val_loss: 6206.8684
Epoch 00069: val_loss did not improve
Epoch 71/300
1s - loss: 933.1827 - val_loss: 5681.6316
Epoch 00070: val_loss did not improve
Epoch 72/300
1s - loss: 930.3739 - val_loss: 5481.6347
Epoch 00071: val_loss did not improve
Epoch 73/300
1s - loss: 921.9692 - val_loss: 5278.2007
Epoch 00072: val_loss did not improve
Epoch 74/300
1s - loss: 918.8714 - val_loss: 6009.2924
Epoch 00073: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid4
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid4 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid429822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5844.0558 - val_loss: 9712.6479
Epoch 00000: val_loss improved from inf to 9712.64793, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 3305.5129      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.81195 0.31859
delta_x = 4.4125 delta_h = 2.21597
U_c = [[-0.06177084]] U_f = [[ 0.]] b_c = [ 0.12272125] b_f = [ 1.09403574]
incx.max(), incx.min(), incx.mean() 2.92973 -2.76625 1.10246
fgtx.max(), fgtx.min(), fgtx.mean() 1.94431 -2.00109 0.678631
delta mean, abs_mean, abs_mean+, abs_mean-: -1.24223 4.4125 2.57442 7.35765
W_c max, min, mean, abs_mean: 0.149045 -0.149003 -0.0441524 0.148214
W_f max, min, mean, abs_mean: 0.103187 -0.103331 -0.0306859 0.102662
beijing_tanh+hardsigmoid4 9712.6480      0.79  0.09  0.73      0.79  0.05  0.75      0.80  0.03  0.78
forget mean min: 0.844465 0.319288
delta_x = 6.54871 delta_h = 4.09842
U_c = [[-0.06177084]] U_f = [[ 0.]] b_c = [ 0.12272125] b_f = [ 1.09403574]
incx.max(), incx.min(), incx.mean() 2.92606 -2.76122 1.34497
fgtx.max(), fgtx.min(), fgtx.mean() 1.94177 -1.9976 0.846608
delta mean, abs_mean, abs_mean+, abs_mean-: -3.33854 6.54871 2.62872 12.6954
W_c max, min, mean, abs_mean: 0.149045 -0.149003 -0.0441524 0.148214
W_f max, min, mean, abs_mean: 0.103187 -0.103331 -0.0306859 0.102662
Epoch 2/300
1s - loss: 2439.1722 - val_loss: 10544.8977
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1849.3482 - val_loss: 9771.0996
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1716.2124 - val_loss: 8749.2036
Epoch 00003: val_loss improved from 9712.64793 to 8749.20355, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1670.6029      0.88  0.25  0.68      0.88  0.23  0.70      0.89  0.20  0.72
forget mean min: 0.854836 0.379378
delta_x = 7.62684 delta_h = 0.814694
U_c = [[-0.01505067]] U_f = [[ 0.]] b_c = [ 0.30249313] b_f = [ 1.10794139]
incx.max(), incx.min(), incx.mean() 6.85259 -6.25915 3.34218
fgtx.max(), fgtx.min(), fgtx.mean() 1.70804 -1.71105 0.792645
delta mean, abs_mean, abs_mean+, abs_mean-: 0.428324 7.62684 5.88127 11.4195
W_c max, min, mean, abs_mean: 0.329239 -0.329203 -0.0982121 0.328399
W_f max, min, mean, abs_mean: 0.0861791 -0.0863321 -0.0255848 0.0856352
beijing_tanh+hardsigmoid4 8749.2036      0.83  0.15  0.73      0.84  0.12  0.75      0.87  0.09  0.80
forget mean min: 0.912888 0.379955
delta_x = 9.95902 delta_h = 1.33828
U_c = [[-0.01505067]] U_f = [[ 0.]] b_c = [ 0.30249313] b_f = [ 1.10794139]
incx.max(), incx.min(), incx.mean() 6.8492 -6.24809 4.53097
fgtx.max(), fgtx.min(), fgtx.mean() 1.70716 -1.70817 1.10264
delta mean, abs_mean, abs_mean+, abs_mean-: -0.647726 9.95902 6.04089 23.1275
W_c max, min, mean, abs_mean: 0.329239 -0.329203 -0.0982121 0.328399
W_f max, min, mean, abs_mean: 0.0861791 -0.0863321 -0.0255848 0.0856352
Epoch 5/300
1s - loss: 1658.4164 - val_loss: 8163.7946
Epoch 00004: val_loss improved from 8749.20355 to 8163.79462, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1612.4048      0.88  0.24  0.69      0.88  0.22  0.71      0.88  0.18  0.73
forget mean min: 0.852061 0.347949
delta_x = 7.9179 delta_h = 0.931129
U_c = [[-0.01756759]] U_f = [[ 0.]] b_c = [ 0.3113032] b_f = [ 1.100456]
incx.max(), incx.min(), incx.mean() 7.05452 -6.44675 3.39998
fgtx.max(), fgtx.min(), fgtx.mean() 1.85663 -1.86071 0.850412
delta mean, abs_mean, abs_mean+, abs_mean-: 0.363512 7.9179 6.03158 12.0486
W_c max, min, mean, abs_mean: 0.339057 -0.339019 -0.101157 0.338215
W_f max, min, mean, abs_mean: 0.0936753 -0.0938279 -0.0278288 0.0931216
beijing_tanh+hardsigmoid4 8163.7947      0.84  0.15  0.73      0.84  0.12  0.76      0.87  0.09  0.80
forget mean min: 0.911592 0.34857
delta_x = 10.1276 delta_h = 1.51993
U_c = [[-0.01756759]] U_f = [[ 0.]] b_c = [ 0.3113032] b_f = [ 1.100456]
incx.max(), incx.min(), incx.mean() 7.05053 -6.43548 4.5778
fgtx.max(), fgtx.min(), fgtx.mean() 1.85553 -1.85761 1.1747
delta mean, abs_mean, abs_mean+, abs_mean-: -0.650116 10.1276 6.15098 23.4708
W_c max, min, mean, abs_mean: 0.339057 -0.339019 -0.101157 0.338215
W_f max, min, mean, abs_mean: 0.0936753 -0.0938279 -0.0278288 0.0931216
Epoch 6/300
1s - loss: 1636.7456 - val_loss: 7776.6972
Epoch 00005: val_loss improved from 8163.79462 to 7776.69724, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1595.3143      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.84865 0.322553
delta_x = 8.13255 delta_h = 1.02905
U_c = [[-0.01924285]] U_f = [[ 0.]] b_c = [ 0.31938997] b_f = [ 1.09535325]
incx.max(), incx.min(), incx.mean() 7.23731 -6.61178 3.44939
fgtx.max(), fgtx.min(), fgtx.mean() 1.9788 -1.98259 0.895305
delta mean, abs_mean, abs_mean+, abs_mean-: 0.407815 8.13255 6.17484 12.5217
W_c max, min, mean, abs_mean: 0.347742 -0.347702 -0.103763 0.346898
W_f max, min, mean, abs_mean: 0.0997893 -0.0999413 -0.029659 0.0992267
beijing_tanh+hardsigmoid4 7776.6973      0.85  0.14  0.74      0.85  0.11  0.77      0.88  0.09  0.81
forget mean min: 0.90849 0.323211
delta_x = 10.3542 delta_h = 1.66866
U_c = [[-0.01924285]] U_f = [[ 0.]] b_c = [ 0.31938997] b_f = [ 1.09535325]
incx.max(), incx.min(), incx.mean() 7.2246 -6.60026 4.60922
fgtx.max(), fgtx.min(), fgtx.mean() 1.97516 -1.9793 1.22706
delta mean, abs_mean, abs_mean+, abs_mean-: -0.620888 10.3542 6.2694 24.5262
W_c max, min, mean, abs_mean: 0.347742 -0.347702 -0.103763 0.346898
W_f max, min, mean, abs_mean: 0.0997893 -0.0999413 -0.029659 0.0992267
Epoch 7/300
1s - loss: 1621.5698 - val_loss: 7432.2047
Epoch 00006: val_loss improved from 7776.69724 to 7432.20469, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1580.8321      0.88  0.24  0.69      0.89  0.21  0.71      0.89  0.18  0.74
forget mean min: 0.845972 0.301279
delta_x = 8.1979 delta_h = 0.965347
U_c = [[-0.01788767]] U_f = [[ 0.]] b_c = [ 0.3250477] b_f = [ 1.08749068]
incx.max(), incx.min(), incx.mean() 7.36397 -6.72981 3.46371
fgtx.max(), fgtx.min(), fgtx.mean() 2.07639 -2.08109 0.925864
delta mean, abs_mean, abs_mean+, abs_mean-: 0.404608 8.1979 6.23506 12.5638
W_c max, min, mean, abs_mean: 0.353989 -0.353947 -0.105637 0.353144
W_f max, min, mean, abs_mean: 0.104745 -0.104898 -0.031141 0.104173
beijing_tanh+hardsigmoid4 7432.2046      0.85  0.13  0.75      0.85  0.11  0.77      0.88  0.08  0.82
forget mean min: 0.906689 0.302036
delta_x = 10.4609 delta_h = 1.56376
U_c = [[-0.01788767]] U_f = [[ 0.]] b_c = [ 0.3250477] b_f = [ 1.08749068]
incx.max(), incx.min(), incx.mean() 7.34043 -6.71699 4.60354
fgtx.max(), fgtx.min(), fgtx.mean() 2.06945 -2.07731 1.2621
delta mean, abs_mean, abs_mean+, abs_mean-: -0.673996 10.4609 6.29399 25.0198
W_c max, min, mean, abs_mean: 0.353989 -0.353947 -0.105637 0.353144
W_f max, min, mean, abs_mean: 0.104745 -0.104898 -0.031141 0.104173
Epoch 8/300
1s - loss: 1608.7860 - val_loss: 7086.9161
Epoch 00007: val_loss improved from 7432.20469 to 7086.91609, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1569.1540      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.845493 0.281121
delta_x = 8.17404 delta_h = 1.07194
U_c = [[-0.02031055]] U_f = [[ 0.]] b_c = [ 0.32850984] b_f = [ 1.08423662]
incx.max(), incx.min(), incx.mean() 7.43446 -6.7984 3.4667
fgtx.max(), fgtx.min(), fgtx.mean() 2.17223 -2.17863 0.959314
delta mean, abs_mean, abs_mean+, abs_mean-: 0.384856 8.17404 6.20502 12.5501
W_c max, min, mean, abs_mean: 0.3577 -0.357657 -0.10675 0.356853
W_f max, min, mean, abs_mean: 0.10967 -0.109819 -0.0326136 0.109087
beijing_tanh+hardsigmoid4 7086.9161      0.85  0.13  0.75      0.86  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.907718 0.282214
delta_x = 10.2719 delta_h = 1.71453
U_c = [[-0.02031055]] U_f = [[ 0.]] b_c = [ 0.32850984] b_f = [ 1.08423662]
incx.max(), incx.min(), incx.mean() 7.40057 -6.78052 4.5645
fgtx.max(), fgtx.min(), fgtx.mean() 2.16187 -2.17317 1.2949
delta mean, abs_mean, abs_mean+, abs_mean-: -0.713612 10.2719 6.17008 24.3656
W_c max, min, mean, abs_mean: 0.3577 -0.357657 -0.10675 0.356853
W_f max, min, mean, abs_mean: 0.10967 -0.109819 -0.0326136 0.109087
Epoch 9/300
1s - loss: 1603.0790 - val_loss: 7056.1054
Epoch 00008: val_loss improved from 7086.91609 to 7056.10539, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1560.7874      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.845279 0.274828
delta_x = 8.11973 delta_h = 1.02501
U_c = [[-0.01931394]] U_f = [[ 0.]] b_c = [ 0.33322504] b_f = [ 1.08334911]
incx.max(), incx.min(), incx.mean() 7.53023 -6.89307 3.47361
fgtx.max(), fgtx.min(), fgtx.mean() 2.20025 -2.20921 0.960071
delta mean, abs_mean, abs_mean+, abs_mean-: 0.407749 8.11973 6.19526 12.3679
W_c max, min, mean, abs_mean: 0.362827 -0.362783 -0.108288 0.361979
W_f max, min, mean, abs_mean: 0.111247 -0.1114 -0.0330861 0.110663
beijing_tanh+hardsigmoid4 7056.1055      0.85  0.13  0.76      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.906197 0.276175
delta_x = 10.2274 delta_h = 1.64601
U_c = [[-0.01931394]] U_f = [[ 0.]] b_c = [ 0.33322504] b_f = [ 1.08334911]
incx.max(), incx.min(), incx.mean() 7.49604 -6.87105 4.52593
fgtx.max(), fgtx.min(), fgtx.mean() 2.1898 -2.20247 1.28178
delta mean, abs_mean, abs_mean+, abs_mean-: -0.756479 10.2274 6.16022 23.7452
W_c max, min, mean, abs_mean: 0.362827 -0.362783 -0.108288 0.361979
W_f max, min, mean, abs_mean: 0.111247 -0.1114 -0.0330861 0.110663
Epoch 10/300
1s - loss: 1600.2420 - val_loss: 7198.1408
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1585.3838 - val_loss: 7000.1207
Epoch 00010: val_loss improved from 7056.10539 to 7000.12068, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1545.8941      0.88  0.23  0.70      0.89  0.20  0.72      0.89  0.17  0.75
forget mean min: 0.84552 0.262668
delta_x = 8.07597 delta_h = 0.866717
U_c = [[-0.01628915]] U_f = [[ 0.]] b_c = [ 0.34539494] b_f = [ 1.08419061]
incx.max(), incx.min(), incx.mean() 7.77236 -7.12471 3.49869
fgtx.max(), fgtx.min(), fgtx.mean() 2.25774 -2.27085 0.958575
delta mean, abs_mean, abs_mean+, abs_mean-: 0.378656 8.07597 6.22975 11.9735
W_c max, min, mean, abs_mean: 0.375324 -0.375276 -0.112037 0.374472
W_f max, min, mean, abs_mean: 0.114419 -0.114579 -0.0340364 0.113836
beijing_tanh+hardsigmoid4 7000.1207      0.85  0.12  0.76      0.85  0.09  0.78      0.88  0.07  0.83
forget mean min: 0.908726 0.26476
delta_x = 10.0861 delta_h = 1.40217
U_c = [[-0.01628915]] U_f = [[ 0.]] b_c = [ 0.34539494] b_f = [ 1.08419061]
incx.max(), incx.min(), incx.mean() 7.74348 -7.0903 4.56019
fgtx.max(), fgtx.min(), fgtx.mean() 2.24896 -2.26039 1.28126
delta mean, abs_mean, abs_mean+, abs_mean-: -0.792103 10.0861 6.14642 22.2963
W_c max, min, mean, abs_mean: 0.375324 -0.375276 -0.112037 0.374472
W_f max, min, mean, abs_mean: 0.114419 -0.114579 -0.0340364 0.113836
Epoch 12/300
1s - loss: 1582.6461 - val_loss: 6964.9425
Epoch 00011: val_loss improved from 7000.12068 to 6964.94253, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1578.7186      0.90  0.25  0.69      0.91  0.23  0.71      0.91  0.20  0.74
forget mean min: 0.846179 0.249216
delta_x = 8.33568 delta_h = 0.6487
U_c = [[-0.01162644]] U_f = [[ 0.]] b_c = [ 0.35746938] b_f = [ 1.0876348]
incx.max(), incx.min(), incx.mean() 8.03531 -7.36104 3.64359
fgtx.max(), fgtx.min(), fgtx.mean() 2.32922 -2.34155 0.996906
delta mean, abs_mean, abs_mean+, abs_mean-: 0.487587 8.33568 6.41069 12.5839
W_c max, min, mean, abs_mean: 0.387732 -0.38768 -0.115759 0.386878
W_f max, min, mean, abs_mean: 0.117949 -0.11811 -0.0350949 0.117367
beijing_tanh+hardsigmoid4 6964.9425      0.85  0.12  0.77      0.86  0.09  0.79      0.89  0.06  0.83
forget mean min: 0.908297 0.251366
delta_x = 10.3669 delta_h = 1.03686
U_c = [[-0.01162644]] U_f = [[ 0.]] b_c = [ 0.35746938] b_f = [ 1.0876348]
incx.max(), incx.min(), incx.mean() 8.01009 -7.3256 4.68214
fgtx.max(), fgtx.min(), fgtx.mean() 2.32157 -2.3308 1.31197
delta mean, abs_mean, abs_mean+, abs_mean-: -0.762915 10.3669 6.29576 23.4542
W_c max, min, mean, abs_mean: 0.387732 -0.38768 -0.115759 0.386878
W_f max, min, mean, abs_mean: 0.117949 -0.11811 -0.0350949 0.117367
Epoch 13/300
1s - loss: 1571.7344 - val_loss: 7120.9245
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1562.1696 - val_loss: 7247.2377
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1557.2510 - val_loss: 7254.0032
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1545.1357 - val_loss: 7061.2234
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1544.5789 - val_loss: 7161.1918
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1543.5423 - val_loss: 7284.7444
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1532.9238 - val_loss: 7224.7650
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1521.6372 - val_loss: 7175.9734
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1501.9338 - val_loss: 6991.5062
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1488.8209 - val_loss: 7047.9823
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1470.4873 - val_loss: 6789.0920
Epoch 00022: val_loss improved from 6964.94253 to 6789.09204, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1404.3717      0.87  0.21  0.71      0.88  0.18  0.74      0.89  0.15  0.77
forget mean min: 0.854396 0.185701
delta_x = 8.6098 delta_h = 0.413364
U_c = [[-0.00794105]] U_f = [[ 0.]] b_c = [ 0.41919816] b_f = [ 1.09692943]
incx.max(), incx.min(), incx.mean() 9.09953 -8.33544 3.92275
fgtx.max(), fgtx.min(), fgtx.mean() 2.64577 -2.66842 1.06789
delta mean, abs_mean, abs_mean+, abs_mean-: 0.245724 8.6098 6.53463 12.971
W_c max, min, mean, abs_mean: 0.44222 -0.442048 -0.13209 0.441287
W_f max, min, mean, abs_mean: 0.135992 -0.13544 -0.0400841 0.134505
beijing_tanh+hardsigmoid4 6789.0920      0.84  0.11  0.76      0.84  0.08  0.78      0.86  0.06  0.82
forget mean min: 0.918878 0.201072
delta_x = 10.1953 delta_h = 0.677634
U_c = [[-0.00794105]] U_f = [[ 0.]] b_c = [ 0.41919816] b_f = [ 1.09692943]
incx.max(), incx.min(), incx.mean() 9.03822 -8.08331 4.94849
fgtx.max(), fgtx.min(), fgtx.mean() 2.62709 -2.59157 1.38052
delta mean, abs_mean, abs_mean+, abs_mean-: -1.02099 10.1953 6.32743 20.3906
W_c max, min, mean, abs_mean: 0.44222 -0.442048 -0.13209 0.441287
W_f max, min, mean, abs_mean: 0.135992 -0.13544 -0.0400841 0.134505
Epoch 24/300
1s - loss: 1453.2322 - val_loss: 6933.3149
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1427.9538 - val_loss: 6964.4890
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1404.7343 - val_loss: 6831.8738
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1375.5057 - val_loss: 6435.2641
Epoch 00026: val_loss improved from 6789.09204 to 6435.26405, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1305.2155      0.88  0.21  0.72      0.89  0.17  0.75      0.91  0.15  0.78
forget mean min: 0.85453 0.119333
delta_x = 8.85699 delta_h = 0.300902
U_c = [[-0.00566]] U_f = [[ 0.]] b_c = [ 0.47257337] b_f = [ 1.07475853]
incx.max(), incx.min(), incx.mean() 10.0249 -9.17063 4.14846
fgtx.max(), fgtx.min(), fgtx.mean() 2.95003 -2.97809 1.13521
delta mean, abs_mean, abs_mean+, abs_mean-: 0.270596 8.85699 6.75591 13.2313
W_c max, min, mean, abs_mean: 0.489256 -0.489104 -0.146155 0.488146
W_f max, min, mean, abs_mean: 0.153866 -0.152219 -0.0447016 0.150754
beijing_tanh+hardsigmoid4 6435.2640      0.85  0.10  0.78      0.85  0.07  0.80      0.87  0.05  0.83
forget mean min: 0.919049 0.156172
delta_x = 10.6203 delta_h = 0.499689
U_c = [[-0.00566]] U_f = [[ 0.]] b_c = [ 0.47257337] b_f = [ 1.07475853]
incx.max(), incx.min(), incx.mean() 9.94115 -8.57429 5.24541
fgtx.max(), fgtx.min(), fgtx.mean() 2.92416 -2.7939 1.47392
delta mean, abs_mean, abs_mean+, abs_mean-: -0.931236 10.6203 6.73672 20.5637
W_c max, min, mean, abs_mean: 0.489256 -0.489104 -0.146155 0.488146
W_f max, min, mean, abs_mean: 0.153866 -0.152219 -0.0447016 0.150754
Epoch 28/300
1s - loss: 1351.2104 - val_loss: 6578.1272
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1312.9148 - val_loss: 6488.8785
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1272.5077 - val_loss: 6346.9005
Epoch 00029: val_loss improved from 6435.26405 to 6346.90053, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1215.6442      0.88  0.20  0.72      0.90  0.17  0.76      0.91  0.14  0.79
forget mean min: 0.849594 0.0833393
delta_x = 9.05744 delta_h = 0.191775
U_c = [[-0.00347586]] U_f = [[ 0.]] b_c = [ 0.53218216] b_f = [ 1.05008221]
incx.max(), incx.min(), incx.mean() 11.2114 -10.2357 4.34766
fgtx.max(), fgtx.min(), fgtx.mean() 3.10758 -3.13339 1.11024
delta mean, abs_mean, abs_mean+, abs_mean-: 0.304112 9.05744 7.1026 12.8357
W_c max, min, mean, abs_mean: 0.549011 -0.549081 -0.164005 0.547815
W_f max, min, mean, abs_mean: 0.16393 -0.161523 -0.0470918 0.159412
beijing_tanh+hardsigmoid4 6346.9005      0.86  0.09  0.79      0.86  0.06  0.82      0.88  0.04  0.85
forget mean min: 0.90914 0.159076
delta_x = 11.0718 delta_h = 0.318914
U_c = [[-0.00347586]] U_f = [[ 0.]] b_c = [ 0.53218216] b_f = [ 1.05008221]
incx.max(), incx.min(), incx.mean() 11.0901 -8.93472 5.49019
fgtx.max(), fgtx.min(), fgtx.mean() 3.07227 -2.7547 1.44256
delta mean, abs_mean, abs_mean+, abs_mean-: -0.912892 11.0718 7.24054 20.0766
W_c max, min, mean, abs_mean: 0.549011 -0.549081 -0.164005 0.547815
W_f max, min, mean, abs_mean: 0.16393 -0.161523 -0.0470918 0.159412
Epoch 31/300
1s - loss: 1229.6401 - val_loss: 6093.7131
Epoch 00030: val_loss improved from 6346.90053 to 6093.71306, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1147.4655      0.88  0.19  0.73      0.90  0.16  0.77      0.91  0.13  0.80
forget mean min: 0.848929 0.0767122
delta_x = 9.07447 delta_h = 0.360915
U_c = [[-0.00675058]] U_f = [[ 0.]] b_c = [ 0.55295438] b_f = [ 1.04040825]
incx.max(), incx.min(), incx.mean() 11.6497 -10.6295 4.42722
fgtx.max(), fgtx.min(), fgtx.mean() 3.13264 -3.15685 1.09366
delta mean, abs_mean, abs_mean+, abs_mean-: 0.279541 9.07447 7.236 12.4346
W_c max, min, mean, abs_mean: 0.570999 -0.57117 -0.170579 0.569785
W_f max, min, mean, abs_mean: 0.165871 -0.163219 -0.0474543 0.160855
beijing_tanh+hardsigmoid4 6093.7131      0.86  0.07  0.81      0.86  0.05  0.83      0.88  0.04  0.85
forget mean min: 0.905583 0.166555
delta_x = 10.8933 delta_h = 0.57559
U_c = [[-0.00675058]] U_f = [[ 0.]] b_c = [ 0.55295438] b_f = [ 1.04040825]
incx.max(), incx.min(), incx.mean() 11.5048 -9.03873 5.52968
fgtx.max(), fgtx.min(), fgtx.mean() 3.09172 -2.70764 1.4047
delta mean, abs_mean, abs_mean+, abs_mean-: -1.02481 10.8933 7.39378 17.9138
W_c max, min, mean, abs_mean: 0.570999 -0.57117 -0.170579 0.569785
W_f max, min, mean, abs_mean: 0.165871 -0.163219 -0.0474543 0.160855
Epoch 32/300
1s - loss: 1198.0309 - val_loss: 6194.1286
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1163.9261 - val_loss: 5642.0398
Epoch 00032: val_loss improved from 6093.71306 to 5642.03983, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1102.1997      0.89  0.18  0.74      0.90  0.15  0.78      0.91  0.12  0.81
forget mean min: 0.849585 0.0541702
delta_x = 9.33777 delta_h = 0.378159
U_c = [[-0.00698203]] U_f = [[ 0.]] b_c = [ 0.59203005] b_f = [ 1.02473402]
incx.max(), incx.min(), incx.mean() 12.4982 -11.3824 4.65681
fgtx.max(), fgtx.min(), fgtx.mean() 3.23532 -3.25388 1.10445
delta mean, abs_mean, abs_mean+, abs_mean-: 0.294635 9.33777 7.52562 12.559
W_c max, min, mean, abs_mean: 0.612675 -0.613032 -0.183047 0.611414
W_f max, min, mean, abs_mean: 0.172 -0.168913 -0.0489296 0.166146
beijing_tanh+hardsigmoid4 5642.0398      0.88  0.07  0.82      0.89  0.05  0.85      0.90  0.04  0.87
forget mean min: 0.909177 0.162125
delta_x = 11.2234 delta_h = 0.588209
U_c = [[-0.00698203]] U_f = [[ 0.]] b_c = [ 0.59203005] b_f = [ 1.02473402]
incx.max(), incx.min(), incx.mean() 12.3273 -9.39667 5.90793
fgtx.max(), fgtx.min(), fgtx.mean() 3.18885 -2.71411 1.44415
delta mean, abs_mean, abs_mean+, abs_mean-: -0.927451 11.2234 7.71696 18.2498
W_c max, min, mean, abs_mean: 0.612675 -0.613032 -0.183047 0.611414
W_f max, min, mean, abs_mean: 0.172 -0.168913 -0.0489296 0.166146
Epoch 34/300
1s - loss: 1147.4230 - val_loss: 5830.6361
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1126.3912 - val_loss: 5616.1220
Epoch 00034: val_loss improved from 5642.03983 to 5616.12199, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1060.6035      0.88  0.17  0.75      0.90  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.846811 0.0295541
delta_x = 9.45901 delta_h = 0.380463
U_c = [[-0.00694336]] U_f = [[ 0.]] b_c = [ 0.6232484] b_f = [ 1.01251423]
incx.max(), incx.min(), incx.mean() 13.1724 -11.9332 4.78225
fgtx.max(), fgtx.min(), fgtx.mean() 3.36275 -3.36474 1.11433
delta mean, abs_mean, abs_mean+, abs_mean-: 0.301308 9.45901 7.73713 12.4002
W_c max, min, mean, abs_mean: 0.646977 -0.647497 -0.193311 0.645634
W_f max, min, mean, abs_mean: 0.179852 -0.176324 -0.0508515 0.173014
beijing_tanh+hardsigmoid4 5616.1219      0.88  0.07  0.82      0.88  0.05  0.84      0.90  0.04  0.87
forget mean min: 0.90452 0.143198
delta_x = 11.4884 delta_h = 0.574765
U_c = [[-0.00694336]] U_f = [[ 0.]] b_c = [ 0.6232484] b_f = [ 1.01251423]
incx.max(), incx.min(), incx.mean() 12.9772 -9.81356 6.01303
fgtx.max(), fgtx.min(), fgtx.mean() 3.31043 -2.79652 1.44378
delta mean, abs_mean, abs_mean+, abs_mean-: -0.980004 11.4884 7.87473 18.7339
W_c max, min, mean, abs_mean: 0.646977 -0.647497 -0.193311 0.645634
W_f max, min, mean, abs_mean: 0.179852 -0.176324 -0.0508515 0.173014
Epoch 36/300
1s - loss: 1116.4691 - val_loss: 5414.5045
Epoch 00035: val_loss improved from 5616.12199 to 5414.50454, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1063.4912      0.89  0.18  0.75      0.91  0.14  0.79      0.91  0.12  0.81
forget mean min: 0.844529 0.0241757
delta_x = 9.53683 delta_h = 0.403309
U_c = [[-0.00721394]] U_f = [[ 0.]] b_c = [ 0.63822448] b_f = [ 1.0064292]
incx.max(), incx.min(), incx.mean() 13.4797 -12.1878 4.84025
fgtx.max(), fgtx.min(), fgtx.mean() 3.3896 -3.38555 1.10899
delta mean, abs_mean, abs_mean+, abs_mean-: 0.341838 9.53683 7.86664 12.355
W_c max, min, mean, abs_mean: 0.662905 -0.663455 -0.198079 0.661472
W_f max, min, mean, abs_mean: 0.18194 -0.178198 -0.051261 0.174606
beijing_tanh+hardsigmoid4 5414.5046      0.89  0.07  0.83      0.89  0.05  0.85      0.91  0.04  0.88
forget mean min: 0.902437 0.136053
delta_x = 11.6546 delta_h = 0.613367
U_c = [[-0.00721394]] U_f = [[ 0.]] b_c = [ 0.63822448] b_f = [ 1.0064292]
incx.max(), incx.min(), incx.mean() 13.2853 -10.0694 6.1191
fgtx.max(), fgtx.min(), fgtx.mean() 3.33826 -2.82616 1.44614
delta mean, abs_mean, abs_mean+, abs_mean-: -0.897584 11.6546 8.02752 19.0188
W_c max, min, mean, abs_mean: 0.662905 -0.663455 -0.198079 0.661472
W_f max, min, mean, abs_mean: 0.18194 -0.178198 -0.051261 0.174606
Epoch 37/300
1s - loss: 1105.9403 - val_loss: 5936.9221
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 1093.0406 - val_loss: 5811.2567
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 1093.2118 - val_loss: 5260.4748
Epoch 00038: val_loss improved from 5414.50454 to 5260.47480, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1058.0562      0.90  0.19  0.74      0.92  0.15  0.79      0.91  0.12  0.81
forget mean min: 0.843824 0.000920002
delta_x = 9.67535 delta_h = 0.662395
U_c = [[-0.01187745]] U_f = [[ 0.]] b_c = [ 0.66851223] b_f = [ 0.99476045]
incx.max(), incx.min(), incx.mean() 14.0586 -12.4891 4.99932
fgtx.max(), fgtx.min(), fgtx.mean() 3.55177 -3.49016 1.14852
delta mean, abs_mean, abs_mean+, abs_mean-: 0.438343 9.67535 8.0998 12.2936
W_c max, min, mean, abs_mean: 0.692164 -0.6928 -0.206826 0.690468
W_f max, min, mean, abs_mean: 0.192095 -0.187722 -0.0535944 0.183159
beijing_tanh+hardsigmoid4 5260.4748      0.90  0.08  0.84      0.91  0.05  0.87      0.92  0.04  0.89
forget mean min: 0.8993 0.0995112
delta_x = 11.9387 delta_h = 1.0122
U_c = [[-0.01187745]] U_f = [[ 0.]] b_c = [ 0.66851223] b_f = [ 0.99476045]
incx.max(), incx.min(), incx.mean() 13.8204 -10.6318 6.25558
fgtx.max(), fgtx.min(), fgtx.mean() 3.48853 -2.9972 1.48119
delta mean, abs_mean, abs_mean+, abs_mean-: -0.744505 11.9387 8.39635 19.0218
W_c max, min, mean, abs_mean: 0.692164 -0.6928 -0.206826 0.690468
W_f max, min, mean, abs_mean: 0.192095 -0.187722 -0.0535944 0.183159
Epoch 40/300
1s - loss: 1087.0931 - val_loss: 5232.6956
Epoch 00039: val_loss improved from 5260.47480 to 5232.69560, saving model to beijing_tanh+hardsigmoid4_weights.hdf5
beijing_tanh+hardsigmoid4 1060.2912      0.90  0.18  0.75      0.91  0.15  0.79      0.91  0.12  0.81
forget mean min: 0.843222 0.0
delta_x = 9.70466 delta_h = 0.679503
U_c = [[-0.01204702]] U_f = [[ 0.]] b_c = [ 0.67344064] b_f = [ 0.99170822]
incx.max(), incx.min(), incx.mean() 14.1479 -12.4445 5.00768
fgtx.max(), fgtx.min(), fgtx.mean() 3.60242 -3.50718 1.1585
delta mean, abs_mean, abs_mean+, abs_mean-: 0.446683 9.70466 8.13834 12.3005
W_c max, min, mean, abs_mean: 0.696871 -0.697489 -0.208234 0.695076
W_f max, min, mean, abs_mean: 0.195025 -0.190525 -0.0543629 0.18584
beijing_tanh+hardsigmoid4 5232.6955      0.90  0.08  0.84      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.899738 0.0931457
delta_x = 11.9534 delta_h = 1.03413
U_c = [[-0.01204702]] U_f = [[ 0.]] b_c = [ 0.67344064] b_f = [ 0.99170822]
incx.max(), incx.min(), incx.mean() 13.9013 -10.6459 6.25484
fgtx.max(), fgtx.min(), fgtx.mean() 3.53643 -3.02598 1.49134
delta mean, abs_mean, abs_mean+, abs_mean-: -0.738219 11.9534 8.35311 19.3069
W_c max, min, mean, abs_mean: 0.696871 -0.697489 -0.208234 0.695076
W_f max, min, mean, abs_mean: 0.195025 -0.190525 -0.0543629 0.18584
Epoch 41/300
1s - loss: 1081.1584 - val_loss: 5825.0528
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 1067.6793 - val_loss: 5932.8237
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 1062.8491 - val_loss: 5594.7468
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 1055.9320 - val_loss: 5658.7889
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 1052.9475 - val_loss: 6000.4618
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 1044.4022 - val_loss: 6163.3210
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 1041.9846 - val_loss: 6559.7134
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 1035.6736 - val_loss: 5859.0611
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 1029.7781 - val_loss: 5977.8198
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 1019.5213 - val_loss: 6104.1080
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 1017.8440 - val_loss: 5879.7305
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 1011.6208 - val_loss: 6483.1131
Epoch 00051: val_loss did not improve
Epoch 53/300
1s - loss: 1006.5467 - val_loss: 6405.1709
Epoch 00052: val_loss did not improve
Epoch 54/300
1s - loss: 1005.0540 - val_loss: 6309.5497
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 990.8686 - val_loss: 6451.1978
Epoch 00054: val_loss did not improve
Epoch 56/300
1s - loss: 991.5269 - val_loss: 7220.6298
Epoch 00055: val_loss did not improve
Epoch 57/300
1s - loss: 985.9622 - val_loss: 5955.2827
Epoch 00056: val_loss did not improve
Epoch 58/300
1s - loss: 978.6139 - val_loss: 6946.8999
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 970.4231 - val_loss: 6605.6100
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 964.4718 - val_loss: 6823.6216
Epoch 00059: val_loss did not improve
Epoch 61/300
1s - loss: 954.0192 - val_loss: 7082.0531
Epoch 00060: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid5
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid5 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid529822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5944.1510 - val_loss: 9841.6173
Epoch 00000: val_loss improved from inf to 9841.61732, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 3279.3398      0.56  0.21  0.49      0.56  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.813371 0.312813
delta_x = 4.41396 delta_h = 2.22026
U_c = [[-0.06217895]] U_f = [[ 0.]] b_c = [ 0.12218719] b_f = [ 1.09496343]
incx.max(), incx.min(), incx.mean() 2.92157 -2.76992 1.11749
fgtx.max(), fgtx.min(), fgtx.mean() 1.96579 -2.0309 0.698921
delta mean, abs_mean, abs_mean+, abs_mean-: -1.21976 4.41396 2.56862 7.44759
W_c max, min, mean, abs_mean: 0.149339 -0.148917 -0.0150362 0.148198
W_f max, min, mean, abs_mean: 0.105007 -0.104641 -0.0103828 0.104068
beijing_tanh+hardsigmoid5 9841.6172      0.79  0.09  0.73      0.79  0.05  0.75      0.80  0.03  0.78
forget mean min: 0.846329 0.313603
delta_x = 6.55678 delta_h = 4.07897
U_c = [[-0.06217895]] U_f = [[ 0.]] b_c = [ 0.12218719] b_f = [ 1.09496343]
incx.max(), incx.min(), incx.mean() 2.9257 -2.76429 1.35158
fgtx.max(), fgtx.min(), fgtx.mean() 1.96869 -2.02695 0.863307
delta mean, abs_mean, abs_mean+, abs_mean-: -3.38349 6.55678 2.61421 12.6445
W_c max, min, mean, abs_mean: 0.149339 -0.148917 -0.0150362 0.148198
W_f max, min, mean, abs_mean: 0.105007 -0.104641 -0.0103828 0.104068
Epoch 2/300
1s - loss: 2408.9705 - val_loss: 10838.2278
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1849.2749 - val_loss: 9898.7059
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1706.9938 - val_loss: 8702.1900
Epoch 00003: val_loss improved from 9841.61732 to 8702.19000, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1657.6671      0.88  0.24  0.68      0.88  0.22  0.70      0.88  0.19  0.73
forget mean min: 0.85355 0.37221
delta_x = 7.69385 delta_h = 0.833479
U_c = [[-0.01540291]] U_f = [[ 0.]] b_c = [ 0.30591089] b_f = [ 1.10757816]
incx.max(), incx.min(), incx.mean() 6.94242 -6.34347 3.35603
fgtx.max(), fgtx.min(), fgtx.mean() 1.74315 -1.74653 0.801145
delta mean, abs_mean, abs_mean+, abs_mean-: 0.414173 7.69385 5.94774 11.4319
W_c max, min, mean, abs_mean: 0.333916 -0.333518 -0.0334897 0.332771
W_f max, min, mean, abs_mean: 0.088383 -0.0879863 -0.00870714 0.0874059
beijing_tanh+hardsigmoid5 8702.1900      0.84  0.16  0.73      0.84  0.12  0.75      0.87  0.10  0.80
forget mean min: 0.913786 0.372828
delta_x = 10.0487 delta_h = 1.3729
U_c = [[-0.01540291]] U_f = [[ 0.]] b_c = [ 0.30591089] b_f = [ 1.10757816]
incx.max(), incx.min(), incx.mean() 6.93928 -6.33171 4.59187
fgtx.max(), fgtx.min(), fgtx.mean() 1.74232 -1.74344 1.12575
delta mean, abs_mean, abs_mean+, abs_mean-: -0.602458 10.0487 6.08305 23.8213
W_c max, min, mean, abs_mean: 0.333916 -0.333518 -0.0334897 0.332771
W_f max, min, mean, abs_mean: 0.088383 -0.0879863 -0.00870714 0.0874059
Epoch 5/300
1s - loss: 1652.4897 - val_loss: 8053.2707
Epoch 00004: val_loss improved from 8702.19000 to 8053.27066, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1620.4200      0.88  0.24  0.69      0.88  0.22  0.71      0.88  0.19  0.73
forget mean min: 0.849867 0.335722
delta_x = 8.01763 delta_h = 1.04399
U_c = [[-0.01948445]] U_f = [[ 0.]] b_c = [ 0.31533602] b_f = [ 1.0999608]
incx.max(), incx.min(), incx.mean() 7.15266 -6.53756 3.42396
fgtx.max(), fgtx.min(), fgtx.mean() 1.91699 -1.92135 0.871566
delta mean, abs_mean, abs_mean+, abs_mean-: 0.432723 8.01763 6.11337 12.2788
W_c max, min, mean, abs_mean: 0.344075 -0.343681 -0.0345048 0.34293
W_f max, min, mean, abs_mean: 0.0971338 -0.0967287 -0.00957967 0.0961476
beijing_tanh+hardsigmoid5 8053.2706      0.85  0.15  0.74      0.85  0.12  0.76      0.88  0.09  0.81
forget mean min: 0.910397 0.336359
delta_x = 10.338 delta_h = 1.70295
U_c = [[-0.01948445]] U_f = [[ 0.]] b_c = [ 0.31533602] b_f = [ 1.0999608]
incx.max(), incx.min(), incx.mean() 7.14661 -6.5262 4.63429
fgtx.max(), fgtx.min(), fgtx.mean() 1.91529 -1.91817 1.21091
delta mean, abs_mean, abs_mean+, abs_mean-: -0.558717 10.338 6.26751 24.7826
W_c max, min, mean, abs_mean: 0.344075 -0.343681 -0.0345048 0.34293
W_f max, min, mean, abs_mean: 0.0971338 -0.0967287 -0.00957967 0.0961476
Epoch 6/300
1s - loss: 1631.8083 - val_loss: 7684.1076
Epoch 00005: val_loss improved from 8053.27066 to 7684.10760, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1608.2263      0.86  0.21  0.70      0.86  0.19  0.72      0.86  0.16  0.74
forget mean min: 0.846367 0.320502
delta_x = 7.99015 delta_h = 1.03837
U_c = [[-0.02006703]] U_f = [[ 0.]] b_c = [ 0.31659183] b_f = [ 1.09090102]
incx.max(), incx.min(), incx.mean() 7.19253 -6.57779 3.34216
fgtx.max(), fgtx.min(), fgtx.mean() 1.98307 -1.98839 0.872597
delta mean, abs_mean, abs_mean+, abs_mean-: 0.252875 7.99015 6.05103 12.1322
W_c max, min, mean, abs_mean: 0.346232 -0.345841 -0.0347195 0.345085
W_f max, min, mean, abs_mean: 0.10052 -0.100109 -0.00991608 0.0995253
beijing_tanh+hardsigmoid5 7684.1077      0.84  0.14  0.74      0.84  0.11  0.76      0.87  0.08  0.81
forget mean min: 0.909177 0.321348
delta_x = 10.1169 delta_h = 1.68312
U_c = [[-0.02006703]] U_f = [[ 0.]] b_c = [ 0.31659183] b_f = [ 1.09090102]
incx.max(), incx.min(), incx.mean() 7.17796 -6.56312 4.52477
fgtx.max(), fgtx.min(), fgtx.mean() 1.97887 -1.98416 1.21367
delta mean, abs_mean, abs_mean+, abs_mean-: -0.777434 10.1169 6.11889 22.9997
W_c max, min, mean, abs_mean: 0.346232 -0.345841 -0.0347195 0.345085
W_f max, min, mean, abs_mean: 0.10052 -0.100109 -0.00991608 0.0995253
Epoch 7/300
1s - loss: 1618.4930 - val_loss: 7535.0256
Epoch 00006: val_loss improved from 7684.10760 to 7535.02561, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1578.6280      0.88  0.23  0.69      0.88  0.21  0.71      0.89  0.18  0.74
forget mean min: 0.845458 0.294627
delta_x = 8.22629 delta_h = 0.877019
U_c = [[-0.01631697]] U_f = [[ 0.]] b_c = [ 0.32523784] b_f = [ 1.08973765]
incx.max(), incx.min(), incx.mean() 7.37992 -6.74941 3.44903
fgtx.max(), fgtx.min(), fgtx.mean() 2.11063 -2.1166 0.934578
delta mean, abs_mean, abs_mean+, abs_mean-: 0.353392 8.22629 6.22859 12.6466
W_c max, min, mean, abs_mean: 0.355277 -0.35489 -0.0356232 0.354129
W_f max, min, mean, abs_mean: 0.106949 -0.10653 -0.0105563 0.105949
beijing_tanh+hardsigmoid5 7535.0256      0.84  0.14  0.74      0.84  0.10  0.77      0.87  0.08  0.81
forget mean min: 0.907248 0.295536
delta_x = 10.3134 delta_h = 1.39691
U_c = [[-0.01631697]] U_f = [[ 0.]] b_c = [ 0.32523784] b_f = [ 1.08973765]
incx.max(), incx.min(), incx.mean() 7.35446 -6.73421 4.55728
fgtx.max(), fgtx.min(), fgtx.mean() 2.10301 -2.11206 1.26615
delta mean, abs_mean, abs_mean+, abs_mean-: -0.806113 10.3134 6.202 23.8074
W_c max, min, mean, abs_mean: 0.355277 -0.35489 -0.0356232 0.354129
W_f max, min, mean, abs_mean: 0.106949 -0.10653 -0.0105563 0.105949
Epoch 8/300
1s - loss: 1609.1364 - val_loss: 7103.3502
Epoch 00007: val_loss improved from 7535.02561 to 7103.35019, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1585.2897      0.89  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.73
forget mean min: 0.843 0.275226
delta_x = 8.1738 delta_h = 1.19343
U_c = [[-0.02237508]] U_f = [[ 0.]] b_c = [ 0.32859746] b_f = [ 1.09085953]
incx.max(), incx.min(), incx.mean() 7.43581 -6.8059 3.45199
fgtx.max(), fgtx.min(), fgtx.mean() 2.20626 -2.21473 0.96958
delta mean, abs_mean, abs_mean+, abs_mean-: 0.464856 8.1738 6.22797 12.5773
W_c max, min, mean, abs_mean: 0.358371 -0.357988 -0.0359319 0.35722
W_f max, min, mean, abs_mean: 0.111897 -0.111478 -0.0110498 0.11089
beijing_tanh+hardsigmoid5 7103.3502      0.85  0.13  0.75      0.86  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.903153 0.276236
delta_x = 10.4249 delta_h = 1.91531
U_c = [[-0.02237508]] U_f = [[ 0.]] b_c = [ 0.32859746] b_f = [ 1.09085953]
incx.max(), incx.min(), incx.mean() 7.41005 -6.78964 4.53808
fgtx.max(), fgtx.min(), fgtx.mean() 2.19826 -2.20968 1.30673
delta mean, abs_mean, abs_mean+, abs_mean-: -0.666241 10.4249 6.28427 24.8054
W_c max, min, mean, abs_mean: 0.358371 -0.357988 -0.0359319 0.35722
W_f max, min, mean, abs_mean: 0.111897 -0.111478 -0.0110498 0.11089
Epoch 9/300
1s - loss: 1599.2462 - val_loss: 7113.7813
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1597.2445 - val_loss: 6984.7150
Epoch 00009: val_loss improved from 7103.35019 to 6984.71495, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1555.6975      0.89  0.24  0.69      0.89  0.22  0.71      0.90  0.19  0.74
forget mean min: 0.844463 0.261542
delta_x = 8.11212 delta_h = 1.05662
U_c = [[-0.01999629]] U_f = [[ 0.]] b_c = [ 0.33782217] b_f = [ 1.09114206]
incx.max(), incx.min(), incx.mean() 7.60297 -6.97963 3.47215
fgtx.max(), fgtx.min(), fgtx.mean() 2.26711 -2.28343 0.978074
delta mean, abs_mean, abs_mean+, abs_mean-: 0.416926 8.11212 6.20458 12.3052
W_c max, min, mean, abs_mean: 0.367786 -0.36741 -0.0368721 0.36663
W_f max, min, mean, abs_mean: 0.115418 -0.115002 -0.0114 0.114408
beijing_tanh+hardsigmoid5 6984.7150      0.85  0.13  0.76      0.86  0.09  0.79      0.88  0.07  0.83
forget mean min: 0.906686 0.263229
delta_x = 10.1623 delta_h = 1.6833
U_c = [[-0.01999629]] U_f = [[ 0.]] b_c = [ 0.33782217] b_f = [ 1.09114206]
incx.max(), incx.min(), incx.mean() 7.58826 -6.9526 4.51137
fgtx.max(), fgtx.min(), fgtx.mean() 2.26252 -2.27499 1.30237
delta mean, abs_mean, abs_mean+, abs_mean-: -0.765263 10.1623 6.13969 23.2764
W_c max, min, mean, abs_mean: 0.367786 -0.36741 -0.0368721 0.36663
W_f max, min, mean, abs_mean: 0.115418 -0.115002 -0.0114 0.114408
Epoch 11/300
1s - loss: 1593.4357 - val_loss: 7118.9968
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1579.4361 - val_loss: 7216.9802
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1572.0641 - val_loss: 6977.6965
Epoch 00012: val_loss improved from 6984.71495 to 6977.69646, saving model to beijing_tanh+hardsigmoid5_weights.hdf5
beijing_tanh+hardsigmoid5 1517.0441      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.17  0.76
forget mean min: 0.8492 0.271002
delta_x = 8.20996 delta_h = 0.570571
U_c = [[-0.01085399]] U_f = [[ 0.]] b_c = [ 0.36099178] b_f = [ 1.09284806]
incx.max(), incx.min(), incx.mean() 8.10943 -7.42606 3.6044
fgtx.max(), fgtx.min(), fgtx.mean() 2.22674 -2.23784 0.932087
delta mean, abs_mean, abs_mean+, abs_mean-: 0.29339 8.20996 6.30782 12.1432
W_c max, min, mean, abs_mean: 0.391551 -0.391187 -0.0392468 0.390392
W_f max, min, mean, abs_mean: 0.113197 -0.112801 -0.0111799 0.112191
beijing_tanh+hardsigmoid5 6977.6965      0.84  0.11  0.76      0.85  0.08  0.79      0.87  0.06  0.82
forget mean min: 0.90897 0.273814
delta_x = 9.81311 delta_h = 0.900454
U_c = [[-0.01085399]] U_f = [[ 0.]] b_c = [ 0.36099178] b_f = [ 1.09284806]
incx.max(), incx.min(), incx.mean() 8.07645 -7.37713 4.59801
fgtx.max(), fgtx.min(), fgtx.mean() 2.21726 -2.22378 1.21763
delta mean, abs_mean, abs_mean+, abs_mean-: -1.05158 9.81311 6.07071 19.5144
W_c max, min, mean, abs_mean: 0.391551 -0.391187 -0.0392468 0.390392
W_f max, min, mean, abs_mean: 0.113197 -0.112801 -0.0111799 0.112191
Epoch 14/300
1s - loss: 1563.3647 - val_loss: 7114.2906
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1560.9625 - val_loss: 7099.8030
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1550.8296 - val_loss: 7224.3851
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1543.7900 - val_loss: 7133.9735
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1542.4803 - val_loss: 7364.1151
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1536.9867 - val_loss: 7489.1701
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1536.0276 - val_loss: 7212.5113
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1521.4396 - val_loss: 7365.0490
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1511.6753 - val_loss: 7178.3410
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1497.2761 - val_loss: 7253.3502
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1480.2556 - val_loss: 7600.9987
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1459.9171 - val_loss: 7307.7801
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1435.1756 - val_loss: 7257.5612
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1404.1164 - val_loss: 7321.2238
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1372.6608 - val_loss: 7863.4107
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1351.6960 - val_loss: 7728.5648
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1322.6461 - val_loss: 8164.3829
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1303.0034 - val_loss: 8322.3399
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1290.6805 - val_loss: 8589.9144
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1267.8532 - val_loss: 8344.1249
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1243.1035 - val_loss: 8781.7857
Epoch 00033: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid6
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid6 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid629822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5814.1426 - val_loss: 9833.6975
Epoch 00000: val_loss improved from inf to 9833.69753, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 3257.0354      0.56  0.21  0.49      0.56  0.20  0.50      0.54  0.18  0.49
forget mean min: 0.812835 0.315607
delta_x = 4.3957 delta_h = 2.13191
U_c = [[-0.05898649]] U_f = [[ 0.]] b_c = [ 0.12260658] b_f = [ 1.09353256]
incx.max(), incx.min(), incx.mean() 2.93437 -2.77799 1.12142
fgtx.max(), fgtx.min(), fgtx.mean() 1.95377 -2.0155 0.694027
delta mean, abs_mean, abs_mean+, abs_mean-: -1.17528 4.3957 2.58626 7.38074
W_c max, min, mean, abs_mean: 0.149261 -0.149074 -0.0740726 0.148587
W_f max, min, mean, abs_mean: 0.10383 -0.10385 -0.0515685 0.103247
beijing_tanh+hardsigmoid6 9833.6974      0.78  0.09  0.73      0.78  0.05  0.75      0.79  0.03  0.77
forget mean min: 0.844689 0.316235
delta_x = 6.53467 delta_h = 3.93679
U_c = [[-0.05898649]] U_f = [[ 0.]] b_c = [ 0.12260658] b_f = [ 1.09353256]
incx.max(), incx.min(), incx.mean() 2.93667 -2.77347 1.3526
fgtx.max(), fgtx.min(), fgtx.mean() 1.95536 -2.01236 0.854667
delta mean, abs_mean, abs_mean+, abs_mean-: -3.33036 6.53467 2.63477 12.5856
W_c max, min, mean, abs_mean: 0.149261 -0.149074 -0.0740726 0.148587
W_f max, min, mean, abs_mean: 0.10383 -0.10385 -0.0515685 0.103247
Epoch 2/300
1s - loss: 2409.1655 - val_loss: 10979.2202
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1855.4190 - val_loss: 9684.7068
Epoch 00002: val_loss improved from 9833.69753 to 9684.70678, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1745.3942      0.85  0.24  0.67      0.86  0.22  0.69      0.86  0.19  0.71
forget mean min: 0.853845 0.413081
delta_x = 6.78053 delta_h = 0.556559
U_c = [[-0.01063511]] U_f = [[ 0.]] b_c = [ 0.27101761] b_f = [ 1.10686421]
incx.max(), incx.min(), incx.mean() 6.18979 -5.65801 2.99432
fgtx.max(), fgtx.min(), fgtx.mean() 1.53879 -1.54146 0.708016
delta mean, abs_mean, abs_mean+, abs_mean-: 0.226151 6.78053 5.22123 9.96043
W_c max, min, mean, abs_mean: 0.297559 -0.297362 -0.148208 0.296862
W_f max, min, mean, abs_mean: 0.0778024 -0.0777949 -0.0385334 0.0771796
beijing_tanh+hardsigmoid6 9684.7069      0.78  0.14  0.69      0.78  0.11  0.71      0.80  0.08  0.75
forget mean min: 0.906384 0.413711
delta_x = 8.75959 delta_h = 0.919604
U_c = [[-0.01063511]] U_f = [[ 0.]] b_c = [ 0.27101761] b_f = [ 1.10686421]
incx.max(), incx.min(), incx.mean() 6.18439 -5.6459 4.01047
fgtx.max(), fgtx.min(), fgtx.mean() 1.53739 -1.53831 0.972201
delta mean, abs_mean, abs_mean+, abs_mean-: -1.19374 8.75959 5.26741 17.6587
W_c max, min, mean, abs_mean: 0.297559 -0.297362 -0.148208 0.296862
W_f max, min, mean, abs_mean: 0.0778024 -0.0777949 -0.0385334 0.0771796
Epoch 4/300
1s - loss: 1714.3537 - val_loss: 8452.6805
Epoch 00003: val_loss improved from 9684.70678 to 8452.68048, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1654.2544      0.87  0.25  0.68      0.88  0.22  0.70      0.88  0.19  0.73
forget mean min: 0.854911 0.378586
delta_x = 7.52522 delta_h = 0.976336
U_c = [[-0.0187483]] U_f = [[ 0.]] b_c = [ 0.29865986] b_f = [ 1.1047281]
incx.max(), incx.min(), incx.mean() 6.77073 -6.18583 3.30036
fgtx.max(), fgtx.min(), fgtx.mean() 1.70852 -1.7118 0.792398
delta mean, abs_mean, abs_mean+, abs_mean-: 0.3676 7.52522 5.80073 11.1953
W_c max, min, mean, abs_mean: 0.325256 -0.325058 -0.162054 0.324554
W_f max, min, mean, abs_mean: 0.0863037 -0.0862967 -0.0427826 0.0856769
beijing_tanh+hardsigmoid6 8452.6804      0.83  0.15  0.72      0.83  0.12  0.75      0.86  0.09  0.80
forget mean min: 0.912337 0.379228
delta_x = 9.66612 delta_h = 1.58652
U_c = [[-0.0187483]] U_f = [[ 0.]] b_c = [ 0.29865986] b_f = [ 1.1047281]
incx.max(), incx.min(), incx.mean() 6.76576 -6.17368 4.44027
fgtx.max(), fgtx.min(), fgtx.mean() 1.70721 -1.70859 1.09332
delta mean, abs_mean, abs_mean+, abs_mean-: -0.740651 9.66612 5.90464 21.308
W_c max, min, mean, abs_mean: 0.325256 -0.325058 -0.162054 0.324554
W_f max, min, mean, abs_mean: 0.0863037 -0.0862967 -0.0427826 0.0856769
Epoch 5/300
1s - loss: 1655.4193 - val_loss: 8024.3140
Epoch 00004: val_loss improved from 8452.68048 to 8024.31402, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1622.7679      0.88  0.25  0.68      0.89  0.23  0.70      0.89  0.20  0.73
forget mean min: 0.852641 0.347963
delta_x = 7.98246 delta_h = 0.976312
U_c = [[-0.01814104]] U_f = [[ 0.]] b_c = [ 0.31225827] b_f = [ 1.09954584]
incx.max(), incx.min(), incx.mean() 7.07336 -6.46405 3.44083
fgtx.max(), fgtx.min(), fgtx.mean() 1.85556 -1.85973 0.858623
delta mean, abs_mean, abs_mean+, abs_mean-: 0.449921 7.98246 6.07615 12.3037
W_c max, min, mean, abs_mean: 0.339818 -0.339619 -0.169333 0.339111
W_f max, min, mean, abs_mean: 0.0936974 -0.0936942 -0.0464783 0.0930677
beijing_tanh+hardsigmoid6 8024.3140      0.85  0.14  0.74      0.85  0.11  0.77      0.88  0.09  0.81
forget mean min: 0.909494 0.348499
delta_x = 10.2354 delta_h = 1.58717
U_c = [[-0.01814104]] U_f = [[ 0.]] b_c = [ 0.31225827] b_f = [ 1.09954584]
incx.max(), incx.min(), incx.mean() 7.06921 -6.45429 4.57765
fgtx.max(), fgtx.min(), fgtx.mean() 1.85442 -1.85705 1.17062
delta mean, abs_mean, abs_mean+, abs_mean-: -0.613623 10.2354 6.1938 24.295
W_c max, min, mean, abs_mean: 0.339818 -0.339619 -0.169333 0.339111
W_f max, min, mean, abs_mean: 0.0936974 -0.0936942 -0.0464783 0.0930677
Epoch 6/300
1s - loss: 1633.9451 - val_loss: 7599.4884
Epoch 00005: val_loss improved from 8024.31402 to 7599.48837, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1623.2072      0.89  0.26  0.68      0.90  0.24  0.70      0.90  0.21  0.73
forget mean min: 0.84977 0.320168
delta_x = 8.14389 delta_h = 1.02782
U_c = [[-0.01888851]] U_f = [[ 0.]] b_c = [ 0.31908104] b_f = [ 1.09287667]
incx.max(), incx.min(), incx.mean() 7.22702 -6.60495 3.49341
fgtx.max(), fgtx.min(), fgtx.mean() 1.98741 -1.99204 0.913252
delta mean, abs_mean, abs_mean+, abs_mean-: 0.513178 8.14389 6.20777 12.6034
W_c max, min, mean, abs_mean: 0.34724 -0.34704 -0.173042 0.346529
W_f max, min, mean, abs_mean: 0.100331 -0.100331 -0.0497925 0.099696
beijing_tanh+hardsigmoid6 7599.4884      0.85  0.13  0.75      0.85  0.11  0.77      0.88  0.08  0.82
forget mean min: 0.904735 0.320742
delta_x = 10.4066 delta_h = 1.65777
U_c = [[-0.01888851]] U_f = [[ 0.]] b_c = [ 0.31908104] b_f = [ 1.09287667]
incx.max(), incx.min(), incx.mean() 7.21546 -6.59497 4.55985
fgtx.max(), fgtx.min(), fgtx.mean() 1.98408 -1.98917 1.22006
delta mean, abs_mean, abs_mean+, abs_mean-: -0.634126 10.4066 6.29536 24.663
W_c max, min, mean, abs_mean: 0.34724 -0.34704 -0.173042 0.346529
W_f max, min, mean, abs_mean: 0.100331 -0.100331 -0.0497925 0.099696
Epoch 7/300
1s - loss: 1618.6590 - val_loss: 7428.6343
Epoch 00006: val_loss improved from 7599.48837 to 7428.63429, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1596.7979      0.89  0.26  0.68      0.90  0.24  0.70      0.90  0.20  0.73
forget mean min: 0.849537 0.305008
delta_x = 8.25718 delta_h = 0.971363
U_c = [[-0.01783218]] U_f = [[ 0.]] b_c = [ 0.32694656] b_f = [ 1.08822644]
incx.max(), incx.min(), incx.mean() 7.39918 -6.76292 3.55199
fgtx.max(), fgtx.min(), fgtx.mean() 2.05805 -2.06318 0.938502
delta mean, abs_mean, abs_mean+, abs_mean-: 0.501209 8.25718 6.28039 12.8105
W_c max, min, mean, abs_mean: 0.355618 -0.355417 -0.177228 0.354902
W_f max, min, mean, abs_mean: 0.103918 -0.103921 -0.0515834 0.103278
beijing_tanh+hardsigmoid6 7428.6344      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.08  0.82
forget mean min: 0.906321 0.30581
delta_x = 10.4232 delta_h = 1.5516
U_c = [[-0.01783218]] U_f = [[ 0.]] b_c = [ 0.32694656] b_f = [ 1.08822644]
incx.max(), incx.min(), incx.mean() 7.37191 -6.74914 4.6117
fgtx.max(), fgtx.min(), fgtx.mean() 2.05012 -2.05917 1.24688
delta mean, abs_mean, abs_mean+, abs_mean-: -0.671829 10.4232 6.30465 24.4759
W_c max, min, mean, abs_mean: 0.355618 -0.355417 -0.177228 0.354902
W_f max, min, mean, abs_mean: 0.103918 -0.103921 -0.0515834 0.103278
Epoch 8/300
1s - loss: 1613.1099 - val_loss: 7326.3246
Epoch 00007: val_loss improved from 7428.63429 to 7326.32462, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1572.8747      0.88  0.24  0.69      0.89  0.22  0.71      0.90  0.19  0.74
forget mean min: 0.84574 0.283899
delta_x = 8.20283 delta_h = 0.944269
U_c = [[-0.01751754]] U_f = [[ 0.]] b_c = [ 0.32905427] b_f = [ 1.0856508]
incx.max(), incx.min(), incx.mean() 7.44647 -6.81132 3.48599
fgtx.max(), fgtx.min(), fgtx.mean() 2.15919 -2.16616 0.957712
delta mean, abs_mean, abs_mean+, abs_mean-: 0.425162 8.20283 6.23893 12.6041
W_c max, min, mean, abs_mean: 0.358256 -0.358053 -0.178544 0.357534
W_f max, min, mean, abs_mean: 0.109109 -0.109113 -0.0541767 0.108464
beijing_tanh+hardsigmoid6 7326.3247      0.85  0.13  0.75      0.85  0.10  0.78      0.87  0.07  0.82
forget mean min: 0.904869 0.28491
delta_x = 10.3753 delta_h = 1.52515
U_c = [[-0.01751754]] U_f = [[ 0.]] b_c = [ 0.32905427] b_f = [ 1.0856508]
incx.max(), incx.min(), incx.mean() 7.4143 -6.79465 4.54562
fgtx.max(), fgtx.min(), fgtx.mean() 2.14943 -2.1611 1.27917
delta mean, abs_mean, abs_mean+, abs_mean-: -0.732433 10.3753 6.22381 24.6485
W_c max, min, mean, abs_mean: 0.358256 -0.358053 -0.178544 0.357534
W_f max, min, mean, abs_mean: 0.109109 -0.109113 -0.0541767 0.108464
Epoch 9/300
1s - loss: 1606.9022 - val_loss: 7161.9949
Epoch 00008: val_loss improved from 7326.32462 to 7161.99490, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1595.4291      0.89  0.25  0.68      0.90  0.23  0.70      0.90  0.20  0.73
forget mean min: 0.846154 0.274664
delta_x = 8.20402 delta_h = 0.977017
U_c = [[-0.01792803]] U_f = [[ 0.]] b_c = [ 0.33542031] b_f = [ 1.08650017]
incx.max(), incx.min(), incx.mean() 7.57429 -6.93134 3.53504
fgtx.max(), fgtx.min(), fgtx.mean() 2.20469 -2.21318 0.974484
delta mean, abs_mean, abs_mean+, abs_mean-: 0.509677 8.20402 6.26236 12.6435
W_c max, min, mean, abs_mean: 0.364725 -0.364522 -0.181777 0.364
W_f max, min, mean, abs_mean: 0.111509 -0.111517 -0.0553737 0.110861
beijing_tanh+hardsigmoid6 7161.9948      0.85  0.13  0.76      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.903381 0.275882
delta_x = 10.4514 delta_h = 1.57886
U_c = [[-0.01792803]] U_f = [[ 0.]] b_c = [ 0.33542031] b_f = [ 1.08650017]
incx.max(), incx.min(), incx.mean() 7.53925 -6.91133 4.56167
fgtx.max(), fgtx.min(), fgtx.mean() 2.19401 -2.20709 1.28715
delta mean, abs_mean, abs_mean+, abs_mean-: -0.698467 10.4514 6.28594 24.8628
W_c max, min, mean, abs_mean: 0.364725 -0.364522 -0.181777 0.364
W_f max, min, mean, abs_mean: 0.111509 -0.111517 -0.0553737 0.110861
Epoch 10/300
1s - loss: 1602.1911 - val_loss: 7007.2943
Epoch 00009: val_loss improved from 7161.99490 to 7007.29435, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1560.3731      0.88  0.23  0.69      0.89  0.21  0.72      0.89  0.18  0.74
forget mean min: 0.845509 0.2662
delta_x = 8.09194 delta_h = 1.07417
U_c = [[-0.02051038]] U_f = [[ 0.]] b_c = [ 0.33700782] b_f = [ 1.08623064]
incx.max(), incx.min(), incx.mean() 7.59628 -6.95933 3.47041
fgtx.max(), fgtx.min(), fgtx.mean() 2.24377 -2.25523 0.968505
delta mean, abs_mean, abs_mean+, abs_mean-: 0.397743 8.09194 6.17154 12.3229
W_c max, min, mean, abs_mean: 0.366391 -0.366189 -0.182609 0.365664
W_f max, min, mean, abs_mean: 0.113673 -0.113682 -0.0564551 0.113023
beijing_tanh+hardsigmoid6 7007.2943      0.85  0.13  0.76      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.907335 0.267956
delta_x = 10.1498 delta_h = 1.72973
U_c = [[-0.02051038]] U_f = [[ 0.]] b_c = [ 0.33700782] b_f = [ 1.08623064]
incx.max(), incx.min(), incx.mean() 7.5606 -6.93091 4.51724
fgtx.max(), fgtx.min(), fgtx.mean() 2.23275 -2.24645 1.29207
delta mean, abs_mean, abs_mean+, abs_mean-: -0.765337 10.1498 6.14231 23.1173
W_c max, min, mean, abs_mean: 0.366391 -0.366189 -0.182609 0.365664
W_f max, min, mean, abs_mean: 0.113673 -0.113682 -0.0564551 0.113023
Epoch 11/300
1s - loss: 1592.9506 - val_loss: 7210.1357
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1581.6975 - val_loss: 7040.7740
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1569.4583 - val_loss: 6949.6410
Epoch 00012: val_loss improved from 7007.29435 to 6949.64096, saving model to beijing_tanh+hardsigmoid6_weights.hdf5
beijing_tanh+hardsigmoid6 1506.4623      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.17  0.76
forget mean min: 0.850224 0.268976
delta_x = 8.19243 delta_h = 0.582857
U_c = [[-0.01120325]] U_f = [[ 0.]] b_c = [ 0.36089349] b_f = [ 1.08562016]
incx.max(), incx.min(), incx.mean() 8.09981 -7.41872 3.62231
fgtx.max(), fgtx.min(), fgtx.mean() 2.22902 -2.24074 0.939374
delta mean, abs_mean, abs_mean+, abs_mean-: 0.296182 8.19243 6.27718 12.1911
W_c max, min, mean, abs_mean: 0.390812 -0.390613 -0.194818 0.390081
W_f max, min, mean, abs_mean: 0.112996 -0.113016 -0.056118 0.112354
beijing_tanh+hardsigmoid6 6949.6410      0.84  0.11  0.76      0.84  0.08  0.79      0.86  0.06  0.82
forget mean min: 0.909005 0.271927
delta_x = 9.81188 delta_h = 0.925895
U_c = [[-0.01120325]] U_f = [[ 0.]] b_c = [ 0.36089349] b_f = [ 1.08562016]
incx.max(), incx.min(), incx.mean() 8.06269 -7.36749 4.59156
fgtx.max(), fgtx.min(), fgtx.mean() 2.21832 -2.22598 1.21855
delta mean, abs_mean, abs_mean+, abs_mean-: -1.06545 9.81188 6.05542 19.5775
W_c max, min, mean, abs_mean: 0.390812 -0.390613 -0.194818 0.390081
W_f max, min, mean, abs_mean: 0.112996 -0.113016 -0.056118 0.112354
Epoch 14/300
1s - loss: 1554.1829 - val_loss: 7066.3568
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1552.0809 - val_loss: 7292.2884
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1545.8313 - val_loss: 7369.8039
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1539.3472 - val_loss: 7228.0301
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1537.7429 - val_loss: 7305.5421
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1537.5676 - val_loss: 7532.8690
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1533.8236 - val_loss: 7432.9134
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1539.1415 - val_loss: 7348.7082
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1529.1067 - val_loss: 7485.1154
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1526.6110 - val_loss: 7627.6364
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1526.1123 - val_loss: 7700.2213
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1530.9236 - val_loss: 7506.8682
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1516.5814 - val_loss: 7487.0294
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1519.6249 - val_loss: 7317.6393
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1500.2697 - val_loss: 7713.7933
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1487.5542 - val_loss: 7552.9124
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1463.1748 - val_loss: 7253.7161
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1427.8799 - val_loss: 7257.2912
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1400.8544 - val_loss: 8041.5126
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1361.0954 - val_loss: 7835.4344
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1332.9897 - val_loss: 8156.2611
Epoch 00033: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid7
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid7 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid729822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5874.2156 - val_loss: 9694.5950
Epoch 00000: val_loss improved from inf to 9694.59505, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 3288.5866      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.813338 0.318629
delta_x = 4.38337 delta_h = 2.18573
U_c = [[-0.06098752]] U_f = [[ 0.]] b_c = [ 0.12244597] b_f = [ 1.09461343]
incx.max(), incx.min(), incx.mean() 2.91691 -2.75431 1.10621
fgtx.max(), fgtx.min(), fgtx.mean() 1.94421 -2.00147 0.684446
delta mean, abs_mean, abs_mean+, abs_mean-: -1.22322 4.38337 2.5563 7.34057
W_c max, min, mean, abs_mean: 0.148805 -0.148502 0.0439733 0.147478
W_f max, min, mean, abs_mean: 0.103903 -0.103611 0.0308165 0.102606
beijing_tanh+hardsigmoid7 9694.5949      0.79  0.09  0.73      0.79  0.05  0.75      0.80  0.03  0.78
forget mean min: 0.847417 0.319327
delta_x = 6.48919 delta_h = 4.0372
U_c = [[-0.06098752]] U_f = [[ 0.]] b_c = [ 0.12244597] b_f = [ 1.09461343]
incx.max(), incx.min(), incx.mean() 2.91805 -2.74929 1.36223
fgtx.max(), fgtx.min(), fgtx.mean() 1.94501 -1.99798 0.862568
delta mean, abs_mean, abs_mean+, abs_mean-: -3.28131 6.48919 2.61202 12.6581
W_c max, min, mean, abs_mean: 0.148805 -0.148502 0.0439733 0.147478
W_f max, min, mean, abs_mean: 0.103903 -0.103611 0.0308165 0.102606
Epoch 2/300
1s - loss: 2420.3517 - val_loss: 10732.2698
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1850.4441 - val_loss: 9318.6253
Epoch 00002: val_loss improved from 9694.59505 to 9318.62533, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1746.1091      0.85  0.25  0.67      0.86  0.22  0.69      0.86  0.19  0.72
forget mean min: 0.853458 0.411331
delta_x = 6.79725 delta_h = 0.790126
U_c = [[-0.01534616]] U_f = [[ 0.]] b_c = [ 0.27507907] b_f = [ 1.10703754]
incx.max(), incx.min(), incx.mean() 6.24495 -5.70666 3.01156
fgtx.max(), fgtx.min(), fgtx.mean() 1.54731 -1.55038 0.709248
delta mean, abs_mean, abs_mean+, abs_mean-: 0.253139 6.79725 5.26628 9.89702
W_c max, min, mean, abs_mean: 0.300847 -0.300533 0.0895899 0.299513
W_f max, min, mean, abs_mean: 0.0789204 -0.0786249 0.0233355 0.0776296
beijing_tanh+hardsigmoid7 9318.6254      0.80  0.15  0.70      0.80  0.11  0.73      0.83  0.09  0.77
forget mean min: 0.907905 0.412018
delta_x = 8.77187 delta_h = 1.30177
U_c = [[-0.01534616]] U_f = [[ 0.]] b_c = [ 0.27507907] b_f = [ 1.10703754]
incx.max(), incx.min(), incx.mean() 6.24082 -5.6934 4.07193
fgtx.max(), fgtx.min(), fgtx.mean() 1.54624 -1.54695 0.984079
delta mean, abs_mean, abs_mean+, abs_mean-: -1.0506 8.77187 5.3299 17.816
W_c max, min, mean, abs_mean: 0.300847 -0.300533 0.0895899 0.299513
W_f max, min, mean, abs_mean: 0.0789204 -0.0786249 0.0233355 0.0776296
Epoch 4/300
1s - loss: 1716.0519 - val_loss: 8585.0315
Epoch 00003: val_loss improved from 9318.62533 to 8585.03148, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1653.3516      0.88  0.25  0.68      0.88  0.23  0.70      0.88  0.20  0.72
forget mean min: 0.853861 0.374048
delta_x = 7.58877 delta_h = 0.935477
U_c = [[-0.01768097]] U_f = [[ 0.]] b_c = [ 0.30305555] b_f = [ 1.1054194]
incx.max(), incx.min(), incx.mean() 6.83833 -6.24525 3.31394
fgtx.max(), fgtx.min(), fgtx.mean() 1.73173 -1.73518 0.797818
delta mean, abs_mean, abs_mean+, abs_mean-: 0.389411 7.58877 5.84868 11.3215
W_c max, min, mean, abs_mean: 0.329079 -0.328763 0.0980597 0.32774
W_f max, min, mean, abs_mean: 0.0881411 -0.0878429 0.0261019 0.0868451
beijing_tanh+hardsigmoid7 8585.0315      0.84  0.15  0.73      0.84  0.12  0.76      0.87  0.09  0.80
forget mean min: 0.912366 0.374681
delta_x = 9.81992 delta_h = 1.53278
U_c = [[-0.01768097]] U_f = [[ 0.]] b_c = [ 0.30305555] b_f = [ 1.1054194]
incx.max(), incx.min(), incx.mean() 6.83537 -6.23331 4.49382
fgtx.max(), fgtx.min(), fgtx.mean() 1.73094 -1.73201 1.11046
delta mean, abs_mean, abs_mean+, abs_mean-: -0.65236 9.81992 5.99133 22.2879
W_c max, min, mean, abs_mean: 0.329079 -0.328763 0.0980597 0.32774
W_f max, min, mean, abs_mean: 0.0881411 -0.0878429 0.0261019 0.0868451
Epoch 5/300
1s - loss: 1659.8771 - val_loss: 8121.0837
Epoch 00004: val_loss improved from 8585.03148 to 8121.08374, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1618.7600      0.88  0.23  0.69      0.88  0.21  0.71      0.88  0.18  0.74
forget mean min: 0.852351 0.351612
delta_x = 7.88532 delta_h = 1.02769
U_c = [[-0.01971372]] U_f = [[ 0.]] b_c = [ 0.31294832] b_f = [ 1.09825706]
incx.max(), incx.min(), incx.mean() 7.05943 -6.44942 3.39784
fgtx.max(), fgtx.min(), fgtx.mean() 1.83588 -1.8402 0.839462
delta mean, abs_mean, abs_mean+, abs_mean-: 0.340056 7.88532 6.00401 11.9762
W_c max, min, mean, abs_mean: 0.339775 -0.339456 0.101268 0.338431
W_f max, min, mean, abs_mean: 0.0933951 -0.0930954 0.0276781 0.0920951
beijing_tanh+hardsigmoid7 8121.0837      0.84  0.16  0.73      0.85  0.12  0.76      0.87  0.09  0.80
forget mean min: 0.912766 0.352314
delta_x = 10.0052 delta_h = 1.66535
U_c = [[-0.01971372]] U_f = [[ 0.]] b_c = [ 0.31294832] b_f = [ 1.09825706]
incx.max(), incx.min(), incx.mean() 7.05465 -6.43653 4.59218
fgtx.max(), fgtx.min(), fgtx.mean() 1.83457 -1.83669 1.16447
delta mean, abs_mean, abs_mean+, abs_mean-: -0.648172 10.0052 6.11805 22.6388
W_c max, min, mean, abs_mean: 0.339775 -0.339456 0.101268 0.338431
W_f max, min, mean, abs_mean: 0.0933951 -0.0930954 0.0276781 0.0920951
Epoch 6/300
1s - loss: 1637.9600 - val_loss: 7720.3187
Epoch 00005: val_loss improved from 8121.08374 to 7720.31872, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1604.1645      0.89  0.25  0.68      0.89  0.23  0.70      0.90  0.20  0.73
forget mean min: 0.847813 0.310184
delta_x = 8.1946 delta_h = 1.0107
U_c = [[-0.01857983]] U_f = [[ 0.]] b_c = [ 0.32161102] b_f = [ 1.09384298]
incx.max(), incx.min(), incx.mean() 7.25006 -6.62402 3.47834
fgtx.max(), fgtx.min(), fgtx.mean() 2.03787 -2.04292 0.928484
delta mean, abs_mean, abs_mean+, abs_mean-: 0.469933 8.1946 6.21081 12.7696
W_c max, min, mean, abs_mean: 0.348934 -0.348613 0.104016 0.347585
W_f max, min, mean, abs_mean: 0.103542 -0.103241 0.0307222 0.102235
beijing_tanh+hardsigmoid7 7720.3188      0.85  0.14  0.75      0.86  0.11  0.77      0.88  0.08  0.82
forget mean min: 0.907302 0.310804
delta_x = 10.4466 delta_h = 1.62889
U_c = [[-0.01857983]] U_f = [[ 0.]] b_c = [ 0.32161102] b_f = [ 1.09384298]
incx.max(), incx.min(), incx.mean() 7.24216 -6.61348 4.61777
fgtx.max(), fgtx.min(), fgtx.mean() 2.03554 -2.03982 1.26362
delta mean, abs_mean, abs_mean+, abs_mean-: -0.590506 10.4466 6.30613 25.2524
W_c max, min, mean, abs_mean: 0.348934 -0.348613 0.104016 0.347585
W_f max, min, mean, abs_mean: 0.103542 -0.103241 0.0307222 0.102235
Epoch 7/300
1s - loss: 1617.0266 - val_loss: 7218.1326
Epoch 00006: val_loss improved from 7720.31872 to 7218.13257, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1586.2755      0.88  0.23  0.69      0.88  0.22  0.71      0.88  0.18  0.74
forget mean min: 0.843986 0.294219
delta_x = 8.11124 delta_h = 1.22414
U_c = [[-0.02344037]] U_f = [[ 0.]] b_c = [ 0.32325757] b_f = [ 1.08561385]
incx.max(), incx.min(), incx.mean() 7.28639 -6.65946 3.40133
fgtx.max(), fgtx.min(), fgtx.mean() 2.10859 -2.11452 0.932101
delta mean, abs_mean, abs_mean+, abs_mean-: 0.384551 8.11124 6.16428 12.4269
W_c max, min, mean, abs_mean: 0.350873 -0.350549 0.104597 0.349519
W_f max, min, mean, abs_mean: 0.10716 -0.106854 0.0318057 0.105842
beijing_tanh+hardsigmoid7 7218.1326      0.85  0.13  0.75      0.86  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.903257 0.294966
delta_x = 10.3138 delta_h = 1.97563
U_c = [[-0.02344037]] U_f = [[ 0.]] b_c = [ 0.32325757] b_f = [ 1.08561385]
incx.max(), incx.min(), incx.mean() 7.26809 -6.64712 4.50014
fgtx.max(), fgtx.min(), fgtx.mean() 2.10305 -2.11079 1.26484
delta mean, abs_mean, abs_mean+, abs_mean-: -0.694215 10.3138 6.2098 24.4136
W_c max, min, mean, abs_mean: 0.350873 -0.350549 0.104597 0.349519
W_f max, min, mean, abs_mean: 0.10716 -0.106854 0.0318057 0.105842
Epoch 8/300
1s - loss: 1612.3668 - val_loss: 7174.3353
Epoch 00007: val_loss improved from 7218.13257 to 7174.33534, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1589.1226      0.90  0.26  0.68      0.90  0.24  0.70      0.90  0.21  0.73
forget mean min: 0.842922 0.270432
delta_x = 8.29836 delta_h = 1.06329
U_c = [[-0.01948581]] U_f = [[ 0.]] b_c = [ 0.33195698] b_f = [ 1.08537543]
incx.max(), incx.min(), incx.mean() 7.46899 -6.83233 3.51204
fgtx.max(), fgtx.min(), fgtx.mean() 2.22472 -2.23322 0.991273
delta mean, abs_mean, abs_mean+, abs_mean-: 0.504918 8.29836 6.29861 12.9385
W_c max, min, mean, abs_mean: 0.359991 -0.359664 0.107333 0.358632
W_f max, min, mean, abs_mean: 0.113116 -0.112805 0.0335924 0.111791
beijing_tanh+hardsigmoid7 7174.3354      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.902265 0.271298
delta_x = 10.5073 delta_h = 1.68862
U_c = [[-0.01948581]] U_f = [[ 0.]] b_c = [ 0.33195698] b_f = [ 1.08537543]
incx.max(), incx.min(), incx.mean() 7.44398 -6.81843 4.56167
fgtx.max(), fgtx.min(), fgtx.mean() 2.21692 -2.22888 1.31846
delta mean, abs_mean, abs_mean+, abs_mean-: -0.691619 10.5073 6.30885 25.2145
W_c max, min, mean, abs_mean: 0.359991 -0.359664 0.107333 0.358632
W_f max, min, mean, abs_mean: 0.113116 -0.112805 0.0335924 0.111791
Epoch 9/300
1s - loss: 1606.0164 - val_loss: 7157.0251
Epoch 00008: val_loss improved from 7174.33534 to 7157.02515, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1574.2949      0.89  0.24  0.69      0.89  0.22  0.71      0.90  0.19  0.74
forget mean min: 0.84247 0.260574
delta_x = 8.27646 delta_h = 0.972083
U_c = [[-0.01788369]] U_f = [[ 0.]] b_c = [ 0.3356849] b_f = [ 1.08624899]
incx.max(), incx.min(), incx.mean() 7.53866 -6.89888 3.49593
fgtx.max(), fgtx.min(), fgtx.mean() 2.27341 -2.28338 0.997434
delta mean, abs_mean, abs_mean+, abs_mean-: 0.438082 8.27646 6.28636 12.7716
W_c max, min, mean, abs_mean: 0.363619 -0.363291 0.108421 0.362257
W_f max, min, mean, abs_mean: 0.115662 -0.115348 0.034358 0.114336
beijing_tanh+hardsigmoid7 7157.0252      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.906701 0.261769
delta_x = 10.3995 delta_h = 1.53952
U_c = [[-0.01788369]] U_f = [[ 0.]] b_c = [ 0.3356849] b_f = [ 1.08624899]
incx.max(), incx.min(), incx.mean() 7.51305 -6.87996 4.57908
fgtx.max(), fgtx.min(), fgtx.mean() 2.26532 -2.27741 1.3393
delta mean, abs_mean, abs_mean+, abs_mean-: -0.730951 10.3995 6.22381 24.9274
W_c max, min, mean, abs_mean: 0.363619 -0.363291 0.108421 0.362257
W_f max, min, mean, abs_mean: 0.115662 -0.115348 0.034358 0.114336
Epoch 10/300
1s - loss: 1598.9859 - val_loss: 7067.7272
Epoch 00009: val_loss improved from 7157.02515 to 7067.72724, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1556.2146      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.842978 0.260651
delta_x = 8.1483 delta_h = 0.994459
U_c = [[-0.01865149]] U_f = [[ 0.]] b_c = [ 0.33929959] b_f = [ 1.08383393]
incx.max(), incx.min(), incx.mean() 7.60087 -6.96608 3.46443
fgtx.max(), fgtx.min(), fgtx.mean() 2.2669 -2.28058 0.975591
delta mean, abs_mean, abs_mean+, abs_mean-: 0.396921 8.1483 6.21481 12.4018
W_c max, min, mean, abs_mean: 0.367336 -0.367004 0.109536 0.365968
W_f max, min, mean, abs_mean: 0.115575 -0.11526 0.0343329 0.114247
beijing_tanh+hardsigmoid7 7067.7272      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.906048 0.262186
delta_x = 10.2483 delta_h = 1.59348
U_c = [[-0.01865149]] U_f = [[ 0.]] b_c = [ 0.33929959] b_f = [ 1.08383393]
incx.max(), incx.min(), incx.mean() 7.57791 -6.94148 4.53021
fgtx.max(), fgtx.min(), fgtx.mean() 2.25973 -2.2729 1.3083
delta mean, abs_mean, abs_mean+, abs_mean-: -0.778088 10.2483 6.1586 23.8519
W_c max, min, mean, abs_mean: 0.367336 -0.367004 0.109536 0.365968
W_f max, min, mean, abs_mean: 0.115575 -0.11526 0.0343329 0.114247
Epoch 11/300
1s - loss: 1594.6596 - val_loss: 7099.0254
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1584.9824 - val_loss: 7443.6186
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1580.7580 - val_loss: 6920.2891
Epoch 00012: val_loss improved from 7067.72724 to 6920.28914, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1527.2250      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.16  0.76
forget mean min: 0.849679 0.264141
delta_x = 8.05227 delta_h = 0.769725
U_c = [[-0.01489347]] U_f = [[ 0.]] b_c = [ 0.35837573] b_f = [ 1.08948457]
incx.max(), incx.min(), incx.mean() 7.98893 -7.32353 3.56053
fgtx.max(), fgtx.min(), fgtx.mean() 2.25361 -2.26878 0.94572
delta mean, abs_mean, abs_mean+, abs_mean-: 0.313033 8.05227 6.20737 11.8634
W_c max, min, mean, abs_mean: 0.386638 -0.386294 0.115326 0.385257
W_f max, min, mean, abs_mean: 0.115117 -0.114791 0.0341951 0.113782
beijing_tanh+hardsigmoid7 6920.2890      0.85  0.12  0.76      0.85  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.911287 0.267261
delta_x = 9.74975 delta_h = 1.22401
U_c = [[-0.01489347]] U_f = [[ 0.]] b_c = [ 0.35837573] b_f = [ 1.08948457]
incx.max(), incx.min(), incx.mean() 7.95645 -7.27072 4.56634
fgtx.max(), fgtx.min(), fgtx.mean() 2.24402 -2.25318 1.24277
delta mean, abs_mean, abs_mean+, abs_mean-: -0.963632 9.74975 5.97036 20.276
W_c max, min, mean, abs_mean: 0.386638 -0.386294 0.115326 0.385257
W_f max, min, mean, abs_mean: 0.115117 -0.114791 0.0341951 0.113782
Epoch 14/300
1s - loss: 1574.2149 - val_loss: 6919.7876
Epoch 00013: val_loss improved from 6920.28914 to 6919.78757, saving model to beijing_tanh+hardsigmoid7_weights.hdf5
beijing_tanh+hardsigmoid7 1511.2220      0.87  0.21  0.71      0.88  0.19  0.73      0.88  0.16  0.76
forget mean min: 0.848273 0.26099
delta_x = 8.0951 delta_h = 0.620241
U_c = [[-0.01200383]] U_f = [[ 0.]] b_c = [ 0.36397907] b_f = [ 1.08934498]
incx.max(), incx.min(), incx.mean() 8.12267 -7.43619 3.55523
fgtx.max(), fgtx.min(), fgtx.mean() 2.27224 -2.28439 0.9346
delta mean, abs_mean, abs_mean+, abs_mean-: 0.253412 8.0951 6.21679 11.9337
W_c max, min, mean, abs_mean: 0.392614 -0.392265 0.117119 0.391226
W_f max, min, mean, abs_mean: 0.115915 -0.115586 0.0344322 0.114576
beijing_tanh+hardsigmoid7 6919.7876      0.84  0.11  0.76      0.84  0.08  0.79      0.87  0.06  0.82
forget mean min: 0.908967 0.264245
delta_x = 9.78929 delta_h = 0.998561
U_c = [[-0.01200383]] U_f = [[ 0.]] b_c = [ 0.36397907] b_f = [ 1.08934498]
incx.max(), incx.min(), incx.mean() 8.08202 -7.38063 4.55518
fgtx.max(), fgtx.min(), fgtx.mean() 2.26034 -2.26812 1.22745
delta mean, abs_mean, abs_mean+, abs_mean-: -1.05735 9.78929 6.00908 19.8338
W_c max, min, mean, abs_mean: 0.392614 -0.392265 0.117119 0.391226
W_f max, min, mean, abs_mean: 0.115915 -0.115586 0.0344322 0.114576
Epoch 15/300
1s - loss: 1561.2705 - val_loss: 6962.3823
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1554.3421 - val_loss: 7257.3715
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1550.5409 - val_loss: 7273.7533
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1546.8643 - val_loss: 7229.6689
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1546.1866 - val_loss: 7265.6824
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1539.6607 - val_loss: 7278.0027
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1536.9935 - val_loss: 7309.5657
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1528.4130 - val_loss: 7334.3204
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1533.9532 - val_loss: 7180.1730
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1524.0479 - val_loss: 7485.4217
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1512.7081 - val_loss: 7292.0494
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1505.9115 - val_loss: 7554.5405
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1485.4444 - val_loss: 7299.9017
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1460.4397 - val_loss: 7353.0766
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1440.6241 - val_loss: 7298.5040
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1411.5401 - val_loss: 7241.3950
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1380.8049 - val_loss: 7238.1205
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1345.8940 - val_loss: 7844.7974
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1319.3564 - val_loss: 7330.0094
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1285.9367 - val_loss: 8124.3230
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1255.8643 - val_loss: 8182.3739
Epoch 00034: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid8
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid8 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid829822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5999.3327 - val_loss: 9686.4124
Epoch 00000: val_loss improved from inf to 9686.41240, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 3326.5419      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.813026 0.31496
delta_x = 4.41888 delta_h = 2.29727
U_c = [[-0.06498225]] U_f = [[ 0.]] b_c = [ 0.12173418] b_f = [ 1.09487653]
incx.max(), incx.min(), incx.mean() 2.91159 -2.76134 1.10558
fgtx.max(), fgtx.min(), fgtx.mean() 1.95476 -2.02007 0.689346
delta mean, abs_mean, abs_mean+, abs_mean-: -1.25794 4.41888 2.56114 7.41286
W_c max, min, mean, abs_mean: 0.149232 -0.149077 -0.0293848 0.148098
W_f max, min, mean, abs_mean: 0.104533 -0.104322 -0.0208469 0.103768
beijing_tanh+hardsigmoid8 9686.4124      0.80  0.09  0.74      0.80  0.05  0.76      0.80  0.03  0.78
forget mean min: 0.844613 0.315701
delta_x = 6.5748 delta_h = 4.25371
U_c = [[-0.06498225]] U_f = [[ 0.]] b_c = [ 0.12173418] b_f = [ 1.09487653]
incx.max(), incx.min(), incx.mean() 2.90884 -2.75605 1.33965
fgtx.max(), fgtx.min(), fgtx.mean() 1.95283 -2.01637 0.853352
delta mean, abs_mean, abs_mean+, abs_mean-: -3.37769 6.5748 2.60942 12.8455
W_c max, min, mean, abs_mean: 0.149232 -0.149077 -0.0293848 0.148098
W_f max, min, mean, abs_mean: 0.104533 -0.104322 -0.0208469 0.103768
Epoch 2/300
1s - loss: 2439.9429 - val_loss: 10664.5380
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1836.9749 - val_loss: 9240.9288
Epoch 00002: val_loss improved from 9686.41240 to 9240.92880, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1742.2425      0.85  0.24  0.67      0.86  0.22  0.69      0.86  0.19  0.72
forget mean min: 0.854583 0.417157
delta_x = 6.76092 delta_h = 0.739399
U_c = [[-0.014486]] U_f = [[ 0.]] b_c = [ 0.27614906] b_f = [ 1.10688305]
incx.max(), incx.min(), incx.mean() 6.30667 -5.76674 3.06198
fgtx.max(), fgtx.min(), fgtx.mean() 1.51798 -1.5211 0.701238
delta mean, abs_mean, abs_mean+, abs_mean-: 0.216167 6.76092 5.25661 9.72903
W_c max, min, mean, abs_mean: 0.303688 -0.303528 -0.06028 0.302555
W_f max, min, mean, abs_mean: 0.0769242 -0.0767277 -0.0153338 0.0761583
beijing_tanh+hardsigmoid8 9240.9287      0.80  0.15  0.70      0.80  0.11  0.72      0.82  0.08  0.77
forget mean min: 0.90915 0.417932
delta_x = 8.58612 delta_h = 1.20496
U_c = [[-0.014486]] U_f = [[ 0.]] b_c = [ 0.27614906] b_f = [ 1.10688305]
incx.max(), incx.min(), incx.mean() 6.30209 -5.75135 4.14759
fgtx.max(), fgtx.min(), fgtx.mean() 1.51683 -1.51722 0.974505
delta mean, abs_mean, abs_mean+, abs_mean-: -1.12053 8.58612 5.28068 16.5574
W_c max, min, mean, abs_mean: 0.303688 -0.303528 -0.06028 0.302555
W_f max, min, mean, abs_mean: 0.0769242 -0.0767277 -0.0153338 0.0761583
Epoch 4/300
1s - loss: 1703.9690 - val_loss: 9000.2943
Epoch 00003: val_loss improved from 9240.92880 to 9000.29430, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1652.3948      0.87  0.23  0.69      0.87  0.21  0.71      0.87  0.18  0.73
forget mean min: 0.854109 0.382973
delta_x = 7.61679 delta_h = 0.691855
U_c = [[-0.01290248]] U_f = [[ 0.]] b_c = [ 0.30557719] b_f = [ 1.10372913]
incx.max(), incx.min(), incx.mean() 6.93908 -6.34078 3.35172
fgtx.max(), fgtx.min(), fgtx.mean() 1.6856 -1.68886 0.774034
delta mean, abs_mean, abs_mean+, abs_mean-: 0.31964 7.61679 5.91231 11.0959
W_c max, min, mean, abs_mean: 0.333759 -0.333597 -0.0662948 0.332623
W_f max, min, mean, abs_mean: 0.085299 -0.0851037 -0.0170071 0.0845207
beijing_tanh+hardsigmoid8 9000.2941      0.83  0.16  0.72      0.83  0.13  0.74      0.86  0.10  0.79
forget mean min: 0.915411 0.383622
delta_x = 9.89113 delta_h = 1.14693
U_c = [[-0.01290248]] U_f = [[ 0.]] b_c = [ 0.30557719] b_f = [ 1.10372913]
incx.max(), incx.min(), incx.mean() 6.93533 -6.32801 4.62234
fgtx.max(), fgtx.min(), fgtx.mean() 1.68464 -1.68562 1.0969
delta mean, abs_mean, abs_mean+, abs_mean-: -0.701614 9.89113 6.0109 22.4807
W_c max, min, mean, abs_mean: 0.333759 -0.333597 -0.0662948 0.332623
W_f max, min, mean, abs_mean: 0.085299 -0.0851037 -0.0170071 0.0845207
Epoch 5/300
1s - loss: 1652.1672 - val_loss: 8109.3439
Epoch 00004: val_loss improved from 9000.29430 to 8109.34393, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1618.6249      0.87  0.22  0.70      0.87  0.19  0.72      0.87  0.16  0.74
forget mean min: 0.849275 0.343892
delta_x = 7.92246 delta_h = 1.00202
U_c = [[-0.01922055]] U_f = [[ 0.]] b_c = [ 0.31208608] b_f = [ 1.0942961]
incx.max(), incx.min(), incx.mean() 7.0905 -6.48214 3.35882
fgtx.max(), fgtx.min(), fgtx.mean() 1.87047 -1.87484 0.840732
delta mean, abs_mean, abs_mean+, abs_mean-: 0.287034 7.92246 6.01323 12.0288
W_c max, min, mean, abs_mean: 0.341137 -0.340973 -0.0677708 0.339998
W_f max, min, mean, abs_mean: 0.0946172 -0.0944218 -0.0188682 0.0938209
beijing_tanh+hardsigmoid8 8109.3439      0.84  0.15  0.73      0.84  0.12  0.75      0.87  0.09  0.80
forget mean min: 0.912042 0.344566
delta_x = 10.0943 delta_h = 1.63417
U_c = [[-0.01922055]] U_f = [[ 0.]] b_c = [ 0.31208608] b_f = [ 1.0942961]
incx.max(), incx.min(), incx.mean() 7.08457 -6.46992 4.58713
fgtx.max(), fgtx.min(), fgtx.mean() 1.86884 -1.87146 1.17968
delta mean, abs_mean, abs_mean+, abs_mean-: -0.689162 10.0943 6.1286 23.1716
W_c max, min, mean, abs_mean: 0.341137 -0.340973 -0.0677708 0.339998
W_f max, min, mean, abs_mean: 0.0946172 -0.0944218 -0.0188682 0.0938209
Epoch 6/300
1s - loss: 1630.0532 - val_loss: 7487.9812
Epoch 00005: val_loss improved from 8109.34393 to 7487.98122, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1591.1531      0.88  0.24  0.69      0.88  0.22  0.71      0.89  0.19  0.73
forget mean min: 0.84625 0.307677
delta_x = 8.12982 delta_h = 1.10211
U_c = [[-0.02076816]] U_f = [[ 0.]] b_c = [ 0.31750983] b_f = [ 1.09062839]
incx.max(), incx.min(), incx.mean() 7.21139 -6.59288 3.417
fgtx.max(), fgtx.min(), fgtx.mean() 2.04734 -2.05225 0.920484
delta mean, abs_mean, abs_mean+, abs_mean-: 0.403209 8.12982 6.15842 12.5756
W_c max, min, mean, abs_mean: 0.346968 -0.346802 -0.0689376 0.345826
W_f max, min, mean, abs_mean: 0.103511 -0.10332 -0.0206463 0.102703
beijing_tanh+hardsigmoid8 7487.9811      0.85  0.14  0.75      0.85  0.11  0.77      0.88  0.08  0.82
forget mean min: 0.906162 0.30834
delta_x = 10.3295 delta_h = 1.77208
U_c = [[-0.02076816]] U_f = [[ 0.]] b_c = [ 0.31750983] b_f = [ 1.09062839]
incx.max(), incx.min(), incx.mean() 7.19843 -6.58171 4.53783
fgtx.max(), fgtx.min(), fgtx.mean() 2.0435 -2.04893 1.25335
delta mean, abs_mean, abs_mean+, abs_mean-: -0.682674 10.3295 6.22923 24.3975
W_c max, min, mean, abs_mean: 0.346968 -0.346802 -0.0689376 0.345826
W_f max, min, mean, abs_mean: 0.103511 -0.10332 -0.0206463 0.102703
Epoch 7/300
1s - loss: 1619.6163 - val_loss: 7280.5957
Epoch 00006: val_loss improved from 7487.98122 to 7280.59575, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1580.1583      0.88  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.845164 0.286576
delta_x = 8.17419 delta_h = 1.14063
U_c = [[-0.02164093]] U_f = [[ 0.]] b_c = [ 0.32239753] b_f = [ 1.08806396]
incx.max(), incx.min(), incx.mean() 7.31148 -6.69085 3.44282
fgtx.max(), fgtx.min(), fgtx.mean() 2.14776 -2.15519 0.958911
delta mean, abs_mean, abs_mean+, abs_mean-: 0.403938 8.17419 6.19211 12.6414
W_c max, min, mean, abs_mean: 0.35218 -0.352014 -0.0699808 0.351036
W_f max, min, mean, abs_mean: 0.108692 -0.108504 -0.0216817 0.107874
beijing_tanh+hardsigmoid8 7280.5957      0.85  0.14  0.75      0.85  0.11  0.78      0.88  0.08  0.82
forget mean min: 0.906801 0.287476
delta_x = 10.2781 delta_h = 1.80823
U_c = [[-0.02164093]] U_f = [[ 0.]] b_c = [ 0.32239753] b_f = [ 1.08806396]
incx.max(), incx.min(), incx.mean() 7.29169 -6.6762 4.53371
fgtx.max(), fgtx.min(), fgtx.mean() 2.14168 -2.15069 1.29414
delta mean, abs_mean, abs_mean+, abs_mean-: -0.720236 10.2781 6.18875 24.1402
W_c max, min, mean, abs_mean: 0.35218 -0.352014 -0.0699808 0.351036
W_f max, min, mean, abs_mean: 0.108692 -0.108504 -0.0216817 0.107874
Epoch 8/300
1s - loss: 1611.7974 - val_loss: 7242.5307
Epoch 00007: val_loss improved from 7280.59575 to 7242.53070, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1579.7226      0.89  0.25  0.69      0.89  0.23  0.70      0.90  0.20  0.73
forget mean min: 0.842156 0.264058
delta_x = 8.31522 delta_h = 0.936133
U_c = [[-0.01704494]] U_f = [[ 0.]] b_c = [ 0.33075115] b_f = [ 1.08805549]
incx.max(), incx.min(), incx.mean() 7.48896 -6.8598 3.50115
fgtx.max(), fgtx.min(), fgtx.mean() 2.25757 -2.26777 0.999886
delta mean, abs_mean, abs_mean+, abs_mean-: 0.465519 8.31522 6.29113 12.9905
W_c max, min, mean, abs_mean: 0.361087 -0.360919 -0.0717628 0.35994
W_f max, min, mean, abs_mean: 0.114344 -0.114162 -0.0228119 0.113519
beijing_tanh+hardsigmoid8 7242.5307      0.85  0.13  0.76      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.903491 0.264961
delta_x = 10.5858 delta_h = 1.49726
U_c = [[-0.01704494]] U_f = [[ 0.]] b_c = [ 0.33075115] b_f = [ 1.08805549]
incx.max(), incx.min(), incx.mean() 7.47193 -6.84548 4.59363
fgtx.max(), fgtx.min(), fgtx.mean() 2.2522 -2.26325 1.34443
delta mean, abs_mean, abs_mean+, abs_mean-: -0.698952 10.5858 6.31148 26.031
W_c max, min, mean, abs_mean: 0.361087 -0.360919 -0.0717628 0.35994
W_f max, min, mean, abs_mean: 0.114344 -0.114162 -0.0228119 0.113519
Epoch 9/300
1s - loss: 1602.7880 - val_loss: 7168.9117
Epoch 00008: val_loss improved from 7242.53070 to 7168.91166, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1570.2369      0.89  0.25  0.69      0.89  0.23  0.70      0.90  0.20  0.74
forget mean min: 0.841982 0.2534
delta_x = 8.2613 delta_h = 0.93127
U_c = [[-0.0170428]] U_f = [[ 0.]] b_c = [ 0.33352634] b_f = [ 1.08844101]
incx.max(), incx.min(), incx.mean() 7.53541 -6.91228 3.48953
fgtx.max(), fgtx.min(), fgtx.mean() 2.30737 -2.32144 1.01113
delta mean, abs_mean, abs_mean+, abs_mean-: 0.44853 8.2613 6.27025 12.7884
W_c max, min, mean, abs_mean: 0.363981 -0.363812 -0.072342 0.362832
W_f max, min, mean, abs_mean: 0.117075 -0.116901 -0.0233585 0.116246
beijing_tanh+hardsigmoid8 7168.9117      0.85  0.13  0.75      0.85  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.905392 0.254621
delta_x = 10.4677 delta_h = 1.48513
U_c = [[-0.0170428]] U_f = [[ 0.]] b_c = [ 0.33352634] b_f = [ 1.08844101]
incx.max(), incx.min(), incx.mean() 7.52195 -6.89322 4.57066
fgtx.max(), fgtx.min(), fgtx.mean() 2.30306 -2.31534 1.35751
delta mean, abs_mean, abs_mean+, abs_mean-: -0.725465 10.4677 6.23592 25.5719
W_c max, min, mean, abs_mean: 0.363981 -0.363812 -0.072342 0.362832
W_f max, min, mean, abs_mean: 0.117075 -0.116901 -0.0233585 0.116246
Epoch 10/300
1s - loss: 1600.1402 - val_loss: 7232.2711
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1594.7637 - val_loss: 6995.5058
Epoch 00010: val_loss improved from 7168.91166 to 6995.50577, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1578.5612      0.90  0.26  0.69      0.90  0.24  0.70      0.91  0.21  0.73
forget mean min: 0.844793 0.24287
delta_x = 8.24295 delta_h = 0.931775
U_c = [[-0.01701935]] U_f = [[ 0.]] b_c = [ 0.34500629] b_f = [ 1.0932281]
incx.max(), incx.min(), incx.mean() 7.75578 -7.12805 3.56869
fgtx.max(), fgtx.min(), fgtx.mean() 2.35905 -2.37888 1.02619
delta mean, abs_mean, abs_mean+, abs_mean-: 0.532118 8.24295 6.31492 12.6319
W_c max, min, mean, abs_mean: 0.375635 -0.375466 -0.0746748 0.374485
W_f max, min, mean, abs_mean: 0.120039 -0.119873 -0.0239529 0.119209
beijing_tanh+hardsigmoid8 6995.5059      0.85  0.12  0.76      0.86  0.09  0.79      0.88  0.07  0.83
forget mean min: 0.905167 0.244718
delta_x = 10.3201 delta_h = 1.47827
U_c = [[-0.01701935]] U_f = [[ 0.]] b_c = [ 0.34500629] b_f = [ 1.0932281]
incx.max(), incx.min(), incx.mean() 7.74838 -7.09902 4.55249
fgtx.max(), fgtx.min(), fgtx.mean() 2.3567 -2.36964 1.33936
delta mean, abs_mean, abs_mean+, abs_mean-: -0.734233 10.3201 6.23241 23.9311
W_c max, min, mean, abs_mean: 0.375635 -0.375466 -0.0746748 0.374485
W_f max, min, mean, abs_mean: 0.120039 -0.119873 -0.0239529 0.119209
Epoch 12/300
1s - loss: 1585.1327 - val_loss: 7037.7202
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1578.8887 - val_loss: 7207.1864
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1563.6226 - val_loss: 7034.7886
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1559.3802 - val_loss: 7063.1083
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1546.2233 - val_loss: 6968.4915
Epoch 00015: val_loss improved from 6995.50577 to 6968.49153, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1511.4123      0.89  0.23  0.70      0.89  0.20  0.73      0.90  0.17  0.75
forget mean min: 0.845809 0.244302
delta_x = 8.45098 delta_h = 0.528608
U_c = [[-0.00978319]] U_f = [[ 0.]] b_c = [ 0.37773564] b_f = [ 1.09595621]
incx.max(), incx.min(), incx.mean() 8.44498 -7.73123 3.69136
fgtx.max(), fgtx.min(), fgtx.mean() 2.36223 -2.37445 0.970286
delta mean, abs_mean, abs_mean+, abs_mean-: 0.374065 8.45098 6.505 12.5546
W_c max, min, mean, abs_mean: 0.407846 -0.407679 -0.0811246 0.406707
W_f max, min, mean, abs_mean: 0.119942 -0.119756 -0.0239265 0.119091
beijing_tanh+hardsigmoid8 6968.4915      0.84  0.11  0.76      0.84  0.08  0.79      0.87  0.06  0.83
forget mean min: 0.904214 0.247201
delta_x = 10.4197 delta_h = 0.865448
U_c = [[-0.00978319]] U_f = [[ 0.]] b_c = [ 0.37773564] b_f = [ 1.09595621]
incx.max(), incx.min(), incx.mean() 8.40552 -7.68173 4.66429
fgtx.max(), fgtx.min(), fgtx.mean() 2.35068 -2.35995 1.25518
delta mean, abs_mean, abs_mean+, abs_mean-: -0.946876 10.4197 6.34409 22.4271
W_c max, min, mean, abs_mean: 0.407846 -0.407679 -0.0811246 0.406707
W_f max, min, mean, abs_mean: 0.119942 -0.119756 -0.0239265 0.119091
Epoch 17/300
1s - loss: 1546.4449 - val_loss: 7043.4441
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1542.8502 - val_loss: 7406.6675
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1535.3978 - val_loss: 7165.0302
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1533.0877 - val_loss: 7590.8077
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1532.7781 - val_loss: 7263.3129
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1520.9527 - val_loss: 7462.9011
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1520.6209 - val_loss: 7391.7677
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1502.0756 - val_loss: 7476.8553
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1496.0579 - val_loss: 7097.0362
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1484.6341 - val_loss: 7406.1247
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1461.0044 - val_loss: 7106.7441
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 1449.8118 - val_loss: 7306.3559
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1424.2051 - val_loss: 6960.1545
Epoch 00028: val_loss improved from 6968.49153 to 6960.15445, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1375.5676      0.88  0.21  0.71      0.89  0.19  0.74      0.90  0.15  0.77
forget mean min: 0.852828 0.154029
delta_x = 8.74495 delta_h = 0.315168
U_c = [[-0.00585744]] U_f = [[ 0.]] b_c = [ 0.45140275] b_f = [ 1.09427142]
incx.max(), incx.min(), incx.mean() 9.55134 -8.76233 4.02068
fgtx.max(), fgtx.min(), fgtx.mean() 2.78924 -2.82413 1.09403
delta mean, abs_mean, abs_mean+, abs_mean-: 0.314616 8.74495 6.69372 13.0388
W_c max, min, mean, abs_mean: 0.466707 -0.466547 -0.0929389 0.465652
W_f max, min, mean, abs_mean: 0.144825 -0.145836 -0.0282045 0.142728
beijing_tanh+hardsigmoid8 6960.1545      0.84  0.11  0.76      0.84  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.912737 0.180102
delta_x = 10.4475 delta_h = 0.519385
U_c = [[-0.00585744]] U_f = [[ 0.]] b_c = [ 0.45140275] b_f = [ 1.09427142]
incx.max(), incx.min(), incx.mean() 9.48158 -8.33705 4.9977
fgtx.max(), fgtx.min(), fgtx.mean() 2.76786 -2.69376 1.3935
delta mean, abs_mean, abs_mean+, abs_mean-: -0.971623 10.4475 6.60348 20.2104
W_c max, min, mean, abs_mean: 0.466707 -0.466547 -0.0929389 0.465652
W_f max, min, mean, abs_mean: 0.144825 -0.145836 -0.0282045 0.142728
Epoch 30/300
1s - loss: 1407.2252 - val_loss: 7287.1961
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1385.5393 - val_loss: 6869.0697
Epoch 00030: val_loss improved from 6960.15445 to 6869.06974, saving model to beijing_tanh+hardsigmoid8_weights.hdf5
beijing_tanh+hardsigmoid8 1322.0831      0.88  0.21  0.72      0.89  0.18  0.75      0.90  0.15  0.78
forget mean min: 0.855668 0.130465
delta_x = 8.73589 delta_h = 0.296075
U_c = [[-0.0055358]] U_f = [[ 0.]] b_c = [ 0.47244978] b_f = [ 1.08517611]
incx.max(), incx.min(), incx.mean() 9.9011 -9.08206 4.10629
fgtx.max(), fgtx.min(), fgtx.mean() 2.89421 -2.93285 1.11545
delta mean, abs_mean, abs_mean+, abs_mean-: 0.306511 8.73589 6.71154 12.9144
W_c max, min, mean, abs_mean: 0.485611 -0.48579 -0.0967874 0.484618
W_f max, min, mean, abs_mean: 0.151756 -0.153068 -0.0292211 0.148759
beijing_tanh+hardsigmoid8 6869.0698      0.85  0.10  0.77      0.85  0.08  0.79      0.87  0.05  0.83
forget mean min: 0.909655 0.166061
delta_x = 10.2345 delta_h = 0.472638
U_c = [[-0.0055358]] U_f = [[ 0.]] b_c = [ 0.47244978] b_f = [ 1.08517611]
incx.max(), incx.min(), incx.mean() 9.80144 -8.50231 4.97833
fgtx.max(), fgtx.min(), fgtx.mean() 2.86362 -2.75487 1.38316
delta mean, abs_mean, abs_mean+, abs_mean-: -1.11624 10.2345 6.636 18.1342
W_c max, min, mean, abs_mean: 0.485611 -0.48579 -0.0967874 0.484618
W_f max, min, mean, abs_mean: 0.151756 -0.153068 -0.0292211 0.148759
Epoch 32/300
1s - loss: 1360.7338 - val_loss: 7206.2063
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1333.2220 - val_loss: 7971.5068
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1313.6041 - val_loss: 7604.5698
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1290.6885 - val_loss: 7693.4857
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 1274.1463 - val_loss: 7738.9373
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 1249.8528 - val_loss: 8877.1378
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 1230.7177 - val_loss: 7451.9256
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 1211.5695 - val_loss: 8158.6278
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 1193.7329 - val_loss: 8306.0480
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 1174.2280 - val_loss: 7903.0132
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 1158.0003 - val_loss: 8287.1808
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 1152.8249 - val_loss: 8672.2501
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 1130.2302 - val_loss: 8012.6869
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 1122.7175 - val_loss: 8039.7804
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 1107.9734 - val_loss: 7690.7578
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 1102.7510 - val_loss: 7498.9520
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 1086.1145 - val_loss: 7660.8857
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 1078.9398 - val_loss: 7215.8797
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 1073.7128 - val_loss: 7660.8218
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 1059.3849 - val_loss: 7572.0010
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 1052.9171 - val_loss: 7299.8687
Epoch 00051: val_loss did not improve
X_train[0].shape = (7032, 40, 23)

training beijing_tanh+hardsigmoid9
Train on 7032 samples, validate on 1392 samples
Before training:
beijing_tanh+hardsigmoid9 9689.3936      0.03  -nan  0.02      0.03  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
delta_x = 3.9477 delta_h = 2.55015
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -3.9477 3.9477 nan 3.9477
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
beijing_tanh+hardsigmoid929822.4830      0.05  -nan  0.05      0.06  -nan  0.06      0.04  -nan  0.04
forget mean min: 0.7 0.7
delta_x = 8.27027 delta_h = 5.12867
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
delta mean, abs_mean, abs_mean+, abs_mean-: -8.27027 8.27027 nan 8.27027
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5934.4886 - val_loss: 9791.6614
Epoch 00000: val_loss improved from inf to 9791.66138, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 3295.2520      0.55  0.22  0.48      0.55  0.20  0.49      0.53  0.18  0.48
forget mean min: 0.813658 0.314965
delta_x = 4.38854 delta_h = 2.20952
U_c = [[-0.0619291]] U_f = [[ 0.]] b_c = [ 0.12256195] b_f = [ 1.09424615]
incx.max(), incx.min(), incx.mean() 2.90774 -2.76134 1.1115
fgtx.max(), fgtx.min(), fgtx.mean() 1.95029 -2.01942 0.692496
delta mean, abs_mean, abs_mean+, abs_mean-: -1.21696 4.38854 2.55707 7.37872
W_c max, min, mean, abs_mean: 0.149573 -0.149937 -0.0150619 0.148089
W_f max, min, mean, abs_mean: 0.104522 -0.104382 -0.0106125 0.103698
beijing_tanh+hardsigmoid9 9791.6615      0.79  0.09  0.73      0.79  0.05  0.76      0.80  0.03  0.78
forget mean min: 0.844821 0.31568
delta_x = 6.56665 delta_h = 4.07929
U_c = [[-0.0619291]] U_f = [[ 0.]] b_c = [ 0.12256195] b_f = [ 1.09424615]
incx.max(), incx.min(), incx.mean() 2.90781 -2.75624 1.3361
fgtx.max(), fgtx.min(), fgtx.mean() 1.95034 -2.01585 0.84977
delta mean, abs_mean, abs_mean+, abs_mean-: -3.39355 6.56665 2.60542 12.735
W_c max, min, mean, abs_mean: 0.149573 -0.149937 -0.0150619 0.148089
W_f max, min, mean, abs_mean: 0.104522 -0.104382 -0.0106125 0.103698
Epoch 2/300
1s - loss: 2447.4772 - val_loss: 11015.4002
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 1857.1049 - val_loss: 9561.7086
Epoch 00002: val_loss improved from 9791.66138 to 9561.70863, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1746.8873      0.85  0.24  0.67      0.86  0.23  0.69      0.86  0.19  0.72
forget mean min: 0.851397 0.411266
delta_x = 6.84938 delta_h = 0.606869
U_c = [[-0.01148448]] U_f = [[ 0.]] b_c = [ 0.27891374] b_f = [ 1.10780978]
incx.max(), incx.min(), incx.mean() 6.33838 -5.7948 3.00954
fgtx.max(), fgtx.min(), fgtx.mean() 1.54784 -1.55148 0.697512
delta mean, abs_mean, abs_mean+, abs_mean-: 0.244041 6.84938 5.32922 9.8741
W_c max, min, mean, abs_mean: 0.305699 -0.306091 -0.0306779 0.304231
W_f max, min, mean, abs_mean: 0.0785477 -0.0784444 -0.00801324 0.0777135
beijing_tanh+hardsigmoid9 9561.7086      0.79  0.14  0.70      0.79  0.11  0.72      0.82  0.08  0.76
forget mean min: 0.906446 0.412021
delta_x = 8.85388 delta_h = 1.00047
U_c = [[-0.01148448]] U_f = [[ 0.]] b_c = [ 0.27891374] b_f = [ 1.10780978]
incx.max(), incx.min(), incx.mean() 6.33434 -5.78 4.09536
fgtx.max(), fgtx.min(), fgtx.mean() 1.54681 -1.5477 0.974876
delta mean, abs_mean, abs_mean+, abs_mean-: -1.104 8.85388 5.38813 17.7289
W_c max, min, mean, abs_mean: 0.305699 -0.306091 -0.0306779 0.304231
W_f max, min, mean, abs_mean: 0.0785477 -0.0784444 -0.00801324 0.0777135
Epoch 4/300
1s - loss: 1713.8413 - val_loss: 8668.5828
Epoch 00003: val_loss improved from 9561.70863 to 8668.58282, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1661.8281      0.88  0.26  0.68      0.89  0.24  0.69      0.89  0.21  0.72
forget mean min: 0.854142 0.3702
delta_x = 7.68183 delta_h = 0.860075
U_c = [[-0.01590102]] U_f = [[ 0.]] b_c = [ 0.30726156] b_f = [ 1.10800672]
incx.max(), incx.min(), incx.mean() 6.94079 -6.34092 3.36385
fgtx.max(), fgtx.min(), fgtx.mean() 1.75313 -1.75701 0.807802
delta mean, abs_mean, abs_mean+, abs_mean-: 0.443386 7.68183 5.93451 11.4741
W_c max, min, mean, abs_mean: 0.334275 -0.334671 -0.0335365 0.332809
W_f max, min, mean, abs_mean: 0.0887967 -0.088691 -0.00903693 0.0879561
beijing_tanh+hardsigmoid9 8668.5829      0.84  0.15  0.73      0.84  0.12  0.75      0.87  0.09  0.80
forget mean min: 0.912366 0.370915
delta_x = 9.92983 delta_h = 1.39734
U_c = [[-0.01590102]] U_f = [[ 0.]] b_c = [ 0.30726156] b_f = [ 1.10800672]
incx.max(), incx.min(), incx.mean() 6.93686 -6.3274 4.53933
fgtx.max(), fgtx.min(), fgtx.mean() 1.75209 -1.75343 1.11846
delta mean, abs_mean, abs_mean+, abs_mean-: -0.646121 9.92983 6.06212 22.5707
W_c max, min, mean, abs_mean: 0.334275 -0.334671 -0.0335365 0.332809
W_f max, min, mean, abs_mean: 0.0887967 -0.088691 -0.00903693 0.0879561
Epoch 5/300
1s - loss: 1654.8866 - val_loss: 7799.9009
Epoch 00004: val_loss improved from 8668.58282 to 7799.90092, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1621.0089      0.88  0.24  0.68      0.88  0.22  0.70      0.88  0.19  0.73
forget mean min: 0.849396 0.337637
delta_x = 7.89031 delta_h = 1.17634
U_c = [[-0.02237237]] U_f = [[ 0.]] b_c = [ 0.31394464] b_f = [ 1.10199153]
incx.max(), incx.min(), incx.mean() 7.09098 -6.48066 3.36812
fgtx.max(), fgtx.min(), fgtx.mean() 1.90886 -1.91381 0.860251
delta mean, abs_mean, abs_mean+, abs_mean-: 0.417202 7.89031 6.03702 11.978
W_c max, min, mean, abs_mean: 0.341586 -0.341987 -0.0342686 0.340122
W_f max, min, mean, abs_mean: 0.0966489 -0.0965398 -0.00982109 0.0958008
beijing_tanh+hardsigmoid9 7799.9008      0.85  0.14  0.75      0.86  0.11  0.77      0.88  0.09  0.82
forget mean min: 0.907583 0.338303
delta_x = 10.1649 delta_h = 1.92387
U_c = [[-0.02237237]] U_f = [[ 0.]] b_c = [ 0.31394464] b_f = [ 1.10199153]
incx.max(), incx.min(), incx.mean() 7.08554 -6.46883 4.52628
fgtx.max(), fgtx.min(), fgtx.mean() 1.90732 -1.91048 1.18647
delta mean, abs_mean, abs_mean+, abs_mean-: -0.57696 10.1649 6.19953 23.6892
W_c max, min, mean, abs_mean: 0.341586 -0.341987 -0.0342686 0.340122
W_f max, min, mean, abs_mean: 0.0966489 -0.0965398 -0.00982109 0.0958008
Epoch 6/300
1s - loss: 1633.2583 - val_loss: 7613.3353
Epoch 00005: val_loss improved from 7799.90092 to 7613.33526, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1606.2964      0.89  0.25  0.68      0.89  0.23  0.70      0.89  0.20  0.73
forget mean min: 0.845876 0.302156
delta_x = 8.16227 delta_h = 0.989819
U_c = [[-0.01813445]] U_f = [[ 0.]] b_c = [ 0.32238412] b_f = [ 1.09589243]
incx.max(), incx.min(), incx.mean() 7.28325 -6.65704 3.44623
fgtx.max(), fgtx.min(), fgtx.mean() 2.07957 -2.08511 0.93325
delta mean, abs_mean, abs_mean+, abs_mean-: 0.462796 8.16227 6.19566 12.666
W_c max, min, mean, abs_mean: 0.350819 -0.351224 -0.0351931 0.349358
W_f max, min, mean, abs_mean: 0.105227 -0.105111 -0.0106771 0.104371
beijing_tanh+hardsigmoid9 7613.3353      0.85  0.14  0.75      0.86  0.11  0.78      0.88  0.08  0.82
forget mean min: 0.904506 0.302837
delta_x = 10.4702 delta_h = 1.60729
U_c = [[-0.01813445]] U_f = [[ 0.]] b_c = [ 0.32238412] b_f = [ 1.09589243]
incx.max(), incx.min(), incx.mean() 7.27255 -6.64564 4.57041
fgtx.max(), fgtx.min(), fgtx.mean() 2.07637 -2.08171 1.2691
delta mean, abs_mean, abs_mean+, abs_mean-: -0.616479 10.4702 6.30679 25.3346
W_c max, min, mean, abs_mean: 0.350819 -0.351224 -0.0351931 0.349358
W_f max, min, mean, abs_mean: 0.105227 -0.105111 -0.0106771 0.104371
Epoch 7/300
1s - loss: 1616.5706 - val_loss: 7297.5316
Epoch 00006: val_loss improved from 7613.33526 to 7297.53156, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1581.2279      0.88  0.24  0.69      0.88  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.845389 0.29203
delta_x = 8.16655 delta_h = 1.1171
U_c = [[-0.02132355]] U_f = [[ 0.]] b_c = [ 0.32687372] b_f = [ 1.08985901]
incx.max(), incx.min(), incx.mean() 7.38304 -6.74874 3.43335
fgtx.max(), fgtx.min(), fgtx.mean() 2.12386 -2.12971 0.935022
delta mean, abs_mean, abs_mean+, abs_mean-: 0.36479 8.16655 6.18373 12.5762
W_c max, min, mean, abs_mean: 0.355731 -0.356141 -0.0356857 0.354273
W_f max, min, mean, abs_mean: 0.107495 -0.107373 -0.0109022 0.106634
beijing_tanh+hardsigmoid9 7297.5317      0.85  0.13  0.75      0.85  0.10  0.77      0.88  0.07  0.82
forget mean min: 0.905029 0.293018
delta_x = 10.1952 delta_h = 1.77826
U_c = [[-0.02132355]] U_f = [[ 0.]] b_c = [ 0.32687372] b_f = [ 1.08985901]
incx.max(), incx.min(), incx.mean() 7.351 -6.73232 4.50033
fgtx.max(), fgtx.min(), fgtx.mean() 2.11421 -2.12477 1.25618
delta mean, abs_mean, abs_mean+, abs_mean-: -0.781752 10.1952 6.18573 22.9549
W_c max, min, mean, abs_mean: 0.355731 -0.356141 -0.0356857 0.354273
W_f max, min, mean, abs_mean: 0.107495 -0.107373 -0.0109022 0.106634
Epoch 8/300
1s - loss: 1608.6098 - val_loss: 7124.3514
Epoch 00007: val_loss improved from 7297.53156 to 7124.35139, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1568.7485      0.89  0.24  0.69      0.89  0.22  0.71      0.89  0.19  0.74
forget mean min: 0.84399 0.273006
delta_x = 8.22773 delta_h = 1.11232
U_c = [[-0.02092504]] U_f = [[ 0.]] b_c = [ 0.33323035] b_f = [ 1.08896565]
incx.max(), incx.min(), incx.mean() 7.50915 -6.86917 3.47596
fgtx.max(), fgtx.min(), fgtx.mean() 2.21576 -2.22393 0.970399
delta mean, abs_mean, abs_mean+, abs_mean-: 0.418265 8.22773 6.24501 12.6873
W_c max, min, mean, abs_mean: 0.362123 -0.362537 -0.0363261 0.360666
W_f max, min, mean, abs_mean: 0.112231 -0.112105 -0.0113743 0.111365
beijing_tanh+hardsigmoid9 7124.3514      0.85  0.13  0.75      0.86  0.10  0.78      0.88  0.07  0.82
forget mean min: 0.906437 0.274177
delta_x = 10.3631 delta_h = 1.77636
U_c = [[-0.02092504]] U_f = [[ 0.]] b_c = [ 0.33323035] b_f = [ 1.08896565]
incx.max(), incx.min(), incx.mean() 7.47563 -6.85021 4.57534
fgtx.max(), fgtx.min(), fgtx.mean() 2.20541 -2.21808 1.30986
delta mean, abs_mean, abs_mean+, abs_mean-: -0.697486 10.3631 6.23862 24.5419
W_c max, min, mean, abs_mean: 0.362123 -0.362537 -0.0363261 0.360666
W_f max, min, mean, abs_mean: 0.112231 -0.112105 -0.0113743 0.111365
Epoch 9/300
1s - loss: 1604.0790 - val_loss: 7246.2465
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1600.3731 - val_loss: 7145.1291
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1596.9413 - val_loss: 7204.7947
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1585.3089 - val_loss: 7135.2706
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1572.2704 - val_loss: 7083.3160
Epoch 00012: val_loss improved from 7124.35139 to 7083.31598, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1510.3681      0.87  0.21  0.70      0.88  0.19  0.73      0.88  0.15  0.76
forget mean min: 0.849885 0.267076
delta_x = 8.07328 delta_h = 0.571482
U_c = [[-0.0110161]] U_f = [[ 0.]] b_c = [ 0.36032534] b_f = [ 1.09181488]
incx.max(), incx.min(), incx.mean() 8.07167 -7.39219 3.56059
fgtx.max(), fgtx.min(), fgtx.mean() 2.24445 -2.25643 0.93146
delta mean, abs_mean, abs_mean+, abs_mean-: 0.258492 8.07328 6.19511 11.9291
W_c max, min, mean, abs_mean: 0.390314 -0.390746 -0.0391508 0.388867
W_f max, min, mean, abs_mean: 0.11407 -0.113944 -0.0115595 0.113183
beijing_tanh+hardsigmoid9 7083.3161      0.83  0.12  0.75      0.83  0.09  0.77      0.86  0.06  0.82
forget mean min: 0.910244 0.270394
delta_x = 9.81138 delta_h = 0.925707
U_c = [[-0.0110161]] U_f = [[ 0.]] b_c = [ 0.36032534] b_f = [ 1.09181488]
incx.max(), incx.min(), incx.mean() 8.03136 -7.3352 4.55924
fgtx.max(), fgtx.min(), fgtx.mean() 2.23272 -2.23985 1.22213
delta mean, abs_mean, abs_mean+, abs_mean-: -1.04946 9.81138 5.97975 20.3107
W_c max, min, mean, abs_mean: 0.390314 -0.390746 -0.0391508 0.388867
W_f max, min, mean, abs_mean: 0.11407 -0.113944 -0.0115595 0.113183
Epoch 14/300
1s - loss: 1558.5146 - val_loss: 7046.9730
Epoch 00013: val_loss improved from 7083.31598 to 7046.97300, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1492.5738      0.88  0.21  0.71      0.88  0.19  0.73      0.89  0.16  0.76
forget mean min: 0.849181 0.266064
delta_x = 8.21483 delta_h = 0.459296
U_c = [[-0.00878196]] U_f = [[ 0.]] b_c = [ 0.36993867] b_f = [ 1.09270775]
incx.max(), incx.min(), incx.mean() 8.26644 -7.56891 3.61837
fgtx.max(), fgtx.min(), fgtx.mean() 2.25032 -2.26239 0.925725
delta mean, abs_mean, abs_mean+, abs_mean-: 0.250498 8.21483 6.31197 12.0883
W_c max, min, mean, abs_mean: 0.399684 -0.400118 -0.0400886 0.398238
W_f max, min, mean, abs_mean: 0.114378 -0.114257 -0.0115917 0.113489
beijing_tanh+hardsigmoid9 7046.9729      0.84  0.11  0.76      0.84  0.08  0.78      0.86  0.06  0.82
forget mean min: 0.908577 0.269306
delta_x = 9.90935 delta_h = 0.743652
U_c = [[-0.00878196]] U_f = [[ 0.]] b_c = [ 0.36993867] b_f = [ 1.09270775]
incx.max(), incx.min(), incx.mean() 8.22529 -7.51202 4.62262
fgtx.max(), fgtx.min(), fgtx.mean() 2.23859 -2.24618 1.21191
delta mean, abs_mean, abs_mean+, abs_mean-: -1.08284 9.90935 6.07566 20.0868
W_c max, min, mean, abs_mean: 0.399684 -0.400118 -0.0400886 0.398238
W_f max, min, mean, abs_mean: 0.114378 -0.114257 -0.0115917 0.113489
Epoch 15/300
1s - loss: 1557.5797 - val_loss: 7043.2817
Epoch 00014: val_loss improved from 7046.97300 to 7043.28173, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1486.3174      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.16  0.76
forget mean min: 0.848588 0.253933
delta_x = 8.29846 delta_h = 0.466684
U_c = [[-0.0088778]] U_f = [[ 0.]] b_c = [ 0.37372479] b_f = [ 1.09759593]
incx.max(), incx.min(), incx.mean() 8.34085 -7.63485 3.64522
fgtx.max(), fgtx.min(), fgtx.mean() 2.31588 -2.32793 0.950957
delta mean, abs_mean, abs_mean+, abs_mean-: 0.282379 8.29846 6.36802 12.285
W_c max, min, mean, abs_mean: 0.403238 -0.403672 -0.0404439 0.401792
W_f max, min, mean, abs_mean: 0.117683 -0.117564 -0.0119228 0.116793
beijing_tanh+hardsigmoid9 7043.2817      0.83  0.10  0.76      0.84  0.07  0.78      0.86  0.05  0.82
forget mean min: 0.907066 0.257333
delta_x = 9.9598 delta_h = 0.749751
U_c = [[-0.0088778]] U_f = [[ 0.]] b_c = [ 0.37372479] b_f = [ 1.09759593]
incx.max(), incx.min(), incx.mean() 8.29752 -7.57636 4.59374
fgtx.max(), fgtx.min(), fgtx.mean() 2.30329 -2.31093 1.22667
delta mean, abs_mean, abs_mean+, abs_mean-: -1.10703 9.9598 6.15061 19.7387
W_c max, min, mean, abs_mean: 0.403238 -0.403672 -0.0404439 0.401792
W_f max, min, mean, abs_mean: 0.117683 -0.117564 -0.0119228 0.116793
Epoch 16/300
1s - loss: 1543.6662 - val_loss: 7316.3383
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1551.0847 - val_loss: 7270.9054
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1532.1809 - val_loss: 7359.1223
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1536.0282 - val_loss: 7322.9258
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1527.5480 - val_loss: 7186.3233
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1524.8847 - val_loss: 7046.1288
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1515.0247 - val_loss: 7049.5674
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1490.1092 - val_loss: 7246.8011
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1473.3273 - val_loss: 7212.8433
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1456.0549 - val_loss: 7195.8941
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1434.9819 - val_loss: 7053.2922
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1406.4037 - val_loss: 6873.4839
Epoch 00026: val_loss improved from 7043.28173 to 6873.48385, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1333.0750      0.88  0.21  0.71      0.89  0.18  0.74      0.90  0.15  0.78
forget mean min: 0.849807 0.133025
delta_x = 8.68793 delta_h = 0.424092
U_c = [[-0.0080082]] U_f = [[ 0.]] b_c = [ 0.45448536] b_f = [ 1.102934]
incx.max(), incx.min(), incx.mean() 9.74272 -8.93128 3.9599
fgtx.max(), fgtx.min(), fgtx.mean() 2.90728 -2.93781 1.0972
delta mean, abs_mean, abs_mean+, abs_mean-: 0.300046 8.68793 6.71884 12.6653
W_c max, min, mean, abs_mean: 0.476777 -0.477117 -0.0478222 0.475371
W_f max, min, mean, abs_mean: 0.150483 -0.151489 -0.0151736 0.148795
beijing_tanh+hardsigmoid9 6873.4838      0.84  0.11  0.77      0.85  0.08  0.79      0.87  0.05  0.83
forget mean min: 0.916341 0.160072
delta_x = 10.2887 delta_h = 0.686126
U_c = [[-0.0080082]] U_f = [[ 0.]] b_c = [ 0.45448536] b_f = [ 1.102934]
incx.max(), incx.min(), incx.mean() 9.63776 -8.49927 4.96593
fgtx.max(), fgtx.min(), fgtx.mean() 2.87442 -2.80257 1.41207
delta mean, abs_mean, abs_mean+, abs_mean-: -1.04385 10.2887 6.43473 20.1185
W_c max, min, mean, abs_mean: 0.476777 -0.477117 -0.0478222 0.475371
W_f max, min, mean, abs_mean: 0.150483 -0.151489 -0.0151736 0.148795
Epoch 28/300
1s - loss: 1380.3570 - val_loss: 7201.0930
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 1351.3419 - val_loss: 7056.7609
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 1326.3182 - val_loss: 7084.7618
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 1302.6262 - val_loss: 7014.6505
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 1271.7290 - val_loss: 7353.2134
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 1245.5043 - val_loss: 7410.5681
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 1227.4593 - val_loss: 7519.5640
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 1202.5488 - val_loss: 7385.6412
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 1182.3991 - val_loss: 7317.2641
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 1166.0377 - val_loss: 7272.9233
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 1155.6739 - val_loss: 7086.2500
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 1140.3313 - val_loss: 7086.7189
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 1125.6186 - val_loss: 7050.1329
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 1121.6408 - val_loss: 6919.5498
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 1110.6100 - val_loss: 6780.7155
Epoch 00041: val_loss improved from 6873.48385 to 6780.71551, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1043.6466      0.89  0.17  0.75      0.91  0.14  0.79      0.92  0.11  0.82
forget mean min: 0.848 0.0
delta_x = 9.3851 delta_h = 0.696689
U_c = [[-0.01300477]] U_f = [[ 0.]] b_c = [ 0.66139579] b_f = [ 1.04424417]
incx.max(), incx.min(), incx.mean() 13.8427 -12.6598 4.68232
fgtx.max(), fgtx.min(), fgtx.mean() 4.03112 -4.07394 1.22967
delta mean, abs_mean, abs_mean+, abs_mean-: 0.329597 9.3851 7.55449 12.6819
W_c max, min, mean, abs_mean: 0.697644 -0.701218 -0.0696405 0.695055
W_f max, min, mean, abs_mean: 0.217657 -0.216477 -0.0219879 0.212565
beijing_tanh+hardsigmoid9 6780.7156      0.89  0.10  0.81      0.89  0.06  0.84      0.91  0.05  0.87
forget mean min: 0.908978 0.000880043
delta_x = 11.7955 delta_h = 1.12095
U_c = [[-0.01300477]] U_f = [[ 0.]] b_c = [ 0.66139579] b_f = [ 1.04424417]
incx.max(), incx.min(), incx.mean() 13.6409 -10.9132 5.92798
fgtx.max(), fgtx.min(), fgtx.mean() 3.96944 -3.53984 1.61063
delta mean, abs_mean, abs_mean+, abs_mean-: -0.903851 11.7955 7.86103 20.667
W_c max, min, mean, abs_mean: 0.697644 -0.701218 -0.0696405 0.695055
W_f max, min, mean, abs_mean: 0.217657 -0.216477 -0.0219879 0.212565
Epoch 43/300
1s - loss: 1103.0017 - val_loss: 7102.7908
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 1094.2890 - val_loss: 6885.3312
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 1085.3025 - val_loss: 6691.1708
Epoch 00044: val_loss improved from 6780.71551 to 6691.17080, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1064.1183      0.91  0.19  0.75      0.92  0.16  0.78      0.93  0.13  0.82
forget mean min: 0.846356 0.0
delta_x = 9.63357 delta_h = 0.625225
U_c = [[-0.0110386]] U_f = [[ 0.]] b_c = [ 0.68960243] b_f = [ 1.03905761]
incx.max(), incx.min(), incx.mean() 14.3499 -13.0087 4.82213
fgtx.max(), fgtx.min(), fgtx.mean() 4.19546 -4.20719 1.26924
delta mean, abs_mean, abs_mean+, abs_mean-: 0.436327 9.63357 7.7852 13.0174
W_c max, min, mean, abs_mean: 0.723572 -0.727441 -0.0719861 0.720074
W_f max, min, mean, abs_mean: 0.227614 -0.225748 -0.0229211 0.221155
beijing_tanh+hardsigmoid9 6691.1708      0.90  0.10  0.82      0.90  0.06  0.85      0.92  0.05  0.88
forget mean min: 0.908381 0.0
delta_x = 12.1378 delta_h = 1.0022
U_c = [[-0.0110386]] U_f = [[ 0.]] b_c = [ 0.68960243] b_f = [ 1.03905761]
incx.max(), incx.min(), incx.mean() 14.156 -11.3617 6.14374
fgtx.max(), fgtx.min(), fgtx.mean() 4.13595 -3.70137 1.67525
delta mean, abs_mean, abs_mean+, abs_mean-: -0.716443 12.1378 8.09333 21.8315
W_c max, min, mean, abs_mean: 0.723572 -0.727441 -0.0719861 0.720074
W_f max, min, mean, abs_mean: 0.227614 -0.225748 -0.0229211 0.221155
Epoch 46/300
1s - loss: 1083.3203 - val_loss: 6335.6060
Epoch 00045: val_loss improved from 6691.17080 to 6335.60599, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1041.9569      0.91  0.18  0.76      0.92  0.16  0.79      0.93  0.12  0.82
forget mean min: 0.848229 0.0
delta_x = 9.553 delta_h = 0.827587
U_c = [[-0.01494915]] U_f = [[ 0.]] b_c = [ 0.69453269] b_f = [ 1.03859043]
incx.max(), incx.min(), incx.mean() 14.4027 -12.999 4.83577
fgtx.max(), fgtx.min(), fgtx.mean() 4.25469 -4.25023 1.28539
delta mean, abs_mean, abs_mean+, abs_mean-: 0.460606 9.553 7.77017 12.7832
W_c max, min, mean, abs_mean: 0.726774 -0.730736 -0.0722181 0.72296
W_f max, min, mean, abs_mean: 0.231456 -0.229249 -0.0232711 0.224389
beijing_tanh+hardsigmoid9 6335.6059      0.91  0.10  0.83      0.92  0.06  0.86      0.93  0.05  0.89
forget mean min: 0.910266 0.0
delta_x = 12.0537 delta_h = 1.32613
U_c = [[-0.01494915]] U_f = [[ 0.]] b_c = [ 0.69453269] b_f = [ 1.03859043]
incx.max(), incx.min(), incx.mean() 14.2032 -11.3222 6.17434
fgtx.max(), fgtx.min(), fgtx.mean() 4.19281 -3.72982 1.701
delta mean, abs_mean, abs_mean+, abs_mean-: -0.634587 12.0537 8.10867 21.4424
W_c max, min, mean, abs_mean: 0.726774 -0.730736 -0.0722181 0.72296
W_f max, min, mean, abs_mean: 0.231456 -0.229249 -0.0232711 0.224389
Epoch 47/300
1s - loss: 1071.9487 - val_loss: 6738.2071
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 1068.7326 - val_loss: 6670.8726
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 1059.8552 - val_loss: 6613.1939
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 1057.5881 - val_loss: 6108.0600
Epoch 00049: val_loss improved from 6335.60599 to 6108.05998, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1024.4574      0.91  0.18  0.76      0.92  0.15  0.79      0.93  0.12  0.83
forget mean min: 0.849046 0.0
delta_x = 9.55987 delta_h = 0.822137
U_c = [[-0.01477793]] U_f = [[ 0.]] b_c = [ 0.72555709] b_f = [ 1.02993643]
incx.max(), incx.min(), incx.mean() 14.8076 -13.1233 4.9042
fgtx.max(), fgtx.min(), fgtx.mean() 4.40252 -4.32986 1.30657
delta mean, abs_mean, abs_mean+, abs_mean-: 0.471267 9.55987 7.85254 12.5783
W_c max, min, mean, abs_mean: 0.751673 -0.755797 -0.074199 0.746144
W_f max, min, mean, abs_mean: 0.243213 -0.239451 -0.0243779 0.233264
beijing_tanh+hardsigmoid9 6108.0600      0.91  0.10  0.83      0.92  0.06  0.87      0.93  0.04  0.89
forget mean min: 0.908043 0.0
delta_x = 12.1919 delta_h = 1.33784
U_c = [[-0.01477793]] U_f = [[ 0.]] b_c = [ 0.72555709] b_f = [ 1.02993643]
incx.max(), incx.min(), incx.mean() 14.5854 -11.5505 6.23497
fgtx.max(), fgtx.min(), fgtx.mean() 4.33314 -3.83806 1.72298
delta mean, abs_mean, abs_mean+, abs_mean-: -0.590992 12.1919 8.28405 21.3189
W_c max, min, mean, abs_mean: 0.751673 -0.755797 -0.074199 0.746144
W_f max, min, mean, abs_mean: 0.243213 -0.239451 -0.0243779 0.233264
Epoch 51/300
1s - loss: 1050.6513 - val_loss: 6307.4011
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 1044.0457 - val_loss: 6310.7742
Epoch 00051: val_loss did not improve
Epoch 53/300
1s - loss: 1037.0889 - val_loss: 6236.6906
Epoch 00052: val_loss did not improve
Epoch 54/300
1s - loss: 1031.3021 - val_loss: 6435.6613
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 1030.4365 - val_loss: 6106.9399
Epoch 00054: val_loss improved from 6108.05998 to 6106.93985, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9  979.9437      0.90  0.17  0.76      0.92  0.14  0.80      0.93  0.10  0.84
forget mean min: 0.850953 0.0
delta_x = 9.58806 delta_h = 0.783839
U_c = [[-0.01423568]] U_f = [[ 0.]] b_c = [ 0.76496547] b_f = [ 1.01567054]
incx.max(), incx.min(), incx.mean() 15.361 -13.463 4.99803
fgtx.max(), fgtx.min(), fgtx.mean() 4.61705 -4.50071 1.33951
delta mean, abs_mean, abs_mean+, abs_mean-: 0.430227 9.58806 7.93823 12.4095
W_c max, min, mean, abs_mean: 0.784921 -0.788874 -0.076617 0.776498
W_f max, min, mean, abs_mean: 0.260056 -0.253768 -0.0259796 0.245601
beijing_tanh+hardsigmoid9 6106.9398      0.91  0.09  0.83      0.91  0.06  0.86      0.93  0.04  0.89
forget mean min: 0.906403 0.0
delta_x = 12.339 delta_h = 1.28374
U_c = [[-0.01423568]] U_f = [[ 0.]] b_c = [ 0.76496547] b_f = [ 1.01567054]
incx.max(), incx.min(), incx.mean() 15.1128 -11.8955 6.29139
fgtx.max(), fgtx.min(), fgtx.mean() 4.5387 -4.00511 1.74944
delta mean, abs_mean, abs_mean+, abs_mean-: -0.694625 12.339 8.45472 20.9296
W_c max, min, mean, abs_mean: 0.784921 -0.788874 -0.076617 0.776498
W_f max, min, mean, abs_mean: 0.260056 -0.253768 -0.0259796 0.245601
Epoch 56/300
1s - loss: 1017.6747 - val_loss: 6097.5570
Epoch 00055: val_loss improved from 6106.93985 to 6097.55701, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9  991.6189      0.91  0.18  0.76      0.93  0.15  0.80      0.93  0.11  0.83
forget mean min: 0.850878 0.0
delta_x = 9.63356 delta_h = 0.778223
U_c = [[-0.01391357]] U_f = [[ 0.]] b_c = [ 0.77433079] b_f = [ 1.01232684]
incx.max(), incx.min(), incx.mean() 15.5102 -13.5558 5.04933
fgtx.max(), fgtx.min(), fgtx.mean() 4.64119 -4.51351 1.34706
delta mean, abs_mean, abs_mean+, abs_mean-: 0.477123 9.63356 8.01623 12.395
W_c max, min, mean, abs_mean: 0.792708 -0.79665 -0.0771725 0.783582
W_f max, min, mean, abs_mean: 0.262615 -0.255557 -0.0262468 0.246769
beijing_tanh+hardsigmoid9 6097.5569      0.91  0.09  0.83      0.91  0.05  0.86      0.93  0.04  0.89
forget mean min: 0.905947 0.0
delta_x = 12.3995 delta_h = 1.26563
U_c = [[-0.01391357]] U_f = [[ 0.]] b_c = [ 0.77433079] b_f = [ 1.01232684]
incx.max(), incx.min(), incx.mean() 15.2393 -11.9625 6.34087
fgtx.max(), fgtx.min(), fgtx.mean() 4.55607 -4.01204 1.75478
delta mean, abs_mean, abs_mean+, abs_mean-: -0.652305 12.3995 8.56086 20.7897
W_c max, min, mean, abs_mean: 0.792708 -0.79665 -0.0771725 0.783582
W_f max, min, mean, abs_mean: 0.262615 -0.255557 -0.0262468 0.246769
Epoch 57/300
1s - loss: 1017.7935 - val_loss: 5894.8814
Epoch 00056: val_loss improved from 6097.55701 to 5894.88141, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9 1011.5760      0.91  0.18  0.76      0.93  0.15  0.80      0.94  0.12  0.83
forget mean min: 0.850374 0.0
delta_x = 9.71879 delta_h = 0.743844
U_c = [[-0.01309421]] U_f = [[ 0.]] b_c = [ 0.78388828] b_f = [ 1.00889552]
incx.max(), incx.min(), incx.mean() 15.6381 -13.7066 5.08139
fgtx.max(), fgtx.min(), fgtx.mean() 4.69372 -4.57878 1.35866
delta mean, abs_mean, abs_mean+, abs_mean-: 0.501531 9.71879 8.06066 12.5906
W_c max, min, mean, abs_mean: 0.801382 -0.805231 -0.0778051 0.791531
W_f max, min, mean, abs_mean: 0.266832 -0.259313 -0.0266506 0.250079
beijing_tanh+hardsigmoid9 5894.8814      0.91  0.08  0.84      0.91  0.06  0.86      0.93  0.04  0.90
forget mean min: 0.904413 0.0
delta_x = 12.5584 delta_h = 1.21527
U_c = [[-0.01309421]] U_f = [[ 0.]] b_c = [ 0.78388828] b_f = [ 1.00889552]
incx.max(), incx.min(), incx.mean() 15.3734 -12.1011 6.3835
fgtx.max(), fgtx.min(), fgtx.mean() 4.61025 -4.07204 1.77117
delta mean, abs_mean, abs_mean+, abs_mean-: -0.616346 12.5584 8.64024 21.3235
W_c max, min, mean, abs_mean: 0.801382 -0.805231 -0.0778051 0.791531
W_f max, min, mean, abs_mean: 0.266832 -0.259313 -0.0266506 0.250079
Epoch 58/300
1s - loss: 1006.0877 - val_loss: 6181.8862
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 1000.1719 - val_loss: 6051.6469
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 1001.2336 - val_loss: 5754.3722
Epoch 00059: val_loss improved from 5894.88141 to 5754.37222, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9  951.5270      0.90  0.16  0.77      0.92  0.13  0.81      0.92  0.10  0.84
forget mean min: 0.850127 0.0
delta_x = 9.64419 delta_h = 0.893171
U_c = [[-0.0164355]] U_f = [[ 0.]] b_c = [ 0.80717051] b_f = [ 0.99679941]
incx.max(), incx.min(), incx.mean() 15.9337 -13.9576 5.07387
fgtx.max(), fgtx.min(), fgtx.mean() 4.78793 -4.67334 1.3517
delta mean, abs_mean, abs_mean+, abs_mean-: 0.417835 9.64419 8.07133 12.2469
W_c max, min, mean, abs_mean: 0.821522 -0.824603 -0.0789341 0.808788
W_f max, min, mean, abs_mean: 0.276902 -0.267206 -0.0277394 0.25594
beijing_tanh+hardsigmoid9 5754.3722      0.90  0.08  0.84      0.90  0.06  0.86      0.93  0.04  0.89
forget mean min: 0.901793 0.0
delta_x = 12.5838 delta_h = 1.45833
U_c = [[-0.0164355]] U_f = [[ 0.]] b_c = [ 0.80717051] b_f = [ 0.99679941]
incx.max(), incx.min(), incx.mean() 15.6189 -12.3345 6.36159
fgtx.max(), fgtx.min(), fgtx.mean() 4.68858 -4.16082 1.76084
delta mean, abs_mean, abs_mean+, abs_mean-: -0.747382 12.5838 8.72636 20.7132
W_c max, min, mean, abs_mean: 0.821522 -0.824603 -0.0789341 0.808788
W_f max, min, mean, abs_mean: 0.276902 -0.267206 -0.0277394 0.25594
Epoch 61/300
1s - loss: 992.0844 - val_loss: 5725.2287
Epoch 00060: val_loss improved from 5754.37222 to 5725.22870, saving model to beijing_tanh+hardsigmoid9_weights.hdf5
beijing_tanh+hardsigmoid9  991.4880      0.91  0.18  0.76      0.93  0.15  0.80      0.94  0.12  0.83
forget mean min: 0.850864 0.0
delta_x = 9.81217 delta_h = 0.754868
U_c = [[-0.01336101]] U_f = [[ 0.]] b_c = [ 0.8171255] b_f = [ 0.99374861]
incx.max(), incx.min(), incx.mean() 16.0797 -14.1301 5.16666
fgtx.max(), fgtx.min(), fgtx.mean() 4.84887 -4.74844 1.38319
delta mean, abs_mean, abs_mean+, abs_mean-: 0.492528 9.81217 8.17314 12.6077
W_c max, min, mean, abs_mean: 0.831614 -0.833762 -0.0795474 0.817212
W_f max, min, mean, abs_mean: 0.281875 -0.271502 -0.0282448 0.259551
beijing_tanh+hardsigmoid9 5725.2286      0.90  0.08  0.84      0.91  0.06  0.86      0.93  0.04  0.90
forget mean min: 0.900947 0.0
delta_x = 12.7466 delta_h = 1.23345
U_c = [[-0.01336101]] U_f = [[ 0.]] b_c = [ 0.8171255] b_f = [ 0.99374861]
incx.max(), incx.min(), incx.mean() 15.7592 -12.5759 6.45697
fgtx.max(), fgtx.min(), fgtx.mean() 4.74737 -4.25627 1.79481
delta mean, abs_mean, abs_mean+, abs_mean-: -0.655952 12.7466 8.8524 21.1332
W_c max, min, mean, abs_mean: 0.831614 -0.833762 -0.0795474 0.817212
W_f max, min, mean, abs_mean: 0.281875 -0.271502 -0.0282448 0.259551
Epoch 62/300
1s - loss: 987.0085 - val_loss: 5870.7809
Epoch 00061: val_loss did not improve
Epoch 63/300
1s - loss: 978.2074 - val_loss: 6149.4574
Epoch 00062: val_loss did not improve
Epoch 64/300
1s - loss: 978.3142 - val_loss: 5887.3847
Epoch 00063: val_loss did not improve
Epoch 65/300
1s - loss: 970.3981 - val_loss: 6523.3163
Epoch 00064: val_loss did not improve
Epoch 66/300
1s - loss: 967.7605 - val_loss: 6015.3251
Epoch 00065: val_loss did not improve
Epoch 67/300
1s - loss: 967.5707 - val_loss: 6066.1908
Epoch 00066: val_loss did not improve
Epoch 68/300
1s - loss: 957.8800 - val_loss: 6463.0181
Epoch 00067: val_loss did not improve
Epoch 69/300
1s - loss: 957.8162 - val_loss: 5851.7030
Epoch 00068: val_loss did not improve
Epoch 70/300
1s - loss: 953.9787 - val_loss: 6221.3975
Epoch 00069: val_loss did not improve
Epoch 71/300
1s - loss: 947.0402 - val_loss: 6230.7630
Epoch 00070: val_loss did not improve
Epoch 72/300
1s - loss: 941.4376 - val_loss: 6138.2023
Epoch 00071: val_loss did not improve
Epoch 73/300
1s - loss: 942.0320 - val_loss: 6212.4673
Epoch 00072: val_loss did not improve
Epoch 74/300
1s - loss: 931.9808 - val_loss: 6680.2215
Epoch 00073: val_loss did not improve
Epoch 75/300
1s - loss: 922.2473 - val_loss: 7132.7286
Epoch 00074: val_loss did not improve
Epoch 76/300
1s - loss: 921.7468 - val_loss: 6750.8050
Epoch 00075: val_loss did not improve
Epoch 77/300
1s - loss: 914.1552 - val_loss: 6928.2091
Epoch 00076: val_loss did not improve
Epoch 78/300
1s - loss: 907.2986 - val_loss: 6890.0112
Epoch 00077: val_loss did not improve
Epoch 79/300
1s - loss: 905.5206 - val_loss: 6955.9285
Epoch 00078: val_loss did not improve
Epoch 80/300
1s - loss: 897.2425 - val_loss: 6342.0813
Epoch 00079: val_loss did not improve
Epoch 81/300
1s - loss: 889.1497 - val_loss: 7030.9151
Epoch 00080: val_loss did not improve
Epoch 82/300
1s - loss: 883.4867 - val_loss: 7523.6814
Epoch 00081: val_loss did not improve

beijing_tanh+hardsigmoid0
beijing_tanh+hardsigmoid0 1036.6225      0.90  0.18  0.75      0.92  0.15  0.80      0.92  0.12  0.82
forget mean min: 0.845161 0.0
delta_x = 9.78095 delta_h = 0.688563
U_c = [[-0.01210496]] U_f = [[ 0.]] b_c = [ 0.70613426] b_f = [ 0.99408478]
incx.max(), incx.min(), incx.mean() 14.7289 -12.7167 5.10866
fgtx.max(), fgtx.min(), fgtx.mean() 3.89895 -3.73274 1.22294
beijing_tanh+hardsigmoid0 5277.0856      0.90  0.08  0.84      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.898084 0.0484894
delta_x = 11.6624 delta_h = 1.03153
U_c = [[-0.01210496]] U_f = [[ 0.]] b_c = [ 0.70613426] b_f = [ 0.99408478]
incx.max(), incx.min(), incx.mean() 14.3855 -10.9905 6.12549
fgtx.max(), fgtx.min(), fgtx.mean() 3.80329 -3.25164 1.50403

beijing_tanh+hardsigmoid1
beijing_tanh+hardsigmoid1 1530.3418      0.87  0.21  0.71      0.88  0.19  0.73      0.88  0.16  0.76
forget mean min: 0.847968 0.26583
delta_x = 8.05093 delta_h = 0.655908
U_c = [[-0.01271261]] U_f = [[ 0.]] b_c = [ 0.36305773] b_f = [ 1.08765352]
incx.max(), incx.min(), incx.mean() 8.08803 -7.42192 3.53392
fgtx.max(), fgtx.min(), fgtx.mean() 2.24109 -2.2585 0.919892
beijing_tanh+hardsigmoid1 6887.7820      0.85  0.12  0.76      0.85  0.08  0.79      0.87  0.06  0.83
forget mean min: 0.911801 0.269108
delta_x = 9.7412 delta_h = 1.05338
U_c = [[-0.01271261]] U_f = [[ 0.]] b_c = [ 0.36305773] b_f = [ 1.08765352]
incx.max(), incx.min(), incx.mean() 8.06175 -7.36543 4.6219
fgtx.max(), fgtx.min(), fgtx.mean() 2.23347 -2.24211 1.23552

beijing_tanh+hardsigmoid2
beijing_tanh+hardsigmoid2 1539.6709      0.88  0.23  0.70      0.89  0.21  0.72      0.89  0.18  0.75
forget mean min: 0.848934 0.274444
delta_x = 8.09516 delta_h = 0.72371
U_c = [[-0.01374162]] U_f = [[ 0.]] b_c = [ 0.34594199] b_f = [ 1.08208239]
incx.max(), incx.min(), incx.mean() 7.80302 -7.15316 3.54768
fgtx.max(), fgtx.min(), fgtx.mean() 2.19748 -2.20986 0.943494
beijing_tanh+hardsigmoid2 6955.3819      0.85  0.12  0.76      0.85  0.09  0.78      0.87  0.06  0.82
forget mean min: 0.911134 0.276592
delta_x = 9.83388 delta_h = 1.15126
U_c = [[-0.01374162]] U_f = [[ 0.]] b_c = [ 0.34594199] b_f = [ 1.08208239]
incx.max(), incx.min(), incx.mean() 7.77574 -7.11672 4.59044
fgtx.max(), fgtx.min(), fgtx.mean() 2.18944 -2.19912 1.25078

beijing_tanh+hardsigmoid3
beijing_tanh+hardsigmoid3  968.5221      0.89  0.16  0.76      0.92  0.12  0.81      0.92  0.10  0.83
forget mean min: 0.857604 0.0
delta_x = 9.56246 delta_h = 0.836902
U_c = [[-0.01539795]] U_f = [[ 0.]] b_c = [ 0.73995489] b_f = [ 1.01567221]
incx.max(), incx.min(), incx.mean() 15.6574 -13.0328 5.19909
fgtx.max(), fgtx.min(), fgtx.mean() 4.33459 -4.002 1.29542
beijing_tanh+hardsigmoid3 4829.1967      0.91  0.08  0.84      0.92  0.05  0.87      0.94  0.04  0.90
forget mean min: 0.903281 0.0
delta_x = 11.6937 delta_h = 1.36943
U_c = [[-0.01539795]] U_f = [[ 0.]] b_c = [ 0.73995489] b_f = [ 1.01567221]
incx.max(), incx.min(), incx.mean() 15.1444 -11.6875 6.16929
fgtx.max(), fgtx.min(), fgtx.mean() 4.18558 -3.61054 1.57643

beijing_tanh+hardsigmoid4
beijing_tanh+hardsigmoid4 1060.2912      0.90  0.18  0.75      0.91  0.15  0.79      0.91  0.12  0.81
forget mean min: 0.843222 0.0
delta_x = 9.70466 delta_h = 0.679503
U_c = [[-0.01204702]] U_f = [[ 0.]] b_c = [ 0.67344064] b_f = [ 0.99170822]
incx.max(), incx.min(), incx.mean() 14.1479 -12.4445 5.00768
fgtx.max(), fgtx.min(), fgtx.mean() 3.60242 -3.50718 1.1585
beijing_tanh+hardsigmoid4 5232.6955      0.90  0.08  0.84      0.90  0.05  0.86      0.92  0.04  0.89
forget mean min: 0.899738 0.0931457
delta_x = 11.9534 delta_h = 1.03413
U_c = [[-0.01204702]] U_f = [[ 0.]] b_c = [ 0.67344064] b_f = [ 0.99170822]
incx.max(), incx.min(), incx.mean() 13.9013 -10.6459 6.25484
fgtx.max(), fgtx.min(), fgtx.mean() 3.53643 -3.02598 1.49134

beijing_tanh+hardsigmoid5
beijing_tanh+hardsigmoid5 1517.0441      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.17  0.76
forget mean min: 0.8492 0.271002
delta_x = 8.20996 delta_h = 0.570571
U_c = [[-0.01085399]] U_f = [[ 0.]] b_c = [ 0.36099178] b_f = [ 1.09284806]
incx.max(), incx.min(), incx.mean() 8.10943 -7.42606 3.6044
fgtx.max(), fgtx.min(), fgtx.mean() 2.22674 -2.23784 0.932087
beijing_tanh+hardsigmoid5 6977.6965      0.84  0.11  0.76      0.85  0.08  0.79      0.87  0.06  0.82
forget mean min: 0.90897 0.273814
delta_x = 9.81311 delta_h = 0.900454
U_c = [[-0.01085399]] U_f = [[ 0.]] b_c = [ 0.36099178] b_f = [ 1.09284806]
incx.max(), incx.min(), incx.mean() 8.07645 -7.37713 4.59801
fgtx.max(), fgtx.min(), fgtx.mean() 2.21726 -2.22378 1.21763

beijing_tanh+hardsigmoid6
beijing_tanh+hardsigmoid6 1506.4623      0.88  0.22  0.70      0.89  0.20  0.73      0.89  0.17  0.76
forget mean min: 0.850224 0.268976
delta_x = 8.19243 delta_h = 0.582857
U_c = [[-0.01120325]] U_f = [[ 0.]] b_c = [ 0.36089349] b_f = [ 1.08562016]
incx.max(), incx.min(), incx.mean() 8.09981 -7.41872 3.62231
fgtx.max(), fgtx.min(), fgtx.mean() 2.22902 -2.24074 0.939374
beijing_tanh+hardsigmoid6 6949.6410      0.84  0.11  0.76      0.84  0.08  0.79      0.86  0.06  0.82
forget mean min: 0.909005 0.271927
delta_x = 9.81188 delta_h = 0.925895
U_c = [[-0.01120325]] U_f = [[ 0.]] b_c = [ 0.36089349] b_f = [ 1.08562016]
incx.max(), incx.min(), incx.mean() 8.06269 -7.36749 4.59156
fgtx.max(), fgtx.min(), fgtx.mean() 2.21832 -2.22598 1.21855

beijing_tanh+hardsigmoid7
beijing_tanh+hardsigmoid7 1511.2220      0.87  0.21  0.71      0.88  0.19  0.73      0.88  0.16  0.76
forget mean min: 0.848273 0.26099
delta_x = 8.0951 delta_h = 0.620241
U_c = [[-0.01200383]] U_f = [[ 0.]] b_c = [ 0.36397907] b_f = [ 1.08934498]
incx.max(), incx.min(), incx.mean() 8.12267 -7.43619 3.55523
fgtx.max(), fgtx.min(), fgtx.mean() 2.27224 -2.28439 0.9346
beijing_tanh+hardsigmoid7 6919.7876      0.84  0.11  0.76      0.84  0.08  0.79      0.87  0.06  0.82
forget mean min: 0.908967 0.264245
delta_x = 9.78929 delta_h = 0.998561
U_c = [[-0.01200383]] U_f = [[ 0.]] b_c = [ 0.36397907] b_f = [ 1.08934498]
incx.max(), incx.min(), incx.mean() 8.08202 -7.38063 4.55518
fgtx.max(), fgtx.min(), fgtx.mean() 2.26034 -2.26812 1.22745

beijing_tanh+hardsigmoid8
beijing_tanh+hardsigmoid8 1322.0831      0.88  0.21  0.72      0.89  0.18  0.75      0.90  0.15  0.78
forget mean min: 0.855668 0.130465
delta_x = 8.73589 delta_h = 0.296075
U_c = [[-0.0055358]] U_f = [[ 0.]] b_c = [ 0.47244978] b_f = [ 1.08517611]
incx.max(), incx.min(), incx.mean() 9.9011 -9.08206 4.10629
fgtx.max(), fgtx.min(), fgtx.mean() 2.89421 -2.93285 1.11545
beijing_tanh+hardsigmoid8 6869.0698      0.85  0.10  0.77      0.85  0.08  0.79      0.87  0.05  0.83
forget mean min: 0.909655 0.166061
delta_x = 10.2345 delta_h = 0.472638
U_c = [[-0.0055358]] U_f = [[ 0.]] b_c = [ 0.47244978] b_f = [ 1.08517611]
incx.max(), incx.min(), incx.mean() 9.80144 -8.50231 4.97833
fgtx.max(), fgtx.min(), fgtx.mean() 2.86362 -2.75487 1.38316

beijing_tanh+hardsigmoid9
beijing_tanh+hardsigmoid9  991.4880      0.91  0.18  0.76      0.93  0.15  0.80      0.94  0.12  0.83
forget mean min: 0.850864 0.0
delta_x = 9.81217 delta_h = 0.754868
U_c = [[-0.01336101]] U_f = [[ 0.]] b_c = [ 0.8171255] b_f = [ 0.99374861]
incx.max(), incx.min(), incx.mean() 16.0797 -14.1301 5.16666
fgtx.max(), fgtx.min(), fgtx.mean() 4.84887 -4.74844 1.38319
beijing_tanh+hardsigmoid9 5725.2286      0.90  0.08  0.84      0.91  0.06  0.86      0.93  0.04  0.90
forget mean min: 0.900947 0.0
delta_x = 12.7466 delta_h = 1.23345
U_c = [[-0.01336101]] U_f = [[ 0.]] b_c = [ 0.8171255] b_f = [ 0.99374861]
incx.max(), incx.min(), incx.mean() 15.7592 -12.5759 6.45697
fgtx.max(), fgtx.min(), fgtx.mean() 4.74737 -4.25627 1.79481
