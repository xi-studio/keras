X_train[0].shape = (6831, 40, 23)

training haerbin0
Train on 6831 samples, validate on 2134 samples
Before training:
            haerbin022317.6837      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.89937 nan 4.89937
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            haerbin019523.4299      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.57342 nan 8.57342
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 17485.4978 - val_loss: 8837.5574
Epoch 00000: val_loss improved from inf to 8837.55744, saving model to haerbin0_weights.hdf5
            haerbin013811.0158      0.56  0.22  0.48      0.56  0.18  0.50      0.54  0.16  0.49
            haerbin0 8837.5574      0.82  0.42  0.52      0.81  0.41  0.52      0.83  0.40  0.53
forget mean min: 0.951732 0.405351
abs_mean, abs_mean+, abs_mean-: 5.63699 2.2513 13.1148
U_c = [[-0.13501479]] U_f = [[ 0.]] b_c = [ 0.11598154] b_f = [ 1.]
Epoch 2/300
1s - loss: 13138.9986 - val_loss: 10716.6201
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 12216.6958 - val_loss: 12454.9740
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 11577.7516 - val_loss: 13306.1112
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 10459.6230 - val_loss: 12168.5955
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 9892.3982 - val_loss: 12783.3619
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 9756.9375 - val_loss: 13525.0001
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 9666.6665 - val_loss: 14627.4552
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 9587.3373 - val_loss: 17184.9826
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 9530.0597 - val_loss: 15033.4870
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 9507.4936 - val_loss: 12900.1813
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 9498.9917 - val_loss: 17480.4358
Epoch 00011: val_loss did not improve
X_train[0].shape = (6831, 40, 23)

training haerbin1
Train on 6831 samples, validate on 2134 samples
Before training:
            haerbin122317.6837      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.89937 nan 4.89937
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            haerbin119523.4299      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.57342 nan 8.57342
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 17438.8447 - val_loss: 8783.2021
Epoch 00000: val_loss improved from inf to 8783.20208, saving model to haerbin1_weights.hdf5
            haerbin113833.7341      0.56  0.22  0.48      0.56  0.19  0.50      0.54  0.16  0.49
            haerbin1 8783.2021      0.83  0.41  0.52      0.82  0.40  0.53      0.84  0.40  0.54
forget mean min: 0.951315 0.409426
abs_mean, abs_mean+, abs_mean-: 5.65934 2.21362 13.4548
U_c = [[-0.13580847]] U_f = [[ 0.]] b_c = [ 0.11598462] b_f = [ 1.]
Epoch 2/300
1s - loss: 13163.3174 - val_loss: 10725.1929
Epoch 00001: val_loss did not improve
Epoch 3/300
1s - loss: 12183.1265 - val_loss: 13135.2536
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 11637.0904 - val_loss: 13333.4451
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 10551.5877 - val_loss: 11654.1832
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 9981.2320 - val_loss: 12302.2469
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 9762.5888 - val_loss: 13620.7833
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 9644.9680 - val_loss: 11611.6151
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 9564.5181 - val_loss: 16422.8992
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 9587.7094 - val_loss: 15104.5327
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 9575.2812 - val_loss: 15869.7682
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 9457.6463 - val_loss: 14529.8131
Epoch 00011: val_loss did not improve
X_train[0].shape = (6831, 40, 23)

training haerbin2
Train on 6831 samples, validate on 2134 samples
Before training:
            haerbin222317.6837      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.89937 nan 4.89937
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            haerbin219523.4299      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.57342 nan 8.57342
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 17519.8458 - val_loss: 8694.3589
Epoch 00000: val_loss improved from inf to 8694.35892, saving model to haerbin2_weights.hdf5
            haerbin213837.2132      0.55  0.22  0.48      0.55  0.19  0.49      0.54  0.16  0.49
            haerbin2 8694.3589      0.81  0.41  0.52      0.80  0.40  0.52      0.81  0.40  0.53
forget mean min: 0.945167 0.398026
abs_mean, abs_mean+, abs_mean-: 5.99451 2.20594 13.0283
U_c = [[-0.14043349]] U_f = [[ 0.]] b_c = [ 0.11602437] b_f = [ 1.]
Epoch 2/300
2s - loss: 13139.4161 - val_loss: 10657.6597
Epoch 00001: val_loss did not improve
Epoch 3/300
2s - loss: 12180.1998 - val_loss: 12895.5142
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 11564.5186 - val_loss: 11615.7138
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 10453.1989 - val_loss: 12811.4460
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 9944.0633 - val_loss: 14861.2946
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 9762.8735 - val_loss: 11291.7036
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 9659.1814 - val_loss: 15237.2351
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 9628.0747 - val_loss: 14194.7366
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 9576.1309 - val_loss: 15968.5410
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 9546.6434 - val_loss: 17034.9888
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 9480.8397 - val_loss: 22256.4079
Epoch 00011: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changchun0
Train on 6210 samples, validate on 1940 samples
Before training:
          changchun022567.0440      0.03  -nan  0.03      0.03  -nan  0.03      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.03819 nan 5.03819
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          changchun011851.2921      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.08138 nan 6.08138
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 19007.3467 - val_loss: 7626.7521
Epoch 00000: val_loss improved from inf to 7626.75213, saving model to changchun0_weights.hdf5
          changchun016690.0447      0.35  0.42  0.28      0.33  0.40  0.27      0.29  0.40  0.25
          changchun0 7626.7522      0.18  0.23  0.17      0.18  0.20  0.17      0.17  0.13  0.16
forget mean min: 0.734269 0.40852
abs_mean, abs_mean+, abs_mean-: 9.52597 1.38436 11.0176
U_c = [[-0.13676223]] U_f = [[ 0.]] b_c = [ 0.10486699] b_f = [ 1.]
Epoch 2/300
1s - loss: 15575.9240 - val_loss: 6189.5412
Epoch 00001: val_loss improved from 7626.75213 to 6189.54120, saving model to changchun0_weights.hdf5
          changchun014208.5441      0.58  0.45  0.39      0.58  0.39  0.42      0.58  0.34  0.45
          changchun0 6189.5412      0.44  0.53  0.30      0.43  0.53  0.29      0.41  0.54  0.28
forget mean min: 0.915119 0.58595
abs_mean, abs_mean+, abs_mean-: 5.03794 2.02546 7.1249
U_c = [[-0.13120505]] U_f = [[ 0.]] b_c = [ 0.19943056] b_f = [ 1.]
Epoch 3/300
1s - loss: 13674.4638 - val_loss: 6398.4078
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 12851.1297 - val_loss: 7032.9966
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 12174.0712 - val_loss: 7979.4883
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 11565.4462 - val_loss: 7381.3857
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 11174.4959 - val_loss: 8581.6454
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 11023.1543 - val_loss: 8439.8919
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 10915.6762 - val_loss: 6503.6513
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 10891.3754 - val_loss: 7132.5882
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 10852.7429 - val_loss: 8145.7027
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 10853.2729 - val_loss: 8862.6222
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 10845.8743 - val_loss: 8162.2577
Epoch 00012: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changchun1
Train on 6210 samples, validate on 1940 samples
Before training:
          changchun122567.0440      0.03  -nan  0.03      0.03  -nan  0.03      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.03819 nan 5.03819
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          changchun111851.2921      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.08138 nan 6.08138
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 18950.1207 - val_loss: 7808.8007
Epoch 00000: val_loss improved from inf to 7808.80069, saving model to changchun1_weights.hdf5
          changchun116704.3071      0.33  0.42  0.27      0.31  0.40  0.26      0.28  0.40  0.24
          changchun1 7808.8007      0.16  0.25  0.15      0.15  0.22  0.14      0.15  0.14  0.14
forget mean min: 0.734725 0.421697
abs_mean, abs_mean+, abs_mean-: 9.40918 1.29822 10.7355
U_c = [[-0.13365059]] U_f = [[ 0.]] b_c = [ 0.10515052] b_f = [ 1.]
Epoch 2/300
1s - loss: 15542.5021 - val_loss: 5635.0719
Epoch 00001: val_loss improved from 7808.80069 to 5635.07192, saving model to changchun1_weights.hdf5
          changchun114218.3092      0.61  0.45  0.40      0.61  0.40  0.43      0.59  0.37  0.44
          changchun1 5635.0720      0.38  0.40  0.31      0.40  0.37  0.33      0.37  0.37  0.31
forget mean min: 0.915352 0.658762
abs_mean, abs_mean+, abs_mean-: 5.18915 1.97681 6.77717
U_c = [[-0.13057391]] U_f = [[ 0.]] b_c = [ 0.19888201] b_f = [ 1.]
Epoch 3/300
1s - loss: 13703.9900 - val_loss: 6790.8410
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 12852.9818 - val_loss: 7498.9400
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 12217.0607 - val_loss: 7692.2255
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 11615.9162 - val_loss: 7567.4628
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 11186.0345 - val_loss: 7435.4889
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 11020.7544 - val_loss: 8347.6348
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 10920.5369 - val_loss: 8919.9049
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 10939.6251 - val_loss: 8022.1771
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 10846.6660 - val_loss: 7440.2992
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 10834.3707 - val_loss: 6602.9383
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 10843.7800 - val_loss: 7557.8716
Epoch 00012: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changchun2
Train on 6210 samples, validate on 1940 samples
Before training:
          changchun222567.0440      0.03  -nan  0.03      0.03  -nan  0.03      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.03819 nan 5.03819
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          changchun211851.2921      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.08138 nan 6.08138
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 18969.4941 - val_loss: 7827.3412
Epoch 00000: val_loss improved from inf to 7827.34121, saving model to changchun2_weights.hdf5
          changchun216748.8492      0.32  0.42  0.26      0.31  0.40  0.26      0.28  0.40  0.24
          changchun2 7827.3412      0.15  0.25  0.14      0.15  0.21  0.14      0.15  0.14  0.14
forget mean min: 0.73354 0.414501
abs_mean, abs_mean+, abs_mean-: 9.29899 1.22926 10.4867
U_c = [[-0.13123623]] U_f = [[ 0.]] b_c = [ 0.10347684] b_f = [ 1.]
Epoch 2/300
1s - loss: 15517.1973 - val_loss: 6399.8265
Epoch 00001: val_loss improved from 7827.34121 to 6399.82649, saving model to changchun2_weights.hdf5
          changchun214162.2195      0.60  0.45  0.40      0.60  0.40  0.43      0.60  0.35  0.46
          changchun2 6399.8265      0.41  0.53  0.28      0.41  0.53  0.28      0.39  0.53  0.28
forget mean min: 0.913261 0.636646
abs_mean, abs_mean+, abs_mean-: 4.91915 1.83808 6.60722
U_c = [[-0.12925006]] U_f = [[ 0.]] b_c = [ 0.19695595] b_f = [ 1.]
Epoch 3/300
1s - loss: 13651.3369 - val_loss: 6687.6991
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 12827.4153 - val_loss: 7192.3770
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 12012.1751 - val_loss: 7111.6175
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 11429.7026 - val_loss: 8539.8606
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 11094.6218 - val_loss: 6978.0540
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 10981.5200 - val_loss: 7442.6674
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 10902.6315 - val_loss: 9103.5162
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 10896.6199 - val_loss: 9057.3460
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 10851.3156 - val_loss: 8768.7250
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 10848.7453 - val_loss: 6983.7047
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 10844.9455 - val_loss: 8415.7956
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shenyang0
Train on 5589 samples, validate on 1746 samples
Before training:
           shenyang019985.9951      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.20619 nan 5.20619
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shenyang012828.1686      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.57121 nan 6.57121
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 16105.0245 - val_loss: 6864.7704
Epoch 00000: val_loss improved from inf to 6864.77041, saving model to shenyang0_weights.hdf5
           shenyang012554.3709      0.43  0.24  0.38      0.44  0.20  0.40      0.45  0.15  0.41
           shenyang0 6864.7703      0.29  0.25  0.26      0.27  0.24  0.25      0.27  0.18  0.25
forget mean min: 0.837134 0.353155
abs_mean, abs_mean+, abs_mean-: 7.80143 1.77033 10.5121
U_c = [[-0.12059779]] U_f = [[ 0.]] b_c = [ 0.09743983] b_f = [ 1.]
Epoch 2/300
1s - loss: 11969.5630 - val_loss: 4956.6872
Epoch 00001: val_loss improved from 6864.77041 to 4956.68720, saving model to shenyang0_weights.hdf5
           shenyang011427.3881      0.56  0.27  0.47      0.57  0.22  0.49      0.57  0.17  0.52
           shenyang0 4956.6872      0.79  0.40  0.51      0.79  0.38  0.53      0.80  0.37  0.54
forget mean min: 0.957068 0.304901
abs_mean, abs_mean+, abs_mean-: 5.3268 3.32036 11.4969
U_c = [[-0.1215517]] U_f = [[ 0.]] b_c = [ 0.17765169] b_f = [ 1.]
Epoch 3/300
1s - loss: 10860.1851 - val_loss: 5658.5247
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 9765.9706 - val_loss: 6426.8525
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 8666.0340 - val_loss: 7694.4609
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7805.0034 - val_loss: 8545.1563
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 7280.3991 - val_loss: 8771.2685
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6876.4608 - val_loss: 9327.1128
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 6626.0818 - val_loss: 8953.1789
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 6436.8157 - val_loss: 9600.9764
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 6283.5557 - val_loss: 9143.7156
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6181.9316 - val_loss: 9276.0472
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6128.3794 - val_loss: 9239.3783
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shenyang1
Train on 5589 samples, validate on 1746 samples
Before training:
           shenyang119985.9951      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.20619 nan 5.20619
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shenyang112828.1686      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.57121 nan 6.57121
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 16034.8150 - val_loss: 6891.9698
Epoch 00000: val_loss improved from inf to 6891.96981, saving model to shenyang1_weights.hdf5
           shenyang112553.1174      0.43  0.24  0.38      0.44  0.20  0.39      0.45  0.15  0.41
           shenyang1 6891.9697      0.28  0.26  0.26      0.27  0.25  0.25      0.27  0.19  0.25
forget mean min: 0.838206 0.345034
abs_mean, abs_mean+, abs_mean-: 7.65749 1.80597 10.3256
U_c = [[-0.11556192]] U_f = [[ 0.]] b_c = [ 0.09792965] b_f = [ 1.]
Epoch 2/300
1s - loss: 11957.4694 - val_loss: 4972.1687
Epoch 00001: val_loss improved from 6891.96981 to 4972.16873, saving model to shenyang1_weights.hdf5
           shenyang111398.1514      0.56  0.26  0.47      0.56  0.21  0.49      0.57  0.16  0.52
           shenyang1 4972.1687      0.78  0.41  0.51      0.79  0.38  0.53      0.79  0.37  0.54
forget mean min: 0.957499 0.317072
abs_mean, abs_mean+, abs_mean-: 5.20238 3.2891 10.4712
U_c = [[-0.11755361]] U_f = [[ 0.]] b_c = [ 0.17816271] b_f = [ 1.]
Epoch 3/300
1s - loss: 10846.5975 - val_loss: 5601.1929
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 9754.6270 - val_loss: 6411.1948
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 8662.4265 - val_loss: 8160.0614
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7787.5611 - val_loss: 8763.7077
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 7248.7358 - val_loss: 9216.9058
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6876.6511 - val_loss: 9494.7964
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 6605.3062 - val_loss: 9319.5063
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 6425.0512 - val_loss: 8727.6944
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 6290.5467 - val_loss: 9292.8228
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6198.1513 - val_loss: 8735.2506
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6128.9110 - val_loss: 9710.4967
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shenyang2
Train on 5589 samples, validate on 1746 samples
Before training:
           shenyang219985.9951      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.20619 nan 5.20619
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shenyang212828.1686      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.57121 nan 6.57121
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 16001.2199 - val_loss: 6819.2190
Epoch 00000: val_loss improved from inf to 6819.21904, saving model to shenyang2_weights.hdf5
           shenyang212561.1261      0.43  0.24  0.38      0.44  0.20  0.40      0.45  0.15  0.42
           shenyang2 6819.2191      0.29  0.26  0.26      0.28  0.24  0.25      0.27  0.19  0.25
forget mean min: 0.839987 0.352681
abs_mean, abs_mean+, abs_mean-: 7.69022 1.75695 10.422
U_c = [[-0.11932097]] U_f = [[ 0.]] b_c = [ 0.09600651] b_f = [ 1.]
Epoch 2/300
1s - loss: 11974.8472 - val_loss: 5036.8602
Epoch 00001: val_loss improved from 6819.21904 to 5036.86020, saving model to shenyang2_weights.hdf5
           shenyang211419.8352      0.56  0.27  0.47      0.57  0.22  0.49      0.57  0.17  0.51
           shenyang2 5036.8602      0.81  0.42  0.51      0.81  0.40  0.52      0.81  0.39  0.53
forget mean min: 0.963151 0.314337
abs_mean, abs_mean+, abs_mean-: 5.05305 3.2774 11.4988
U_c = [[-0.12511423]] U_f = [[ 0.]] b_c = [ 0.17553027] b_f = [ 1.]
Epoch 3/300
1s - loss: 10855.6386 - val_loss: 5913.5269
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 9857.7310 - val_loss: 6061.4357
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 8686.2772 - val_loss: 7810.7261
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7817.1684 - val_loss: 9025.5260
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 7315.0175 - val_loss: 8756.7119
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6942.3369 - val_loss: 8947.1222
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 6670.5251 - val_loss: 9178.1041
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 6485.1321 - val_loss: 8892.1335
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 6379.6706 - val_loss: 9599.9906
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6208.9445 - val_loss: 9196.7064
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6187.4863 - val_loss: 8985.0420
Epoch 00012: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training beijing0
Train on 7452 samples, validate on 2328 samples
Before training:
            beijing017847.6134      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.41179 nan 5.41179
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            beijing033481.9608      0.05  -nan  0.05      0.05  -nan  0.05      0.05  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.33326 nan 9.33326
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 10957.2236 - val_loss: 18656.3567
Epoch 00000: val_loss improved from inf to 18656.35666, saving model to beijing0_weights.hdf5
            beijing0 6972.1640      0.68  0.19  0.59      0.68  0.17  0.60      0.66  0.15  0.59
            beijing018656.3570      0.68  0.18  0.59      0.68  0.15  0.61      0.65  0.15  0.58
forget mean min: 0.772512 0.293119
abs_mean, abs_mean+, abs_mean-: 10.1552 2.73663 17.5483
U_c = [[-0.08087946]] U_f = [[ 0.]] b_c = [ 0.12932669] b_f = [ 1.]
Epoch 2/300
2s - loss: 5538.0355 - val_loss: 20934.2448
Epoch 00001: val_loss did not improve
Epoch 3/300
2s - loss: 4165.6046 - val_loss: 18750.7113
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 3822.0527 - val_loss: 17124.8939
Epoch 00003: val_loss improved from 18656.35666 to 17124.89395, saving model to beijing0_weights.hdf5
            beijing0 3684.9240      0.90  0.23  0.71      0.91  0.21  0.73      0.90  0.19  0.74
            beijing017124.8941      0.83  0.26  0.65      0.84  0.22  0.68      0.85  0.20  0.70
forget mean min: 0.91 0.394524
abs_mean, abs_mean+, abs_mean-: 11.2808 7.03617 21.8554
U_c = [[-0.00980364]] U_f = [[ 0.]] b_c = [ 0.38347828] b_f = [ 1.]
Epoch 5/300
2s - loss: 3674.1057 - val_loss: 15902.6265
Epoch 00004: val_loss improved from 17124.89395 to 15902.62646, saving model to beijing0_weights.hdf5
            beijing0 3582.4213      0.91  0.23  0.71      0.91  0.21  0.73      0.91  0.19  0.75
            beijing015902.6267      0.83  0.25  0.65      0.84  0.21  0.69      0.85  0.19  0.71
forget mean min: 0.904167 0.388925
abs_mean, abs_mean+, abs_mean-: 12.1303 7.79232 21.9166
U_c = [[-0.00871747]] U_f = [[ 0.]] b_c = [ 0.42424464] b_f = [ 1.]
Epoch 6/300
2s - loss: 3590.9227 - val_loss: 15211.7982
Epoch 00005: val_loss improved from 15902.62646 to 15211.79823, saving model to beijing0_weights.hdf5
            beijing0 3630.4935      0.92  0.23  0.72      0.92  0.22  0.73      0.92  0.19  0.75
            beijing015211.7983      0.82  0.23  0.66      0.83  0.19  0.70      0.85  0.17  0.72
forget mean min: 0.893004 0.379984
abs_mean, abs_mean+, abs_mean-: 12.8079 8.39248 21.9078
U_c = [[-0.01027606]] U_f = [[ 0.]] b_c = [ 0.44995838] b_f = [ 1.]
Epoch 7/300
2s - loss: 3560.7963 - val_loss: 14734.5155
Epoch 00006: val_loss improved from 15211.79823 to 14734.51551, saving model to beijing0_weights.hdf5
            beijing0 3500.4287      0.92  0.23  0.72      0.92  0.21  0.74      0.92  0.19  0.75
            beijing014734.5155      0.84  0.24  0.66      0.85  0.20  0.70      0.86  0.19  0.72
forget mean min: 0.894655 0.378001
abs_mean, abs_mean+, abs_mean-: 13.157 8.72571 21.9518
U_c = [[-0.01549599]] U_f = [[ 0.]] b_c = [ 0.46617648] b_f = [ 1.]
Epoch 8/300
2s - loss: 3530.6140 - val_loss: 14635.0703
Epoch 00007: val_loss improved from 14734.51551 to 14635.07027, saving model to beijing0_weights.hdf5
            beijing0 3493.2528      0.92  0.23  0.72      0.92  0.21  0.74      0.92  0.18  0.76
            beijing014635.0701      0.83  0.23  0.66      0.84  0.19  0.70      0.85  0.18  0.72
forget mean min: 0.8902 0.360991
abs_mean, abs_mean+, abs_mean-: 13.4989 9.00668 22.0571
U_c = [[-0.0161262]] U_f = [[ 0.]] b_c = [ 0.47108549] b_f = [ 1.]
Epoch 9/300
2s - loss: 3514.4431 - val_loss: 14623.4396
Epoch 00008: val_loss improved from 14635.07027 to 14623.43959, saving model to beijing0_weights.hdf5
            beijing0 3431.1846      0.91  0.21  0.73      0.91  0.19  0.75      0.91  0.16  0.77
            beijing014623.4397      0.83  0.23  0.66      0.84  0.20  0.70      0.85  0.18  0.72
forget mean min: 0.890309 0.360489
abs_mean, abs_mean+, abs_mean-: 13.399 8.98679 21.4848
U_c = [[-0.01795621]] U_f = [[ 0.]] b_c = [ 0.47521839] b_f = [ 1.]
Epoch 10/300
2s - loss: 3488.6361 - val_loss: 14769.4715
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 3471.9279 - val_loss: 14605.8654
Epoch 00010: val_loss improved from 14623.43959 to 14605.86541, saving model to beijing0_weights.hdf5
            beijing0 3377.9325      0.92  0.21  0.73      0.91  0.19  0.75      0.91  0.17  0.77
            beijing014605.8655      0.83  0.23  0.67      0.84  0.19  0.70      0.85  0.17  0.72
forget mean min: 0.885691 0.331323
abs_mean, abs_mean+, abs_mean-: 13.9227 9.31338 22.3136
U_c = [[-0.01964052]] U_f = [[ 0.]] b_c = [ 0.4896051] b_f = [ 1.]
Epoch 12/300
2s - loss: 3472.2905 - val_loss: 14779.0320
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 3442.6998 - val_loss: 14706.9208
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 3443.5209 - val_loss: 14901.9810
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 3405.4631 - val_loss: 14877.5741
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 3363.5825 - val_loss: 15081.6384
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 3316.9608 - val_loss: 15070.9784
Epoch 00016: val_loss did not improve
Epoch 18/300
2s - loss: 3274.5846 - val_loss: 15308.2629
Epoch 00017: val_loss did not improve
Epoch 19/300
2s - loss: 3222.7551 - val_loss: 15551.9143
Epoch 00018: val_loss did not improve
Epoch 20/300
2s - loss: 3181.4786 - val_loss: 15605.2954
Epoch 00019: val_loss did not improve
Epoch 21/300
2s - loss: 3117.0590 - val_loss: 15638.0444
Epoch 00020: val_loss did not improve
Epoch 22/300
2s - loss: 3068.2284 - val_loss: 15664.5772
Epoch 00021: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training beijing1
Train on 7452 samples, validate on 2328 samples
Before training:
            beijing117847.6134      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.41179 nan 5.41179
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            beijing133481.9608      0.05  -nan  0.05      0.05  -nan  0.05      0.05  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.33326 nan 9.33326
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 10992.3238 - val_loss: 18514.4963
Epoch 00000: val_loss improved from inf to 18514.49635, saving model to beijing1_weights.hdf5
            beijing1 7011.8358      0.69  0.20  0.59      0.69  0.17  0.60      0.67  0.16  0.59
            beijing118514.4966      0.69  0.20  0.59      0.69  0.16  0.61      0.67  0.16  0.59
forget mean min: 0.771552 0.28815
abs_mean, abs_mean+, abs_mean-: 10.4479 2.74844 18.0841
U_c = [[-0.08755587]] U_f = [[ 0.]] b_c = [ 0.12895083] b_f = [ 1.]
Epoch 2/300
2s - loss: 5594.7967 - val_loss: 21045.7264
Epoch 00001: val_loss did not improve
Epoch 3/300
2s - loss: 4142.3892 - val_loss: 18688.1911
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 3800.5975 - val_loss: 16336.2015
Epoch 00003: val_loss improved from 18514.49635 to 16336.20148, saving model to beijing1_weights.hdf5
            beijing1 3725.0384      0.89  0.22  0.71      0.90  0.20  0.73      0.89  0.18  0.75
            beijing116336.2013      0.83  0.26  0.64      0.84  0.22  0.68      0.85  0.20  0.70
forget mean min: 0.908591 0.398862
abs_mean, abs_mean+, abs_mean-: 11.0313 6.86205 20.7924
U_c = [[-0.01283863]] U_f = [[ 0.]] b_c = [ 0.38506648] b_f = [ 1.]
Epoch 5/300
2s - loss: 3645.2622 - val_loss: 15332.5792
Epoch 00004: val_loss improved from 16336.20148 to 15332.57924, saving model to beijing1_weights.hdf5
            beijing1 3587.9553      0.92  0.24  0.71      0.92  0.22  0.73      0.92  0.20  0.74
            beijing115332.5793      0.83  0.24  0.66      0.85  0.21  0.69      0.86  0.19  0.71
forget mean min: 0.899993 0.385044
abs_mean, abs_mean+, abs_mean-: 12.4115 7.99807 21.9153
U_c = [[-0.01449404]] U_f = [[ 0.]] b_c = [ 0.42756006] b_f = [ 1.]
Epoch 6/300
2s - loss: 3583.1282 - val_loss: 14875.6641
Epoch 00005: val_loss improved from 15332.57924 to 14875.66407, saving model to beijing1_weights.hdf5
            beijing1 3508.7752      0.91  0.22  0.72      0.91  0.20  0.74      0.91  0.18  0.76
            beijing114875.6642      0.83  0.24  0.66      0.84  0.20  0.70      0.85  0.18  0.72
forget mean min: 0.894823 0.384746
abs_mean, abs_mean+, abs_mean-: 12.6551 8.23551 21.5027
U_c = [[-0.01566979]] U_f = [[ 0.]] b_c = [ 0.44809395] b_f = [ 1.]
Epoch 7/300
2s - loss: 3551.6048 - val_loss: 14847.8302
Epoch 00006: val_loss improved from 14875.66407 to 14847.83023, saving model to beijing1_weights.hdf5
            beijing1 3486.2178      0.92  0.23  0.72      0.92  0.21  0.73      0.92  0.19  0.75
            beijing114847.8305      0.85  0.26  0.65      0.86  0.23  0.68      0.87  0.21  0.70
forget mean min: 0.904997 0.370562
abs_mean, abs_mean+, abs_mean-: 13.2084 8.80894 22.3264
U_c = [[-0.01540008]] U_f = [[ 0.]] b_c = [ 0.46507123] b_f = [ 1.]
Epoch 8/300
1s - loss: 3522.8058 - val_loss: 14709.2227
Epoch 00007: val_loss improved from 14847.83023 to 14709.22274, saving model to beijing1_weights.hdf5
            beijing1 3441.4231      0.92  0.22  0.73      0.92  0.20  0.75      0.92  0.18  0.77
            beijing114709.2228      0.83  0.24  0.66      0.85  0.20  0.69      0.85  0.19  0.71
forget mean min: 0.894059 0.3604
abs_mean, abs_mean+, abs_mean-: 13.3119 8.91194 21.6997
U_c = [[-0.01615529]] U_f = [[ 0.]] b_c = [ 0.4692679] b_f = [ 1.]
Epoch 9/300
1s - loss: 3501.4074 - val_loss: 14630.3666
Epoch 00008: val_loss improved from 14709.22274 to 14630.36664, saving model to beijing1_weights.hdf5
            beijing1 3423.2128      0.91  0.21  0.73      0.91  0.19  0.75      0.91  0.16  0.77
            beijing114630.3666      0.83  0.24  0.66      0.85  0.21  0.69      0.85  0.19  0.71
forget mean min: 0.896057 0.355084
abs_mean, abs_mean+, abs_mean-: 13.3377 8.97442 21.4194
U_c = [[-0.01777618]] U_f = [[ 0.]] b_c = [ 0.47506154] b_f = [ 1.]
Epoch 10/300
1s - loss: 3486.3162 - val_loss: 14587.8915
Epoch 00009: val_loss improved from 14630.36664 to 14587.89152, saving model to beijing1_weights.hdf5
            beijing1 3388.7392      0.92  0.21  0.73      0.92  0.19  0.75      0.91  0.17  0.77
            beijing114587.8916      0.83  0.23  0.66      0.84  0.20  0.70      0.85  0.19  0.71
forget mean min: 0.890766 0.334834
abs_mean, abs_mean+, abs_mean-: 13.6743 9.12978 22.1257
U_c = [[-0.01993527]] U_f = [[ 0.]] b_c = [ 0.48082152] b_f = [ 1.]
Epoch 11/300
1s - loss: 3467.8577 - val_loss: 14782.9963
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 3469.5985 - val_loss: 14801.6514
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 3456.6225 - val_loss: 14828.8134
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 3427.2201 - val_loss: 14900.5260
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 3415.6214 - val_loss: 14839.2081
Epoch 00014: val_loss did not improve
Epoch 16/300
2s - loss: 3382.5993 - val_loss: 14978.7997
Epoch 00015: val_loss did not improve
Epoch 17/300
2s - loss: 3342.9519 - val_loss: 15079.1181
Epoch 00016: val_loss did not improve
Epoch 18/300
2s - loss: 3297.3774 - val_loss: 15191.7388
Epoch 00017: val_loss did not improve
Epoch 19/300
2s - loss: 3258.0013 - val_loss: 15201.2222
Epoch 00018: val_loss did not improve
Epoch 20/300
2s - loss: 3205.3070 - val_loss: 15365.9415
Epoch 00019: val_loss did not improve
Epoch 21/300
2s - loss: 3137.1471 - val_loss: 15580.9574
Epoch 00020: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training beijing2
Train on 7452 samples, validate on 2328 samples
Before training:
            beijing217847.6134      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.41179 nan 5.41179
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            beijing233481.9608      0.05  -nan  0.05      0.05  -nan  0.05      0.05  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.33326 nan 9.33326
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 10999.3462 - val_loss: 18547.7475
Epoch 00000: val_loss improved from inf to 18547.74751, saving model to beijing2_weights.hdf5
            beijing2 7022.8226      0.69  0.19  0.59      0.68  0.17  0.60      0.66  0.16  0.59
            beijing218547.7476      0.69  0.20  0.59      0.69  0.16  0.61      0.66  0.15  0.59
forget mean min: 0.770053 0.293387
abs_mean, abs_mean+, abs_mean-: 10.4296 2.71276 18.0127
U_c = [[-0.08732094]] U_f = [[ 0.]] b_c = [ 0.12831646] b_f = [ 1.]
Epoch 2/300
2s - loss: 5595.6023 - val_loss: 20599.4483
Epoch 00001: val_loss did not improve
Epoch 3/300
2s - loss: 4160.2167 - val_loss: 18885.8328
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 3813.3664 - val_loss: 17281.8378
Epoch 00003: val_loss improved from 18547.74751 to 17281.83779, saving model to beijing2_weights.hdf5
            beijing2 3744.2019      0.92  0.24  0.71      0.91  0.23  0.72      0.92  0.21  0.74
            beijing217281.8380      0.83  0.25  0.65      0.84  0.21  0.69      0.86  0.19  0.71
forget mean min: 0.908403 0.389916
abs_mean, abs_mean+, abs_mean-: 11.6038 7.29287 22.381
U_c = [[-0.00834325]] U_f = [[ 0.]] b_c = [ 0.39073625] b_f = [ 1.]
Epoch 5/300
2s - loss: 3659.1965 - val_loss: 15614.9128
Epoch 00004: val_loss improved from 17281.83779 to 15614.91280, saving model to beijing2_weights.hdf5
            beijing2 3631.4889      0.92  0.24  0.71      0.92  0.22  0.73      0.92  0.20  0.75
            beijing215614.9130      0.82  0.24  0.66      0.84  0.20  0.70      0.85  0.18  0.72
forget mean min: 0.900228 0.383771
abs_mean, abs_mean+, abs_mean-: 12.4146 8.03959 21.9898
U_c = [[-0.00910961]] U_f = [[ 0.]] b_c = [ 0.43230301] b_f = [ 1.]
Epoch 6/300
2s - loss: 3587.3683 - val_loss: 14960.3489
Epoch 00005: val_loss improved from 15614.91280 to 14960.34892, saving model to beijing2_weights.hdf5
            beijing2 3518.5730      0.92  0.23  0.72      0.92  0.21  0.74      0.92  0.19  0.76
            beijing214960.3492      0.83  0.24  0.66      0.84  0.20  0.70      0.85  0.18  0.72
forget mean min: 0.895343 0.37881
abs_mean, abs_mean+, abs_mean-: 12.7902 8.35448 21.8261
U_c = [[-0.01439767]] U_f = [[ 0.]] b_c = [ 0.44911441] b_f = [ 1.]
Epoch 7/300
2s - loss: 3554.5580 - val_loss: 14731.7580
Epoch 00006: val_loss improved from 14960.34892 to 14731.75802, saving model to beijing2_weights.hdf5
            beijing2 3481.4851      0.91  0.22  0.72      0.91  0.20  0.74      0.91  0.17  0.76
            beijing214731.7579      0.84  0.24  0.66      0.85  0.21  0.70      0.86  0.19  0.71
forget mean min: 0.897761 0.377393
abs_mean, abs_mean+, abs_mean-: 12.936 8.57655 21.482
U_c = [[-0.01552132]] U_f = [[ 0.]] b_c = [ 0.46420035] b_f = [ 1.]
Epoch 8/300
2s - loss: 3534.4479 - val_loss: 14673.5475
Epoch 00007: val_loss improved from 14731.75802 to 14673.54751, saving model to beijing2_weights.hdf5
            beijing2 3463.2273      0.91  0.21  0.73      0.91  0.19  0.75      0.90  0.17  0.76
            beijing214673.5475      0.83  0.24  0.66      0.84  0.20  0.70      0.85  0.18  0.71
forget mean min: 0.894238 0.368019
abs_mean, abs_mean+, abs_mean-: 13.2256 8.84633 21.4907
U_c = [[-0.01599342]] U_f = [[ 0.]] b_c = [ 0.4717809] b_f = [ 1.]
Epoch 9/300
2s - loss: 3514.9625 - val_loss: 14616.6306
Epoch 00008: val_loss improved from 14673.54751 to 14616.63064, saving model to beijing2_weights.hdf5
            beijing2 3459.3127      0.91  0.21  0.73      0.90  0.18  0.75      0.90  0.16  0.77
            beijing214616.6306      0.83  0.24  0.66      0.85  0.21  0.69      0.85  0.19  0.71
forget mean min: 0.895476 0.358363
abs_mean, abs_mean+, abs_mean-: 13.3026 8.94606 21.2293
U_c = [[-0.01877299]] U_f = [[ 0.]] b_c = [ 0.4761889] b_f = [ 1.]
Epoch 10/300
2s - loss: 3494.3657 - val_loss: 14693.8932
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 3469.0545 - val_loss: 14719.0309
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 3465.1217 - val_loss: 14704.5528
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 3455.3154 - val_loss: 14815.2867
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 3431.4256 - val_loss: 14779.7971
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 3404.9910 - val_loss: 14856.4762
Epoch 00014: val_loss did not improve
Epoch 16/300
2s - loss: 3382.6252 - val_loss: 14958.6075
Epoch 00015: val_loss did not improve
Epoch 17/300
2s - loss: 3340.9713 - val_loss: 14967.3459
Epoch 00016: val_loss did not improve
Epoch 18/300
2s - loss: 3284.4009 - val_loss: 15411.1044
Epoch 00017: val_loss did not improve
Epoch 19/300
2s - loss: 3267.5687 - val_loss: 15221.5088
Epoch 00018: val_loss did not improve
Epoch 20/300
2s - loss: 3217.2564 - val_loss: 15221.6839
Epoch 00019: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training tianjin0
Train on 6210 samples, validate on 1940 samples
Before training:
            tianjin0 9263.0556      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.36253 nan 4.36253
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            tianjin028503.3696      0.05  -nan  0.05      0.06  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.77555 nan 8.77555
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 5948.6254 - val_loss: 12179.3939
Epoch 00000: val_loss improved from inf to 12179.39385, saving model to tianjin0_weights.hdf5
            tianjin0 3268.3713      0.54  0.16  0.49      0.54  0.11  0.51      0.53  0.08  0.50
            tianjin012179.3940      0.74  0.08  0.70      0.74  0.05  0.71      0.72  0.02  0.71
forget mean min: 0.814513 0.277851
abs_mean, abs_mean+, abs_mean-: 9.94911 2.25823 18.2951
U_c = [[-0.11243463]] U_f = [[ 0.]] b_c = [ 0.10788567] b_f = [ 1.]
Epoch 2/300
1s - loss: 2770.9760 - val_loss: 10846.9214
Epoch 00001: val_loss improved from 12179.39385 to 10846.92145, saving model to tianjin0_weights.hdf5
            tianjin0 2394.2432      0.77  0.19  0.65      0.79  0.15  0.69      0.79  0.11  0.72
            tianjin010846.9214      0.77  0.13  0.69      0.77  0.10  0.70      0.76  0.08  0.71
forget mean min: 0.862839 0.366516
abs_mean, abs_mean+, abs_mean-: 9.10016 4.15488 17.9016
U_c = [[-0.05284479]] U_f = [[ 0.]] b_c = [ 0.20172581] b_f = [ 1.]
Epoch 3/300
1s - loss: 2282.9194 - val_loss: 9229.7516
Epoch 00002: val_loss improved from 10846.92145 to 9229.75164, saving model to tianjin0_weights.hdf5
            tianjin0 2205.6631      0.85  0.23  0.68      0.87  0.18  0.73      0.88  0.14  0.77
            tianjin0 9229.7515      0.85  0.17  0.73      0.86  0.15  0.75      0.85  0.13  0.75
forget mean min: 0.875388 0.366979
abs_mean, abs_mean+, abs_mean-: 10.7785 5.61357 21.7195
U_c = [[-0.06863869]] U_f = [[ 0.]] b_c = [ 0.2772091] b_f = [ 1.]
Epoch 4/300
1s - loss: 2168.7117 - val_loss: 8793.0851
Epoch 00003: val_loss improved from 9229.75164 to 8793.08510, saving model to tianjin0_weights.hdf5
            tianjin0 2144.7951      0.88  0.24  0.69      0.89  0.19  0.74      0.90  0.15  0.78
            tianjin0 8793.0851      0.86  0.14  0.75      0.86  0.13  0.76      0.86  0.11  0.78
forget mean min: 0.86731 0.371364
abs_mean, abs_mean+, abs_mean-: 11.8221 6.44608 22.4534
U_c = [[-0.07166336]] U_f = [[ 0.]] b_c = [ 0.33515498] b_f = [ 1.]
Epoch 5/300
1s - loss: 2125.6841 - val_loss: 9327.3028
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 2101.3405 - val_loss: 9105.9152
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 2079.5446 - val_loss: 10108.0157
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 2055.4606 - val_loss: 10882.5320
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2016.3084 - val_loss: 10729.6326
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1987.6261 - val_loss: 12309.3418
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1970.2756 - val_loss: 12913.3173
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1964.3430 - val_loss: 12968.8959
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1963.4058 - val_loss: 11250.6432
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1956.3323 - val_loss: 12452.0627
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1956.7741 - val_loss: 12485.7800
Epoch 00014: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training tianjin1
Train on 6210 samples, validate on 1940 samples
Before training:
            tianjin1 9263.0556      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.36253 nan 4.36253
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            tianjin128503.3696      0.05  -nan  0.05      0.06  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.77555 nan 8.77555
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 5881.7014 - val_loss: 12409.4301
Epoch 00000: val_loss improved from inf to 12409.43008, saving model to tianjin1_weights.hdf5
            tianjin1 3245.7091      0.55  0.15  0.50      0.55  0.11  0.52      0.54  0.08  0.51
            tianjin112409.4301      0.72  0.08  0.68      0.72  0.05  0.69      0.70  0.02  0.69
forget mean min: 0.810247 0.27643
abs_mean, abs_mean+, abs_mean-: 9.79502 2.2503 17.7866
U_c = [[-0.10598098]] U_f = [[ 0.]] b_c = [ 0.10850222] b_f = [ 1.]
Epoch 2/300
1s - loss: 2756.0265 - val_loss: 10512.7130
Epoch 00001: val_loss improved from 12409.43008 to 10512.71300, saving model to tianjin1_weights.hdf5
            tianjin1 2411.1878      0.80  0.21  0.65      0.81  0.17  0.70      0.82  0.13  0.72
            tianjin110512.7129      0.79  0.13  0.70      0.79  0.11  0.72      0.78  0.08  0.73
forget mean min: 0.867692 0.340784
abs_mean, abs_mean+, abs_mean-: 9.35135 4.28945 19.3729
U_c = [[-0.05652855]] U_f = [[ 0.]] b_c = [ 0.20097494] b_f = [ 1.]
Epoch 3/300
1s - loss: 2281.2794 - val_loss: 9228.1448
Epoch 00002: val_loss improved from 10512.71300 to 9228.14475, saving model to tianjin1_weights.hdf5
            tianjin1 2196.0270      0.84  0.22  0.68      0.85  0.17  0.72      0.85  0.13  0.76
            tianjin1 9228.1448      0.85  0.16  0.73      0.85  0.14  0.75      0.84  0.12  0.75
forget mean min: 0.873697 0.375008
abs_mean, abs_mean+, abs_mean-: 10.6117 5.50052 21.0066
U_c = [[-0.06570005]] U_f = [[ 0.]] b_c = [ 0.27810225] b_f = [ 1.]
Epoch 4/300
1s - loss: 2165.1014 - val_loss: 8962.8512
Epoch 00003: val_loss improved from 9228.14475 to 8962.85115, saving model to tianjin1_weights.hdf5
            tianjin1 2129.7862      0.87  0.23  0.69      0.88  0.18  0.74      0.89  0.13  0.78
            tianjin1 8962.8512      0.85  0.13  0.75      0.86  0.12  0.77      0.85  0.10  0.78
forget mean min: 0.863917 0.375036
abs_mean, abs_mean+, abs_mean-: 11.7888 6.26361 22.1059
U_c = [[-0.07554765]] U_f = [[ 0.]] b_c = [ 0.33435285] b_f = [ 1.]
Epoch 5/300
1s - loss: 2119.8662 - val_loss: 8921.2907
Epoch 00004: val_loss improved from 8962.85115 to 8921.29069, saving model to tianjin1_weights.hdf5
            tianjin1 2100.7004      0.89  0.24  0.69      0.90  0.19  0.74      0.90  0.14  0.78
            tianjin1 8921.2907      0.85  0.13  0.76      0.85  0.11  0.77      0.85  0.09  0.79
forget mean min: 0.858784 0.366317
abs_mean, abs_mean+, abs_mean-: 12.605 6.84905 22.9734
U_c = [[-0.07889187]] U_f = [[ 0.]] b_c = [ 0.37323794] b_f = [ 1.]
Epoch 6/300
1s - loss: 2094.8503 - val_loss: 9019.3985
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 2074.1771 - val_loss: 10767.9766
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 2043.0285 - val_loss: 10422.0506
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1999.9780 - val_loss: 10585.3628
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1981.1483 - val_loss: 11738.7499
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1972.3657 - val_loss: 10607.8558
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1967.8968 - val_loss: 11893.9296
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1962.1787 - val_loss: 10976.1508
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1957.2195 - val_loss: 12092.6707
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1956.7217 - val_loss: 12084.6314
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1950.3760 - val_loss: 11936.5016
Epoch 00015: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training tianjin2
Train on 6210 samples, validate on 1940 samples
Before training:
            tianjin2 9263.0556      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.36253 nan 4.36253
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            tianjin228503.3696      0.05  -nan  0.05      0.06  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.77555 nan 8.77555
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 5877.6438 - val_loss: 12475.2835
Epoch 00000: val_loss improved from inf to 12475.28350, saving model to tianjin2_weights.hdf5
            tianjin2 3241.3277      0.55  0.15  0.50      0.55  0.10  0.52      0.54  0.07  0.52
            tianjin212475.2834      0.72  0.08  0.68      0.71  0.05  0.69      0.69  0.02  0.68
forget mean min: 0.810419 0.281943
abs_mean, abs_mean+, abs_mean-: 9.69659 2.24612 17.3779
U_c = [[-0.10332257]] U_f = [[ 0.]] b_c = [ 0.10783198] b_f = [ 1.]
Epoch 2/300
1s - loss: 2742.3426 - val_loss: 10836.8091
Epoch 00001: val_loss improved from 12475.28350 to 10836.80909, saving model to tianjin2_weights.hdf5
            tianjin2 2408.1898      0.76  0.19  0.65      0.78  0.14  0.69      0.78  0.10  0.72
            tianjin210836.8092      0.76  0.12  0.69      0.76  0.09  0.70      0.75  0.07  0.71
forget mean min: 0.859396 0.375075
abs_mean, abs_mean+, abs_mean-: 9.1006 4.02163 17.4575
U_c = [[-0.05464036]] U_f = [[ 0.]] b_c = [ 0.19878176] b_f = [ 1.]
Epoch 3/300
1s - loss: 2285.2836 - val_loss: 9386.9331
Epoch 00002: val_loss improved from 10836.80909 to 9386.93311, saving model to tianjin2_weights.hdf5
            tianjin2 2198.7778      0.84  0.22  0.68      0.86  0.18  0.73      0.86  0.13  0.76
            tianjin2 9386.9331      0.83  0.16  0.72      0.84  0.14  0.74      0.83  0.11  0.75
forget mean min: 0.868848 0.372764
abs_mean, abs_mean+, abs_mean-: 10.7265 5.5483 21.2871
U_c = [[-0.06291839]] U_f = [[ 0.]] b_c = [ 0.27929655] b_f = [ 1.]
Epoch 4/300
1s - loss: 2172.2843 - val_loss: 8704.1641
Epoch 00003: val_loss improved from 9386.93311 to 8704.16408, saving model to tianjin2_weights.hdf5
            tianjin2 2148.8504      0.88  0.24  0.69      0.90  0.19  0.74      0.90  0.15  0.78
            tianjin2 8704.1640      0.86  0.15  0.75      0.86  0.13  0.76      0.86  0.11  0.78
forget mean min: 0.867181 0.360427
abs_mean, abs_mean+, abs_mean-: 12.1445 6.60928 23.9363
U_c = [[-0.07285442]] U_f = [[ 0.]] b_c = [ 0.33532339] b_f = [ 1.]
Epoch 5/300
1s - loss: 2127.2087 - val_loss: 8641.3080
Epoch 00004: val_loss improved from 8704.16408 to 8641.30803, saving model to tianjin2_weights.hdf5
            tianjin2 2125.9153      0.90  0.24  0.70      0.91  0.20  0.74      0.91  0.15  0.78
            tianjin2 8641.3080      0.86  0.13  0.76      0.87  0.12  0.78      0.87  0.10  0.79
forget mean min: 0.862665 0.353192
abs_mean, abs_mean+, abs_mean-: 12.9166 7.07014 24.5769
U_c = [[-0.08347644]] U_f = [[ 0.]] b_c = [ 0.36758977] b_f = [ 1.]
Epoch 6/300
1s - loss: 2099.0144 - val_loss: 9418.7282
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 2077.0299 - val_loss: 9088.6072
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 2055.6184 - val_loss: 10069.7693
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2016.9993 - val_loss: 11544.8077
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1987.6358 - val_loss: 13138.0193
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1979.0685 - val_loss: 11212.1094
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1965.7366 - val_loss: 10762.3468
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1966.1585 - val_loss: 10791.6758
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1957.4378 - val_loss: 12110.1220
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1958.1288 - val_loss: 12713.1652
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1948.3414 - val_loss: 10959.5446
Epoch 00015: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training tangshan0
Train on 3726 samples, validate on 1164 samples
Before training:
           tangshan011203.3119      0.03  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.88994 nan 4.88994
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           tangshan027800.0934      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.02168 nan 9.02168
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 8950.6649 - val_loss: 14590.4537
Epoch 00000: val_loss improved from inf to 14590.45375, saving model to tangshan0_weights.hdf5
           tangshan0 4882.9362      0.40  0.04  0.39      0.41  0.01  0.40      0.40  0.01  0.40
           tangshan014590.4538      0.55  0.04  0.54      0.55  0.01  0.55      0.54  0.01  0.54
forget mean min: 0.777707 0.363503
abs_mean, abs_mean+, abs_mean-: 10.7231 1.41267 12.7929
U_c = [[-0.11207553]] U_f = [[ 0.]] b_c = [ 0.07072834] b_f = [ 1.]
Epoch 2/300
1s - loss: 3830.2070 - val_loss: 9932.1644
Epoch 00001: val_loss improved from 14590.45375 to 9932.16441, saving model to tangshan0_weights.hdf5
           tangshan0 3240.3514      0.66  0.07  0.63      0.68  0.03  0.66      0.67  0.02  0.66
           tangshan0 9932.1644      0.83  0.10  0.76      0.85  0.04  0.82      0.84  0.04  0.81
forget mean min: 0.868222 0.271259
abs_mean, abs_mean+, abs_mean-: 8.65819 2.67826 17.8389
U_c = [[-0.093593]] U_f = [[ 0.]] b_c = [ 0.12860784] b_f = [ 1.]
Epoch 3/300
1s - loss: 2812.6652 - val_loss: 9425.9740
Epoch 00002: val_loss improved from 9932.16441 to 9425.97396, saving model to tangshan0_weights.hdf5
           tangshan0 2443.5136      0.79  0.16  0.69      0.82  0.13  0.73      0.83  0.12  0.74
           tangshan0 9425.9740      0.97  0.31  0.67      0.97  0.28  0.70      0.97  0.28  0.70
forget mean min: 0.970989 0.319193
abs_mean, abs_mean+, abs_mean-: 6.21225 3.96693 21.2495
U_c = [[-0.04894748]] U_f = [[ 0.]] b_c = [ 0.18498753] b_f = [ 1.]
Epoch 4/300
1s - loss: 2318.5262 - val_loss: 9488.2894
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 2150.9450 - val_loss: 7764.3161
Epoch 00004: val_loss improved from 9425.97396 to 7764.31613, saving model to tangshan0_weights.hdf5
           tangshan0 2086.5672      0.86  0.20  0.71      0.88  0.16  0.75      0.89  0.15  0.78
           tangshan0 7764.3162      0.97  0.31  0.68      0.98  0.28  0.70      0.98  0.28  0.71
forget mean min: 0.958402 0.392453
abs_mean, abs_mean+, abs_mean-: 7.94247 5.48355 17.7927
U_c = [[-0.05455098]] U_f = [[ 0.]] b_c = [ 0.27792975] b_f = [ 1.]
Epoch 6/300
1s - loss: 2047.7822 - val_loss: 6766.5755
Epoch 00005: val_loss improved from 7764.31613 to 6766.57551, saving model to tangshan0_weights.hdf5
           tangshan0 2038.6365      0.85  0.18  0.72      0.88  0.15  0.76      0.88  0.13  0.78
           tangshan0 6766.5755      0.95  0.23  0.74      0.96  0.20  0.77      0.97  0.20  0.78
forget mean min: 0.934974 0.393533
abs_mean, abs_mean+, abs_mean-: 8.60698 5.54532 16.3487
U_c = [[-0.06143298]] U_f = [[ 0.]] b_c = [ 0.31315494] b_f = [ 1.]
Epoch 7/300
1s - loss: 1975.8395 - val_loss: 6392.2704
Epoch 00006: val_loss improved from 6766.57551 to 6392.27040, saving model to tangshan0_weights.hdf5
           tangshan0 1949.3804      0.89  0.20  0.72      0.92  0.18  0.76      0.91  0.17  0.77
           tangshan0 6392.2704      0.95  0.23  0.74      0.96  0.20  0.78      0.97  0.20  0.78
forget mean min: 0.935939 0.366121
abs_mean, abs_mean+, abs_mean-: 9.86704 6.6489 18.8228
U_c = [[-0.06176683]] U_f = [[ 0.]] b_c = [ 0.34896082] b_f = [ 1.]
Epoch 8/300
1s - loss: 1943.9251 - val_loss: 6363.5281
Epoch 00007: val_loss improved from 6392.27040 to 6363.52810, saving model to tangshan0_weights.hdf5
           tangshan0 1920.6097      0.89  0.20  0.73      0.92  0.17  0.77      0.91  0.16  0.78
           tangshan0 6363.5281      0.95  0.24  0.73      0.96  0.21  0.77      0.97  0.20  0.78
forget mean min: 0.937035 0.359605
abs_mean, abs_mean+, abs_mean-: 10.1295 6.97471 18.7834
U_c = [[-0.06221735]] U_f = [[ 0.]] b_c = [ 0.37434343] b_f = [ 1.]
Epoch 9/300
1s - loss: 1915.9300 - val_loss: 6234.9206
Epoch 00008: val_loss improved from 6363.52810 to 6234.92061, saving model to tangshan0_weights.hdf5
           tangshan0 1892.5007      0.89  0.20  0.73      0.92  0.17  0.78      0.92  0.16  0.78
           tangshan0 6234.9206      0.94  0.22  0.75      0.96  0.17  0.80      0.97  0.16  0.81
forget mean min: 0.92926 0.347952
abs_mean, abs_mean+, abs_mean-: 10.4352 7.00851 19.2689
U_c = [[-0.06545996]] U_f = [[ 0.]] b_c = [ 0.39407808] b_f = [ 1.]
Epoch 10/300
0s - loss: 1889.0609 - val_loss: 6310.8080
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 1861.8239 - val_loss: 6198.6702
Epoch 00010: val_loss improved from 6234.92061 to 6198.67020, saving model to tangshan0_weights.hdf5
           tangshan0 1844.4091      0.89  0.19  0.74      0.92  0.16  0.78      0.91  0.15  0.79
           tangshan0 6198.6703      0.93  0.19  0.77      0.96  0.13  0.83      0.96  0.11  0.86
forget mean min: 0.92008 0.331596
abs_mean, abs_mean+, abs_mean-: 10.9792 7.22611 19.956
U_c = [[-0.06615102]] U_f = [[ 0.]] b_c = [ 0.43320939] b_f = [ 1.]
Epoch 12/300
1s - loss: 1849.0694 - val_loss: 6331.2198
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1838.0113 - val_loss: 6423.8873
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1827.6191 - val_loss: 6323.0185
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1828.5477 - val_loss: 6361.3255
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1822.8487 - val_loss: 6373.2225
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1816.5848 - val_loss: 6402.3634
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1813.5676 - val_loss: 6385.3084
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1808.2131 - val_loss: 6541.6805
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1810.0599 - val_loss: 6499.9788
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1800.8617 - val_loss: 6521.8384
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1801.4133 - val_loss: 6456.7321
Epoch 00021: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training tangshan1
Train on 3726 samples, validate on 1164 samples
Before training:
           tangshan111203.3119      0.03  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.88994 nan 4.88994
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           tangshan127800.0934      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.02168 nan 9.02168
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 8934.9377 - val_loss: 14677.8399
Epoch 00000: val_loss improved from inf to 14677.83985, saving model to tangshan1_weights.hdf5
           tangshan1 4924.6697      0.40  0.05  0.39      0.40  0.02  0.40      0.40  0.01  0.40
           tangshan114677.8400      0.55  0.04  0.54      0.55  0.01  0.54      0.54  0.01  0.53
forget mean min: 0.776106 0.363652
abs_mean, abs_mean+, abs_mean-: 10.7378 1.43664 12.7426
U_c = [[-0.11129913]] U_f = [[ 0.]] b_c = [ 0.07019924] b_f = [ 1.]
Epoch 2/300
1s - loss: 3830.5532 - val_loss: 9969.5721
Epoch 00001: val_loss improved from 14677.83985 to 9969.57208, saving model to tangshan1_weights.hdf5
           tangshan1 3226.0553      0.66  0.06  0.63      0.68  0.03  0.66      0.67  0.02  0.66
           tangshan1 9969.5721      0.82  0.09  0.76      0.84  0.04  0.82      0.84  0.04  0.81
forget mean min: 0.865362 0.271927
abs_mean, abs_mean+, abs_mean-: 8.70131 2.71451 17.7275
U_c = [[-0.0919538]] U_f = [[ 0.]] b_c = [ 0.12828723] b_f = [ 1.]
Epoch 3/300
1s - loss: 2802.2042 - val_loss: 8537.9251
Epoch 00002: val_loss improved from 9969.57208 to 8537.92513, saving model to tangshan1_weights.hdf5
           tangshan1 2442.5655      0.78  0.16  0.68      0.81  0.13  0.72      0.82  0.12  0.74
           tangshan1 8537.9251      0.96  0.29  0.69      0.96  0.26  0.72      0.97  0.25  0.72
forget mean min: 0.963121 0.335887
abs_mean, abs_mean+, abs_mean-: 6.58584 3.9749 19.9054
U_c = [[-0.04848628]] U_f = [[ 0.]] b_c = [ 0.18468705] b_f = [ 1.]
Epoch 4/300
1s - loss: 2303.1392 - val_loss: 8588.4665
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 2142.3255 - val_loss: 7523.0971
Epoch 00004: val_loss improved from 8537.92513 to 7523.09711, saving model to tangshan1_weights.hdf5
           tangshan1 2081.9836      0.86  0.20  0.70      0.89  0.17  0.75      0.90  0.16  0.77
           tangshan1 7523.0972      0.97  0.30  0.68      0.98  0.27  0.71      0.98  0.27  0.71
forget mean min: 0.957569 0.38397
abs_mean, abs_mean+, abs_mean-: 8.21278 5.60491 18.726
U_c = [[-0.05266662]] U_f = [[ 0.]] b_c = [ 0.27479252] b_f = [ 1.]
Epoch 6/300
1s - loss: 2045.4227 - val_loss: 6604.1660
Epoch 00005: val_loss improved from 7523.09711 to 6604.16598, saving model to tangshan1_weights.hdf5
           tangshan1 2004.7009      0.87  0.19  0.72      0.89  0.16  0.76      0.90  0.14  0.78
           tangshan1 6604.1659      0.96  0.24  0.73      0.97  0.21  0.76      0.97  0.21  0.77
forget mean min: 0.939467 0.389596
abs_mean, abs_mean+, abs_mean-: 8.867 5.79758 17.4439
U_c = [[-0.05881978]] U_f = [[ 0.]] b_c = [ 0.31192571] b_f = [ 1.]
Epoch 7/300
1s - loss: 1976.9514 - val_loss: 6547.1353
Epoch 00006: val_loss improved from 6604.16598 to 6547.13527, saving model to tangshan1_weights.hdf5
           tangshan1 1991.9169      0.87  0.18  0.73      0.90  0.15  0.78      0.90  0.13  0.79
           tangshan1 6547.1353      0.96  0.23  0.75      0.97  0.20  0.78      0.98  0.19  0.79
forget mean min: 0.933294 0.385257
abs_mean, abs_mean+, abs_mean-: 9.3643 6.03878 17.8746
U_c = [[-0.06589916]] U_f = [[ 0.]] b_c = [ 0.33925235] b_f = [ 1.]
Epoch 8/300
1s - loss: 1947.5598 - val_loss: 6366.1160
Epoch 00007: val_loss improved from 6547.13527 to 6366.11597, saving model to tangshan1_weights.hdf5
           tangshan1 1927.1486      0.89  0.19  0.73      0.91  0.16  0.77      0.91  0.15  0.78
           tangshan1 6366.1160      0.95  0.21  0.75      0.96  0.17  0.81      0.97  0.15  0.83
forget mean min: 0.925426 0.372356
abs_mean, abs_mean+, abs_mean-: 10.0919 6.49542 18.8561
U_c = [[-0.06646663]] U_f = [[ 0.]] b_c = [ 0.36571467] b_f = [ 1.]
Epoch 9/300
1s - loss: 1925.9796 - val_loss: 6219.8854
Epoch 00008: val_loss improved from 6366.11597 to 6219.88544, saving model to tangshan1_weights.hdf5
           tangshan1 1920.6629      0.89  0.21  0.72      0.92  0.18  0.77      0.92  0.17  0.77
           tangshan1 6219.8854      0.94  0.22  0.75      0.96  0.17  0.80      0.97  0.16  0.82
forget mean min: 0.929015 0.355152
abs_mean, abs_mean+, abs_mean-: 10.4946 7.02684 19.4926
U_c = [[-0.06153023]] U_f = [[ 0.]] b_c = [ 0.38961977] b_f = [ 1.]
Epoch 10/300
1s - loss: 1897.7330 - val_loss: 6290.2899
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1868.7599 - val_loss: 6470.1884
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1854.7366 - val_loss: 6386.3356
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1841.8108 - val_loss: 6312.2585
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1835.3212 - val_loss: 6386.0365
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1827.5482 - val_loss: 6394.1282
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1820.5618 - val_loss: 6415.3480
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1815.4516 - val_loss: 6190.4923
Epoch 00016: val_loss improved from 6219.88544 to 6190.49231, saving model to tangshan1_weights.hdf5
           tangshan1 1794.9264      0.90  0.19  0.74      0.92  0.15  0.79      0.92  0.14  0.80
           tangshan1 6190.4923      0.93  0.17  0.78      0.96  0.11  0.86      0.96  0.08  0.88
forget mean min: 0.914711 0.332512
abs_mean, abs_mean+, abs_mean-: 11.7685 7.51712 22.1374
U_c = [[-0.06649411]] U_f = [[ 0.]] b_c = [ 0.48736101] b_f = [ 1.]
Epoch 18/300
1s - loss: 1813.8783 - val_loss: 6300.4580
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1812.4985 - val_loss: 6336.4088
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1808.0550 - val_loss: 6263.6191
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1799.7406 - val_loss: 6323.7018
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1802.3303 - val_loss: 6519.7460
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1800.5492 - val_loss: 6396.4347
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1796.0367 - val_loss: 6296.8220
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1798.0377 - val_loss: 6462.0119
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1794.5903 - val_loss: 6466.1804
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 1796.0718 - val_loss: 6286.7302
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 1797.2910 - val_loss: 6555.3794
Epoch 00027: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training tangshan2
Train on 3726 samples, validate on 1164 samples
Before training:
           tangshan211203.3119      0.03  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.88994 nan 4.88994
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           tangshan227800.0934      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 9.02168 nan 9.02168
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
0s - loss: 8948.5609 - val_loss: 14988.5175
Epoch 00000: val_loss improved from inf to 14988.51748, saving model to tangshan2_weights.hdf5
           tangshan2 4940.7696      0.40  0.04  0.39      0.41  0.01  0.40      0.40  0.01  0.40
           tangshan214988.5176      0.53  0.04  0.52      0.53  0.01  0.52      0.51  0.00  0.51
forget mean min: 0.771292 0.365161
abs_mean, abs_mean+, abs_mean-: 10.8278 1.42569 12.7479
U_c = [[-0.1104807]] U_f = [[ 0.]] b_c = [ 0.0700989] b_f = [ 1.]
Epoch 2/300
1s - loss: 3827.7092 - val_loss: 9979.4335
Epoch 00001: val_loss improved from 14988.51748 to 9979.43353, saving model to tangshan2_weights.hdf5
           tangshan2 3222.9798      0.66  0.07  0.63      0.68  0.03  0.67      0.67  0.02  0.66
           tangshan2 9979.4336      0.82  0.09  0.76      0.84  0.04  0.81      0.84  0.04  0.81
forget mean min: 0.865199 0.264335
abs_mean, abs_mean+, abs_mean-: 8.71985 2.71365 17.931
U_c = [[-0.09209378]] U_f = [[ 0.]] b_c = [ 0.12814556] b_f = [ 1.]
Epoch 3/300
1s - loss: 2808.3103 - val_loss: 8572.2291
Epoch 00002: val_loss improved from 9979.43353 to 8572.22906, saving model to tangshan2_weights.hdf5
           tangshan2 2448.5150      0.79  0.16  0.69      0.82  0.13  0.73      0.82  0.12  0.74
           tangshan2 8572.2291      0.96  0.29  0.68      0.97  0.26  0.71      0.97  0.26  0.72
forget mean min: 0.964079 0.335307
abs_mean, abs_mean+, abs_mean-: 6.52429 3.98948 19.2062
U_c = [[-0.04967891]] U_f = [[ 0.]] b_c = [ 0.18439603] b_f = [ 1.]
Epoch 4/300
1s - loss: 2310.9026 - val_loss: 8987.1626
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 2134.9084 - val_loss: 7511.1468
Epoch 00004: val_loss improved from 8572.22906 to 7511.14676, saving model to tangshan2_weights.hdf5
           tangshan2 2086.3446      0.87  0.21  0.70      0.89  0.18  0.74      0.90  0.17  0.76
           tangshan2 7511.1469      0.97  0.29  0.69      0.98  0.27  0.72      0.98  0.27  0.71
forget mean min: 0.956665 0.37713
abs_mean, abs_mean+, abs_mean-: 8.55271 5.8381 19.6334
U_c = [[-0.05158921]] U_f = [[ 0.]] b_c = [ 0.28128353] b_f = [ 1.]
Epoch 6/300
1s - loss: 2034.6228 - val_loss: 6806.2925
Epoch 00005: val_loss improved from 7511.14676 to 6806.29255, saving model to tangshan2_weights.hdf5
           tangshan2 1986.9497      0.88  0.21  0.71      0.90  0.18  0.75      0.91  0.16  0.77
           tangshan2 6806.2926      0.97  0.28  0.70      0.97  0.25  0.73      0.98  0.25  0.74
forget mean min: 0.948188 0.377959
abs_mean, abs_mean+, abs_mean-: 9.11114 6.20464 18.8496
U_c = [[-0.05783562]] U_f = [[ 0.]] b_c = [ 0.31619194] b_f = [ 1.]
Epoch 7/300
1s - loss: 1970.5642 - val_loss: 6424.6459
Epoch 00006: val_loss improved from 6806.29255 to 6424.64586, saving model to tangshan2_weights.hdf5
           tangshan2 1943.4320      0.89  0.20  0.73      0.91  0.17  0.77      0.91  0.16  0.77
           tangshan2 6424.6458      0.95  0.23  0.74      0.96  0.20  0.78      0.97  0.19  0.79
forget mean min: 0.934741 0.372045
abs_mean, abs_mean+, abs_mean-: 9.7108 6.42253 18.3874
U_c = [[-0.06334027]] U_f = [[ 0.]] b_c = [ 0.34487429] b_f = [ 1.]
Epoch 8/300
1s - loss: 1941.0424 - val_loss: 6365.0132
Epoch 00007: val_loss improved from 6424.64586 to 6365.01315, saving model to tangshan2_weights.hdf5
           tangshan2 1917.6471      0.89  0.21  0.72      0.92  0.18  0.77      0.91  0.17  0.77
           tangshan2 6365.0131      0.95  0.22  0.75      0.96  0.18  0.79      0.97  0.18  0.80
forget mean min: 0.931557 0.364113
abs_mean, abs_mean+, abs_mean-: 10.0972 6.72222 18.8006
U_c = [[-0.06267917]] U_f = [[ 0.]] b_c = [ 0.3748062] b_f = [ 1.]
Epoch 9/300
1s - loss: 1914.8613 - val_loss: 6185.0816
Epoch 00008: val_loss improved from 6365.01315 to 6185.08161, saving model to tangshan2_weights.hdf5
           tangshan2 1896.6283      0.89  0.20  0.73      0.92  0.17  0.77      0.92  0.16  0.78
           tangshan2 6185.0817      0.95  0.21  0.75      0.96  0.17  0.80      0.97  0.16  0.82
forget mean min: 0.929044 0.35401
abs_mean, abs_mean+, abs_mean-: 10.3906 6.97488 18.7624
U_c = [[-0.06248041]] U_f = [[ 0.]] b_c = [ 0.3945998] b_f = [ 1.]
Epoch 10/300
1s - loss: 1885.7412 - val_loss: 6368.4601
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1858.2227 - val_loss: 6440.9350
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1849.1727 - val_loss: 6370.6350
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1840.3743 - val_loss: 6492.0048
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1835.2498 - val_loss: 6548.7564
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1829.2023 - val_loss: 6331.4360
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1820.6716 - val_loss: 6394.5375
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1816.1323 - val_loss: 6458.1125
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1813.9186 - val_loss: 6602.4059
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1814.2200 - val_loss: 6424.1918
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1802.6818 - val_loss: 6245.0834
Epoch 00019: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training baoding0
Train on 3726 samples, validate on 1164 samples
Before training:
            baoding023075.2322      0.03  -nan  0.03      0.04  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.15754 nan 6.15754
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            baoding052911.9993      0.06  -nan  0.06      0.07  -nan  0.07      0.08  -nan  0.08
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 14.2668 nan 14.2668
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 19479.6892 - val_loss: 21975.0254
Epoch 00000: val_loss improved from inf to 21975.02538, saving model to baoding0_weights.hdf5
            baoding013354.9028      0.34  0.07  0.33      0.34  0.04  0.34      0.34  0.03  0.34
            baoding021975.0255      0.84  0.08  0.78      0.84  0.05  0.80      0.85  0.02  0.84
forget mean min: 0.883096 0.390504
abs_mean, abs_mean+, abs_mean-: 12.8802 1.39664 15.0621
U_c = [[-0.11153077]] U_f = [[ 0.]] b_c = [ 0.06998897] b_f = [ 1.]
Epoch 2/300
1s - loss: 11106.6165 - val_loss: 14784.2978
Epoch 00001: val_loss improved from 21975.02538 to 14784.29780, saving model to baoding0_weights.hdf5
            baoding0 9647.1943      0.75  0.18  0.65      0.76  0.15  0.67      0.75  0.13  0.67
            baoding014784.2976      0.96  0.12  0.85      0.96  0.08  0.89      0.98  0.05  0.93
forget mean min: 0.963531 0.237901
abs_mean, abs_mean+, abs_mean-: 7.06504 2.70213 33.8581
U_c = [[-0.10334796]] U_f = [[ 0.]] b_c = [ 0.12744936] b_f = [ 1.]
Epoch 3/300
1s - loss: 8936.5598 - val_loss: 17607.7481
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 8055.4551 - val_loss: 17756.3321
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 7689.4350 - val_loss: 16137.4809
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7422.1236 - val_loss: 15313.4201
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 7078.7131 - val_loss: 15004.4438
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6649.0194 - val_loss: 15982.0925
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 6489.9397 - val_loss: 14278.6745
Epoch 00008: val_loss improved from 14784.29780 to 14278.67448, saving model to baoding0_weights.hdf5
            baoding0 6349.3236      0.91  0.22  0.72      0.93  0.18  0.77      0.93  0.15  0.80
            baoding014278.6744      0.99  0.10  0.89      0.99  0.06  0.93      1.00  0.03  0.96
forget mean min: 0.958353 0.338084
abs_mean, abs_mean+, abs_mean-: 14.6769 9.01129 38.14
U_c = [[-0.04872022]] U_f = [[ 0.]] b_c = [ 0.4430609] b_f = [ 1.]
Epoch 10/300
1s - loss: 6354.4361 - val_loss: 13732.2678
Epoch 00009: val_loss improved from 14278.67448 to 13732.26783, saving model to baoding0_weights.hdf5
            baoding0 6211.3313      0.90  0.21  0.72      0.93  0.18  0.77      0.93  0.14  0.80
            baoding013732.2678      0.98  0.10  0.88      0.99  0.06  0.93      1.00  0.03  0.96
forget mean min: 0.946887 0.360676
abs_mean, abs_mean+, abs_mean-: 15.585 9.1329 36.231
U_c = [[-0.0535511]] U_f = [[ 0.]] b_c = [ 0.47466737] b_f = [ 1.]
Epoch 11/300
1s - loss: 6251.3818 - val_loss: 14245.5957
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6162.3279 - val_loss: 13988.7020
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6077.8720 - val_loss: 14185.8431
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 6005.3941 - val_loss: 13533.1119
Epoch 00013: val_loss improved from 13732.26783 to 13533.11187, saving model to baoding0_weights.hdf5
            baoding0 5863.1068      0.90  0.25  0.69      0.92  0.22  0.73      0.93  0.19  0.76
            baoding013533.1118      0.99  0.12  0.87      1.00  0.07  0.92      1.00  0.05  0.95
forget mean min: 0.946888 0.369162
abs_mean, abs_mean+, abs_mean-: 18.6426 11.6398 40.5962
U_c = [[-0.0438787]] U_f = [[ 0.]] b_c = [ 0.59400678] b_f = [ 1.]
Epoch 15/300
1s - loss: 5987.1213 - val_loss: 13801.7673
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 5936.3205 - val_loss: 14091.2804
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 5939.7075 - val_loss: 13656.3972
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 5896.6106 - val_loss: 13309.6056
Epoch 00017: val_loss improved from 13533.11187 to 13309.60558, saving model to baoding0_weights.hdf5
            baoding0 5674.7419      0.89  0.24  0.69      0.92  0.21  0.74      0.92  0.19  0.76
            baoding013309.6055      0.98  0.11  0.87      0.99  0.07  0.92      0.99  0.04  0.95
forget mean min: 0.934499 0.370049
abs_mean, abs_mean+, abs_mean-: 20.8624 12.935 41.0375
U_c = [[-0.04240735]] U_f = [[ 0.]] b_c = [ 0.6630103] b_f = [ 1.]
Epoch 19/300
0s - loss: 5889.3315 - val_loss: 13814.6716
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 5823.7649 - val_loss: 14171.0154
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 5809.6531 - val_loss: 13982.5591
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 5892.7358 - val_loss: 13305.8000
Epoch 00021: val_loss improved from 13309.60558 to 13305.80005, saving model to baoding0_weights.hdf5
            baoding0 5677.3583      0.89  0.26  0.68      0.92  0.23  0.72      0.92  0.21  0.74
            baoding013305.8002      0.98  0.11  0.88      0.99  0.07  0.92      1.00  0.04  0.95
forget mean min: 0.938822 0.3427
abs_mean, abs_mean+, abs_mean-: 21.5631 13.7621 42.9361
U_c = [[-0.04459242]] U_f = [[ 0.]] b_c = [ 0.69873297] b_f = [ 1.]
Epoch 23/300
0s - loss: 5813.3883 - val_loss: 14170.9618
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 5799.7774 - val_loss: 13754.9953
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 5822.8082 - val_loss: 13511.3662
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 5827.2256 - val_loss: 15018.1261
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 5785.8704 - val_loss: 14557.0481
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 5822.2630 - val_loss: 14617.2078
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 5811.3147 - val_loss: 14810.8019
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 5798.8534 - val_loss: 14042.9877
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 5822.1261 - val_loss: 14547.5225
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 5838.7592 - val_loss: 13877.9115
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 5815.4560 - val_loss: 14583.4607
Epoch 00032: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training baoding1
Train on 3726 samples, validate on 1164 samples
Before training:
            baoding123075.2322      0.03  -nan  0.03      0.04  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.15754 nan 6.15754
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            baoding152911.9993      0.06  -nan  0.06      0.07  -nan  0.07      0.08  -nan  0.08
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 14.2668 nan 14.2668
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 19728.1785 - val_loss: 22333.0723
Epoch 00000: val_loss improved from inf to 22333.07227, saving model to baoding1_weights.hdf5
            baoding113513.7539      0.32  0.07  0.31      0.33  0.04  0.32      0.32  0.03  0.32
            baoding122333.0725      0.83  0.08  0.77      0.83  0.04  0.80      0.85  0.02  0.84
forget mean min: 0.880963 0.398761
abs_mean, abs_mean+, abs_mean-: 12.946 1.32151 14.9242
U_c = [[-0.11099413]] U_f = [[ 0.]] b_c = [ 0.06965332] b_f = [ 1.]
Epoch 2/300
1s - loss: 11169.5608 - val_loss: 14880.8343
Epoch 00001: val_loss improved from 22333.07227 to 14880.83429, saving model to baoding1_weights.hdf5
            baoding1 9684.5292      0.75  0.18  0.64      0.76  0.15  0.67      0.75  0.13  0.67
            baoding114880.8341      0.96  0.12  0.84      0.96  0.08  0.89      0.98  0.05  0.93
forget mean min: 0.962186 0.232108
abs_mean, abs_mean+, abs_mean-: 7.17157 2.69804 34.8959
U_c = [[-0.10401342]] U_f = [[ 0.]] b_c = [ 0.12690993] b_f = [ 1.]
Epoch 3/300
1s - loss: 8945.7239 - val_loss: 17425.9635
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 8036.5970 - val_loss: 18971.4418
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 7679.7360 - val_loss: 15660.5500
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7404.5171 - val_loss: 14627.5328
Epoch 00005: val_loss improved from 14880.83429 to 14627.53283, saving model to baoding1_weights.hdf5
            baoding1 7244.7482      0.91  0.23  0.72      0.94  0.19  0.77      0.94  0.17  0.79
            baoding114627.5328      0.98  0.11  0.87      0.98  0.07  0.91      0.99  0.05  0.94
forget mean min: 0.972132 0.412879
abs_mean, abs_mean+, abs_mean-: 10.0404 6.82955 31.261
U_c = [[-0.06431857]] U_f = [[ 0.]] b_c = [ 0.3236936] b_f = [ 1.]
Epoch 7/300
1s - loss: 7138.3117 - val_loss: 14723.8649
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6821.7243 - val_loss: 14044.8412
Epoch 00007: val_loss improved from 14627.53283 to 14044.84116, saving model to baoding1_weights.hdf5
            baoding1 6650.6061      0.89  0.19  0.73      0.92  0.15  0.79      0.92  0.13  0.81
            baoding114044.8412      0.98  0.09  0.89      0.98  0.05  0.93      0.98  0.02  0.96
forget mean min: 0.951572 0.370044
abs_mean, abs_mean+, abs_mean-: 13.2498 8.02388 31.2168
U_c = [[-0.05365033]] U_f = [[ 0.]] b_c = [ 0.40088645] b_f = [ 1.]
Epoch 9/300
1s - loss: 6597.0437 - val_loss: 14135.9411
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 6464.6249 - val_loss: 13616.3391
Epoch 00009: val_loss improved from 14044.84116 to 13616.33908, saving model to baoding1_weights.hdf5
            baoding1 6295.8675      0.90  0.21  0.72      0.92  0.17  0.77      0.92  0.14  0.80
            baoding113616.3391      0.98  0.10  0.89      0.99  0.06  0.93      0.99  0.03  0.96
forget mean min: 0.948799 0.359914
abs_mean, abs_mean+, abs_mean-: 15.4644 9.44166 34.6386
U_c = [[-0.0518078]] U_f = [[ 0.]] b_c = [ 0.47340882] b_f = [ 1.]
Epoch 11/300
1s - loss: 6350.1350 - val_loss: 13752.9340
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6271.3880 - val_loss: 13904.4519
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6186.3215 - val_loss: 14467.3846
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 6116.1006 - val_loss: 14576.9276
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 6077.8330 - val_loss: 14256.7906
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 6035.1146 - val_loss: 13685.4401
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 5970.9096 - val_loss: 14760.7582
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 5950.0795 - val_loss: 14718.5516
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 5943.0528 - val_loss: 13721.3530
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 5868.4401 - val_loss: 14384.5404
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 5884.3222 - val_loss: 14591.1529
Epoch 00020: val_loss did not improve
X_train[0].shape = (3726, 40, 23)

training baoding2
Train on 3726 samples, validate on 1164 samples
Before training:
            baoding223075.2322      0.03  -nan  0.03      0.04  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.15754 nan 6.15754
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            baoding252911.9993      0.06  -nan  0.06      0.07  -nan  0.07      0.08  -nan  0.08
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 14.2668 nan 14.2668
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 19488.3600 - val_loss: 21527.6097
Epoch 00000: val_loss improved from inf to 21527.60970, saving model to baoding2_weights.hdf5
            baoding213327.3708      0.34  0.07  0.32      0.34  0.04  0.33      0.34  0.03  0.33
            baoding221527.6097      0.84  0.08  0.78      0.84  0.05  0.81      0.86  0.02  0.85
forget mean min: 0.886349 0.392937
abs_mean, abs_mean+, abs_mean-: 12.6886 1.4159 15.0026
U_c = [[-0.11323478]] U_f = [[ 0.]] b_c = [ 0.07078137] b_f = [ 1.]
Epoch 2/300
1s - loss: 11100.0136 - val_loss: 14841.8398
Epoch 00001: val_loss improved from 21527.60970 to 14841.83980, saving model to baoding2_weights.hdf5
            baoding2 9659.5871      0.75  0.18  0.65      0.76  0.15  0.67      0.75  0.13  0.67
            baoding214841.8399      0.96  0.12  0.85      0.97  0.08  0.89      0.98  0.06  0.93
forget mean min: 0.965055 0.229628
abs_mean, abs_mean+, abs_mean-: 6.95849 2.71206 34.2907
U_c = [[-0.1050051]] U_f = [[ 0.]] b_c = [ 0.12680623] b_f = [ 1.]
Epoch 3/300
1s - loss: 8932.6382 - val_loss: 17531.1651
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 8027.0628 - val_loss: 18456.9964
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 7650.6312 - val_loss: 16454.4346
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 7358.8599 - val_loss: 14056.1740
Epoch 00005: val_loss improved from 14841.83980 to 14056.17396, saving model to baoding2_weights.hdf5
            baoding2 7208.3999      0.90  0.21  0.73      0.93  0.17  0.78      0.93  0.15  0.80
            baoding214056.1740      0.97  0.10  0.87      0.97  0.06  0.91      0.98  0.04  0.95
forget mean min: 0.964562 0.428439
abs_mean, abs_mean+, abs_mean-: 9.78012 6.42902 23.5448
U_c = [[-0.05841191]] U_f = [[ 0.]] b_c = [ 0.32225317] b_f = [ 1.]
Epoch 7/300
1s - loss: 7130.6970 - val_loss: 14494.9290
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 6835.8715 - val_loss: 14675.7375
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 6640.2497 - val_loss: 14422.8219
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 6473.3703 - val_loss: 14537.1270
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 6352.7024 - val_loss: 14165.8212
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 6262.3960 - val_loss: 14589.7587
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 6191.5967 - val_loss: 14349.2564
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 6128.5022 - val_loss: 14822.3104
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 6100.3252 - val_loss: 14972.1763
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 6064.7731 - val_loss: 13944.6436
Epoch 00015: val_loss improved from 14056.17396 to 13944.64357, saving model to baoding2_weights.hdf5
            baoding2 6058.5482      0.91  0.24  0.71      0.93  0.22  0.74      0.94  0.19  0.77
            baoding213944.6435      0.96  0.11  0.86      0.97  0.07  0.90      0.98  0.04  0.94
forget mean min: 0.937238 0.362326
abs_mean, abs_mean+, abs_mean-: 19.9856 12.5336 40.537
U_c = [[-0.04330651]] U_f = [[ 0.]] b_c = [ 0.63874739] b_f = [ 1.]
Epoch 17/300
1s - loss: 6045.2776 - val_loss: 14289.2711
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 6037.6263 - val_loss: 14136.3679
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 6010.6142 - val_loss: 14467.6830
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 5981.5731 - val_loss: 14082.7494
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 6002.1747 - val_loss: 14690.4482
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 5983.5432 - val_loss: 14735.3148
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 5987.7801 - val_loss: 15203.2833
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 5945.8586 - val_loss: 14347.2339
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 5965.4786 - val_loss: 14652.8566
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 5966.1241 - val_loss: 14396.3161
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 5920.5108 - val_loss: 15111.4957
Epoch 00026: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training shijiazhuang0
Train on 4347 samples, validate on 1358 samples
Before training:
       shijiazhuang014930.0929      0.03  -nan  0.03      0.04  -nan  0.04      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.73305 nan 4.73305
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
       shijiazhuang043084.1501      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 11.2542 nan 11.2542
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11354.6459 - val_loss: 20789.9281
Epoch 00000: val_loss improved from inf to 20789.92809, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 6573.4330      0.48  0.04  0.47      0.49  0.03  0.48      0.48  0.01  0.47
       shijiazhuang020789.9281      0.71  0.19  0.61      0.70  0.15  0.63      0.69  0.11  0.63
forget mean min: 0.855426 0.330127
abs_mean, abs_mean+, abs_mean-: 9.97438 1.47976 12.2372
U_c = [[-0.10947877]] U_f = [[ 0.]] b_c = [ 0.07904898] b_f = [ 1.]
Epoch 2/300
1s - loss: 5476.3858 - val_loss: 18876.2687
Epoch 00001: val_loss improved from 20789.92809 to 18876.26874, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 4539.2154      0.65  0.10  0.61      0.66  0.09  0.62      0.65  0.07  0.62
       shijiazhuang018876.2689      0.86  0.22  0.70      0.86  0.18  0.72      0.86  0.13  0.76
forget mean min: 0.919654 0.184405
abs_mean, abs_mean+, abs_mean-: 7.42681 3.13153 27.1851
U_c = [[-0.07147396]] U_f = [[ 0.]] b_c = [ 0.14598268] b_f = [ 1.]
Epoch 3/300
1s - loss: 4160.0929 - val_loss: 19782.6193
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 3756.0275 - val_loss: 17766.9248
Epoch 00003: val_loss improved from 18876.26874 to 17766.92482, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 3590.6080      0.83  0.21  0.68      0.84  0.19  0.70      0.83  0.18  0.71
       shijiazhuang017766.9250      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.920593 0.357501
abs_mean, abs_mean+, abs_mean-: 9.95687 5.52967 23.3672
U_c = [[-0.05848821]] U_f = [[ 0.]] b_c = [ 0.25797895] b_f = [ 1.]
Epoch 5/300
1s - loss: 3481.2538 - val_loss: 17312.0783
Epoch 00004: val_loss improved from 17766.92482 to 17312.07835, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 3347.8627      0.85  0.22  0.68      0.87  0.20  0.71      0.86  0.18  0.72
       shijiazhuang017312.0784      0.85  0.20  0.70      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.912862 0.34815
abs_mean, abs_mean+, abs_mean-: 11.4723 6.37985 27.9352
U_c = [[-0.05990894]] U_f = [[ 0.]] b_c = [ 0.31035185] b_f = [ 1.]
Epoch 6/300
1s - loss: 3278.4533 - val_loss: 17096.0281
Epoch 00005: val_loss improved from 17312.07835 to 17096.02807, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 3161.6371      0.86  0.22  0.69      0.88  0.21  0.72      0.88  0.18  0.74
       shijiazhuang017096.0280      0.85  0.20  0.71      0.85  0.16  0.74      0.86  0.11  0.77
forget mean min: 0.90937 0.33509
abs_mean, abs_mean+, abs_mean-: 12.8205 7.15928 31.0425
U_c = [[-0.06069152]] U_f = [[ 0.]] b_c = [ 0.35866177] b_f = [ 1.]
Epoch 7/300
1s - loss: 3143.1414 - val_loss: 16553.6268
Epoch 00006: val_loss improved from 17096.02807 to 16553.62676, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 3046.0422      0.87  0.23  0.69      0.89  0.21  0.72      0.89  0.19  0.74
       shijiazhuang016553.6266      0.86  0.20  0.71      0.87  0.15  0.75      0.87  0.11  0.78
forget mean min: 0.914963 0.324576
abs_mean, abs_mean+, abs_mean-: 13.2719 7.83492 29.6229
U_c = [[-0.06023917]] U_f = [[ 0.]] b_c = [ 0.39378488] b_f = [ 1.]
Epoch 8/300
1s - loss: 2990.8405 - val_loss: 16726.9905
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2892.1926 - val_loss: 16309.5172
Epoch 00008: val_loss improved from 16553.62676 to 16309.51723, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2782.9544      0.87  0.23  0.69      0.89  0.21  0.72      0.88  0.18  0.73
       shijiazhuang016309.5172      0.88  0.21  0.72      0.88  0.17  0.75      0.89  0.12  0.79
forget mean min: 0.920179 0.319453
abs_mean, abs_mean+, abs_mean-: 14.2692 8.46601 28.6276
U_c = [[-0.05864107]] U_f = [[ 0.]] b_c = [ 0.45221403] b_f = [ 1.]
Epoch 10/300
1s - loss: 2829.9564 - val_loss: 15473.2453
Epoch 00009: val_loss improved from 16309.51723 to 15473.24527, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2765.2415      0.89  0.25  0.68      0.91  0.23  0.71      0.90  0.21  0.73
       shijiazhuang015473.2453      0.89  0.20  0.72      0.89  0.17  0.76      0.91  0.12  0.81
forget mean min: 0.921413 0.31697
abs_mean, abs_mean+, abs_mean-: 15.0251 9.02066 30.9608
U_c = [[-0.05580652]] U_f = [[ 0.]] b_c = [ 0.47798368] b_f = [ 1.]
Epoch 11/300
1s - loss: 2795.5117 - val_loss: 15567.3412
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 2776.1371 - val_loss: 15473.5360
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 2767.0738 - val_loss: 15569.2008
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 2757.4462 - val_loss: 15499.7502
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 2750.9877 - val_loss: 16182.2233
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 2747.0927 - val_loss: 16093.9319
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 2739.8884 - val_loss: 15373.0119
Epoch 00016: val_loss improved from 15473.24527 to 15373.01187, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2678.6584      0.88  0.25  0.68      0.90  0.23  0.71      0.90  0.21  0.72
       shijiazhuang015373.0118      0.89  0.20  0.73      0.89  0.16  0.77      0.91  0.12  0.82
forget mean min: 0.916212 0.284883
abs_mean, abs_mean+, abs_mean-: 16.9177 10.1773 34.7027
U_c = [[-0.06060189]] U_f = [[ 0.]] b_c = [ 0.55428737] b_f = [ 1.]
Epoch 18/300
1s - loss: 2733.8353 - val_loss: 15882.4531
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 2720.0456 - val_loss: 16171.7471
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 2714.7609 - val_loss: 16294.7108
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 2701.9705 - val_loss: 16179.7019
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 2712.5540 - val_loss: 16233.3807
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 2701.4543 - val_loss: 17078.5056
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 2689.0452 - val_loss: 16631.7492
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 2689.2786 - val_loss: 16634.1671
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 2701.5638 - val_loss: 16555.5842
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 2697.2910 - val_loss: 17075.1815
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 2693.2171 - val_loss: 16764.5862
Epoch 00027: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training shijiazhuang1
Train on 4347 samples, validate on 1358 samples
Before training:
       shijiazhuang114930.0929      0.03  -nan  0.03      0.04  -nan  0.04      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.73305 nan 4.73305
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
       shijiazhuang143084.1501      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 11.2542 nan 11.2542
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11355.1546 - val_loss: 20715.6279
Epoch 00000: val_loss improved from inf to 20715.62794, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 6539.8348      0.48  0.04  0.47      0.49  0.03  0.48      0.48  0.01  0.48
       shijiazhuang120715.6278      0.71  0.19  0.61      0.71  0.15  0.63      0.70  0.11  0.64
forget mean min: 0.854982 0.323947
abs_mean, abs_mean+, abs_mean-: 9.95433 1.50366 12.4907
U_c = [[-0.11058871]] U_f = [[ 0.]] b_c = [ 0.07947281] b_f = [ 1.]
Epoch 2/300
1s - loss: 5457.6567 - val_loss: 18802.2509
Epoch 00001: val_loss improved from 20715.62794 to 18802.25094, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 4533.3458      0.66  0.10  0.61      0.66  0.09  0.62      0.66  0.07  0.63
       shijiazhuang118802.2509      0.86  0.22  0.70      0.86  0.18  0.72      0.86  0.13  0.76
forget mean min: 0.920282 0.178152
abs_mean, abs_mean+, abs_mean-: 7.42998 3.14853 26.9651
U_c = [[-0.07333859]] U_f = [[ 0.]] b_c = [ 0.14594868] b_f = [ 1.]
Epoch 3/300
1s - loss: 4149.1643 - val_loss: 19482.6719
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 3731.2479 - val_loss: 18047.4238
Epoch 00003: val_loss improved from 18802.25094 to 18047.42383, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 3576.4040      0.84  0.22  0.68      0.85  0.20  0.70      0.84  0.18  0.71
       shijiazhuang118047.4238      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.920718 0.348494
abs_mean, abs_mean+, abs_mean-: 10.0137 5.64978 24.02
U_c = [[-0.05830983]] U_f = [[ 0.]] b_c = [ 0.26153809] b_f = [ 1.]
Epoch 5/300
1s - loss: 3473.8379 - val_loss: 17437.1116
Epoch 00004: val_loss improved from 18047.42383 to 17437.11157, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 3345.5229      0.86  0.23  0.68      0.87  0.22  0.70      0.87  0.19  0.72
       shijiazhuang117437.1116      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.914247 0.340742
abs_mean, abs_mean+, abs_mean-: 11.4997 6.49683 28.2808
U_c = [[-0.06140331]] U_f = [[ 0.]] b_c = [ 0.31338578] b_f = [ 1.]
Epoch 6/300
1s - loss: 3278.2591 - val_loss: 16990.1741
Epoch 00005: val_loss improved from 17437.11157 to 16990.17411, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 3162.6333      0.86  0.23  0.69      0.89  0.21  0.72      0.88  0.18  0.73
       shijiazhuang116990.1743      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.11  0.78
forget mean min: 0.911503 0.327409
abs_mean, abs_mean+, abs_mean-: 12.6846 7.23133 30.4569
U_c = [[-0.06151561]] U_f = [[ 0.]] b_c = [ 0.35468316] b_f = [ 1.]
Epoch 7/300
1s - loss: 3134.3410 - val_loss: 16656.1590
Epoch 00006: val_loss improved from 16990.17411 to 16656.15904, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 3040.6710      0.87  0.22  0.69      0.89  0.21  0.72      0.89  0.18  0.74
       shijiazhuang116656.1590      0.86  0.20  0.71      0.86  0.15  0.74      0.87  0.11  0.78
forget mean min: 0.915558 0.331198
abs_mean, abs_mean+, abs_mean-: 13.1139 7.71645 27.9476
U_c = [[-0.06292531]] U_f = [[ 0.]] b_c = [ 0.38808948] b_f = [ 1.]
Epoch 8/300
1s - loss: 3003.5901 - val_loss: 16766.9339
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2883.7490 - val_loss: 16486.2349
Epoch 00008: val_loss improved from 16656.15904 to 16486.23488, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 2779.2991      0.87  0.23  0.69      0.89  0.21  0.72      0.88  0.18  0.74
       shijiazhuang116486.2350      0.88  0.21  0.71      0.88  0.17  0.75      0.89  0.12  0.79
forget mean min: 0.92082 0.321862
abs_mean, abs_mean+, abs_mean-: 14.3233 8.40873 29.1125
U_c = [[-0.05638723]] U_f = [[ 0.]] b_c = [ 0.44636145] b_f = [ 1.]
Epoch 10/300
1s - loss: 2831.0830 - val_loss: 16419.5191
Epoch 00009: val_loss improved from 16486.23488 to 16419.51907, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 2730.2310      0.86  0.23  0.68      0.87  0.21  0.71      0.86  0.18  0.73
       shijiazhuang116419.5192      0.87  0.20  0.71      0.88  0.16  0.75      0.89  0.12  0.80
forget mean min: 0.917174 0.320219
abs_mean, abs_mean+, abs_mean-: 15.0407 8.87324 29.9262
U_c = [[-0.05305398]] U_f = [[ 0.]] b_c = [ 0.46786445] b_f = [ 1.]
Epoch 11/300
1s - loss: 2789.3841 - val_loss: 16137.6691
Epoch 00010: val_loss improved from 16419.51907 to 16137.66910, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 2706.9817      0.87  0.23  0.69      0.89  0.22  0.71      0.89  0.19  0.73
       shijiazhuang116137.6691      0.87  0.19  0.72      0.88  0.16  0.75      0.90  0.11  0.81
forget mean min: 0.914676 0.307815
abs_mean, abs_mean+, abs_mean-: 15.5916 9.19668 31.203
U_c = [[-0.05470452]] U_f = [[ 0.]] b_c = [ 0.48838094] b_f = [ 1.]
Epoch 12/300
1s - loss: 2778.7675 - val_loss: 15913.6929
Epoch 00011: val_loss improved from 16137.66910 to 15913.69290, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 2692.3438      0.87  0.24  0.68      0.89  0.22  0.71      0.89  0.19  0.73
       shijiazhuang115913.6930      0.88  0.20  0.72      0.89  0.16  0.76      0.90  0.11  0.81
forget mean min: 0.915416 0.308496
abs_mean, abs_mean+, abs_mean-: 15.9517 9.47577 31.771
U_c = [[-0.05697878]] U_f = [[ 0.]] b_c = [ 0.50334686] b_f = [ 1.]
Epoch 13/300
1s - loss: 2762.5924 - val_loss: 15631.2065
Epoch 00012: val_loss improved from 15913.69290 to 15631.20651, saving model to shijiazhuang1_weights.hdf5
       shijiazhuang1 2685.9478      0.87  0.24  0.68      0.89  0.22  0.71      0.89  0.20  0.73
       shijiazhuang115631.2066      0.88  0.20  0.72      0.89  0.16  0.76      0.91  0.12  0.81
forget mean min: 0.916429 0.30732
abs_mean, abs_mean+, abs_mean-: 16.2583 9.69136 33.6143
U_c = [[-0.05785783]] U_f = [[ 0.]] b_c = [ 0.51939124] b_f = [ 1.]
Epoch 14/300
1s - loss: 2753.5034 - val_loss: 15659.5266
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 2751.0357 - val_loss: 16057.7089
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 2731.8892 - val_loss: 15800.1957
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 2721.5353 - val_loss: 16035.0359
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 2723.0012 - val_loss: 16254.9762
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 2711.1257 - val_loss: 16744.9472
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 2707.9808 - val_loss: 16245.8877
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 2689.9503 - val_loss: 16252.6161
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 2701.4118 - val_loss: 16690.4864
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 2702.8317 - val_loss: 16547.6263
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 2695.8518 - val_loss: 16890.6697
Epoch 00023: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training shijiazhuang2
Train on 4347 samples, validate on 1358 samples
Before training:
       shijiazhuang214930.0929      0.03  -nan  0.03      0.04  -nan  0.04      0.03  -nan  0.03
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.73305 nan 4.73305
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
       shijiazhuang243084.1501      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 11.2542 nan 11.2542
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11507.4136 - val_loss: 21040.8491
Epoch 00000: val_loss improved from inf to 21040.84910, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 6612.9998      0.48  0.04  0.47      0.48  0.03  0.48      0.48  0.02  0.47
       shijiazhuang221040.8487      0.70  0.19  0.60      0.70  0.16  0.62      0.69  0.11  0.63
forget mean min: 0.852886 0.328592
abs_mean, abs_mean+, abs_mean-: 10.239 1.46461 12.3886
U_c = [[-0.11273559]] U_f = [[ 0.]] b_c = [ 0.07894033] b_f = [ 1.]
Epoch 2/300
1s - loss: 5540.9656 - val_loss: 18648.5947
Epoch 00001: val_loss improved from 21040.84910 to 18648.59474, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 4585.7879      0.65  0.10  0.60      0.66  0.08  0.62      0.65  0.06  0.62
       shijiazhuang218648.5946      0.87  0.22  0.69      0.86  0.18  0.72      0.87  0.14  0.76
forget mean min: 0.921346 0.17923
abs_mean, abs_mean+, abs_mean-: 7.39375 3.10444 27.239
U_c = [[-0.07786473]] U_f = [[ 0.]] b_c = [ 0.14567252] b_f = [ 1.]
Epoch 3/300
1s - loss: 4162.5189 - val_loss: 19608.5816
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 3745.0366 - val_loss: 17718.1012
Epoch 00003: val_loss improved from 18648.59474 to 17718.10121, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 3587.7096      0.83  0.22  0.68      0.85  0.20  0.70      0.84  0.18  0.71
       shijiazhuang217718.1012      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.92126 0.353907
abs_mean, abs_mean+, abs_mean-: 10.0118 5.60543 23.4677
U_c = [[-0.06159448]] U_f = [[ 0.]] b_c = [ 0.25997296] b_f = [ 1.]
Epoch 5/300
1s - loss: 3481.9883 - val_loss: 17204.5332
Epoch 00004: val_loss improved from 17718.10121 to 17204.53321, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 3349.3884      0.85  0.22  0.68      0.87  0.21  0.70      0.86  0.18  0.72
       shijiazhuang217204.5333      0.86  0.20  0.70      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.912274 0.345164
abs_mean, abs_mean+, abs_mean-: 11.5481 6.43134 27.6875
U_c = [[-0.06124928]] U_f = [[ 0.]] b_c = [ 0.31309968] b_f = [ 1.]
Epoch 6/300
1s - loss: 3272.6834 - val_loss: 16896.6735
Epoch 00005: val_loss improved from 17204.53321 to 16896.67350, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 3164.2190      0.86  0.22  0.69      0.88  0.21  0.71      0.87  0.18  0.73
       shijiazhuang216896.6733      0.86  0.20  0.71      0.86  0.16  0.74      0.86  0.12  0.77
forget mean min: 0.910672 0.327134
abs_mean, abs_mean+, abs_mean-: 12.8003 7.22915 31.356
U_c = [[-0.06026867]] U_f = [[ 0.]] b_c = [ 0.35747313] b_f = [ 1.]
Epoch 7/300
1s - loss: 3135.2065 - val_loss: 16800.7515
Epoch 00006: val_loss improved from 16896.67350 to 16800.75154, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 3068.4985      0.88  0.24  0.69      0.90  0.22  0.71      0.89  0.20  0.73
       shijiazhuang216800.7515      0.86  0.19  0.71      0.87  0.15  0.75      0.87  0.11  0.78
forget mean min: 0.918339 0.320416
abs_mean, abs_mean+, abs_mean-: 13.1337 7.87095 29.3927
U_c = [[-0.055259]] U_f = [[ 0.]] b_c = [ 0.39468583] b_f = [ 1.]
Epoch 8/300
1s - loss: 3006.3207 - val_loss: 16610.6698
Epoch 00007: val_loss improved from 16800.75154 to 16610.66978, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2878.3577      0.87  0.23  0.69      0.89  0.22  0.71      0.89  0.19  0.73
       shijiazhuang216610.6697      0.88  0.21  0.72      0.88  0.17  0.75      0.88  0.13  0.78
forget mean min: 0.925891 0.335525
abs_mean, abs_mean+, abs_mean-: 13.3483 8.01169 27.7599
U_c = [[-0.0609261]] U_f = [[ 0.]] b_c = [ 0.42230892] b_f = [ 1.]
Epoch 9/300
1s - loss: 2887.9164 - val_loss: 16232.2295
Epoch 00008: val_loss improved from 16610.66978 to 16232.22954, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2807.7822      0.88  0.24  0.68      0.90  0.23  0.71      0.90  0.20  0.73
       shijiazhuang216232.2294      0.89  0.22  0.71      0.89  0.18  0.74      0.90  0.13  0.79
forget mean min: 0.926501 0.310958
abs_mean, abs_mean+, abs_mean-: 14.1976 8.5279 29.4943
U_c = [[-0.05896899]] U_f = [[ 0.]] b_c = [ 0.44637614] b_f = [ 1.]
Epoch 10/300
1s - loss: 2838.6525 - val_loss: 16150.5278
Epoch 00009: val_loss improved from 16232.22954 to 16150.52777, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2741.1683      0.87  0.23  0.69      0.89  0.21  0.71      0.88  0.19  0.73
       shijiazhuang216150.5277      0.88  0.20  0.72      0.88  0.16  0.75      0.89  0.11  0.80
forget mean min: 0.917462 0.315844
abs_mean, abs_mean+, abs_mean-: 14.8371 8.84096 28.9553
U_c = [[-0.05398196]] U_f = [[ 0.]] b_c = [ 0.46992275] b_f = [ 1.]
Epoch 11/300
1s - loss: 2792.2662 - val_loss: 16047.4434
Epoch 00010: val_loss improved from 16150.52777 to 16047.44336, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2712.1565      0.86  0.22  0.69      0.88  0.21  0.71      0.87  0.18  0.73
       shijiazhuang216047.4432      0.87  0.19  0.72      0.88  0.15  0.76      0.89  0.11  0.81
forget mean min: 0.912974 0.312749
abs_mean, abs_mean+, abs_mean-: 15.3891 9.14116 29.8608
U_c = [[-0.05526292]] U_f = [[ 0.]] b_c = [ 0.48843208] b_f = [ 1.]
Epoch 12/300
1s - loss: 2781.0014 - val_loss: 15826.1894
Epoch 00011: val_loss improved from 16047.44336 to 15826.18937, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2705.1287      0.87  0.24  0.68      0.89  0.22  0.71      0.88  0.19  0.73
       shijiazhuang215826.1894      0.87  0.20  0.72      0.88  0.16  0.75      0.89  0.11  0.80
forget mean min: 0.91633 0.30828
abs_mean, abs_mean+, abs_mean-: 15.7569 9.37056 32.0948
U_c = [[-0.05377675]] U_f = [[ 0.]] b_c = [ 0.50349236] b_f = [ 1.]
Epoch 13/300
1s - loss: 2770.7274 - val_loss: 15746.6346
Epoch 00012: val_loss improved from 15826.18937 to 15746.63465, saving model to shijiazhuang2_weights.hdf5
       shijiazhuang2 2691.9598      0.86  0.24  0.68      0.88  0.22  0.70      0.87  0.19  0.72
       shijiazhuang215746.6347      0.87  0.20  0.72      0.88  0.16  0.75      0.90  0.11  0.81
forget mean min: 0.914734 0.307895
abs_mean, abs_mean+, abs_mean-: 16.0829 9.60102 32.6018
U_c = [[-0.05602229]] U_f = [[ 0.]] b_c = [ 0.51735234] b_f = [ 1.]
Epoch 14/300
1s - loss: 2756.6895 - val_loss: 16215.4527
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 2754.3144 - val_loss: 16194.9074
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 2740.2310 - val_loss: 15787.8270
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 2727.6757 - val_loss: 16335.3236
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 2711.9004 - val_loss: 16444.1650
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 2718.7061 - val_loss: 16424.1445
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 2702.6393 - val_loss: 16161.9463
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 2706.3979 - val_loss: 16317.0314
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 2697.0479 - val_loss: 16451.9330
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 2701.3256 - val_loss: 16541.1039
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 2704.1563 - val_loss: 16532.1265
Epoch 00023: val_loss did not improve
X_train[0].shape = (4968, 40, 23)

training xingtai+handan0
Train on 4968 samples, validate on 1552 samples
Before training:
     xingtai+handan015698.4954      0.03  -nan  0.03      0.02  -nan  0.02      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.44541 nan 5.44541
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
     xingtai+handan049759.0225      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 12.3375 nan 12.3375
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11777.3425 - val_loss: 22207.2165
Epoch 00000: val_loss improved from inf to 22207.21647, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 7363.3301      0.40  0.10  0.38      0.40  0.06  0.39      0.38  0.04  0.38
     xingtai+handan022207.2160      0.78  0.13  0.70      0.77  0.10  0.71      0.76  0.08  0.71
forget mean min: 0.861157 0.310868
abs_mean, abs_mean+, abs_mean-: 11.242 1.71903 16.6078
U_c = [[-0.12202779]] U_f = [[ 0.]] b_c = [ 0.08828691] b_f = [ 1.]
Epoch 2/300
1s - loss: 6123.3468 - val_loss: 18152.8076
Epoch 00001: val_loss improved from 22207.21647 to 18152.80757, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 5107.5757      0.71  0.21  0.60      0.71  0.16  0.63      0.68  0.14  0.61
     xingtai+handan018152.8075      0.90  0.16  0.77      0.89  0.14  0.78      0.88  0.11  0.79
forget mean min: 0.939783 0.152544
abs_mean, abs_mean+, abs_mean-: 7.50301 3.32183 27.0809
U_c = [[-0.08023345]] U_f = [[ 0.]] b_c = [ 0.16363691] b_f = [ 1.]
Epoch 3/300
1s - loss: 4747.4185 - val_loss: 19405.4812
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 4399.1396 - val_loss: 17956.8783
Epoch 00003: val_loss improved from 18152.80757 to 17956.87833, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 4294.7310      0.84  0.26  0.65      0.86  0.22  0.69      0.86  0.20  0.71
     xingtai+handan017956.8782      0.92  0.16  0.78      0.90  0.14  0.79      0.90  0.11  0.80
forget mean min: 0.943834 0.235295
abs_mean, abs_mean+, abs_mean-: 9.71267 5.84722 27.9091
U_c = [[-0.06094687]] U_f = [[ 0.]] b_c = [ 0.27914724] b_f = [ 1.]
Epoch 5/300
1s - loss: 4252.9091 - val_loss: 16005.5101
Epoch 00004: val_loss improved from 17956.87833 to 16005.51015, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 4136.3241      0.85  0.25  0.66      0.87  0.21  0.71      0.87  0.19  0.72
     xingtai+handan016005.5100      0.92  0.17  0.78      0.92  0.14  0.80      0.91  0.11  0.81
forget mean min: 0.941539 0.264477
abs_mean, abs_mean+, abs_mean-: 11.0488 6.492 29.2831
U_c = [[-0.06281462]] U_f = [[ 0.]] b_c = [ 0.31781301] b_f = [ 1.]
Epoch 6/300
1s - loss: 4084.7885 - val_loss: 15401.6340
Epoch 00005: val_loss improved from 16005.51015 to 15401.63399, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 3992.0312      0.85  0.25  0.66      0.88  0.22  0.70      0.87  0.19  0.72
     xingtai+handan015401.6341      0.91  0.16  0.77      0.91  0.13  0.80      0.90  0.11  0.81
forget mean min: 0.934252 0.288947
abs_mean, abs_mean+, abs_mean-: 12.4312 7.27266 29.906
U_c = [[-0.06452883]] U_f = [[ 0.]] b_c = [ 0.36459172] b_f = [ 1.]
Epoch 7/300
1s - loss: 3989.3446 - val_loss: 15208.1215
Epoch 00006: val_loss improved from 15401.63399 to 15208.12146, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 3922.3950      0.87  0.26  0.67      0.89  0.22  0.71      0.89  0.20  0.73
     xingtai+handan015208.1215      0.91  0.16  0.77      0.90  0.13  0.80      0.90  0.11  0.81
forget mean min: 0.930464 0.330343
abs_mean, abs_mean+, abs_mean-: 12.952 7.90564 26.0984
U_c = [[-0.06286415]] U_f = [[ 0.]] b_c = [ 0.40357533] b_f = [ 1.]
Epoch 8/300
1s - loss: 3849.5383 - val_loss: 15964.8099
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3637.1917 - val_loss: 16111.3793
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 3584.1029 - val_loss: 16246.8795
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 3568.7526 - val_loss: 16372.5506
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 3550.7653 - val_loss: 16346.6160
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 3545.7826 - val_loss: 16169.0965
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 3546.5701 - val_loss: 15918.5707
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 3540.5714 - val_loss: 15980.9370
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 3538.8359 - val_loss: 16080.2044
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 3535.7269 - val_loss: 15985.8053
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 3526.0263 - val_loss: 16444.4176
Epoch 00017: val_loss did not improve
X_train[0].shape = (4968, 40, 23)

training xingtai+handan1
Train on 4968 samples, validate on 1552 samples
Before training:
     xingtai+handan115698.4954      0.03  -nan  0.03      0.02  -nan  0.02      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.44541 nan 5.44541
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
     xingtai+handan149759.0225      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 12.3375 nan 12.3375
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11696.5260 - val_loss: 22010.5248
Epoch 00000: val_loss improved from inf to 22010.52478, saving model to xingtai+handan1_weights.hdf5
     xingtai+handan1 7334.4527      0.40  0.10  0.38      0.40  0.06  0.39      0.39  0.04  0.38
     xingtai+handan122010.5247      0.77  0.13  0.70      0.77  0.10  0.71      0.76  0.08  0.71
forget mean min: 0.862493 0.310106
abs_mean, abs_mean+, abs_mean-: 11.0804 1.71658 17.0594
U_c = [[-0.12148492]] U_f = [[ 0.]] b_c = [ 0.08837395] b_f = [ 1.]
Epoch 2/300
1s - loss: 6113.3502 - val_loss: 18167.8755
Epoch 00001: val_loss improved from 22010.52478 to 18167.87545, saving model to xingtai+handan1_weights.hdf5
     xingtai+handan1 5115.1885      0.70  0.20  0.59      0.70  0.16  0.62      0.67  0.14  0.61
     xingtai+handan118167.8754      0.90  0.16  0.77      0.88  0.13  0.78      0.88  0.11  0.79
forget mean min: 0.939554 0.16543
abs_mean, abs_mean+, abs_mean-: 7.44477 3.29411 26.095
U_c = [[-0.07787853]] U_f = [[ 0.]] b_c = [ 0.16274813] b_f = [ 1.]
Epoch 3/300
1s - loss: 4754.6958 - val_loss: 18779.1839
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 4411.5316 - val_loss: 18446.7439
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 4262.2072 - val_loss: 16007.9647
Epoch 00004: val_loss improved from 18167.87545 to 16007.96473, saving model to xingtai+handan1_weights.hdf5
     xingtai+handan1 4159.3064      0.85  0.25  0.66      0.87  0.21  0.70      0.86  0.19  0.72
     xingtai+handan116007.9647      0.92  0.17  0.78      0.91  0.14  0.79      0.91  0.12  0.81
forget mean min: 0.940934 0.265962
abs_mean, abs_mean+, abs_mean-: 11.013 6.37019 28.9036
U_c = [[-0.06421916]] U_f = [[ 0.]] b_c = [ 0.31435654] b_f = [ 1.]
Epoch 6/300
1s - loss: 4090.3158 - val_loss: 15596.1218
Epoch 00005: val_loss improved from 16007.96473 to 15596.12178, saving model to xingtai+handan1_weights.hdf5
     xingtai+handan1 3994.8957      0.86  0.25  0.66      0.87  0.22  0.70      0.87  0.19  0.72
     xingtai+handan115596.1218      0.91  0.17  0.76      0.91  0.14  0.79      0.90  0.11  0.81
forget mean min: 0.937199 0.280269
abs_mean, abs_mean+, abs_mean-: 12.2133 7.22561 29.7137
U_c = [[-0.06173662]] U_f = [[ 0.]] b_c = [ 0.36302638] b_f = [ 1.]
Epoch 7/300
1s - loss: 3997.3860 - val_loss: 15706.6489
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 3873.3671 - val_loss: 15800.1041
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3653.3582 - val_loss: 16624.1961
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 3592.4371 - val_loss: 16514.9936
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 3556.0533 - val_loss: 15863.6816
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 3545.4267 - val_loss: 16258.4102
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 3543.8579 - val_loss: 16309.2580
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 3539.9047 - val_loss: 16230.9748
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 3535.8682 - val_loss: 16285.6740
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 3537.6398 - val_loss: 16360.8630
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 3533.0172 - val_loss: 16174.5678
Epoch 00016: val_loss did not improve
X_train[0].shape = (4968, 40, 23)

training xingtai+handan2
Train on 4968 samples, validate on 1552 samples
Before training:
     xingtai+handan215698.4954      0.03  -nan  0.03      0.02  -nan  0.02      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.44541 nan 5.44541
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
     xingtai+handan249759.0225      0.05  -nan  0.05      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 12.3375 nan 12.3375
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 11627.2215 - val_loss: 21983.4550
Epoch 00000: val_loss improved from inf to 21983.45496, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 7309.0760      0.40  0.10  0.38      0.40  0.06  0.39      0.39  0.04  0.38
     xingtai+handan221983.4550      0.78  0.13  0.70      0.77  0.10  0.71      0.76  0.08  0.71
forget mean min: 0.862921 0.303885
abs_mean, abs_mean+, abs_mean-: 11.0542 1.73744 17.2721
U_c = [[-0.12033601]] U_f = [[ 0.]] b_c = [ 0.08848783] b_f = [ 1.]
Epoch 2/300
1s - loss: 6117.1459 - val_loss: 18265.7493
Epoch 00001: val_loss improved from 21983.45496 to 18265.74933, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 5112.7852      0.70  0.20  0.60      0.71  0.16  0.62      0.67  0.14  0.61
     xingtai+handan218265.7488      0.90  0.16  0.76      0.88  0.13  0.77      0.88  0.11  0.79
forget mean min: 0.937272 0.150316
abs_mean, abs_mean+, abs_mean-: 7.56024 3.31256 26.8442
U_c = [[-0.07936465]] U_f = [[ 0.]] b_c = [ 0.16295293] b_f = [ 1.]
Epoch 3/300
1s - loss: 4745.8964 - val_loss: 19014.7891
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 4416.6971 - val_loss: 18202.0898
Epoch 00003: val_loss improved from 18265.74933 to 18202.08979, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 4314.7466      0.84  0.26  0.65      0.86  0.22  0.69      0.85  0.20  0.70
     xingtai+handan218202.0895      0.93  0.17  0.78      0.91  0.15  0.79      0.91  0.12  0.81
forget mean min: 0.946334 0.231714
abs_mean, abs_mean+, abs_mean-: 9.40578 5.71161 27.5031
U_c = [[-0.06114636]] U_f = [[ 0.]] b_c = [ 0.27249879] b_f = [ 1.]
Epoch 5/300
1s - loss: 4273.8534 - val_loss: 16485.8138
Epoch 00004: val_loss improved from 18202.08979 to 16485.81385, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 4168.2379      0.86  0.26  0.66      0.88  0.22  0.70      0.87  0.20  0.72
     xingtai+handan216485.8137      0.93  0.17  0.78      0.92  0.14  0.80      0.91  0.12  0.81
forget mean min: 0.942932 0.236226
abs_mean, abs_mean+, abs_mean-: 10.7762 6.37311 30.6228
U_c = [[-0.06358105]] U_f = [[ 0.]] b_c = [ 0.31015503] b_f = [ 1.]
Epoch 6/300
1s - loss: 4113.2522 - val_loss: 15491.0491
Epoch 00005: val_loss improved from 16485.81385 to 15491.04906, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 4011.6060      0.86  0.26  0.66      0.88  0.22  0.71      0.88  0.20  0.72
     xingtai+handan215491.0488      0.91  0.17  0.77      0.91  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.93913 0.279688
abs_mean, abs_mean+, abs_mean-: 11.9993 7.14026 29.0672
U_c = [[-0.06501488]] U_f = [[ 0.]] b_c = [ 0.35404581] b_f = [ 1.]
Epoch 7/300
1s - loss: 4009.6998 - val_loss: 15485.5722
Epoch 00006: val_loss improved from 15491.04906 to 15485.57222, saving model to xingtai+handan2_weights.hdf5
     xingtai+handan2 3940.7953      0.85  0.25  0.66      0.87  0.22  0.70      0.87  0.19  0.72
     xingtai+handan215485.5720      0.91  0.17  0.77      0.91  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.930986 0.320732
abs_mean, abs_mean+, abs_mean-: 12.7766 7.74969 25.5628
U_c = [[-0.0661608]] U_f = [[ 0.]] b_c = [ 0.39283475] b_f = [ 1.]
Epoch 8/300
1s - loss: 3890.5071 - val_loss: 15794.8092
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3671.6918 - val_loss: 16408.0828
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 3587.0175 - val_loss: 16510.8151
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 3559.8888 - val_loss: 16761.7900
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 3561.5870 - val_loss: 16437.7522
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 3555.2141 - val_loss: 16412.0449
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 3536.3178 - val_loss: 15973.3696
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 3537.7499 - val_loss: 15945.2361
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 3531.0955 - val_loss: 16264.2232
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 3531.8788 - val_loss: 15911.8962
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 3533.1315 - val_loss: 15638.3400
Epoch 00017: val_loss did not improve
X_train[0].shape = (3105, 40, 23)

training jinan0
Train on 3105 samples, validate on 970 samples
Before training:
              jinan013504.9636      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.97649 nan 5.97649
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              jinan037048.4109      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 10.6406 nan 10.6406
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
0s - loss: 11674.8702 - val_loss: 27659.0429
Epoch 00000: val_loss improved from inf to 27659.04288, saving model to jinan0_weights.hdf5
              jinan0 8275.4821      0.18  0.09  0.17      0.17  0.05  0.17      0.17  0.01  0.17
              jinan027659.0422      0.21  0.02  0.20      0.20  0.01  0.20      0.18  0.00  0.18
forget mean min: 0.767254 0.439599
abs_mean, abs_mean+, abs_mean-: 13.9366 nan 13.9366
U_c = [[-0.10595882]] U_f = [[ 0.]] b_c = [ 0.05911893] b_f = [ 1.]
Epoch 2/300
0s - loss: 5979.1591 - val_loss: 15486.3325
Epoch 00001: val_loss improved from 27659.04288 to 15486.33251, saving model to jinan0_weights.hdf5
              jinan0 4757.0917      0.57  0.13  0.53      0.56  0.10  0.53      0.56  0.06  0.53
              jinan015486.3322      0.86  0.05  0.82      0.86  0.04  0.83      0.85  0.02  0.84
forget mean min: 0.89728 0.290309
abs_mean, abs_mean+, abs_mean-: 9.67609 1.99115 16.4762
U_c = [[-0.13744847]] U_f = [[ 0.]] b_c = [ 0.10662249] b_f = [ 1.]
Epoch 3/300
0s - loss: 4332.1719 - val_loss: 12199.8123
Epoch 00002: val_loss improved from 15486.33251 to 12199.81225, saving model to jinan0_weights.hdf5
              jinan0 3922.7615      0.79  0.22  0.64      0.79  0.18  0.67      0.78  0.14  0.69
              jinan012199.8122      0.96  0.10  0.87      0.96  0.07  0.89      0.96  0.06  0.91
forget mean min: 0.949728 0.245975
abs_mean, abs_mean+, abs_mean-: 6.86852 2.82355 19.0084
U_c = [[-0.13815056]] U_f = [[ 0.]] b_c = [ 0.15171133] b_f = [ 1.]
Epoch 4/300
0s - loss: 3687.1253 - val_loss: 11704.4549
Epoch 00003: val_loss improved from 12199.81225 to 11704.45487, saving model to jinan0_weights.hdf5
              jinan0 3462.3150      0.88  0.26  0.67      0.89  0.22  0.71      0.88  0.18  0.73
              jinan011704.4548      0.98  0.14  0.85      0.98  0.11  0.87      0.98  0.09  0.89
forget mean min: 0.968167 0.240928
abs_mean, abs_mean+, abs_mean-: 6.2255 3.80991 20.1868
U_c = [[-0.10719715]] U_f = [[ 0.]] b_c = [ 0.1969806] b_f = [ 1.]
Epoch 5/300
0s - loss: 3359.3576 - val_loss: 11516.0628
Epoch 00004: val_loss improved from 11704.45487 to 11516.06280, saving model to jinan0_weights.hdf5
              jinan0 3255.6990      0.89  0.27  0.67      0.90  0.23  0.71      0.90  0.20  0.73
              jinan011516.0629      0.98  0.14  0.85      0.98  0.11  0.87      0.98  0.09  0.89
forget mean min: 0.96712 0.348156
abs_mean, abs_mean+, abs_mean-: 6.89525 4.70482 15.1908
U_c = [[-0.09665]] U_f = [[ 0.]] b_c = [ 0.23881863] b_f = [ 1.]
Epoch 6/300
0s - loss: 3216.2022 - val_loss: 11539.0858
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 3162.1772 - val_loss: 11542.5130
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 3134.1115 - val_loss: 11575.6254
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3119.1789 - val_loss: 11462.9424
Epoch 00008: val_loss improved from 11516.06280 to 11462.94243, saving model to jinan0_weights.hdf5
              jinan0 3089.8974      0.91  0.27  0.68      0.92  0.23  0.72      0.92  0.21  0.74
              jinan011462.9424      0.99  0.13  0.85      0.99  0.11  0.88      0.98  0.09  0.90
forget mean min: 0.954955 0.361656
abs_mean, abs_mean+, abs_mean-: 9.39249 6.62796 17.6838
U_c = [[-0.11027627]] U_f = [[ 0.]] b_c = [ 0.36013192] b_f = [ 1.]
Epoch 10/300
1s - loss: 3105.0786 - val_loss: 11414.0893
Epoch 00009: val_loss improved from 11462.94243 to 11414.08930, saving model to jinan0_weights.hdf5
              jinan0 3081.3610      0.90  0.27  0.68      0.91  0.23  0.72      0.91  0.21  0.74
              jinan011414.0893      0.98  0.13  0.86      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.952161 0.354567
abs_mean, abs_mean+, abs_mean-: 9.93815 6.91815 19.0356
U_c = [[-0.10877438]] U_f = [[ 0.]] b_c = [ 0.38112399] b_f = [ 1.]
Epoch 11/300
1s - loss: 3097.9446 - val_loss: 11602.2602
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 3090.1998 - val_loss: 11258.6006
Epoch 00011: val_loss improved from 11414.08930 to 11258.60064, saving model to jinan0_weights.hdf5
              jinan0 3069.6009      0.90  0.27  0.68      0.92  0.23  0.72      0.91  0.21  0.73
              jinan011258.6008      0.99  0.13  0.86      0.99  0.11  0.88      0.98  0.09  0.90
forget mean min: 0.950841 0.352509
abs_mean, abs_mean+, abs_mean-: 10.4385 7.27498 20.0076
U_c = [[-0.11383504]] U_f = [[ 0.]] b_c = [ 0.41304499] b_f = [ 1.]
Epoch 13/300
0s - loss: 3091.5128 - val_loss: 11575.1925
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 3086.2886 - val_loss: 11514.0221
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 3080.3351 - val_loss: 11533.9738
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 3080.4970 - val_loss: 11356.7425
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 3075.0476 - val_loss: 11286.2320
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 3070.4367 - val_loss: 11407.9802
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 3068.1648 - val_loss: 11202.6190
Epoch 00018: val_loss improved from 11258.60064 to 11202.61897, saving model to jinan0_weights.hdf5
              jinan0 3039.1711      0.89  0.26  0.68      0.91  0.23  0.72      0.91  0.21  0.73
              jinan011202.6191      0.98  0.13  0.86      0.99  0.11  0.88      0.99  0.09  0.90
forget mean min: 0.945507 0.355797
abs_mean, abs_mean+, abs_mean-: 11.3358 7.66686 21.3613
U_c = [[-0.11983003]] U_f = [[ 0.]] b_c = [ 0.49704829] b_f = [ 1.]
Epoch 20/300
0s - loss: 3067.2038 - val_loss: 11157.9771
Epoch 00019: val_loss improved from 11202.61897 to 11157.97715, saving model to jinan0_weights.hdf5
              jinan0 3032.7973      0.90  0.26  0.68      0.91  0.23  0.72      0.91  0.21  0.74
              jinan011157.9769      0.98  0.13  0.86      0.99  0.11  0.88      0.98  0.09  0.90
forget mean min: 0.945473 0.354576
abs_mean, abs_mean+, abs_mean-: 11.3712 7.68977 21.6143
U_c = [[-0.11491943]] U_f = [[ 0.]] b_c = [ 0.51020497] b_f = [ 1.]
Epoch 21/300
0s - loss: 3064.5691 - val_loss: 11239.9824
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 3054.4361 - val_loss: 10834.1018
Epoch 00021: val_loss improved from 11157.97715 to 10834.10181, saving model to jinan0_weights.hdf5
              jinan0 3023.6789      0.88  0.26  0.67      0.89  0.22  0.71      0.88  0.20  0.72
              jinan010834.1019      0.97  0.12  0.85      0.98  0.10  0.88      0.98  0.09  0.90
forget mean min: 0.940493 0.362095
abs_mean, abs_mean+, abs_mean-: 11.5802 7.64703 21.5989
U_c = [[-0.11229022]] U_f = [[ 0.]] b_c = [ 0.53308564] b_f = [ 1.]
Epoch 23/300
0s - loss: 3048.1655 - val_loss: 10700.7884
Epoch 00022: val_loss improved from 10834.10181 to 10700.78836, saving model to jinan0_weights.hdf5
              jinan0 3018.5654      0.90  0.27  0.67      0.91  0.23  0.71      0.90  0.21  0.73
              jinan010700.7882      0.97  0.13  0.85      0.98  0.10  0.88      0.98  0.09  0.89
forget mean min: 0.94366 0.36684
abs_mean, abs_mean+, abs_mean-: 11.5082 7.82399 21.1042
U_c = [[-0.11084405]] U_f = [[ 0.]] b_c = [ 0.54804164] b_f = [ 1.]
Epoch 24/300
0s - loss: 3037.9495 - val_loss: 10656.7354
Epoch 00023: val_loss improved from 10700.78836 to 10656.73542, saving model to jinan0_weights.hdf5
              jinan0 3011.7616      0.86  0.25  0.67      0.87  0.21  0.71      0.87  0.20  0.72
              jinan010656.7355      0.97  0.12  0.86      0.97  0.10  0.88      0.98  0.09  0.89
forget mean min: 0.9344 0.370697
abs_mean, abs_mean+, abs_mean-: 11.7418 7.60893 20.8713
U_c = [[-0.10649721]] U_f = [[ 0.]] b_c = [ 0.5619424] b_f = [ 1.]
Epoch 25/300
0s - loss: 3037.4247 - val_loss: 10560.6958
Epoch 00024: val_loss improved from 10656.73542 to 10560.69580, saving model to jinan0_weights.hdf5
              jinan0 2993.9176      0.88  0.26  0.67      0.89  0.22  0.71      0.89  0.20  0.72
              jinan010560.6957      0.97  0.12  0.85      0.97  0.10  0.87      0.98  0.09  0.89
forget mean min: 0.938927 0.355548
abs_mean, abs_mean+, abs_mean-: 11.8067 7.85355 21.5192
U_c = [[-0.10704904]] U_f = [[ 0.]] b_c = [ 0.57835579] b_f = [ 1.]
Epoch 26/300
1s - loss: 3029.0680 - val_loss: 10778.2981
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 3020.8209 - val_loss: 10465.4397
Epoch 00026: val_loss improved from 10560.69580 to 10465.43968, saving model to jinan0_weights.hdf5
              jinan0 2998.2997      0.90  0.27  0.67      0.91  0.23  0.71      0.90  0.21  0.73
              jinan010465.4400      0.97  0.13  0.85      0.98  0.11  0.88      0.98  0.09  0.90
forget mean min: 0.942302 0.361452
abs_mean, abs_mean+, abs_mean-: 11.8442 8.13581 21.0299
U_c = [[-0.10581456]] U_f = [[ 0.]] b_c = [ 0.61350977] b_f = [ 1.]
Epoch 28/300
0s - loss: 3008.7161 - val_loss: 10496.5242
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 3016.5450 - val_loss: 10556.7510
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 3007.0048 - val_loss: 10660.4660
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 2991.6919 - val_loss: 10972.0098
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 2972.8081 - val_loss: 10441.5549
Epoch 00031: val_loss improved from 10465.43968 to 10441.55490, saving model to jinan0_weights.hdf5
              jinan0 2937.1031      0.86  0.25  0.67      0.86  0.21  0.70      0.86  0.20  0.71
              jinan010441.5546      0.96  0.11  0.85      0.96  0.09  0.87      0.96  0.08  0.89
forget mean min: 0.922128 0.43395
abs_mean, abs_mean+, abs_mean-: 11.2006 7.52375 16.6741
U_c = [[-0.08765731]] U_f = [[ 0.]] b_c = [ 0.71021855] b_f = [ 1.]
Epoch 33/300
1s - loss: 2946.2519 - val_loss: 11006.3234
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 2928.6727 - val_loss: 9916.9455
Epoch 00033: val_loss improved from 10441.55490 to 9916.94552, saving model to jinan0_weights.hdf5
              jinan0 2933.4753      0.86  0.25  0.67      0.87  0.22  0.69      0.86  0.21  0.70
              jinan0 9916.9454      0.96  0.12  0.85      0.96  0.09  0.87      0.96  0.08  0.88
forget mean min: 0.923594 0.474104
abs_mean, abs_mean+, abs_mean-: 11.2983 7.88104 16.417
U_c = [[-0.07638421]] U_f = [[ 0.]] b_c = [ 0.7567625] b_f = [ 1.]
Epoch 35/300
1s - loss: 2910.1154 - val_loss: 10812.9356
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 2881.5531 - val_loss: 11339.1190
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 2856.3813 - val_loss: 10690.4247
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 2803.6589 - val_loss: 11058.2220
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 2755.1719 - val_loss: 11107.1781
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 2685.0226 - val_loss: 10615.3349
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 2608.4827 - val_loss: 10135.9869
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 2538.5568 - val_loss: 11221.6499
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 2495.9982 - val_loss: 10841.9184
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 2454.9797 - val_loss: 10986.4931
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 2401.4627 - val_loss: 10317.8737
Epoch 00044: val_loss did not improve
X_train[0].shape = (3105, 40, 23)

training jinan1
Train on 3105 samples, validate on 970 samples
Before training:
              jinan113504.9636      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.97649 nan 5.97649
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              jinan137048.4109      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 10.6406 nan 10.6406
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
0s - loss: 11699.5339 - val_loss: 27693.6364
Epoch 00000: val_loss improved from inf to 27693.63643, saving model to jinan1_weights.hdf5
              jinan1 8403.3417      0.15  0.09  0.14      0.14  0.06  0.14      0.14  0.01  0.14
              jinan127693.6365      0.19  0.01  0.18      0.18  0.01  0.18      0.17  0.00  0.17
forget mean min: 0.768782 0.446479
abs_mean, abs_mean+, abs_mean-: 13.998 nan 13.998
U_c = [[-0.10624635]] U_f = [[ 0.]] b_c = [ 0.05903505] b_f = [ 1.]
Epoch 2/300
0s - loss: 5995.5232 - val_loss: 15364.5814
Epoch 00001: val_loss improved from 27693.63643 to 15364.58143, saving model to jinan1_weights.hdf5
              jinan1 4749.1348      0.58  0.13  0.53      0.57  0.10  0.53      0.56  0.06  0.54
              jinan115364.5815      0.86  0.05  0.82      0.86  0.04  0.83      0.86  0.02  0.84
forget mean min: 0.899623 0.289982
abs_mean, abs_mean+, abs_mean-: 9.54355 1.98767 16.2102
U_c = [[-0.13776176]] U_f = [[ 0.]] b_c = [ 0.10648913] b_f = [ 1.]
Epoch 3/300
0s - loss: 4328.7340 - val_loss: 12177.7053
Epoch 00002: val_loss improved from 15364.58143 to 12177.70530, saving model to jinan1_weights.hdf5
              jinan1 3932.8190      0.79  0.22  0.64      0.79  0.18  0.68      0.78  0.14  0.69
              jinan112177.7054      0.96  0.10  0.87      0.96  0.07  0.89      0.96  0.06  0.91
forget mean min: 0.950483 0.245852
abs_mean, abs_mean+, abs_mean-: 6.78295 2.83559 19.0599
U_c = [[-0.13812989]] U_f = [[ 0.]] b_c = [ 0.15175898] b_f = [ 1.]
Epoch 4/300
0s - loss: 3700.7288 - val_loss: 11693.0055
Epoch 00003: val_loss improved from 12177.70530 to 11693.00546, saving model to jinan1_weights.hdf5
              jinan1 3474.1746      0.87  0.25  0.67      0.88  0.21  0.71      0.87  0.17  0.73
              jinan111693.0054      0.98  0.14  0.85      0.98  0.11  0.87      0.97  0.09  0.89
forget mean min: 0.964321 0.246904
abs_mean, abs_mean+, abs_mean-: 6.44627 3.7553 20.2133
U_c = [[-0.10911848]] U_f = [[ 0.]] b_c = [ 0.1963813] b_f = [ 1.]
Epoch 5/300
0s - loss: 3368.2833 - val_loss: 11439.2995
Epoch 00004: val_loss improved from 11693.00546 to 11439.29948, saving model to jinan1_weights.hdf5
              jinan1 3252.7861      0.89  0.27  0.67      0.90  0.23  0.71      0.90  0.20  0.73
              jinan111439.2995      0.98  0.14  0.85      0.98  0.11  0.87      0.98  0.09  0.89
forget mean min: 0.965436 0.360671
abs_mean, abs_mean+, abs_mean-: 7.02386 4.69342 15.1661
U_c = [[-0.09938824]] U_f = [[ 0.]] b_c = [ 0.24010418] b_f = [ 1.]
Epoch 6/300
0s - loss: 3219.5392 - val_loss: 11093.1831
Epoch 00005: val_loss improved from 11439.29948 to 11093.18313, saving model to jinan1_weights.hdf5
              jinan1 3166.7187      0.89  0.27  0.67      0.90  0.23  0.71      0.89  0.21  0.72
              jinan111093.1829      0.98  0.14  0.85      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.960393 0.363114
abs_mean, abs_mean+, abs_mean-: 7.74792 5.32864 15.1372
U_c = [[-0.09751972]] U_f = [[ 0.]] b_c = [ 0.27824554] b_f = [ 1.]
Epoch 7/300
0s - loss: 3161.6655 - val_loss: 11334.8929
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 3134.2021 - val_loss: 11314.2424
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 3119.3048 - val_loss: 11509.4674
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 3107.9378 - val_loss: 11391.3891
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 3098.2083 - val_loss: 11400.3563
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 3094.1528 - val_loss: 11663.5261
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 3088.2879 - val_loss: 11331.8924
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 3092.3712 - val_loss: 11410.2305
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 3087.7496 - val_loss: 11369.6190
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 3086.9650 - val_loss: 11368.4292
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 3080.5453 - val_loss: 11393.9838
Epoch 00016: val_loss did not improve
X_train[0].shape = (3105, 40, 23)

training jinan2
Train on 3105 samples, validate on 970 samples
Before training:
              jinan213504.9636      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.97649 nan 5.97649
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              jinan237048.4109      0.04  -nan  0.04      0.05  -nan  0.05      0.04  -nan  0.04
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 10.6406 nan 10.6406
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
0s - loss: 11656.0048 - val_loss: 27344.4452
Epoch 00000: val_loss improved from inf to 27344.44518, saving model to jinan2_weights.hdf5
              jinan2 8203.9237      0.18  0.09  0.17      0.17  0.06  0.17      0.17  0.01  0.16
              jinan227344.4446      0.21  0.02  0.21      0.21  0.01  0.20      0.19  0.00  0.19
forget mean min: 0.770672 0.444
abs_mean, abs_mean+, abs_mean-: 13.874 nan 13.874
U_c = [[-0.10659236]] U_f = [[ 0.]] b_c = [ 0.05969475] b_f = [ 1.]
Epoch 2/300
0s - loss: 5974.2864 - val_loss: 15365.7730
Epoch 00001: val_loss improved from 27344.44518 to 15365.77297, saving model to jinan2_weights.hdf5
              jinan2 4760.4316      0.57  0.13  0.52      0.56  0.10  0.53      0.55  0.06  0.53
              jinan215365.7730      0.85  0.06  0.81      0.85  0.04  0.82      0.84  0.02  0.82
forget mean min: 0.898975 0.298315
abs_mean, abs_mean+, abs_mean-: 9.60444 1.95146 16.3219
U_c = [[-0.13826273]] U_f = [[ 0.]] b_c = [ 0.10688245] b_f = [ 1.]
Epoch 3/300
0s - loss: 4325.8971 - val_loss: 12112.2514
Epoch 00002: val_loss improved from 15365.77297 to 12112.25137, saving model to jinan2_weights.hdf5
              jinan2 3930.3733      0.78  0.22  0.64      0.78  0.17  0.67      0.77  0.14  0.68
              jinan212112.2514      0.96  0.10  0.87      0.96  0.07  0.89      0.96  0.06  0.91
forget mean min: 0.949008 0.250883
abs_mean, abs_mean+, abs_mean-: 6.84246 2.80228 19.0333
U_c = [[-0.13793302]] U_f = [[ 0.]] b_c = [ 0.15142974] b_f = [ 1.]
Epoch 4/300
0s - loss: 3694.3996 - val_loss: 11733.8803
Epoch 00003: val_loss improved from 12112.25137 to 11733.88035, saving model to jinan2_weights.hdf5
              jinan2 3465.7138      0.87  0.26  0.67      0.88  0.21  0.71      0.88  0.18  0.74
              jinan211733.8804      0.98  0.14  0.85      0.98  0.11  0.87      0.97  0.09  0.89
forget mean min: 0.966436 0.234172
abs_mean, abs_mean+, abs_mean-: 6.29455 3.75631 20.2638
U_c = [[-0.10788172]] U_f = [[ 0.]] b_c = [ 0.19668631] b_f = [ 1.]
Epoch 5/300
0s - loss: 3358.2286 - val_loss: 11474.2229
Epoch 00004: val_loss improved from 11733.88035 to 11474.22290, saving model to jinan2_weights.hdf5
              jinan2 3263.9707      0.89  0.28  0.67      0.90  0.24  0.71      0.90  0.21  0.73
              jinan211474.2232      0.99  0.14  0.85      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.967917 0.345523
abs_mean, abs_mean+, abs_mean-: 6.78489 4.66152 15.3196
U_c = [[-0.10116646]] U_f = [[ 0.]] b_c = [ 0.23897372] b_f = [ 1.]
Epoch 6/300
0s - loss: 3214.8698 - val_loss: 11255.5967
Epoch 00005: val_loss improved from 11474.22290 to 11255.59668, saving model to jinan2_weights.hdf5
              jinan2 3194.3493      0.89  0.27  0.67      0.90  0.24  0.70      0.89  0.21  0.72
              jinan211255.5968      0.99  0.13  0.86      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.962171 0.348952
abs_mean, abs_mean+, abs_mean-: 7.73514 5.48692 15.0717
U_c = [[-0.09857028]] U_f = [[ 0.]] b_c = [ 0.27686486] b_f = [ 1.]
Epoch 7/300
0s - loss: 3160.9914 - val_loss: 11431.7480
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 3133.7002 - val_loss: 11605.2075
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 3116.8276 - val_loss: 11250.0094
Epoch 00008: val_loss improved from 11255.59668 to 11250.00941, saving model to jinan2_weights.hdf5
              jinan2 3089.0753      0.88  0.26  0.67      0.90  0.22  0.71      0.89  0.20  0.73
              jinan211250.0091      0.99  0.13  0.86      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.951369 0.358836
abs_mean, abs_mean+, abs_mean-: 9.71007 6.66064 18.1567
U_c = [[-0.11234277]] U_f = [[ 0.]] b_c = [ 0.36106598] b_f = [ 1.]
Epoch 10/300
0s - loss: 3107.2474 - val_loss: 11484.4011
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 3098.4497 - val_loss: 11513.5700
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 3094.7143 - val_loss: 11642.0843
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 3094.5056 - val_loss: 11439.3914
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 3083.8455 - val_loss: 11781.9538
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 3087.6864 - val_loss: 11598.0751
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 3080.9431 - val_loss: 11182.8370
Epoch 00015: val_loss improved from 11250.00941 to 11182.83700, saving model to jinan2_weights.hdf5
              jinan2 3073.1061      0.88  0.26  0.67      0.88  0.22  0.71      0.88  0.20  0.72
              jinan211182.8371      0.98  0.12  0.87      0.99  0.10  0.89      0.98  0.09  0.90
forget mean min: 0.941654 0.360855
abs_mean, abs_mean+, abs_mean-: 11.0828 7.46728 19.6804
U_c = [[-0.12141538]] U_f = [[ 0.]] b_c = [ 0.46452266] b_f = [ 1.]
Epoch 17/300
0s - loss: 3078.0195 - val_loss: 11265.5630
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 3080.0202 - val_loss: 11382.8936
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 3072.8796 - val_loss: 11344.8543
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 3067.7788 - val_loss: 11029.1872
Epoch 00019: val_loss improved from 11182.83700 to 11029.18721, saving model to jinan2_weights.hdf5
              jinan2 3043.6873      0.90  0.27  0.68      0.91  0.23  0.71      0.91  0.21  0.73
              jinan211029.1872      0.98  0.13  0.86      0.99  0.10  0.88      0.98  0.09  0.90
forget mean min: 0.946529 0.350219
abs_mean, abs_mean+, abs_mean-: 11.3407 7.72824 21.958
U_c = [[-0.11541776]] U_f = [[ 0.]] b_c = [ 0.51580936] b_f = [ 1.]
Epoch 21/300
0s - loss: 3064.3450 - val_loss: 11088.0222
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 3062.4529 - val_loss: 10996.6603
Epoch 00021: val_loss improved from 11029.18721 to 10996.66034, saving model to jinan2_weights.hdf5
              jinan2 3042.4191      0.89  0.26  0.68      0.90  0.23  0.71      0.90  0.20  0.73
              jinan210996.6602      0.98  0.13  0.85      0.99  0.11  0.88      0.98  0.09  0.90
forget mean min: 0.944707 0.358908
abs_mean, abs_mean+, abs_mean-: 11.4961 7.77249 21.4656
U_c = [[-0.11722716]] U_f = [[ 0.]] b_c = [ 0.54257792] b_f = [ 1.]
Epoch 23/300
0s - loss: 3060.1399 - val_loss: 10795.2231
Epoch 00022: val_loss improved from 10996.66034 to 10795.22308, saving model to jinan2_weights.hdf5
              jinan2 3023.8614      0.90  0.26  0.68      0.91  0.23  0.72      0.90  0.21  0.73
              jinan210795.2231      0.98  0.13  0.86      0.99  0.10  0.89      0.98  0.09  0.89
forget mean min: 0.942949 0.360284
abs_mean, abs_mean+, abs_mean-: 11.4805 7.73149 21.4647
U_c = [[-0.11550792]] U_f = [[ 0.]] b_c = [ 0.55428827] b_f = [ 1.]
Epoch 24/300
0s - loss: 3051.5166 - val_loss: 10629.4286
Epoch 00023: val_loss improved from 10795.22308 to 10629.42862, saving model to jinan2_weights.hdf5
              jinan2 3009.3575      0.88  0.26  0.67      0.89  0.22  0.71      0.89  0.20  0.72
              jinan210629.4284      0.97  0.12  0.85      0.98  0.10  0.88      0.98  0.09  0.89
forget mean min: 0.940022 0.363843
abs_mean, abs_mean+, abs_mean-: 11.5684 7.70597 20.9166
U_c = [[-0.11337833]] U_f = [[ 0.]] b_c = [ 0.56831622] b_f = [ 1.]
Epoch 25/300
0s - loss: 3038.7261 - val_loss: 10828.4446
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 3036.5722 - val_loss: 10768.8583
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 3023.3478 - val_loss: 10411.1938
Epoch 00026: val_loss improved from 10629.42862 to 10411.19377, saving model to jinan2_weights.hdf5
              jinan2 3006.9514      0.89  0.27  0.67      0.90  0.23  0.71      0.90  0.21  0.72
              jinan210411.1937      0.97  0.12  0.85      0.98  0.10  0.88      0.98  0.09  0.89
forget mean min: 0.941361 0.355407
abs_mean, abs_mean+, abs_mean-: 11.8661 8.07091 21.153
U_c = [[-0.10845212]] U_f = [[ 0.]] b_c = [ 0.61240119] b_f = [ 1.]
Epoch 28/300
1s - loss: 3023.9417 - val_loss: 10665.7522
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 3012.8759 - val_loss: 10356.0698
Epoch 00028: val_loss improved from 10411.19377 to 10356.06979, saving model to jinan2_weights.hdf5
              jinan2 2987.5093      0.87  0.25  0.67      0.87  0.21  0.71      0.87  0.20  0.71
              jinan210356.0699      0.96  0.12  0.85      0.97  0.09  0.88      0.97  0.09  0.89
forget mean min: 0.933133 0.350933
abs_mean, abs_mean+, abs_mean-: 12.2014 8.18076 20.4818
U_c = [[-0.10400286]] U_f = [[ 0.]] b_c = [ 0.64640224] b_f = [ 1.]
Epoch 30/300
0s - loss: 3011.7122 - val_loss: 10839.5396
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 3007.4559 - val_loss: 10710.6437
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 2991.2047 - val_loss: 10515.2727
Epoch 00031: val_loss did not improve
Epoch 33/300
0s - loss: 2980.6432 - val_loss: 10679.8762
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 2949.4878 - val_loss: 11032.5588
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 2939.6921 - val_loss: 10427.4084
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 2922.3526 - val_loss: 10284.0433
Epoch 00035: val_loss improved from 10356.06979 to 10284.04326, saving model to jinan2_weights.hdf5
              jinan2 2901.4381      0.88  0.26  0.67      0.88  0.23  0.70      0.88  0.21  0.71
              jinan210284.0433      0.96  0.13  0.84      0.97  0.11  0.87      0.97  0.09  0.89
forget mean min: 0.923901 0.514613
abs_mean, abs_mean+, abs_mean-: 10.8777 7.68699 15.2691
U_c = [[-0.07765447]] U_f = [[ 0.]] b_c = [ 0.78946382] b_f = [ 1.]
Epoch 37/300
0s - loss: 2903.4730 - val_loss: 10417.3535
Epoch 00036: val_loss did not improve
Epoch 38/300
0s - loss: 2892.7902 - val_loss: 10879.7208
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 2871.3750 - val_loss: 10525.2081
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 2844.6205 - val_loss: 10301.2971
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 2809.1582 - val_loss: 10584.5813
Epoch 00040: val_loss did not improve
Epoch 42/300
0s - loss: 2767.5448 - val_loss: 11254.5645
Epoch 00041: val_loss did not improve
Epoch 43/300
0s - loss: 2708.8142 - val_loss: 9811.4754
Epoch 00042: val_loss improved from 10284.04326 to 9811.47542, saving model to jinan2_weights.hdf5
              jinan2 2655.1319      0.87  0.25  0.67      0.87  0.23  0.70      0.86  0.21  0.70
              jinan2 9811.4753      0.96  0.11  0.86      0.96  0.08  0.89      0.97  0.07  0.90
forget mean min: 0.916064 0.48115
abs_mean, abs_mean+, abs_mean-: 11.0426 8.42368 14.0371
U_c = [[-0.04980201]] U_f = [[ 0.]] b_c = [ 0.93586206] b_f = [ 1.]
Epoch 44/300
0s - loss: 2641.6149 - val_loss: 9316.8204
Epoch 00043: val_loss improved from 9811.47542 to 9316.82040, saving model to jinan2_weights.hdf5
              jinan2 2648.7926      0.87  0.26  0.67      0.87  0.23  0.69      0.86  0.22  0.70
              jinan2 9316.8202      0.95  0.12  0.84      0.95  0.10  0.86      0.95  0.08  0.88
forget mean min: 0.918417 0.465564
abs_mean, abs_mean+, abs_mean-: 11.3321 8.87075 14.2571
U_c = [[-0.04463811]] U_f = [[ 0.]] b_c = [ 0.95453] b_f = [ 1.]
Epoch 45/300
0s - loss: 2578.7304 - val_loss: 10470.0121
Epoch 00044: val_loss did not improve
Epoch 46/300
0s - loss: 2518.2925 - val_loss: 10924.3642
Epoch 00045: val_loss did not improve
Epoch 47/300
0s - loss: 2458.8842 - val_loss: 9578.7776
Epoch 00046: val_loss did not improve
Epoch 48/300
0s - loss: 2416.1238 - val_loss: 10640.2994
Epoch 00047: val_loss did not improve
Epoch 49/300
0s - loss: 2357.5775 - val_loss: 10713.0045
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 2303.4449 - val_loss: 10639.8267
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 2269.1229 - val_loss: 10716.7812
Epoch 00050: val_loss did not improve
Epoch 52/300
0s - loss: 2228.2963 - val_loss: 10292.7471
Epoch 00051: val_loss did not improve
Epoch 53/300
0s - loss: 2194.0362 - val_loss: 11153.7506
Epoch 00052: val_loss did not improve
Epoch 54/300
0s - loss: 2159.3309 - val_loss: 10435.7927
Epoch 00053: val_loss did not improve
Epoch 55/300
0s - loss: 2127.7598 - val_loss: 11124.6224
Epoch 00054: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training xian0
Train on 7452 samples, validate on 2328 samples
Before training:
               xian0 5716.4221      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.73221 nan 3.73221
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
               xian026987.8319      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.37394 nan 8.37394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 3449.6198 - val_loss: 9423.1246
Epoch 00000: val_loss improved from inf to 9423.12464, saving model to xian0_weights.hdf5
               xian0 1859.7289      0.46  0.31  0.38      0.48  0.30  0.40      0.48  0.29  0.41
               xian0 9423.1247      0.75  0.06  0.71      0.75  0.04  0.73      0.75  0.02  0.74
forget mean min: 0.886131 0.244369
abs_mean, abs_mean+, abs_mean-: 6.72018 2.50819 16.251
U_c = [[-0.09667903]] U_f = [[ 0.]] b_c = [ 0.12209431] b_f = [ 1.]
Epoch 2/300
2s - loss: 1654.5543 - val_loss: 7591.8538
Epoch 00001: val_loss improved from 9423.12464 to 7591.85378, saving model to xian0_weights.hdf5
               xian0 1527.4215      0.72  0.35  0.52      0.75  0.34  0.54      0.76  0.33  0.55
               xian0 7591.8538      0.86  0.07  0.81      0.87  0.04  0.83      0.87  0.03  0.85
forget mean min: 0.930382 0.385947
abs_mean, abs_mean+, abs_mean-: 5.57244 3.49063 8.98859
U_c = [[-0.05604139]] U_f = [[ 0.]] b_c = [ 0.20953034] b_f = [ 1.]
Epoch 3/300
2s - loss: 1487.3415 - val_loss: 7691.0470
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 1424.7688 - val_loss: 8291.0568
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 1385.6376 - val_loss: 7831.9771
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 1363.8446 - val_loss: 8801.8766
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 1353.9331 - val_loss: 8770.5406
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 1343.4019 - val_loss: 8160.2510
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 1331.7506 - val_loss: 7822.9978
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 1318.9908 - val_loss: 8295.8092
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 1307.0288 - val_loss: 8673.4564
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 1302.6055 - val_loss: 8918.1141
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 1287.8365 - val_loss: 8500.6925
Epoch 00012: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training xian1
Train on 7452 samples, validate on 2328 samples
Before training:
               xian1 5716.4221      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.73221 nan 3.73221
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
               xian126987.8319      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.37394 nan 8.37394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 3424.7703 - val_loss: 9405.4319
Epoch 00000: val_loss improved from inf to 9405.43185, saving model to xian1_weights.hdf5
               xian1 1853.8460      0.46  0.31  0.38      0.48  0.29  0.40      0.48  0.28  0.41
               xian1 9405.4318      0.75  0.06  0.72      0.75  0.04  0.73      0.75  0.02  0.74
forget mean min: 0.887625 0.248768
abs_mean, abs_mean+, abs_mean-: 6.74045 2.52968 16.297
U_c = [[-0.09747067]] U_f = [[ 0.]] b_c = [ 0.12208412] b_f = [ 1.]
Epoch 2/300
2s - loss: 1649.8039 - val_loss: 7661.6075
Epoch 00001: val_loss improved from 9405.43185 to 7661.60754, saving model to xian1_weights.hdf5
               xian1 1525.1195      0.72  0.35  0.52      0.75  0.34  0.55      0.77  0.33  0.55
               xian1 7661.6076      0.86  0.07  0.81      0.86  0.04  0.83      0.86  0.03  0.84
forget mean min: 0.931476 0.386338
abs_mean, abs_mean+, abs_mean-: 5.61396 3.52851 8.97599
U_c = [[-0.0548193]] U_f = [[ 0.]] b_c = [ 0.20882133] b_f = [ 1.]
Epoch 3/300
2s - loss: 1484.9208 - val_loss: 7292.7528
Epoch 00002: val_loss improved from 7661.60754 to 7292.75279, saving model to xian1_weights.hdf5
               xian1 1445.5382      0.73  0.35  0.52      0.76  0.34  0.55      0.78  0.33  0.56
               xian1 7292.7528      0.87  0.07  0.81      0.87  0.04  0.84      0.87  0.02  0.85
forget mean min: 0.934826 0.433513
abs_mean, abs_mean+, abs_mean-: 5.29389 3.51534 7.76328
U_c = [[-0.03794761]] U_f = [[ 0.]] b_c = [ 0.25569138] b_f = [ 1.]
Epoch 4/300
2s - loss: 1427.9695 - val_loss: 7304.7642
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 1384.9839 - val_loss: 8165.1412
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 1370.2584 - val_loss: 7991.7119
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1356.4670 - val_loss: 7161.9584
Epoch 00006: val_loss improved from 7292.75279 to 7161.95836, saving model to xian1_weights.hdf5
               xian1 1386.4091      0.78  0.38  0.53      0.82  0.37  0.55      0.84  0.37  0.56
               xian1 7161.9584      0.87  0.07  0.82      0.88  0.04  0.85      0.88  0.02  0.87
forget mean min: 0.943082 0.553185
abs_mean, abs_mean+, abs_mean-: 6.35877 4.33564 9.47809
U_c = [[-0.01518877]] U_f = [[ 0.]] b_c = [ 0.33499885] b_f = [ 1.]
Epoch 8/300
2s - loss: 1346.3180 - val_loss: 8233.2335
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 1335.0314 - val_loss: 8286.7880
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 1322.3829 - val_loss: 7638.9608
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 1313.3813 - val_loss: 8451.0527
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 1302.2813 - val_loss: 8296.7542
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1288.8842 - val_loss: 8310.3072
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 1275.7079 - val_loss: 8378.4307
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 1254.9174 - val_loss: 8292.5373
Epoch 00014: val_loss did not improve
Epoch 16/300
2s - loss: 1244.4909 - val_loss: 8765.3201
Epoch 00015: val_loss did not improve
Epoch 17/300
2s - loss: 1218.6469 - val_loss: 8229.6179
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1197.2300 - val_loss: 8562.4255
Epoch 00017: val_loss did not improve
X_train[0].shape = (7452, 40, 23)

training xian2
Train on 7452 samples, validate on 2328 samples
Before training:
               xian2 5716.4221      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.73221 nan 3.73221
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
               xian226987.8319      0.04  -nan  0.04      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 8.37394 nan 8.37394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 3446.3253 - val_loss: 9198.5315
Epoch 00000: val_loss improved from inf to 9198.53148, saving model to xian2_weights.hdf5
               xian2 1860.3827      0.44  0.30  0.37      0.46  0.29  0.39      0.47  0.27  0.40
               xian2 9198.5315      0.77  0.06  0.73      0.77  0.04  0.74      0.77  0.02  0.75
forget mean min: 0.890303 0.250121
abs_mean, abs_mean+, abs_mean-: 6.60393 2.49428 15.9235
U_c = [[-0.10037943]] U_f = [[ 0.]] b_c = [ 0.12195117] b_f = [ 1.]
Epoch 2/300
1s - loss: 1645.8044 - val_loss: 7346.7435
Epoch 00001: val_loss improved from 9198.53148 to 7346.74350, saving model to xian2_weights.hdf5
               xian2 1545.1599      0.75  0.37  0.52      0.78  0.36  0.54      0.79  0.36  0.55
               xian2 7346.7434      0.87  0.07  0.81      0.87  0.04  0.84      0.87  0.03  0.85
forget mean min: 0.93179 0.385669
abs_mean, abs_mean+, abs_mean-: 5.6466 3.60445 9.35205
U_c = [[-0.05060286]] U_f = [[ 0.]] b_c = [ 0.21410862] b_f = [ 1.]
Epoch 3/300
1s - loss: 1480.1999 - val_loss: 7779.8606
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1424.4238 - val_loss: 7467.7116
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 1385.7117 - val_loss: 7740.2188
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 1373.2853 - val_loss: 8353.1119
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 1357.7060 - val_loss: 8143.6187
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 1349.9564 - val_loss: 8095.9551
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 1337.6477 - val_loss: 7879.3158
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 1324.0302 - val_loss: 8232.0336
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 1314.3145 - val_loss: 8194.7441
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 1299.0116 - val_loss: 8731.2571
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 1288.5428 - val_loss: 8375.2259
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanjing0
Train on 5589 samples, validate on 1746 samples
Before training:
            nanjing0 4028.1246      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.27214 nan 3.27214
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            nanjing012370.3202      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.27394 nan 6.27394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2861.4911 - val_loss: 5908.2365
Epoch 00000: val_loss improved from inf to 5908.23646, saving model to nanjing0_weights.hdf5
            nanjing0 1782.6443      0.08  0.42  0.07      0.09  -nan  0.08      0.08  -nan  0.07
            nanjing0 5908.2364      0.49  0.05  0.47      0.48  0.01  0.48      0.45  0.00  0.45
forget mean min: 0.780976 0.278645
abs_mean, abs_mean+, abs_mean-: 7.78221 2.06994 12.6293
U_c = [[-0.131163]] U_f = [[ 0.]] b_c = [ 0.09557836] b_f = [ 1.]
Epoch 2/300
1s - loss: 1211.6455 - val_loss: 2711.7571
Epoch 00001: val_loss improved from 5908.23646 to 2711.75707, saving model to nanjing0_weights.hdf5
            nanjing0  934.8331      0.39  0.41  0.31      0.39  0.40  0.31      0.39  0.35  0.33
            nanjing0 2711.7571      0.93  0.16  0.79      0.93  0.13  0.82      0.92  0.11  0.83
forget mean min: 0.92342 0.162504
abs_mean, abs_mean+, abs_mean-: 5.58006 3.31573 15.2419
U_c = [[-0.11962051]] U_f = [[ 0.]] b_c = [ 0.16944756] b_f = [ 1.]
Epoch 3/300
1s - loss: 898.0504 - val_loss: 2404.5177
Epoch 00002: val_loss improved from 2711.75707 to 2404.51768, saving model to nanjing0_weights.hdf5
            nanjing0  867.6246      0.51  0.40  0.38      0.52  0.39  0.39      0.50  0.37  0.38
            nanjing0 2404.5177      0.93  0.15  0.80      0.93  0.12  0.83      0.92  0.09  0.84
forget mean min: 0.929115 0.288135
abs_mean, abs_mean+, abs_mean-: 6.25567 4.12179 12.3174
U_c = [[-0.1047155]] U_f = [[ 0.]] b_c = [ 0.22416565] b_f = [ 1.]
Epoch 4/300
1s - loss: 858.2277 - val_loss: 2451.4427
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 842.8344 - val_loss: 2527.3033
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 831.9826 - val_loss: 2585.6765
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 827.5140 - val_loss: 2680.6936
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 826.3178 - val_loss: 2680.5512
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 825.4974 - val_loss: 2677.9941
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 823.9586 - val_loss: 2682.8707
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 820.4188 - val_loss: 2724.8824
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 812.3194 - val_loss: 2830.5752
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 800.3327 - val_loss: 2763.2143
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 784.0692 - val_loss: 2737.0033
Epoch 00013: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanjing1
Train on 5589 samples, validate on 1746 samples
Before training:
            nanjing1 4028.1246      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.27214 nan 3.27214
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            nanjing112370.3202      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.27394 nan 6.27394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2856.9285 - val_loss: 5991.0698
Epoch 00000: val_loss improved from inf to 5991.06980, saving model to nanjing1_weights.hdf5
            nanjing1 1803.4837      0.08  0.51  0.07      0.09  -nan  0.08      0.08  -nan  0.07
            nanjing1 5991.0698      0.48  0.05  0.47      0.48  0.01  0.47      0.44  0.00  0.44
forget mean min: 0.780484 0.285871
abs_mean, abs_mean+, abs_mean-: 7.81701 2.05676 12.554
U_c = [[-0.13187486]] U_f = [[ 0.]] b_c = [ 0.09500639] b_f = [ 1.]
Epoch 2/300
1s - loss: 1243.5629 - val_loss: 2732.0327
Epoch 00001: val_loss improved from 5991.06980 to 2732.03274, saving model to nanjing1_weights.hdf5
            nanjing1  941.5415      0.38  0.41  0.30      0.38  0.39  0.31      0.38  0.34  0.32
            nanjing1 2732.0327      0.93  0.16  0.79      0.93  0.13  0.82      0.92  0.11  0.82
forget mean min: 0.923998 0.167147
abs_mean, abs_mean+, abs_mean-: 5.5742 3.30398 15.1805
U_c = [[-0.12183418]] U_f = [[ 0.]] b_c = [ 0.16851898] b_f = [ 1.]
Epoch 3/300
1s - loss: 898.4260 - val_loss: 2376.2814
Epoch 00002: val_loss improved from 2732.03274 to 2376.28142, saving model to nanjing1_weights.hdf5
            nanjing1  868.8073      0.53  0.41  0.39      0.54  0.40  0.40      0.52  0.39  0.39
            nanjing1 2376.2814      0.93  0.15  0.80      0.93  0.12  0.83      0.93  0.10  0.84
forget mean min: 0.930294 0.285281
abs_mean, abs_mean+, abs_mean-: 6.27041 4.17179 12.4096
U_c = [[-0.10395339]] U_f = [[ 0.]] b_c = [ 0.22853011] b_f = [ 1.]
Epoch 4/300
1s - loss: 856.6385 - val_loss: 2458.0691
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 840.9414 - val_loss: 2612.3102
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 831.9950 - val_loss: 2522.8241
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 828.9843 - val_loss: 2583.2184
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 827.2453 - val_loss: 2723.3605
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 826.1848 - val_loss: 2677.0408
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 824.5996 - val_loss: 2697.8255
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 823.6291 - val_loss: 2734.6177
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 822.2610 - val_loss: 2765.8122
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 817.7389 - val_loss: 2788.7571
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 808.4631 - val_loss: 2724.6161
Epoch 00013: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanjing2
Train on 5589 samples, validate on 1746 samples
Before training:
            nanjing2 4028.1246      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.27214 nan 3.27214
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            nanjing212370.3202      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 6.27394 nan 6.27394
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2856.7447 - val_loss: 5898.9940
Epoch 00000: val_loss improved from inf to 5898.99403, saving model to nanjing2_weights.hdf5
            nanjing2 1794.5212      0.08  -nan  0.07      0.08  -nan  0.07      0.08  -nan  0.07
            nanjing2 5898.9941      0.49  0.05  0.48      0.49  0.01  0.48      0.45  0.00  0.45
forget mean min: 0.781325 0.281081
abs_mean, abs_mean+, abs_mean-: 7.80393 2.07664 12.6894
U_c = [[-0.13236825]] U_f = [[ 0.]] b_c = [ 0.09502317] b_f = [ 1.]
Epoch 2/300
1s - loss: 1229.9770 - val_loss: 2721.2150
Epoch 00001: val_loss improved from 5898.99403 to 2721.21498, saving model to nanjing2_weights.hdf5
            nanjing2  936.3829      0.41  0.42  0.32      0.41  0.41  0.32      0.41  0.37  0.33
            nanjing2 2721.2150      0.93  0.15  0.79      0.93  0.12  0.82      0.92  0.10  0.83
forget mean min: 0.917329 0.153564
abs_mean, abs_mean+, abs_mean-: 5.83073 3.42596 15.6868
U_c = [[-0.11814948]] U_f = [[ 0.]] b_c = [ 0.17099959] b_f = [ 1.]
Epoch 3/300
1s - loss: 898.1481 - val_loss: 2452.8043
Epoch 00002: val_loss improved from 2721.21498 to 2452.80425, saving model to nanjing2_weights.hdf5
            nanjing2  867.6164      0.48  0.39  0.37      0.48  0.38  0.37      0.47  0.36  0.37
            nanjing2 2452.8043      0.92  0.14  0.79      0.91  0.11  0.82      0.91  0.09  0.84
forget mean min: 0.926692 0.292781
abs_mean, abs_mean+, abs_mean-: 6.27881 4.076 12.2644
U_c = [[-0.11039829]] U_f = [[ 0.]] b_c = [ 0.22632368] b_f = [ 1.]
Epoch 4/300
1s - loss: 858.2259 - val_loss: 2385.8574
Epoch 00003: val_loss improved from 2452.80425 to 2385.85742, saving model to nanjing2_weights.hdf5
            nanjing2  847.9907      0.58  0.39  0.42      0.59  0.38  0.43      0.59  0.36  0.44
            nanjing2 2385.8575      0.91  0.14  0.80      0.91  0.10  0.82      0.90  0.09  0.83
forget mean min: 0.925949 0.294112
abs_mean, abs_mean+, abs_mean-: 6.82205 4.5137 12.8379
U_c = [[-0.10776101]] U_f = [[ 0.]] b_c = [ 0.26696709] b_f = [ 1.]
Epoch 5/300
1s - loss: 840.9111 - val_loss: 2526.8092
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 830.5235 - val_loss: 2675.3414
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 829.2901 - val_loss: 2577.0827
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 826.3635 - val_loss: 2650.8126
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 825.0778 - val_loss: 2662.9313
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 823.6137 - val_loss: 2786.3587
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 820.0393 - val_loss: 2764.3611
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 812.7184 - val_loss: 2755.1269
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 801.7163 - val_loss: 2758.0554
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 789.8251 - val_loss: 2893.1447
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 775.4049 - val_loss: 2881.3649
Epoch 00014: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shanghai0
Train on 5589 samples, validate on 1746 samples
Before training:
           shanghai0 3539.4690      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.11597 nan 3.11597
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shanghai0 8910.3603      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.34373 nan 5.34373
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2439.2496 - val_loss: 3501.6057
Epoch 00000: val_loss improved from inf to 3501.60566, saving model to shanghai0_weights.hdf5
           shanghai0 1456.1342      0.08  0.53  0.07      0.08  0.50  0.07      0.08  0.48  0.07
           shanghai0 3501.6057      0.45  0.32  0.38      0.44  0.30  0.38      0.41  0.25  0.36
forget mean min: 0.843867 0.294133
abs_mean, abs_mean+, abs_mean-: 5.98255 1.95345 10.8948
U_c = [[-0.13278402]] U_f = [[ 0.]] b_c = [ 0.09528982] b_f = [ 1.]
Epoch 2/300
1s - loss: 1163.4326 - val_loss: 2242.5773
Epoch 00001: val_loss improved from 3501.60566 to 2242.57734, saving model to shanghai0_weights.hdf5
           shanghai0  918.6390      0.22  0.34  0.19      0.23  0.31  0.20      0.22  0.28  0.20
           shanghai0 2242.5773      0.81  0.34  0.57      0.81  0.31  0.59      0.80  0.26  0.63
forget mean min: 0.90392 0.27641
abs_mean, abs_mean+, abs_mean-: 5.57237 3.22656 10.4735
U_c = [[-0.14281674]] U_f = [[ 0.]] b_c = [ 0.17279217] b_f = [ 1.]
Epoch 3/300
1s - loss: 838.1183 - val_loss: 2122.9930
Epoch 00002: val_loss improved from 2242.57734 to 2122.99295, saving model to shanghai0_weights.hdf5
           shanghai0  791.4180      0.46  0.36  0.37      0.49  0.35  0.39      0.50  0.32  0.41
           shanghai0 2122.9929      0.72  0.27  0.57      0.72  0.25  0.58      0.70  0.22  0.58
forget mean min: 0.917645 0.486628
abs_mean, abs_mean+, abs_mean-: 4.61054 3.33115 6.21945
U_c = [[-0.07931741]] U_f = [[ 0.]] b_c = [ 0.24496841] b_f = [ 1.]
Epoch 4/300
1s - loss: 780.4107 - val_loss: 2173.7027
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 765.1728 - val_loss: 2074.3744
Epoch 00004: val_loss improved from 2122.99295 to 2074.37441, saving model to shanghai0_weights.hdf5
           shanghai0  758.8362      0.46  0.30  0.39      0.49  0.25  0.42      0.52  0.20  0.45
           shanghai0 2074.3744      0.69  0.28  0.54      0.68  0.27  0.55      0.66  0.23  0.56
forget mean min: 0.906136 0.474948
abs_mean, abs_mean+, abs_mean-: 5.35869 4.27826 6.54411
U_c = [[-0.0734764]] U_f = [[ 0.]] b_c = [ 0.33865884] b_f = [ 1.]
Epoch 6/300
1s - loss: 757.4716 - val_loss: 1994.8487
Epoch 00005: val_loss improved from 2074.37441 to 1994.84870, saving model to shanghai0_weights.hdf5
           shanghai0  749.8652      0.58  0.41  0.42      0.61  0.39  0.44      0.63  0.35  0.48
           shanghai0 1994.8487      0.74  0.29  0.57      0.72  0.28  0.56      0.71  0.25  0.57
forget mean min: 0.906297 0.446728
abs_mean, abs_mean+, abs_mean-: 5.89135 4.94818 6.98538
U_c = [[-0.0759271]] U_f = [[ 0.]] b_c = [ 0.37606189] b_f = [ 1.]
Epoch 7/300
1s - loss: 750.4866 - val_loss: 2011.0150
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 744.9442 - val_loss: 1945.2847
Epoch 00007: val_loss improved from 1994.84870 to 1945.28468, saving model to shanghai0_weights.hdf5
           shanghai0  733.9436      0.59  0.38  0.44      0.62  0.35  0.47      0.67  0.30  0.52
           shanghai0 1945.2847      0.74  0.29  0.57      0.74  0.28  0.57      0.72  0.25  0.58
forget mean min: 0.900393 0.435466
abs_mean, abs_mean+, abs_mean-: 6.29592 5.34949 7.39614
U_c = [[-0.07841355]] U_f = [[ 0.]] b_c = [ 0.43860167] b_f = [ 1.]
Epoch 9/300
1s - loss: 737.3571 - val_loss: 2004.6671
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 724.9580 - val_loss: 2027.8430
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 714.4036 - val_loss: 2073.6310
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 707.6137 - val_loss: 2005.5651
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 702.7144 - val_loss: 2051.6945
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 694.7382 - val_loss: 2097.2159
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 686.5096 - val_loss: 1951.9124
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 674.6799 - val_loss: 2062.2389
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 656.2190 - val_loss: 2193.3399
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 638.1164 - val_loss: 2170.8421
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 618.0474 - val_loss: 2107.2022
Epoch 00018: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shanghai1
Train on 5589 samples, validate on 1746 samples
Before training:
           shanghai1 3539.4690      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.11597 nan 3.11597
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shanghai1 8910.3603      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.34373 nan 5.34373
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2453.8954 - val_loss: 3505.5181
Epoch 00000: val_loss improved from inf to 3505.51814, saving model to shanghai1_weights.hdf5
           shanghai1 1457.6643      0.08  0.51  0.07      0.09  0.48  0.08      0.08  0.47  0.07
           shanghai1 3505.5181      0.45  0.32  0.37      0.43  0.29  0.37      0.40  0.25  0.35
forget mean min: 0.843127 0.295413
abs_mean, abs_mean+, abs_mean-: 5.96955 1.91877 10.8974
U_c = [[-0.13122736]] U_f = [[ 0.]] b_c = [ 0.09449974] b_f = [ 1.]
Epoch 2/300
1s - loss: 1157.5822 - val_loss: 2211.2414
Epoch 00001: val_loss improved from 3505.51814 to 2211.24144, saving model to shanghai1_weights.hdf5
           shanghai1  915.3947      0.23  0.35  0.20      0.24  0.33  0.21      0.23  0.31  0.20
           shanghai1 2211.2414      0.83  0.34  0.59      0.82  0.32  0.60      0.81  0.27  0.63
forget mean min: 0.90692 0.275258
abs_mean, abs_mean+, abs_mean-: 5.51735 3.23134 10.4637
U_c = [[-0.14256203]] U_f = [[ 0.]] b_c = [ 0.1733494] b_f = [ 1.]
Epoch 3/300
1s - loss: 838.4374 - val_loss: 2098.0387
Epoch 00002: val_loss improved from 2211.24144 to 2098.03871, saving model to shanghai1_weights.hdf5
           shanghai1  792.3238      0.52  0.39  0.39      0.55  0.37  0.42      0.57  0.35  0.43
           shanghai1 2098.0387      0.76  0.29  0.58      0.75  0.27  0.59      0.74  0.24  0.60
forget mean min: 0.920433 0.485029
abs_mean, abs_mean+, abs_mean-: 4.7919 3.4976 6.62521
U_c = [[-0.07999463]] U_f = [[ 0.]] b_c = [ 0.24284504] b_f = [ 1.]
Epoch 4/300
1s - loss: 779.7352 - val_loss: 2130.1641
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 765.4359 - val_loss: 2025.2201
Epoch 00004: val_loss improved from 2098.03871 to 2025.22006, saving model to shanghai1_weights.hdf5
           shanghai1  755.7748      0.51  0.33  0.41      0.53  0.30  0.43      0.57  0.25  0.47
           shanghai1 2025.2201      0.71  0.28  0.56      0.70  0.26  0.56      0.69  0.23  0.57
forget mean min: 0.906214 0.462399
abs_mean, abs_mean+, abs_mean-: 5.42825 4.33222 6.68735
U_c = [[-0.0722093]] U_f = [[ 0.]] b_c = [ 0.33418167] b_f = [ 1.]
Epoch 6/300
1s - loss: 759.2975 - val_loss: 2022.8792
Epoch 00005: val_loss improved from 2025.22006 to 2022.87920, saving model to shanghai1_weights.hdf5
           shanghai1  748.2018      0.52  0.34  0.41      0.55  0.30  0.45      0.58  0.25  0.49
           shanghai1 2022.8792      0.70  0.27  0.56      0.69  0.26  0.56      0.67  0.23  0.56
forget mean min: 0.900858 0.44587
abs_mean, abs_mean+, abs_mean-: 5.74748 4.63019 6.98366
U_c = [[-0.07652251]] U_f = [[ 0.]] b_c = [ 0.36863494] b_f = [ 1.]
Epoch 7/300
1s - loss: 751.8662 - val_loss: 1935.3271
Epoch 00006: val_loss improved from 2022.87920 to 1935.32706, saving model to shanghai1_weights.hdf5
           shanghai1  746.0661      0.53  0.36  0.41      0.55  0.33  0.43      0.59  0.28  0.48
           shanghai1 1935.3271      0.74  0.29  0.57      0.73  0.28  0.57      0.72  0.24  0.58
forget mean min: 0.902169 0.442039
abs_mean, abs_mean+, abs_mean-: 6.01578 5.07606 7.08911
U_c = [[-0.07727881]] U_f = [[ 0.]] b_c = [ 0.40195069] b_f = [ 1.]
Epoch 8/300
1s - loss: 746.7916 - val_loss: 2020.6778
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 739.8639 - val_loss: 2004.6351
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 729.2933 - val_loss: 2000.0751
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 719.0653 - val_loss: 1994.7835
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 710.6186 - val_loss: 1966.3688
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 701.7970 - val_loss: 2081.2498
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 694.4394 - val_loss: 2042.8670
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 684.8154 - val_loss: 2079.2275
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 671.1791 - val_loss: 2087.3742
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 651.5535 - val_loss: 2073.8650
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 629.7277 - val_loss: 2130.4010
Epoch 00017: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training shanghai2
Train on 5589 samples, validate on 1746 samples
Before training:
           shanghai2 3539.4690      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.11597 nan 3.11597
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           shanghai2 8910.3603      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.34373 nan 5.34373
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2433.9323 - val_loss: 3504.0889
Epoch 00000: val_loss improved from inf to 3504.08887, saving model to shanghai2_weights.hdf5
           shanghai2 1454.9712      0.08  0.51  0.07      0.09  0.48  0.08      0.08  0.47  0.07
           shanghai2 3504.0888      0.45  0.32  0.38      0.44  0.29  0.37      0.40  0.25  0.36
forget mean min: 0.842267 0.292415
abs_mean, abs_mean+, abs_mean-: 6.01883 1.93742 10.996
U_c = [[-0.13240065]] U_f = [[ 0.]] b_c = [ 0.09440024] b_f = [ 1.]
Epoch 2/300
1s - loss: 1156.6670 - val_loss: 2198.6817
Epoch 00001: val_loss improved from 3504.08887 to 2198.68174, saving model to shanghai2_weights.hdf5
           shanghai2  913.9510      0.23  0.35  0.20      0.23  0.33  0.20      0.22  0.32  0.20
           shanghai2 2198.6817      0.82  0.34  0.58      0.82  0.32  0.59      0.81  0.26  0.63
forget mean min: 0.908778 0.271827
abs_mean, abs_mean+, abs_mean-: 5.47321 3.23026 10.2391
U_c = [[-0.13839824]] U_f = [[ 0.]] b_c = [ 0.17330152] b_f = [ 1.]
Epoch 3/300
1s - loss: 840.1264 - val_loss: 2107.0357
Epoch 00002: val_loss improved from 2198.68174 to 2107.03566, saving model to shanghai2_weights.hdf5
           shanghai2  790.9730      0.43  0.34  0.35      0.46  0.32  0.38      0.50  0.27  0.42
           shanghai2 2107.0356      0.71  0.28  0.56      0.71  0.26  0.57      0.69  0.22  0.58
forget mean min: 0.918867 0.493522
abs_mean, abs_mean+, abs_mean-: 4.64397 3.38916 6.19665
U_c = [[-0.08009145]] U_f = [[ 0.]] b_c = [ 0.24291553] b_f = [ 1.]
Epoch 4/300
2s - loss: 781.2979 - val_loss: 2142.5066
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 765.9338 - val_loss: 2083.5040
Epoch 00004: val_loss improved from 2107.03566 to 2083.50401, saving model to shanghai2_weights.hdf5
           shanghai2  765.5029      0.41  0.28  0.35      0.44  0.23  0.38      0.45  0.18  0.41
           shanghai2 2083.5040      0.67  0.26  0.54      0.67  0.23  0.56      0.66  0.20  0.57
forget mean min: 0.903689 0.47576
abs_mean, abs_mean+, abs_mean-: 5.25602 4.13463 6.43174
U_c = [[-0.0737646]] U_f = [[ 0.]] b_c = [ 0.33764952] b_f = [ 1.]
Epoch 6/300
1s - loss: 756.0657 - val_loss: 2030.1196
Epoch 00005: val_loss improved from 2083.50401 to 2030.11958, saving model to shanghai2_weights.hdf5
           shanghai2  755.8391      0.56  0.39  0.41      0.59  0.37  0.44      0.61  0.35  0.46
           shanghai2 2030.1196      0.72  0.28  0.57      0.71  0.27  0.56      0.70  0.24  0.57
forget mean min: 0.905522 0.448883
abs_mean, abs_mean+, abs_mean-: 5.67494 4.66936 6.81549
U_c = [[-0.0764267]] U_f = [[ 0.]] b_c = [ 0.37469789] b_f = [ 1.]
Epoch 7/300
1s - loss: 750.5004 - val_loss: 2100.4789
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 744.2584 - val_loss: 1961.5370
Epoch 00007: val_loss improved from 2030.11958 to 1961.53701, saving model to shanghai2_weights.hdf5
           shanghai2  736.8150      0.50  0.32  0.41      0.53  0.27  0.44      0.56  0.22  0.49
           shanghai2 1961.5370      0.72  0.28  0.56      0.71  0.27  0.56      0.69  0.24  0.57
forget mean min: 0.898919 0.447381
abs_mean, abs_mean+, abs_mean-: 6.10504 5.11727 7.19509
U_c = [[-0.07992202]] U_f = [[ 0.]] b_c = [ 0.43753377] b_f = [ 1.]
Epoch 9/300
1s - loss: 734.7975 - val_loss: 1997.9959
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 721.3788 - val_loss: 2012.3272
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 711.0809 - val_loss: 1985.7459
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 704.3815 - val_loss: 1991.1867
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 699.3520 - val_loss: 2013.7323
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 693.6707 - val_loss: 2005.8492
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 686.5400 - val_loss: 2038.6598
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 679.9307 - val_loss: 1967.1815
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 670.9058 - val_loss: 2087.7608
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 658.5932 - val_loss: 2064.5727
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 642.6954 - val_loss: 2071.5004
Epoch 00018: val_loss did not improve
X_train[0].shape = (6831, 40, 23)

training hangzhou0
Train on 6831 samples, validate on 2134 samples
Before training:
           hangzhou0 3359.0189      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.18611 nan 3.18611
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           hangzhou010315.4272      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.76607 nan 5.76607
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2157.2409 - val_loss: 3929.6103
Epoch 00000: val_loss improved from inf to 3929.61028, saving model to hangzhou0_weights.hdf5
           hangzhou0 1293.2097      0.08  0.35  0.07      0.09  0.32  0.08      0.09  0.24  0.08
           hangzhou0 3929.6103      0.57  0.17  0.51      0.56  0.12  0.52      0.53  0.10  0.50
forget mean min: 0.837678 0.286475
abs_mean, abs_mean+, abs_mean-: 6.60419 2.10988 11.5009
U_c = [[-0.15055987]] U_f = [[ 0.]] b_c = [ 0.10859113] b_f = [ 1.]
Epoch 2/300
1s - loss: 964.8621 - val_loss: 2525.7554
Epoch 00001: val_loss improved from 3929.61028 to 2525.75543, saving model to hangzhou0_weights.hdf5
           hangzhou0  819.7666      0.19  0.30  0.17      0.21  0.27  0.18      0.21  0.22  0.19
           hangzhou0 2525.7554      0.83  0.22  0.67      0.84  0.18  0.71      0.85  0.14  0.74
forget mean min: 0.933499 0.407252
abs_mean, abs_mean+, abs_mean-: 4.82544 3.00791 8.00387
U_c = [[-0.141148]] U_f = [[ 0.]] b_c = [ 0.19162163] b_f = [ 1.]
Epoch 3/300
2s - loss: 767.0028 - val_loss: 2396.7262
Epoch 00002: val_loss improved from 2525.75543 to 2396.72622, saving model to hangzhou0_weights.hdf5
           hangzhou0  745.2415      0.42  0.38  0.33      0.46  0.35  0.37      0.48  0.29  0.40
           hangzhou0 2396.7262      0.89  0.25  0.68      0.90  0.22  0.72      0.92  0.19  0.76
forget mean min: 0.961603 0.641429
abs_mean, abs_mean+, abs_mean-: 3.47702 2.84602 4.517
U_c = [[-0.07936877]] U_f = [[ 0.]] b_c = [ 0.21564193] b_f = [ 1.]
Epoch 4/300
2s - loss: 736.6558 - val_loss: 2539.4926
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 728.2598 - val_loss: 2581.0894
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 721.0283 - val_loss: 2573.8007
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 713.8796 - val_loss: 2820.4021
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 706.2117 - val_loss: 2843.2595
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 699.8644 - val_loss: 2885.9534
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 692.6659 - val_loss: 2903.7208
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 684.3059 - val_loss: 2795.5309
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 677.1841 - val_loss: 2900.1515
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 666.5060 - val_loss: 3019.9707
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 659.6082 - val_loss: 2835.1172
Epoch 00013: val_loss did not improve
X_train[0].shape = (6831, 40, 23)

training hangzhou1
Train on 6831 samples, validate on 2134 samples
Before training:
           hangzhou1 3359.0189      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.18611 nan 3.18611
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           hangzhou110315.4272      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.76607 nan 5.76607
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 2150.6744 - val_loss: 3735.0547
Epoch 00000: val_loss improved from inf to 3735.05474, saving model to hangzhou1_weights.hdf5
           hangzhou1 1242.3098      0.08  0.35  0.07      0.09  0.33  0.08      0.09  0.25  0.08
           hangzhou1 3735.0547      0.60  0.17  0.53      0.59  0.13  0.54      0.56  0.10  0.52
forget mean min: 0.845305 0.273865
abs_mean, abs_mean+, abs_mean-: 6.38322 2.12093 11.6286
U_c = [[-0.15085547]] U_f = [[ 0.]] b_c = [ 0.10934857] b_f = [ 1.]
Epoch 2/300
2s - loss: 948.9871 - val_loss: 2440.7314
Epoch 00001: val_loss improved from 3735.05474 to 2440.73144, saving model to hangzhou1_weights.hdf5
           hangzhou1  820.4115      0.22  0.30  0.20      0.23  0.28  0.21      0.25  0.21  0.22
           hangzhou1 2440.7315      0.84  0.22  0.68      0.85  0.18  0.71      0.87  0.14  0.76
forget mean min: 0.932621 0.438976
abs_mean, abs_mean+, abs_mean-: 4.67183 2.97276 7.69681
U_c = [[-0.13238379]] U_f = [[ 0.]] b_c = [ 0.19210093] b_f = [ 1.]
Epoch 3/300
2s - loss: 768.0955 - val_loss: 2387.6688
Epoch 00002: val_loss improved from 2440.73144 to 2387.66883, saving model to hangzhou1_weights.hdf5
           hangzhou1  742.4160      0.39  0.36  0.32      0.43  0.32  0.36      0.45  0.26  0.38
           hangzhou1 2387.6688      0.85  0.24  0.67      0.86  0.21  0.70      0.88  0.18  0.74
forget mean min: 0.957013 0.645149
abs_mean, abs_mean+, abs_mean-: 3.38436 2.70652 4.36751
U_c = [[-0.0762668]] U_f = [[ 0.]] b_c = [ 0.21540923] b_f = [ 1.]
Epoch 4/300
2s - loss: 738.4829 - val_loss: 2493.1994
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 730.8943 - val_loss: 2538.0457
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 723.9643 - val_loss: 2663.7191
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 717.4980 - val_loss: 2708.6260
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 708.6568 - val_loss: 2756.2287
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 700.9447 - val_loss: 2794.9891
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 694.2437 - val_loss: 2804.1249
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 684.4622 - val_loss: 2935.3195
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 674.3303 - val_loss: 2869.5561
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 664.3016 - val_loss: 2939.4063
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 652.0090 - val_loss: 3025.1123
Epoch 00013: val_loss did not improve
X_train[0].shape = (6831, 40, 23)

training hangzhou2
Train on 6831 samples, validate on 2134 samples
Before training:
           hangzhou2 3359.0189      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.18611 nan 3.18611
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           hangzhou210315.4272      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.76607 nan 5.76607
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 2147.2220 - val_loss: 3581.3711
Epoch 00000: val_loss improved from inf to 3581.37108, saving model to hangzhou2_weights.hdf5
           hangzhou2 1176.2220      0.09  0.30  0.08      0.09  0.29  0.08      0.09  0.23  0.08
           hangzhou2 3581.3711      0.62  0.17  0.55      0.61  0.13  0.56      0.59  0.11  0.55
forget mean min: 0.854085 0.266053
abs_mean, abs_mean+, abs_mean-: 6.00505 2.06396 11.2483
U_c = [[-0.14930381]] U_f = [[ 0.]] b_c = [ 0.10899646] b_f = [ 1.]
Epoch 2/300
2s - loss: 925.9937 - val_loss: 2393.6935
Epoch 00001: val_loss improved from 3581.37108 to 2393.69353, saving model to hangzhou2_weights.hdf5
           hangzhou2  823.5793      0.25  0.33  0.22      0.27  0.31  0.23      0.28  0.24  0.25
           hangzhou2 2393.6935      0.85  0.23  0.68      0.86  0.19  0.72      0.88  0.15  0.76
forget mean min: 0.928995 0.4294
abs_mean, abs_mean+, abs_mean-: 4.45443 2.89898 7.28674
U_c = [[-0.11988696]] U_f = [[ 0.]] b_c = [ 0.18942098] b_f = [ 1.]
Epoch 3/300
2s - loss: 766.9136 - val_loss: 2447.6882
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 736.9148 - val_loss: 2507.8811
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 728.1513 - val_loss: 2704.0564
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 720.2063 - val_loss: 2685.5531
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 711.0902 - val_loss: 2712.6593
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 702.3435 - val_loss: 2804.8749
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 693.4349 - val_loss: 2864.8131
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 684.3300 - val_loss: 2907.0029
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 677.4232 - val_loss: 2862.4807
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 669.9689 - val_loss: 2832.1169
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 663.4213 - val_loss: 2839.3169
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training hefei0
Train on 5589 samples, validate on 1746 samples
Before training:
              hefei0 6673.9235      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.09241 nan 4.09241
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              hefei013881.0850      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.14108 nan 7.14109
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4936.0821 - val_loss: 5830.6875
Epoch 00000: val_loss improved from inf to 5830.68751, saving model to hefei0_weights.hdf5
              hefei0 3066.2262      0.20  0.32  0.18      0.21  0.26  0.20      0.20  0.20  0.19
              hefei0 5830.6875      0.63  0.17  0.56      0.63  0.10  0.59      0.61  0.07  0.58
forget mean min: 0.842817 0.250603
abs_mean, abs_mean+, abs_mean-: 7.70324 2.00164 13.5712
U_c = [[-0.1365189]] U_f = [[ 0.]] b_c = [ 0.09595048] b_f = [ 1.]
Epoch 2/300
1s - loss: 2395.4202 - val_loss: 4055.8566
Epoch 00001: val_loss improved from 5830.68751 to 4055.85658, saving model to hefei0_weights.hdf5
              hefei0 2097.9476      0.51  0.42  0.37      0.54  0.39  0.40      0.54  0.36  0.41
              hefei0 4055.8565      0.93  0.26  0.70      0.94  0.21  0.75      0.93  0.19  0.76
forget mean min: 0.941537 0.226303
abs_mean, abs_mean+, abs_mean-: 5.7108 3.28033 16.1886
U_c = [[-0.16975671]] U_f = [[ 0.]] b_c = [ 0.16989684] b_f = [ 1.]
Epoch 3/300
1s - loss: 1998.7296 - val_loss: 3625.1857
Epoch 00002: val_loss improved from 4055.85658 to 3625.18570, saving model to hefei0_weights.hdf5
              hefei0 1898.8549      0.64  0.45  0.42      0.67  0.44  0.44      0.68  0.40  0.47
              hefei0 3625.1857      0.95  0.23  0.74      0.95  0.19  0.78      0.94  0.16  0.80
forget mean min: 0.945327 0.341136
abs_mean, abs_mean+, abs_mean-: 6.25401 4.69153 9.86496
U_c = [[-0.16248539]] U_f = [[ 0.]] b_c = [ 0.24131347] b_f = [ 1.]
Epoch 4/300
1s - loss: 1871.6046 - val_loss: 3608.1898
Epoch 00003: val_loss improved from 3625.18570 to 3608.18977, saving model to hefei0_weights.hdf5
              hefei0 1860.5763      0.70  0.46  0.44      0.73  0.45  0.45      0.74  0.42  0.48
              hefei0 3608.1898      0.97  0.24  0.74      0.97  0.19  0.79      0.96  0.17  0.81
forget mean min: 0.955869 0.345542
abs_mean, abs_mean+, abs_mean-: 6.36631 5.23446 9.31059
U_c = [[-0.1440554]] U_f = [[ 0.]] b_c = [ 0.2822676] b_f = [ 1.]
Epoch 5/300
1s - loss: 1839.0952 - val_loss: 3682.2309
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1817.8039 - val_loss: 3791.8915
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1804.2292 - val_loss: 3879.9329
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1795.6068 - val_loss: 4039.8553
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1790.5387 - val_loss: 4021.3086
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1784.1321 - val_loss: 4104.6451
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1783.0552 - val_loss: 4235.2903
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1780.3162 - val_loss: 4097.1765
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1776.3542 - val_loss: 4210.2583
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1771.0921 - val_loss: 4182.4111
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1763.8374 - val_loss: 4182.6409
Epoch 00014: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training hefei1
Train on 5589 samples, validate on 1746 samples
Before training:
              hefei1 6673.9235      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.09241 nan 4.09241
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              hefei113881.0850      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.14108 nan 7.14109
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4913.5788 - val_loss: 5782.9285
Epoch 00000: val_loss improved from inf to 5782.92850, saving model to hefei1_weights.hdf5
              hefei1 3037.2926      0.20  0.32  0.18      0.22  0.26  0.20      0.20  0.20  0.19
              hefei1 5782.9285      0.64  0.16  0.57      0.64  0.10  0.60      0.61  0.07  0.59
forget mean min: 0.843174 0.250872
abs_mean, abs_mean+, abs_mean-: 7.61914 1.97864 13.3243
U_c = [[-0.13623486]] U_f = [[ 0.]] b_c = [ 0.09598861] b_f = [ 1.]
Epoch 2/300
1s - loss: 2388.3778 - val_loss: 4064.1058
Epoch 00001: val_loss improved from 5782.92850 to 4064.10580, saving model to hefei1_weights.hdf5
              hefei1 2098.9678      0.54  0.42  0.39      0.58  0.41  0.41      0.58  0.37  0.44
              hefei1 4064.1058      0.93  0.26  0.70      0.94  0.21  0.75      0.93  0.19  0.76
forget mean min: 0.94135 0.221387
abs_mean, abs_mean+, abs_mean-: 5.75815 3.33398 16.1639
U_c = [[-0.16970512]] U_f = [[ 0.]] b_c = [ 0.17124595] b_f = [ 1.]
Epoch 3/300
1s - loss: 1999.1069 - val_loss: 3611.6503
Epoch 00002: val_loss improved from 4064.10580 to 3611.65034, saving model to hefei1_weights.hdf5
              hefei1 1902.4811      0.64  0.45  0.42      0.68  0.44  0.44      0.69  0.41  0.46
              hefei1 3611.6504      0.96  0.24  0.74      0.95  0.20  0.77      0.95  0.17  0.80
forget mean min: 0.948676 0.333376
abs_mean, abs_mean+, abs_mean-: 6.15449 4.66928 9.87491
U_c = [[-0.16303495]] U_f = [[ 0.]] b_c = [ 0.23936346] b_f = [ 1.]
Epoch 4/300
1s - loss: 1875.3597 - val_loss: 3611.7616
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1839.9619 - val_loss: 3658.7078
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1818.1830 - val_loss: 3757.3005
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1804.3418 - val_loss: 3874.1493
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1795.4749 - val_loss: 4037.9536
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1791.5440 - val_loss: 4120.4055
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1786.7210 - val_loss: 4080.8066
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1781.7544 - val_loss: 4076.9255
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1780.3064 - val_loss: 4102.1453
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1777.4126 - val_loss: 4174.1519
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1776.3437 - val_loss: 4210.2750
Epoch 00013: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training hefei2
Train on 5589 samples, validate on 1746 samples
Before training:
              hefei2 6673.9235      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.09241 nan 4.09241
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              hefei213881.0850      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.14108 nan 7.14109
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4935.0413 - val_loss: 5778.2890
Epoch 00000: val_loss improved from inf to 5778.28895, saving model to hefei2_weights.hdf5
              hefei2 3049.6712      0.20  0.32  0.18      0.21  0.25  0.20      0.20  0.19  0.19
              hefei2 5778.2890      0.64  0.16  0.57      0.64  0.09  0.60      0.62  0.07  0.59
forget mean min: 0.843004 0.25427
abs_mean, abs_mean+, abs_mean-: 7.58378 1.99192 13.1891
U_c = [[-0.13640869]] U_f = [[ 0.]] b_c = [ 0.09583981] b_f = [ 1.]
Epoch 2/300
1s - loss: 2390.5203 - val_loss: 4052.7462
Epoch 00001: val_loss improved from 5778.28895 to 4052.74624, saving model to hefei2_weights.hdf5
              hefei2 2095.5187      0.52  0.43  0.38      0.55  0.40  0.40      0.56  0.37  0.42
              hefei2 4052.7463      0.94  0.27  0.70      0.94  0.22  0.74      0.93  0.19  0.76
forget mean min: 0.944359 0.222306
abs_mean, abs_mean+, abs_mean-: 5.62753 3.33209 16.506
U_c = [[-0.16356266]] U_f = [[ 0.]] b_c = [ 0.17149901] b_f = [ 1.]
Epoch 3/300
1s - loss: 2002.3860 - val_loss: 3615.5974
Epoch 00002: val_loss improved from 4052.74624 to 3615.59736, saving model to hefei2_weights.hdf5
              hefei2 1906.2336      0.62  0.45  0.41      0.65  0.44  0.43      0.66  0.41  0.46
              hefei2 3615.5973      0.96  0.24  0.74      0.96  0.20  0.77      0.95  0.17  0.80
forget mean min: 0.951056 0.331726
abs_mean, abs_mean+, abs_mean-: 6.01726 4.70099 9.0669
U_c = [[-0.16560988]] U_f = [[ 0.]] b_c = [ 0.23979864] b_f = [ 1.]
Epoch 4/300
1s - loss: 1873.7641 - val_loss: 3660.4258
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1840.1615 - val_loss: 3692.2211
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1817.8942 - val_loss: 3814.4244
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1804.2837 - val_loss: 3821.2621
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1795.0726 - val_loss: 4007.6797
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1788.4132 - val_loss: 4103.2383
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1780.9335 - val_loss: 4184.9463
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1782.0845 - val_loss: 4139.6629
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1775.5491 - val_loss: 4112.4334
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1768.1398 - val_loss: 4048.0471
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1766.1314 - val_loss: 4176.8825
Epoch 00013: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training wuhan0
Train on 6210 samples, validate on 1940 samples
Before training:
              wuhan0 5738.0322      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.97979 nan 3.97979
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              wuhan017167.7161      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.32485 nan 7.32485
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4148.3752 - val_loss: 10502.8964
Epoch 00000: val_loss improved from inf to 10502.89644, saving model to wuhan0_weights.hdf5
              wuhan0 2672.6695      0.20  0.44  0.17      0.22  0.37  0.19      0.21  0.32  0.19
              wuhan010502.8964      0.43  0.08  0.41      0.42  0.05  0.41      0.39  0.03  0.39
forget mean min: 0.788909 0.246444
abs_mean, abs_mean+, abs_mean-: 9.2686 2.0008 14.1684
U_c = [[-0.1419514]] U_f = [[ 0.]] b_c = [ 0.10165084] b_f = [ 1.]
Epoch 2/300
1s - loss: 1709.2168 - val_loss: 5654.8012
Epoch 00001: val_loss improved from 10502.89644 to 5654.80116, saving model to wuhan0_weights.hdf5
              wuhan0 1484.5998      0.71  0.46  0.44      0.74  0.43  0.47      0.74  0.42  0.48
              wuhan0 5654.8012      0.86  0.13  0.76      0.86  0.08  0.80      0.86  0.05  0.82
forget mean min: 0.962555 0.253404
abs_mean, abs_mean+, abs_mean-: 4.96613 3.18679 11.7828
U_c = [[-0.09369592]] U_f = [[ 0.]] b_c = [ 0.17891802] b_f = [ 1.]
Epoch 3/300
1s - loss: 1430.1318 - val_loss: 5879.9850
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1392.9343 - val_loss: 5394.1509
Epoch 00003: val_loss improved from 5654.80116 to 5394.15090, saving model to wuhan0_weights.hdf5
              wuhan0 1413.0703      0.56  0.44  0.39      0.58  0.41  0.41      0.57  0.40  0.42
              wuhan0 5394.1509      0.86  0.11  0.78      0.86  0.06  0.82      0.86  0.04  0.83
forget mean min: 0.95687 0.344125
abs_mean, abs_mean+, abs_mean-: 4.30851 3.04236 6.3616
U_c = [[-0.05107993]] U_f = [[ 0.]] b_c = [ 0.23688769] b_f = [ 1.]
Epoch 5/300
1s - loss: 1380.4225 - val_loss: 5896.5780
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1372.5071 - val_loss: 5743.9739
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1366.5471 - val_loss: 5083.3404
Epoch 00006: val_loss improved from 5394.15090 to 5083.34038, saving model to wuhan0_weights.hdf5
              wuhan0 1425.4888      0.69  0.49  0.41      0.71  0.48  0.43      0.69  0.48  0.42
              wuhan0 5083.3404      0.91  0.12  0.81      0.90  0.08  0.84      0.90  0.05  0.86
forget mean min: 0.966478 0.382976
abs_mean, abs_mean+, abs_mean-: 4.63612 3.4294 7.36854
U_c = [[-0.03676471]] U_f = [[ 0.]] b_c = [ 0.27508292] b_f = [ 1.]
Epoch 8/300
1s - loss: 1355.9191 - val_loss: 6475.2270
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1338.0190 - val_loss: 6578.2190
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1309.3228 - val_loss: 6338.4333
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1260.4747 - val_loss: 6616.2589
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1225.4262 - val_loss: 6274.5307
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1183.5448 - val_loss: 7623.5937
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1151.3836 - val_loss: 7664.8739
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1113.7328 - val_loss: 7708.6634
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1078.9681 - val_loss: 8071.9178
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1053.8196 - val_loss: 8589.9037
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1020.4993 - val_loss: 7979.5658
Epoch 00017: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training wuhan1
Train on 6210 samples, validate on 1940 samples
Before training:
              wuhan1 5738.0322      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.97979 nan 3.97979
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              wuhan117167.7161      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.32485 nan 7.32485
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4130.4705 - val_loss: 10443.8635
Epoch 00000: val_loss improved from inf to 10443.86347, saving model to wuhan1_weights.hdf5
              wuhan1 2628.6092      0.19  0.45  0.16      0.21  0.38  0.18      0.20  0.34  0.18
              wuhan110443.8636      0.43  0.08  0.42      0.42  0.05  0.41      0.40  0.03  0.39
forget mean min: 0.792693 0.251181
abs_mean, abs_mean+, abs_mean-: 9.17597 1.98995 14.0113
U_c = [[-0.14152108]] U_f = [[ 0.]] b_c = [ 0.10178109] b_f = [ 1.]
Epoch 2/300
1s - loss: 1731.3653 - val_loss: 5767.8596
Epoch 00001: val_loss improved from 10443.86347 to 5767.85955, saving model to wuhan1_weights.hdf5
              wuhan1 1493.5443      0.59  0.44  0.41      0.62  0.40  0.44      0.61  0.39  0.44
              wuhan1 5767.8596      0.84  0.11  0.76      0.84  0.06  0.79      0.83  0.04  0.80
forget mean min: 0.95326 0.26608
abs_mean, abs_mean+, abs_mean-: 5.40611 3.18875 11.4134
U_c = [[-0.09548576]] U_f = [[ 0.]] b_c = [ 0.17654438] b_f = [ 1.]
Epoch 3/300
1s - loss: 1430.5020 - val_loss: 5922.3069
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1390.0957 - val_loss: 5408.1105
Epoch 00003: val_loss improved from 5767.85955 to 5408.11047, saving model to wuhan1_weights.hdf5
              wuhan1 1405.3542      0.72  0.48  0.43      0.74  0.47  0.45      0.74  0.46  0.45
              wuhan1 5408.1105      0.87  0.11  0.78      0.87  0.07  0.81      0.86  0.05  0.83
forget mean min: 0.962514 0.330091
abs_mean, abs_mean+, abs_mean-: 4.31219 3.19677 6.76215
U_c = [[-0.05032012]] U_f = [[ 0.]] b_c = [ 0.23977938] b_f = [ 1.]
Epoch 5/300
1s - loss: 1376.5293 - val_loss: 5212.4241
Epoch 00004: val_loss improved from 5408.11047 to 5212.42408, saving model to wuhan1_weights.hdf5
              wuhan1 1469.7906      0.71  0.50  0.41      0.74  0.49  0.43      0.74  0.48  0.44
              wuhan1 5212.4241      0.91  0.12  0.81      0.91  0.08  0.84      0.91  0.05  0.86
forget mean min: 0.967636 0.344686
abs_mean, abs_mean+, abs_mean-: 4.44985 3.43058 6.64138
U_c = [[-0.04148889]] U_f = [[ 0.]] b_c = [ 0.25436601] b_f = [ 1.]
Epoch 6/300
1s - loss: 1370.8309 - val_loss: 5373.4796
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1357.4563 - val_loss: 5918.2784
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1336.0975 - val_loss: 6165.6186
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1306.0335 - val_loss: 6468.2270
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1265.9144 - val_loss: 6682.0303
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1223.5842 - val_loss: 6564.9803
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1187.1563 - val_loss: 7636.7652
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1148.8332 - val_loss: 7921.4151
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1109.7054 - val_loss: 8501.0870
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1081.0875 - val_loss: 8175.1922
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1054.4656 - val_loss: 8086.3831
Epoch 00015: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training wuhan2
Train on 6210 samples, validate on 1940 samples
Before training:
              wuhan2 5738.0322      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.97979 nan 3.97979
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
              wuhan217167.7161      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 7.32485 nan 7.32485
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 4156.7637 - val_loss: 10587.7062
Epoch 00000: val_loss improved from inf to 10587.70616, saving model to wuhan2_weights.hdf5
              wuhan2 2800.3600      0.19  0.45  0.16      0.21  0.38  0.18      0.20  0.35  0.18
              wuhan210587.7062      0.44  0.08  0.42      0.42  0.05  0.41      0.40  0.03  0.40
forget mean min: 0.779525 0.265481
abs_mean, abs_mean+, abs_mean-: 9.34367 1.99169 14.429
U_c = [[-0.14084992]] U_f = [[ 0.]] b_c = [ 0.10115661] b_f = [ 1.]
Epoch 2/300
1s - loss: 1776.2858 - val_loss: 6008.1498
Epoch 00001: val_loss improved from 10587.70616 to 6008.14977, saving model to wuhan2_weights.hdf5
              wuhan2 1489.3330      0.72  0.46  0.44      0.75  0.44  0.47      0.75  0.42  0.49
              wuhan2 6008.1498      0.82  0.12  0.74      0.83  0.07  0.78      0.82  0.05  0.79
forget mean min: 0.953722 0.245898
abs_mean, abs_mean+, abs_mean-: 5.49432 3.41469 11.7681
U_c = [[-0.09848006]] U_f = [[ 0.]] b_c = [ 0.1830475] b_f = [ 1.]
Epoch 3/300
1s - loss: 1430.6540 - val_loss: 5689.9052
Epoch 00002: val_loss improved from 6008.14977 to 5689.90523, saving model to wuhan2_weights.hdf5
              wuhan2 1432.8876      0.55  0.42  0.39      0.58  0.39  0.43      0.58  0.37  0.43
              wuhan2 5689.9052      0.84  0.10  0.77      0.84  0.06  0.80      0.83  0.03  0.81
forget mean min: 0.950927 0.338215
abs_mean, abs_mean+, abs_mean-: 4.36286 2.94047 6.53536
U_c = [[-0.05852862]] U_f = [[ 0.]] b_c = [ 0.22015925] b_f = [ 1.]
Epoch 4/300
1s - loss: 1392.0157 - val_loss: 5588.4817
Epoch 00003: val_loss improved from 5689.90523 to 5588.48171, saving model to wuhan2_weights.hdf5
              wuhan2 1378.0174      0.66  0.45  0.43      0.69  0.43  0.45      0.68  0.43  0.45
              wuhan2 5588.4818      0.85  0.10  0.77      0.85  0.06  0.81      0.84  0.03  0.82
forget mean min: 0.956499 0.338198
abs_mean, abs_mean+, abs_mean-: 4.25613 3.01431 6.39959
U_c = [[-0.04494981]] U_f = [[ 0.]] b_c = [ 0.23891041] b_f = [ 1.]
Epoch 5/300
1s - loss: 1380.2632 - val_loss: 5247.2138
Epoch 00004: val_loss improved from 5588.48171 to 5247.21379, saving model to wuhan2_weights.hdf5
              wuhan2 1403.0524      0.63  0.46  0.41      0.66  0.44  0.44      0.66  0.43  0.44
              wuhan2 5247.2138      0.90  0.12  0.80      0.90  0.08  0.83      0.90  0.05  0.85
forget mean min: 0.961829 0.350507
abs_mean, abs_mean+, abs_mean-: 4.39873 3.22988 6.50755
U_c = [[-0.04554087]] U_f = [[ 0.]] b_c = [ 0.25595471] b_f = [ 1.]
Epoch 6/300
1s - loss: 1371.0675 - val_loss: 5940.0013
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1367.9539 - val_loss: 5652.3118
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1359.3280 - val_loss: 6074.2346
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1347.3866 - val_loss: 5714.1941
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1321.9436 - val_loss: 5994.5408
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1283.7793 - val_loss: 6229.1173
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1243.5020 - val_loss: 6389.3368
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1209.2729 - val_loss: 6525.9642
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1182.4400 - val_loss: 7907.1812
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1150.4088 - val_loss: 7019.4179
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1120.9413 - val_loss: 8353.2307
Epoch 00015: val_loss did not improve
X_train[0].shape = (10557, 40, 23)

training chongqing0
Train on 10557 samples, validate on 3298 samples
Before training:
          chongqing0 2170.0847      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.78466 nan 2.78466
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          chongqing0 6911.4035      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.5066 nan 4.5066
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 1107.9618 - val_loss: 1325.4305
Epoch 00000: val_loss improved from inf to 1325.43051, saving model to chongqing0_weights.hdf5
          chongqing0  505.0407      0.06  0.38  0.05      0.07  0.42  0.06      0.08  0.47  0.07
          chongqing0 1325.4305      0.62  0.30  0.49      0.62  0.29  0.50      0.64  0.29  0.51
forget mean min: 0.982253 0.578673
abs_mean, abs_mean+, abs_mean-: 2.85328 2.50973 4.63111
U_c = [[-0.14545768]] U_f = [[ 0.]] b_c = [ 0.15347131] b_f = [ 1.]
Epoch 2/300
2s - loss: 376.7261 - val_loss: 1271.6548
Epoch 00001: val_loss improved from 1325.43051 to 1271.65481, saving model to chongqing0_weights.hdf5
          chongqing0  349.1345      0.14  0.37  0.12      0.17  0.36  0.14      0.19  0.35  0.16
          chongqing0 1271.6548      0.78  0.36  0.55      0.80  0.35  0.56      0.80  0.34  0.57
forget mean min: 0.992232 0.849085
abs_mean, abs_mean+, abs_mean-: 1.99547 1.80423 3.5819
U_c = [[-0.07018565]] U_f = [[ 0.]] b_c = [ 0.12125797] b_f = [ 1.]
Epoch 3/300
2s - loss: 339.8723 - val_loss: 1221.9008
Epoch 00002: val_loss improved from 1271.65481 to 1221.90077, saving model to chongqing0_weights.hdf5
          chongqing0  335.3959      0.13  0.37  0.11      0.15  0.36  0.13      0.18  0.35  0.14
          chongqing0 1221.9008      0.76  0.33  0.56      0.78  0.32  0.57      0.78  0.32  0.58
forget mean min: 0.992006 0.785487
abs_mean, abs_mean+, abs_mean-: 1.92483 1.69704 3.73265
U_c = [[-0.0696326]] U_f = [[ 0.]] b_c = [ 0.11459387] b_f = [ 1.]
Epoch 4/300
2s - loss: 333.7052 - val_loss: 1267.8670
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 329.5945 - val_loss: 1262.8521
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 328.1407 - val_loss: 1266.2321
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 328.2321 - val_loss: 1269.9066
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 328.1753 - val_loss: 1220.8542
Epoch 00007: val_loss improved from 1221.90077 to 1220.85416, saving model to chongqing0_weights.hdf5
          chongqing0  326.0431      0.14  0.37  0.12      0.18  0.35  0.15      0.20  0.35  0.16
          chongqing0 1220.8541      0.77  0.34  0.55      0.78  0.33  0.57      0.79  0.32  0.58
forget mean min: 0.991976 0.548306
abs_mean, abs_mean+, abs_mean-: 1.97533 1.5874 7.87445
U_c = [[-0.06370002]] U_f = [[ 0.]] b_c = [ 0.11742537] b_f = [ 1.]
Epoch 9/300
2s - loss: 327.9485 - val_loss: 1201.4207
Epoch 00008: val_loss improved from 1220.85416 to 1201.42072, saving model to chongqing0_weights.hdf5
          chongqing0  328.3432      0.14  0.37  0.12      0.17  0.34  0.14      0.19  0.35  0.16
          chongqing0 1201.4207      0.76  0.33  0.55      0.77  0.32  0.57      0.78  0.31  0.58
forget mean min: 0.990256 0.496366
abs_mean, abs_mean+, abs_mean-: 2.02022 1.57622 7.86297
U_c = [[-0.06488934]] U_f = [[ 0.]] b_c = [ 0.11809569] b_f = [ 1.]
Epoch 10/300
2s - loss: 328.3566 - val_loss: 1249.3607
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 327.5458 - val_loss: 1290.8890
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 327.8212 - val_loss: 1231.0365
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 327.8194 - val_loss: 1207.1050
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 327.6369 - val_loss: 1283.2412
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 327.5564 - val_loss: 1247.3185
Epoch 00014: val_loss did not improve
Epoch 16/300
2s - loss: 326.6833 - val_loss: 1247.1576
Epoch 00015: val_loss did not improve
Epoch 17/300
2s - loss: 325.1541 - val_loss: 1288.0096
Epoch 00016: val_loss did not improve
Epoch 18/300
2s - loss: 322.9237 - val_loss: 1285.6779
Epoch 00017: val_loss did not improve
Epoch 19/300
2s - loss: 320.1465 - val_loss: 1280.0665
Epoch 00018: val_loss did not improve
Epoch 20/300
2s - loss: 317.7224 - val_loss: 1221.4598
Epoch 00019: val_loss did not improve
X_train[0].shape = (10557, 40, 23)

training chongqing1
Train on 10557 samples, validate on 3298 samples
Before training:
          chongqing1 2170.0847      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.78466 nan 2.78466
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          chongqing1 6911.4035      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.5066 nan 4.5066
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 1101.4303 - val_loss: 1306.7586
Epoch 00000: val_loss improved from inf to 1306.75855, saving model to chongqing1_weights.hdf5
          chongqing1  501.8544      0.06  0.35  0.06      0.08  0.36  0.07      0.08  0.42  0.08
          chongqing1 1306.7585      0.63  0.30  0.50      0.64  0.29  0.51      0.65  0.28  0.53
forget mean min: 0.982224 0.579733
abs_mean, abs_mean+, abs_mean-: 2.92186 2.57268 4.74167
U_c = [[-0.14249603]] U_f = [[ 0.]] b_c = [ 0.1531049] b_f = [ 1.]
Epoch 2/300
2s - loss: 376.5801 - val_loss: 1154.6111
Epoch 00001: val_loss improved from 1306.75855 to 1154.61110, saving model to chongqing1_weights.hdf5
          chongqing1  343.9329      0.12  0.37  0.11      0.15  0.38  0.13      0.17  0.37  0.14
          chongqing1 1154.6111      0.80  0.33  0.58      0.81  0.32  0.59      0.82  0.31  0.60
forget mean min: 0.986745 0.825197
abs_mean, abs_mean+, abs_mean-: 2.20422 1.94856 3.42779
U_c = [[-0.0691612]] U_f = [[ 0.]] b_c = [ 0.12947267] b_f = [ 1.]
Epoch 3/300
2s - loss: 342.3334 - val_loss: 1178.7655
Epoch 00002: val_loss did not improve
Epoch 4/300
2s - loss: 340.7347 - val_loss: 1144.1849
Epoch 00003: val_loss improved from 1154.61110 to 1144.18490, saving model to chongqing1_weights.hdf5
          chongqing1  339.8713      0.13  0.37  0.11      0.15  0.36  0.13      0.17  0.37  0.14
          chongqing1 1144.1849      0.78  0.31  0.58      0.79  0.30  0.59      0.80  0.30  0.60
forget mean min: 0.989208 0.790097
abs_mean, abs_mean+, abs_mean-: 2.04071 1.72254 4.15352
U_c = [[-0.06687689]] U_f = [[ 0.]] b_c = [ 0.12322207] b_f = [ 1.]
Epoch 5/300
2s - loss: 334.5003 - val_loss: 1259.1091
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 328.6515 - val_loss: 1277.2264
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 328.3082 - val_loss: 1254.2004
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 327.8892 - val_loss: 1258.4544
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 328.2168 - val_loss: 1245.7599
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 327.9847 - val_loss: 1225.2441
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 328.0821 - val_loss: 1264.7965
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 327.3598 - val_loss: 1269.9648
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 327.3453 - val_loss: 1266.5227
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 327.4865 - val_loss: 1263.8757
Epoch 00013: val_loss did not improve
Epoch 15/300
2s - loss: 327.7523 - val_loss: 1275.7193
Epoch 00014: val_loss did not improve
X_train[0].shape = (10557, 40, 23)

training chongqing2
Train on 10557 samples, validate on 3298 samples
Before training:
          chongqing2 2170.0847      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.78466 nan 2.78466
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          chongqing2 6911.4035      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.5066 nan 4.5066
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
2s - loss: 1102.1600 - val_loss: 1298.3434
Epoch 00000: val_loss improved from inf to 1298.34339, saving model to chongqing2_weights.hdf5
          chongqing2  485.5925      0.06  0.35  0.06      0.08  0.36  0.07      0.08  0.42  0.08
          chongqing2 1298.3434      0.64  0.31  0.50      0.65  0.30  0.51      0.66  0.29  0.53
forget mean min: 0.983391 0.641267
abs_mean, abs_mean+, abs_mean-: 2.83394 2.51548 4.48563
U_c = [[-0.13823226]] U_f = [[ 0.]] b_c = [ 0.1523398] b_f = [ 1.]
Epoch 2/300
2s - loss: 366.7183 - val_loss: 1192.2979
Epoch 00001: val_loss improved from 1298.34339 to 1192.29789, saving model to chongqing2_weights.hdf5
          chongqing2  338.2738      0.12  0.36  0.11      0.15  0.35  0.13      0.17  0.36  0.14
          chongqing2 1192.2979      0.77  0.33  0.56      0.78  0.32  0.57      0.79  0.31  0.58
forget mean min: 0.990012 0.77442
abs_mean, abs_mean+, abs_mean-: 1.99572 1.73446 3.71383
U_c = [[-0.07021654]] U_f = [[ 0.]] b_c = [ 0.11192877] b_f = [ 1.]
Epoch 3/300
2s - loss: 337.5716 - val_loss: 1189.1129
Epoch 00002: val_loss improved from 1192.29789 to 1189.11293, saving model to chongqing2_weights.hdf5
          chongqing2  333.5610      0.14  0.38  0.12      0.17  0.36  0.14      0.20  0.37  0.16
          chongqing2 1189.1129      0.78  0.33  0.57      0.79  0.32  0.58      0.80  0.32  0.59
forget mean min: 0.990712 0.722324
abs_mean, abs_mean+, abs_mean-: 1.98899 1.64558 5.25909
U_c = [[-0.06401688]] U_f = [[ 0.]] b_c = [ 0.10738797] b_f = [ 1.]
Epoch 4/300
2s - loss: 332.9447 - val_loss: 1286.3050
Epoch 00003: val_loss did not improve
Epoch 5/300
2s - loss: 329.4154 - val_loss: 1257.8981
Epoch 00004: val_loss did not improve
Epoch 6/300
2s - loss: 328.3437 - val_loss: 1251.2991
Epoch 00005: val_loss did not improve
Epoch 7/300
2s - loss: 328.0852 - val_loss: 1228.8562
Epoch 00006: val_loss did not improve
Epoch 8/300
2s - loss: 327.9209 - val_loss: 1249.2256
Epoch 00007: val_loss did not improve
Epoch 9/300
2s - loss: 328.0761 - val_loss: 1242.3035
Epoch 00008: val_loss did not improve
Epoch 10/300
2s - loss: 328.2950 - val_loss: 1234.8132
Epoch 00009: val_loss did not improve
Epoch 11/300
2s - loss: 328.1509 - val_loss: 1261.7953
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 328.0176 - val_loss: 1275.9225
Epoch 00011: val_loss did not improve
Epoch 13/300
2s - loss: 327.5403 - val_loss: 1293.7459
Epoch 00012: val_loss did not improve
Epoch 14/300
2s - loss: 328.0994 - val_loss: 1269.8275
Epoch 00013: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training chengdu0
Train on 4347 samples, validate on 1358 samples
Before training:
            chengdu0 2979.9095      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.15953 nan 3.15953
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            chengdu013857.4108      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.91095 nan 5.91095
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
0s - loss: 2240.4888 - val_loss: 4167.5663
Epoch 00000: val_loss improved from inf to 4167.56626, saving model to chengdu0_weights.hdf5
            chengdu0 1333.7383      0.06  -nan  0.06      0.06  -nan  0.06      0.07  -nan  0.06
            chengdu0 4167.5663      0.61  0.06  0.58      0.62  0.04  0.61      0.64  0.02  0.63
forget mean min: 0.902444 0.329805
abs_mean, abs_mean+, abs_mean-: 4.71822 1.76167 9.13032
U_c = [[-0.11787681]] U_f = [[ 0.]] b_c = [ 0.07656353] b_f = [ 1.]
Epoch 2/300
0s - loss: 1025.2088 - val_loss: 3180.4312
Epoch 00001: val_loss improved from 4167.56626 to 3180.43122, saving model to chengdu0_weights.hdf5
            chengdu0  810.6119      0.19  0.43  0.17      0.20  0.43  0.17      0.19  0.40  0.17
            chengdu0 3180.4312      0.83  0.21  0.67      0.84  0.20  0.69      0.84  0.18  0.72
forget mean min: 0.960824 0.203344
abs_mean, abs_mean+, abs_mean-: 3.96762 2.7758 11.461
U_c = [[-0.12973578]] U_f = [[ 0.]] b_c = [ 0.13639759] b_f = [ 1.]
Epoch 3/300
0s - loss: 714.4809 - val_loss: 2669.0277
Epoch 00002: val_loss improved from 3180.43122 to 2669.02773, saving model to chengdu0_weights.hdf5
            chengdu0  628.9197      0.42  0.38  0.34      0.44  0.37  0.35      0.44  0.35  0.36
            chengdu0 2669.0278      0.89  0.29  0.65      0.90  0.29  0.66      0.90  0.27  0.68
forget mean min: 0.974085 0.338228
abs_mean, abs_mean+, abs_mean-: 3.79185 3.20402 6.64226
U_c = [[-0.087596]] U_f = [[ 0.]] b_c = [ 0.18553126] b_f = [ 1.]
Epoch 4/300
0s - loss: 572.7032 - val_loss: 2100.1011
Epoch 00003: val_loss improved from 2669.02773 to 2100.10109, saving model to chengdu0_weights.hdf5
            chengdu0  534.3917      0.43  0.33  0.35      0.48  0.28  0.40      0.51  0.23  0.44
            chengdu0 2100.1011      0.92  0.25  0.70      0.93  0.24  0.71      0.94  0.22  0.74
forget mean min: 0.975502 0.699975
abs_mean, abs_mean+, abs_mean-: 3.67512 3.36876 4.55698
U_c = [[-0.05349875]] U_f = [[ 0.]] b_c = [ 0.21654947] b_f = [ 1.]
Epoch 5/300
0s - loss: 524.6462 - val_loss: 2061.1952
Epoch 00004: val_loss improved from 2100.10109 to 2061.19523, saving model to chengdu0_weights.hdf5
            chengdu0  512.9163      0.47  0.35  0.38      0.52  0.32  0.42      0.55  0.26  0.46
            chengdu0 2061.1952      0.92  0.25  0.71      0.93  0.24  0.72      0.94  0.22  0.74
forget mean min: 0.975494 0.74236
abs_mean, abs_mean+, abs_mean-: 3.62909 3.34394 4.41496
U_c = [[-0.04101771]] U_f = [[ 0.]] b_c = [ 0.2219369] b_f = [ 1.]
Epoch 6/300
0s - loss: 515.9904 - val_loss: 2067.9745
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 513.4272 - val_loss: 2051.1216
Epoch 00006: val_loss improved from 2061.19523 to 2051.12156, saving model to chengdu0_weights.hdf5
            chengdu0  523.8422      0.53  0.34  0.42      0.59  0.30  0.47      0.62  0.24  0.52
            chengdu0 2051.1216      0.93  0.24  0.72      0.95  0.23  0.74      0.95  0.20  0.77
forget mean min: 0.975492 0.72064
abs_mean, abs_mean+, abs_mean-: 3.92503 3.56751 4.96143
U_c = [[-0.03616342]] U_f = [[ 0.]] b_c = [ 0.23169851] b_f = [ 1.]
Epoch 8/300
0s - loss: 513.7677 - val_loss: 2062.6237
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 512.7512 - val_loss: 1996.7963
Epoch 00008: val_loss improved from 2051.12156 to 1996.79630, saving model to chengdu0_weights.hdf5
            chengdu0  509.6825      0.43  0.31  0.36      0.47  0.28  0.40      0.49  0.22  0.42
            chengdu0 1996.7963      0.90  0.22  0.71      0.91  0.21  0.73      0.92  0.18  0.76
forget mean min: 0.971691 0.763293
abs_mean, abs_mean+, abs_mean-: 3.74245 3.32136 4.7621
U_c = [[-0.03433074]] U_f = [[ 0.]] b_c = [ 0.23826095] b_f = [ 1.]
Epoch 10/300
0s - loss: 512.6658 - val_loss: 2107.8624
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 511.3235 - val_loss: 2045.0517
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 511.5854 - val_loss: 2066.1977
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 512.2819 - val_loss: 2027.8828
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 510.9904 - val_loss: 2059.8434
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 509.9530 - val_loss: 2036.7726
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 508.9850 - val_loss: 2065.0063
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 508.4893 - val_loss: 2067.3673
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 507.4787 - val_loss: 2103.5107
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 503.2083 - val_loss: 2094.1241
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 501.1206 - val_loss: 2168.1361
Epoch 00019: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training chengdu1
Train on 4347 samples, validate on 1358 samples
Before training:
            chengdu1 2979.9095      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.15953 nan 3.15953
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            chengdu113857.4108      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.91095 nan 5.91095
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2211.5296 - val_loss: 4245.5950
Epoch 00000: val_loss improved from inf to 4245.59496, saving model to chengdu1_weights.hdf5
            chengdu1 1329.3228      0.06  -nan  0.06      0.07  -nan  0.06      0.07  -nan  0.06
            chengdu1 4245.5950      0.59  0.06  0.56      0.60  0.04  0.59      0.61  0.02  0.60
forget mean min: 0.902513 0.324776
abs_mean, abs_mean+, abs_mean-: 4.8702 1.77565 9.76349
U_c = [[-0.11855771]] U_f = [[ 0.]] b_c = [ 0.07732981] b_f = [ 1.]
Epoch 2/300
1s - loss: 1024.6245 - val_loss: 3184.5208
Epoch 00001: val_loss improved from 4245.59496 to 3184.52077, saving model to chengdu1_weights.hdf5
            chengdu1  805.7892      0.20  0.45  0.17      0.19  0.46  0.17      0.19  0.44  0.17
            chengdu1 3184.5207      0.83  0.22  0.67      0.84  0.20  0.69      0.84  0.18  0.71
forget mean min: 0.962884 0.213695
abs_mean, abs_mean+, abs_mean-: 3.85657 2.7434 10.578
U_c = [[-0.12979801]] U_f = [[ 0.]] b_c = [ 0.13644105] b_f = [ 1.]
Epoch 3/300
1s - loss: 709.9570 - val_loss: 2594.5466
Epoch 00002: val_loss improved from 3184.52077 to 2594.54664, saving model to chengdu1_weights.hdf5
            chengdu1  624.6666      0.42  0.39  0.33      0.44  0.38  0.35      0.43  0.36  0.35
            chengdu1 2594.5467      0.89  0.29  0.65      0.90  0.28  0.66      0.90  0.26  0.68
forget mean min: 0.973194 0.359261
abs_mean, abs_mean+, abs_mean-: 3.74649 3.18537 6.27261
U_c = [[-0.08411734]] U_f = [[ 0.]] b_c = [ 0.18650579] b_f = [ 1.]
Epoch 4/300
1s - loss: 569.9607 - val_loss: 2111.9234
Epoch 00003: val_loss improved from 2594.54664 to 2111.92337, saving model to chengdu1_weights.hdf5
            chengdu1  526.9579      0.43  0.35  0.35      0.47  0.30  0.39      0.49  0.25  0.42
            chengdu1 2111.9234      0.90  0.26  0.68      0.91  0.25  0.70      0.92  0.23  0.72
forget mean min: 0.974899 0.720055
abs_mean, abs_mean+, abs_mean-: 3.5966 3.34821 4.27071
U_c = [[-0.05089835]] U_f = [[ 0.]] b_c = [ 0.21510111] b_f = [ 1.]
Epoch 5/300
1s - loss: 524.0150 - val_loss: 2067.8204
Epoch 00004: val_loss improved from 2111.92337 to 2067.82035, saving model to chengdu1_weights.hdf5
            chengdu1  514.6320      0.49  0.34  0.39      0.55  0.30  0.44      0.58  0.25  0.49
            chengdu1 2067.8204      0.92  0.25  0.70      0.94  0.25  0.71      0.94  0.23  0.73
forget mean min: 0.975529 0.729382
abs_mean, abs_mean+, abs_mean-: 3.66839 3.36926 4.52765
U_c = [[-0.04037761]] U_f = [[ 0.]] b_c = [ 0.21971011] b_f = [ 1.]
Epoch 6/300
1s - loss: 516.6663 - val_loss: 2060.9538
Epoch 00005: val_loss improved from 2067.82035 to 2060.95384, saving model to chengdu1_weights.hdf5
            chengdu1  509.7480      0.50  0.36  0.39      0.54  0.33  0.43      0.58  0.28  0.47
            chengdu1 2060.9538      0.92  0.24  0.71      0.94  0.24  0.73      0.94  0.21  0.75
forget mean min: 0.975685 0.739358
abs_mean, abs_mean+, abs_mean-: 3.72124 3.39742 4.64963
U_c = [[-0.0367755]] U_f = [[ 0.]] b_c = [ 0.22315949] b_f = [ 1.]
Epoch 7/300
1s - loss: 514.9724 - val_loss: 2061.5820
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 513.2101 - val_loss: 2066.4355
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 513.3962 - val_loss: 2083.1526
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 512.4571 - val_loss: 2042.4257
Epoch 00009: val_loss improved from 2060.95384 to 2042.42567, saving model to chengdu1_weights.hdf5
            chengdu1  511.0348      0.46  0.33  0.37      0.50  0.29  0.41      0.53  0.24  0.45
            chengdu1 2042.4256      0.92  0.21  0.73      0.93  0.20  0.76      0.94  0.18  0.78
forget mean min: 0.971454 0.72963
abs_mean, abs_mean+, abs_mean-: 3.87148 3.4 5.09106
U_c = [[-0.03221773]] U_f = [[ 0.]] b_c = [ 0.23952936] b_f = [ 1.]
Epoch 11/300
1s - loss: 512.4631 - val_loss: 2039.9385
Epoch 00010: val_loss improved from 2042.42567 to 2039.93850, saving model to chengdu1_weights.hdf5
            chengdu1  511.0943      0.43  0.30  0.36      0.47  0.27  0.40      0.50  0.21  0.43
            chengdu1 2039.9385      0.90  0.20  0.74      0.92  0.19  0.76      0.93  0.17  0.78
forget mean min: 0.969809 0.740374
abs_mean, abs_mean+, abs_mean-: 3.84357 3.32594 5.14303
U_c = [[-0.03182621]] U_f = [[ 0.]] b_c = [ 0.24283874] b_f = [ 1.]
Epoch 12/300
1s - loss: 511.1597 - val_loss: 2074.9875
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 511.0420 - val_loss: 2107.0267
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 511.6084 - val_loss: 2174.1484
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 510.5843 - val_loss: 2096.1719
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 510.9075 - val_loss: 2096.9944
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 508.9270 - val_loss: 2210.6998
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 507.9564 - val_loss: 2195.2436
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 506.2401 - val_loss: 2143.2917
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 504.8838 - val_loss: 2039.2611
Epoch 00019: val_loss improved from 2039.93850 to 2039.26113, saving model to chengdu1_weights.hdf5
            chengdu1  506.5128      0.40  0.28  0.35      0.44  0.23  0.39      0.46  0.18  0.41
            chengdu1 2039.2611      0.89  0.18  0.74      0.90  0.18  0.76      0.92  0.15  0.79
forget mean min: 0.964648 0.718826
abs_mean, abs_mean+, abs_mean-: 3.80931 3.24854 4.94828
U_c = [[-0.02397999]] U_f = [[ 0.]] b_c = [ 0.27192244] b_f = [ 1.]
Epoch 21/300
1s - loss: 502.4920 - val_loss: 2050.3031
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 501.2104 - val_loss: 2059.9309
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 498.1688 - val_loss: 2072.7954
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 495.0639 - val_loss: 2093.6929
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 492.2242 - val_loss: 2152.2487
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 488.6227 - val_loss: 2086.7678
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 485.4930 - val_loss: 2176.0963
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 481.3862 - val_loss: 2348.6034
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 478.4379 - val_loss: 2062.4180
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 475.6040 - val_loss: 2032.1977
Epoch 00029: val_loss improved from 2039.26113 to 2032.19771, saving model to chengdu1_weights.hdf5
            chengdu1  468.0718      0.51  0.30  0.41      0.56  0.27  0.46      0.59  0.20  0.51
            chengdu1 2032.1977      0.88  0.19  0.73      0.89  0.18  0.75      0.90  0.15  0.78
forget mean min: 0.961745 0.71203
abs_mean, abs_mean+, abs_mean-: 3.95308 3.36028 5.07967
U_c = [[-0.01838142]] U_f = [[ 0.]] b_c = [ 0.30808905] b_f = [ 1.]
Epoch 31/300
1s - loss: 473.8319 - val_loss: 2105.9343
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 471.0711 - val_loss: 2112.1556
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 470.7608 - val_loss: 2067.4721
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 469.3214 - val_loss: 2093.2331
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 466.6062 - val_loss: 2100.4879
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 464.5202 - val_loss: 2134.6464
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 461.6475 - val_loss: 2157.1096
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 459.0943 - val_loss: 2200.3279
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 456.8552 - val_loss: 2108.2678
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 453.7638 - val_loss: 2137.6927
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 450.7706 - val_loss: 2114.2532
Epoch 00040: val_loss did not improve
X_train[0].shape = (4347, 40, 23)

training chengdu2
Train on 4347 samples, validate on 1358 samples
Before training:
            chengdu2 2979.9095      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.15953 nan 3.15953
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
            chengdu213857.4108      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.91095 nan 5.91095
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2237.5901 - val_loss: 4248.3672
Epoch 00000: val_loss improved from inf to 4248.36719, saving model to chengdu2_weights.hdf5
            chengdu2 1346.6271      0.06  -nan  0.06      0.06  -nan  0.06      0.06  -nan  0.06
            chengdu2 4248.3672      0.59  0.06  0.56      0.60  0.04  0.59      0.60  0.02  0.60
forget mean min: 0.901613 0.327806
abs_mean, abs_mean+, abs_mean-: 4.86082 1.78609 9.5962
U_c = [[-0.11781041]] U_f = [[ 0.]] b_c = [ 0.07645771] b_f = [ 1.]
Epoch 2/300
1s - loss: 1027.6360 - val_loss: 3172.1916
Epoch 00001: val_loss improved from 4248.36719 to 3172.19161, saving model to chengdu2_weights.hdf5
            chengdu2  808.5629      0.19  0.42  0.17      0.19  0.42  0.17      0.19  0.39  0.17
            chengdu2 3172.1916      0.83  0.22  0.67      0.84  0.20  0.69      0.84  0.18  0.71
forget mean min: 0.962681 0.214581
abs_mean, abs_mean+, abs_mean-: 3.84302 2.71821 10.5515
U_c = [[-0.12883127]] U_f = [[ 0.]] b_c = [ 0.13486058] b_f = [ 1.]
Epoch 3/300
1s - loss: 710.2275 - val_loss: 2590.3265
Epoch 00002: val_loss improved from 3172.19161 to 2590.32648, saving model to chengdu2_weights.hdf5
            chengdu2  634.1046      0.49  0.41  0.37      0.51  0.40  0.38      0.51  0.37  0.40
            chengdu2 2590.3265      0.92  0.30  0.66      0.93  0.30  0.66      0.93  0.28  0.69
forget mean min: 0.975715 0.339503
abs_mean, abs_mean+, abs_mean-: 3.86347 3.31649 7.00331
U_c = [[-0.08180095]] U_f = [[ 0.]] b_c = [ 0.18768206] b_f = [ 1.]
Epoch 4/300
1s - loss: 568.9731 - val_loss: 2145.1709
Epoch 00003: val_loss improved from 2590.32648 to 2145.17089, saving model to chengdu2_weights.hdf5
            chengdu2  525.9874      0.44  0.34  0.35      0.48  0.30  0.40      0.51  0.24  0.43
            chengdu2 2145.1709      0.90  0.27  0.68      0.91  0.26  0.69      0.92  0.24  0.71
forget mean min: 0.975329 0.723353
abs_mean, abs_mean+, abs_mean-: 3.61623 3.36093 4.32949
U_c = [[-0.05152753]] U_f = [[ 0.]] b_c = [ 0.21472792] b_f = [ 1.]
Epoch 5/300
1s - loss: 521.8981 - val_loss: 2037.3487
Epoch 00004: val_loss improved from 2145.17089 to 2037.34870, saving model to chengdu2_weights.hdf5
            chengdu2  517.7442      0.51  0.35  0.40      0.56  0.31  0.45      0.60  0.25  0.50
            chengdu2 2037.3487      0.93  0.25  0.71      0.94  0.24  0.72      0.95  0.22  0.75
forget mean min: 0.975858 0.72143
abs_mean, abs_mean+, abs_mean-: 3.75005 3.41202 4.7424
U_c = [[-0.03868558]] U_f = [[ 0.]] b_c = [ 0.22047909] b_f = [ 1.]
Epoch 6/300
1s - loss: 515.5166 - val_loss: 2064.6325
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 513.9219 - val_loss: 2133.8960
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 513.4605 - val_loss: 2085.4843
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 512.9016 - val_loss: 2051.6974
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 512.9957 - val_loss: 2090.9631
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 512.5009 - val_loss: 2049.8602
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 512.6271 - val_loss: 2059.1565
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 510.8948 - val_loss: 2073.2097
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 510.8405 - val_loss: 2061.2080
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 509.8449 - val_loss: 2126.5335
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 508.6353 - val_loss: 2063.6433
Epoch 00015: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanchang0
Train on 5589 samples, validate on 1746 samples
Before training:
           nanchang0 2819.6255      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.56054 nan 2.56054
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           nanchang0 6492.3994      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.55425 nan 4.55425
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2053.6412 - val_loss: 3052.3705
Epoch 00000: val_loss improved from inf to 3052.37052, saving model to nanchang0_weights.hdf5
           nanchang0 1479.4727      0.08  0.51  0.07      0.09  0.43  0.08      0.09  0.44  0.08
           nanchang0 3052.3705      0.30  0.14  0.29      0.29  0.12  0.28      0.30  0.08  0.29
forget mean min: 0.766985 0.299977
abs_mean, abs_mean+, abs_mean-: 5.79814 1.85608 8.27784
U_c = [[-0.12091522]] U_f = [[ 0.]] b_c = [ 0.09187072] b_f = [ 1.]
Epoch 2/300
1s - loss: 1215.4089 - val_loss: 1809.4304
Epoch 00001: val_loss improved from 3052.37052 to 1809.43039, saving model to nanchang0_weights.hdf5
           nanchang0 1037.7766      0.22  0.48  0.18      0.24  0.43  0.20      0.24  0.42  0.20
           nanchang0 1809.4304      0.64  0.38  0.46      0.63  0.36  0.47      0.65  0.35  0.48
forget mean min: 0.952906 0.214144
abs_mean, abs_mean+, abs_mean-: 3.43657 2.40937 6.43178
U_c = [[-0.08622906]] U_f = [[ 0.]] b_c = [ 0.1469724] b_f = [ 1.]
Epoch 3/300
1s - loss: 961.3957 - val_loss: 1905.2859
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 890.8284 - val_loss: 2057.6256
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 876.0045 - val_loss: 1982.5564
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 867.2711 - val_loss: 1877.8672
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 861.1024 - val_loss: 2053.3226
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 854.7410 - val_loss: 2066.0389
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 850.0567 - val_loss: 1985.4033
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 847.2214 - val_loss: 2041.4446
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 841.1820 - val_loss: 2058.3453
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 833.4434 - val_loss: 2013.3063
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 824.2282 - val_loss: 2237.4703
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanchang1
Train on 5589 samples, validate on 1746 samples
Before training:
           nanchang1 2819.6255      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.56054 nan 2.56054
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           nanchang1 6492.3994      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.55425 nan 4.55425
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2070.8624 - val_loss: 3073.9656
Epoch 00000: val_loss improved from inf to 3073.96565, saving model to nanchang1_weights.hdf5
           nanchang1 1487.7745      0.08  0.50  0.07      0.09  0.40  0.08      0.09  0.38  0.08
           nanchang1 3073.9656      0.28  0.11  0.27      0.27  0.10  0.26      0.28  0.07  0.28
forget mean min: 0.768065 0.312351
abs_mean, abs_mean+, abs_mean-: 5.8 1.78908 8.129
U_c = [[-0.12252123]] U_f = [[ 0.]] b_c = [ 0.09107624] b_f = [ 1.]
Epoch 2/300
1s - loss: 1208.6417 - val_loss: 1826.3187
Epoch 00001: val_loss improved from 3073.96565 to 1826.31869, saving model to nanchang1_weights.hdf5
           nanchang1 1031.8663      0.22  0.47  0.18      0.25  0.42  0.21      0.25  0.40  0.21
           nanchang1 1826.3187      0.65  0.38  0.47      0.64  0.37  0.47      0.66  0.35  0.48
forget mean min: 0.954267 0.221344
abs_mean, abs_mean+, abs_mean-: 3.51031 2.47458 6.57641
U_c = [[-0.08326694]] U_f = [[ 0.]] b_c = [ 0.15097022] b_f = [ 1.]
Epoch 3/300
1s - loss: 961.9699 - val_loss: 2018.6530
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 893.2744 - val_loss: 1896.3038
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 874.0004 - val_loss: 1913.7180
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 863.8071 - val_loss: 1926.4045
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 855.7617 - val_loss: 1918.6493
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 849.8907 - val_loss: 2088.0058
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 839.9829 - val_loss: 2045.4820
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 828.2342 - val_loss: 2041.5365
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 813.0847 - val_loss: 2119.2425
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 797.3506 - val_loss: 2038.4904
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 784.7857 - val_loss: 2020.0059
Epoch 00012: val_loss did not improve
X_train[0].shape = (5589, 40, 23)

training nanchang2
Train on 5589 samples, validate on 1746 samples
Before training:
           nanchang2 2819.6255      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.56054 nan 2.56054
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           nanchang2 6492.3994      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 4.55425 nan 4.55425
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2056.4031 - val_loss: 3045.5197
Epoch 00000: val_loss improved from inf to 3045.51971, saving model to nanchang2_weights.hdf5
           nanchang2 1478.7692      0.08  0.51  0.07      0.09  0.44  0.08      0.09  0.43  0.08
           nanchang2 3045.5197      0.30  0.15  0.28      0.29  0.14  0.27      0.29  0.09  0.28
forget mean min: 0.769491 0.305994
abs_mean, abs_mean+, abs_mean-: 5.7885 1.86106 8.19708
U_c = [[-0.12170809]] U_f = [[ 0.]] b_c = [ 0.09231231] b_f = [ 1.]
Epoch 2/300
1s - loss: 1211.3716 - val_loss: 1840.3517
Epoch 00001: val_loss improved from 3045.51971 to 1840.35174, saving model to nanchang2_weights.hdf5
           nanchang2 1039.3907      0.20  0.48  0.17      0.23  0.43  0.19      0.22  0.43  0.19
           nanchang2 1840.3517      0.66  0.40  0.46      0.65  0.39  0.46      0.66  0.38  0.47
forget mean min: 0.957698 0.208451
abs_mean, abs_mean+, abs_mean-: 3.34513 2.43537 6.35309
U_c = [[-0.08915217]] U_f = [[ 0.]] b_c = [ 0.1489073] b_f = [ 1.]
Epoch 3/300
1s - loss: 960.9464 - val_loss: 1828.7075
Epoch 00002: val_loss improved from 1840.35174 to 1828.70754, saving model to nanchang2_weights.hdf5
           nanchang2  909.9107      0.25  0.32  0.22      0.29  0.24  0.25      0.28  0.20  0.25
           nanchang2 1828.7076      0.62  0.35  0.47      0.62  0.34  0.47      0.65  0.32  0.50
forget mean min: 0.964663 0.342146
abs_mean, abs_mean+, abs_mean-: 3.03685 2.26254 4.73332
U_c = [[-0.0313106]] U_f = [[ 0.]] b_c = [ 0.1813755] b_f = [ 1.]
Epoch 4/300
1s - loss: 890.6512 - val_loss: 2077.9091
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 875.2223 - val_loss: 1984.4321
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 865.4537 - val_loss: 2082.8498
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 858.9716 - val_loss: 1994.6774
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 852.1162 - val_loss: 1979.1974
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 844.6820 - val_loss: 2040.1167
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 828.5851 - val_loss: 2056.5640
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 810.8074 - val_loss: 2080.5808
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 798.9992 - val_loss: 2303.9324
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 785.7854 - val_loss: 2042.1444
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 772.8865 - val_loss: 2049.8443
Epoch 00013: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changsha0
Train on 6210 samples, validate on 1940 samples
Before training:
           changsha0 3488.6052      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.54028 nan 3.54028
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           changsha010416.0418      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.4061 nan 5.4061
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2183.8001 - val_loss: 6601.0320
Epoch 00000: val_loss improved from inf to 6601.03201, saving model to changsha0_weights.hdf5
           changsha0 1290.4964      0.26  0.40  0.22      0.27  0.36  0.24      0.28  0.30  0.25
           changsha0 6601.0320      0.27  0.13  0.26      0.27  0.09  0.26      0.26  0.03  0.26
forget mean min: 0.721634 0.328434
abs_mean, abs_mean+, abs_mean-: 7.7722 1.90813 10.6689
U_c = [[-0.13320881]] U_f = [[ 0.]] b_c = [ 0.09974828] b_f = [ 1.]
Epoch 2/300
1s - loss: 988.8529 - val_loss: 3566.0025
Epoch 00001: val_loss improved from 6601.03201 to 3566.00249, saving model to changsha0_weights.hdf5
           changsha0  891.5846      0.43  0.34  0.35      0.48  0.25  0.41      0.50  0.18  0.45
           changsha0 3566.0025      0.30  0.22  0.28      0.31  0.16  0.29      0.30  0.08  0.29
forget mean min: 0.922645 0.62938
abs_mean, abs_mean+, abs_mean-: 3.65711 1.93318 4.50933
U_c = [[-0.11044829]] U_f = [[ 0.]] b_c = [ 0.1766187] b_f = [ 1.]
Epoch 3/300
1s - loss: 808.6462 - val_loss: 3947.5687
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 727.0205 - val_loss: 3160.6129
Epoch 00003: val_loss improved from 3566.00249 to 3160.61287, saving model to changsha0_weights.hdf5
           changsha0  758.5723      0.64  0.41  0.45      0.70  0.33  0.52      0.73  0.28  0.56
           changsha0 3160.6129      0.42  0.29  0.37      0.42  0.27  0.37      0.41  0.24  0.37
forget mean min: 0.938786 0.788317
abs_mean, abs_mean+, abs_mean-: 3.30828 2.56444 3.90672
U_c = [[-0.05898638]] U_f = [[ 0.]] b_c = [ 0.25948638] b_f = [ 1.]
Epoch 5/300
1s - loss: 718.5019 - val_loss: 4131.3684
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 710.8875 - val_loss: 3713.4944
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 700.7149 - val_loss: 3518.7267
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 689.5695 - val_loss: 4012.3661
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 673.9539 - val_loss: 3705.4450
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 662.1569 - val_loss: 3760.2495
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 642.8019 - val_loss: 3755.5185
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 624.4430 - val_loss: 3353.0965
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 606.2598 - val_loss: 4261.8414
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 588.9144 - val_loss: 4347.8640
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 575.2380 - val_loss: 4336.3365
Epoch 00014: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changsha1
Train on 6210 samples, validate on 1940 samples
Before training:
           changsha1 3488.6052      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.54028 nan 3.54028
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           changsha110416.0418      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.4061 nan 5.4061
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2167.2645 - val_loss: 6626.0339
Epoch 00000: val_loss improved from inf to 6626.03386, saving model to changsha1_weights.hdf5
           changsha1 1299.7392      0.27  0.40  0.23      0.28  0.35  0.24      0.29  0.29  0.26
           changsha1 6626.0339      0.27  0.13  0.26      0.27  0.08  0.27      0.26  0.03  0.26
forget mean min: 0.716992 0.324079
abs_mean, abs_mean+, abs_mean-: 7.75168 1.91479 10.7631
U_c = [[-0.13144846]] U_f = [[ 0.]] b_c = [ 0.09960366] b_f = [ 1.]
Epoch 2/300
1s - loss: 997.6843 - val_loss: 3437.9316
Epoch 00001: val_loss improved from 6626.03386 to 3437.93162, saving model to changsha1_weights.hdf5
           changsha1  893.8819      0.39  0.35  0.32      0.44  0.26  0.38      0.45  0.19  0.41
           changsha1 3437.9317      0.34  0.23  0.31      0.35  0.18  0.32      0.34  0.11  0.32
forget mean min: 0.926874 0.635557
abs_mean, abs_mean+, abs_mean-: 3.69562 2.08695 4.61336
U_c = [[-0.11735117]] U_f = [[ 0.]] b_c = [ 0.17619322] b_f = [ 1.]
Epoch 3/300
1s - loss: 820.2875 - val_loss: 4009.5746
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 729.3306 - val_loss: 3577.0474
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 718.9995 - val_loss: 4221.4821
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 711.9835 - val_loss: 3852.1371
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 705.7630 - val_loss: 3986.3441
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 699.3372 - val_loss: 3898.6932
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 686.4562 - val_loss: 4222.3615
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 668.2220 - val_loss: 3583.2890
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 646.0287 - val_loss: 4125.6052
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 624.4526 - val_loss: 3968.7826
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 601.2632 - val_loss: 3940.1526
Epoch 00012: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training changsha2
Train on 6210 samples, validate on 1940 samples
Before training:
           changsha2 3488.6052      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 3.54028 nan 3.54028
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
           changsha210416.0418      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 5.4061 nan 5.4061
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 2200.0061 - val_loss: 6639.9807
Epoch 00000: val_loss improved from inf to 6639.98074, saving model to changsha2_weights.hdf5
           changsha2 1300.3865      0.26  0.41  0.22      0.27  0.36  0.23      0.28  0.30  0.25
           changsha2 6639.9807      0.27  0.13  0.26      0.27  0.09  0.27      0.26  0.03  0.26
forget mean min: 0.714962 0.321532
abs_mean, abs_mean+, abs_mean-: 7.8463 1.89771 10.9776
U_c = [[-0.13389139]] U_f = [[ 0.]] b_c = [ 0.09867986] b_f = [ 1.]
Epoch 2/300
1s - loss: 998.4360 - val_loss: 3506.8446
Epoch 00001: val_loss improved from 6639.98074 to 3506.84463, saving model to changsha2_weights.hdf5
           changsha2  886.1209      0.47  0.36  0.37      0.52  0.27  0.43      0.54  0.20  0.48
           changsha2 3506.8446      0.35  0.21  0.32      0.36  0.15  0.34      0.35  0.08  0.34
forget mean min: 0.925097 0.637354
abs_mean, abs_mean+, abs_mean-: 3.85298 2.22833 4.81136
U_c = [[-0.11258098]] U_f = [[ 0.]] b_c = [ 0.17532478] b_f = [ 1.]
Epoch 3/300
1s - loss: 804.6885 - val_loss: 3597.4677
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 725.7230 - val_loss: 3727.7814
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 715.6820 - val_loss: 3662.3842
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 707.7526 - val_loss: 3229.9011
Epoch 00005: val_loss improved from 3506.84463 to 3229.90106, saving model to changsha2_weights.hdf5
           changsha2  846.7704      0.71  0.45  0.45      0.76  0.39  0.51      0.79  0.36  0.54
           changsha2 3229.9011      0.43  0.19  0.39      0.43  0.16  0.40      0.42  0.12  0.39
forget mean min: 0.929045 0.763492
abs_mean, abs_mean+, abs_mean-: 3.79695 3.17574 4.27863
U_c = [[-0.03750661]] U_f = [[ 0.]] b_c = [ 0.30536434] b_f = [ 1.]
Epoch 7/300
1s - loss: 696.9740 - val_loss: 4106.7460
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 682.9321 - val_loss: 3919.2456
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 670.2006 - val_loss: 3614.7570
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 654.2416 - val_loss: 3932.5039
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 637.6343 - val_loss: 4325.3164
Epoch 00010: val_loss did not improve
Epoch 12/300
2s - loss: 619.2570 - val_loss: 4351.5606
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 601.5461 - val_loss: 3902.6013
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 587.4161 - val_loss: 4014.0901
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 578.8123 - val_loss: 3685.0134
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 568.9949 - val_loss: 3295.2103
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 565.0498 - val_loss: 3877.5748
Epoch 00016: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training guangzhou0
Train on 6210 samples, validate on 1940 samples
Before training:
          guangzhou0 1555.3170      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.54275 nan 2.54275
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          guangzhou0 3365.8038      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.99625 nan 2.99625
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 898.6068 - val_loss: 1404.3841
Epoch 00000: val_loss improved from inf to 1404.38414, saving model to guangzhou0_weights.hdf5
          guangzhou0  430.2243      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou0 1404.3841      0.06  -nan  0.05      0.06  -nan  0.05      0.06  -nan  0.06
forget mean min: 0.799007 0.291922
abs_mean, abs_mean+, abs_mean-: 4.02226 1.60192 5.11248
U_c = [[-0.13696936]] U_f = [[ 0.]] b_c = [ 0.0973787] b_f = [ 1.]
Epoch 2/300
1s - loss: 328.2008 - val_loss: 1251.0251
Epoch 00001: val_loss improved from 1404.38414 to 1251.02515, saving model to guangzhou0_weights.hdf5
          guangzhou0  273.1881      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou0 1251.0252      0.05  -nan  0.04      0.05  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.895134 0.484332
abs_mean, abs_mean+, abs_mean-: 2.55205 1.45981 3.12395
U_c = [[-0.15513672]] U_f = [[ 0.]] b_c = [ 0.17102432] b_f = [ 1.]
Epoch 3/300
1s - loss: 255.6743 - val_loss: 1014.3623
Epoch 00002: val_loss improved from 1251.02515 to 1014.36229, saving model to guangzhou0_weights.hdf5
          guangzhou0  263.8727      0.09  0.48  0.08      0.13  0.40  0.11      0.17  0.28  0.14
          guangzhou0 1014.3623      0.11  -nan  0.09      0.10  -nan  0.09      0.10  -nan  0.09
forget mean min: 0.910578 0.499472
abs_mean, abs_mean+, abs_mean-: 2.54024 2.07358 3.07348
U_c = [[-0.10751693]] U_f = [[ 0.]] b_c = [ 0.23549213] b_f = [ 1.]
Epoch 4/300
1s - loss: 244.1193 - val_loss: 1149.9031
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 240.6860 - val_loss: 1106.4994
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 238.7138 - val_loss: 1083.8663
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 236.8301 - val_loss: 995.3269
Epoch 00006: val_loss improved from 1014.36229 to 995.32695, saving model to guangzhou0_weights.hdf5
          guangzhou0  240.7837      0.18  0.33  0.16      0.28  0.22  0.25      0.38  0.16  0.34
          guangzhou0  995.3269      0.13  -nan  0.11      0.13  -nan  0.11      0.12  -nan  0.11
forget mean min: 0.883477 0.516429
abs_mean, abs_mean+, abs_mean-: 2.62153 2.05961 3.20498
U_c = [[-0.07288222]] U_f = [[ 0.]] b_c = [ 0.33620694] b_f = [ 1.]
Epoch 8/300
1s - loss: 234.6079 - val_loss: 1009.0333
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 232.5359 - val_loss: 988.2264
Epoch 00008: val_loss improved from 995.32695 to 988.22642, saving model to guangzhou0_weights.hdf5
          guangzhou0  230.1765      0.15  0.27  0.14      0.23  0.20  0.21      0.32  0.14  0.29
          guangzhou0  988.2264      0.10  -nan  0.08      0.10  -nan  0.09      0.10  -nan  0.09
forget mean min: 0.879758 0.539972
abs_mean, abs_mean+, abs_mean-: 2.58811 2.07651 3.05279
U_c = [[-0.06885584]] U_f = [[ 0.]] b_c = [ 0.36794245] b_f = [ 1.]
Epoch 10/300
1s - loss: 229.5660 - val_loss: 936.4187
Epoch 00009: val_loss improved from 988.22642 to 936.41866, saving model to guangzhou0_weights.hdf5
          guangzhou0  242.6590      0.27  0.48  0.22      0.41  0.43  0.31      0.59  0.32  0.47
          guangzhou0  936.4187      0.10  -nan  0.09      0.10  -nan  0.09      0.10  -nan  0.09
forget mean min: 0.87794 0.518401
abs_mean, abs_mean+, abs_mean-: 2.7546 2.28006 3.19626
U_c = [[-0.06527336]] U_f = [[ 0.]] b_c = [ 0.38232449] b_f = [ 1.]
Epoch 11/300
1s - loss: 227.5403 - val_loss: 931.3420
Epoch 00010: val_loss improved from 936.41866 to 931.34196, saving model to guangzhou0_weights.hdf5
          guangzhou0  231.9657      0.23  0.38  0.20      0.36  0.30  0.31      0.51  0.20  0.45
          guangzhou0  931.3419      0.16  0.14  0.13      0.15  -nan  0.13      0.15  -nan  0.13
forget mean min: 0.8797 0.532325
abs_mean, abs_mean+, abs_mean-: 2.77464 2.28466 3.28556
U_c = [[-0.06276456]] U_f = [[ 0.]] b_c = [ 0.39753598] b_f = [ 1.]
Epoch 12/300
1s - loss: 226.0724 - val_loss: 1020.8181
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 223.3778 - val_loss: 958.8494
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 222.6160 - val_loss: 925.2033
Epoch 00013: val_loss improved from 931.34196 to 925.20331, saving model to guangzhou0_weights.hdf5
          guangzhou0  236.4186      0.28  0.43  0.23      0.42  0.33  0.35      0.53  0.19  0.47
          guangzhou0  925.2033      0.12  -nan  0.11      0.13  -nan  0.11      0.12  -nan  0.11
forget mean min: 0.872277 0.55408
abs_mean, abs_mean+, abs_mean-: 2.81738 2.3644 3.22304
U_c = [[-0.0600777]] U_f = [[ 0.]] b_c = [ 0.4346526] b_f = [ 1.]
Epoch 15/300
1s - loss: 221.5345 - val_loss: 1021.2046
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 219.5819 - val_loss: 1050.8288
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 218.4211 - val_loss: 991.2339
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 216.9656 - val_loss: 901.7386
Epoch 00017: val_loss improved from 925.20331 to 901.73862, saving model to guangzhou0_weights.hdf5
          guangzhou0  231.0256      0.31  0.44  0.25      0.45  0.35  0.36      0.58  0.20  0.51
          guangzhou0  901.7386      0.14  0.08  0.12      0.14  0.08  0.12      0.13  -nan  0.11
forget mean min: 0.866872 0.559508
abs_mean, abs_mean+, abs_mean-: 2.92525 2.56773 3.2277
U_c = [[-0.05456602]] U_f = [[ 0.]] b_c = [ 0.48210803] b_f = [ 1.]
Epoch 19/300
1s - loss: 215.8640 - val_loss: 1053.6076
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 213.4219 - val_loss: 934.7367
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 212.3424 - val_loss: 1072.5615
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 210.4695 - val_loss: 1062.8727
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 207.0529 - val_loss: 915.8453
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 205.0568 - val_loss: 960.4441
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 201.6613 - val_loss: 1016.0005
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 200.0029 - val_loss: 809.5777
Epoch 00025: val_loss improved from 901.73862 to 809.57766, saving model to guangzhou0_weights.hdf5
          guangzhou0  231.0896      0.37  0.48  0.27      0.52  0.46  0.36      0.70  0.41  0.47
          guangzhou0  809.5777      0.30  0.17  0.27      0.30  0.13  0.27      0.28  0.09  0.26
forget mean min: 0.865415 0.542771
abs_mean, abs_mean+, abs_mean-: 3.2389 2.96288 3.49953
U_c = [[-0.0450904]] U_f = [[ 0.]] b_c = [ 0.55703777] b_f = [ 1.]
Epoch 27/300
1s - loss: 196.0743 - val_loss: 988.6971
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 192.8791 - val_loss: 940.5348
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 189.3506 - val_loss: 862.2702
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 186.3285 - val_loss: 793.8608
Epoch 00029: val_loss improved from 809.57766 to 793.86084, saving model to guangzhou0_weights.hdf5
          guangzhou0  198.7395      0.44  0.52  0.30      0.61  0.51  0.37      0.80  0.40  0.52
          guangzhou0  793.8608      0.34  0.21  0.30      0.34  0.13  0.30      0.33  0.09  0.30
forget mean min: 0.86076 0.560835
abs_mean, abs_mean+, abs_mean-: 3.42519 3.08135 3.74976
U_c = [[-0.04149103]] U_f = [[ 0.]] b_c = [ 0.58574194] b_f = [ 1.]
Epoch 31/300
1s - loss: 183.4893 - val_loss: 951.3071
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 180.4940 - val_loss: 945.3964
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 178.2439 - val_loss: 970.6711
Epoch 00032: val_loss did not improve
Epoch 34/300
1s - loss: 175.7573 - val_loss: 887.1758
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 173.6536 - val_loss: 882.5339
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 172.0377 - val_loss: 1015.4758
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 171.0025 - val_loss: 858.7464
Epoch 00036: val_loss did not improve
Epoch 38/300
1s - loss: 169.1997 - val_loss: 907.3671
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 167.5555 - val_loss: 856.3249
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 166.4274 - val_loss: 741.9891
Epoch 00039: val_loss improved from 793.86084 to 741.98905, saving model to guangzhou0_weights.hdf5
          guangzhou0  189.1313      0.48  0.54  0.31      0.65  0.53  0.38      0.85  0.44  0.51
          guangzhou0  741.9891      0.44  0.24  0.39      0.47  0.19  0.42      0.45  0.12  0.41
forget mean min: 0.853652 0.514821
abs_mean, abs_mean+, abs_mean-: 3.94579 3.80827 4.06687
U_c = [[-0.06159347]] U_f = [[ 0.]] b_c = [ 0.68233627] b_f = [ 1.]
Epoch 41/300
1s - loss: 165.2826 - val_loss: 943.6182
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 163.8977 - val_loss: 952.2750
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 162.1555 - val_loss: 984.5219
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 161.0297 - val_loss: 757.4820
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 160.1994 - val_loss: 1024.3960
Epoch 00044: val_loss did not improve
Epoch 46/300
1s - loss: 158.5211 - val_loss: 800.3006
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 157.8740 - val_loss: 774.7468
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 156.5549 - val_loss: 987.9859
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 155.2670 - val_loss: 823.1873
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 154.2595 - val_loss: 798.0788
Epoch 00049: val_loss did not improve
Epoch 51/300
1s - loss: 153.6775 - val_loss: 891.9014
Epoch 00050: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training guangzhou1
Train on 6210 samples, validate on 1940 samples
Before training:
          guangzhou1 1555.3170      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.54275 nan 2.54275
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          guangzhou1 3365.8038      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.99625 nan 2.99625
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 894.9214 - val_loss: 1436.3642
Epoch 00000: val_loss improved from inf to 1436.36419, saving model to guangzhou1_weights.hdf5
          guangzhou1  429.6132      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou1 1436.3642      0.05  -nan  0.05      0.06  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.801336 0.290573
abs_mean, abs_mean+, abs_mean-: 3.98315 1.57635 5.00359
U_c = [[-0.13746868]] U_f = [[ 0.]] b_c = [ 0.09733833] b_f = [ 1.]
Epoch 2/300
1s - loss: 324.8880 - val_loss: 1099.3529
Epoch 00001: val_loss improved from 1436.36419 to 1099.35291, saving model to guangzhou1_weights.hdf5
          guangzhou1  268.9276      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou1 1099.3529      0.06  -nan  0.06      0.07  -nan  0.06      0.07  -nan  0.07
forget mean min: 0.917804 0.459587
abs_mean, abs_mean+, abs_mean-: 2.63439 1.9329 3.32102
U_c = [[-0.15695491]] U_f = [[ 0.]] b_c = [ 0.17645873] b_f = [ 1.]
Epoch 3/300
1s - loss: 254.6167 - val_loss: 1052.3800
Epoch 00002: val_loss improved from 1099.35291 to 1052.38005, saving model to guangzhou1_weights.hdf5
          guangzhou1  245.3807      0.06  0.25  0.05      0.09  -nan  0.07      0.13  -nan  0.10
          guangzhou1 1052.3800      0.08  -nan  0.07      0.09  -nan  0.07      0.09  -nan  0.08
forget mean min: 0.902149 0.524808
abs_mean, abs_mean+, abs_mean-: 2.37158 1.71994 2.99441
U_c = [[-0.10506134]] U_f = [[ 0.]] b_c = [ 0.23485571] b_f = [ 1.]
Epoch 4/300
1s - loss: 243.5162 - val_loss: 944.3065
Epoch 00003: val_loss improved from 1052.38005 to 944.30649, saving model to guangzhou1_weights.hdf5
          guangzhou1  263.5640      0.18  0.52  0.15      0.27  0.47  0.22      0.40  0.39  0.31
          guangzhou1  944.3065      0.11  -nan  0.09      0.11  -nan  0.09      0.11  -nan  0.09
forget mean min: 0.901899 0.520541
abs_mean, abs_mean+, abs_mean-: 2.59418 2.05 3.25729
U_c = [[-0.09080996]] U_f = [[ 0.]] b_c = [ 0.27187687] b_f = [ 1.]
Epoch 5/300
1s - loss: 241.2006 - val_loss: 1174.2762
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 239.6662 - val_loss: 906.5924
Epoch 00005: val_loss improved from 944.30649 to 906.59241, saving model to guangzhou1_weights.hdf5
          guangzhou1  270.4492      0.31  0.57  0.22      0.46  0.54  0.30      0.65  0.48  0.40
          guangzhou1  906.5924      0.11  -nan  0.09      0.11  -nan  0.09      0.11  -nan  0.10
forget mean min: 0.892715 0.516585
abs_mean, abs_mean+, abs_mean-: 2.62073 2.12569 3.16566
U_c = [[-0.07750149]] U_f = [[ 0.]] b_c = [ 0.31950605] b_f = [ 1.]
Epoch 7/300
1s - loss: 238.3373 - val_loss: 921.9030
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 237.2446 - val_loss: 1024.5485
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 235.3177 - val_loss: 923.8686
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 233.9893 - val_loss: 995.8914
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 231.2057 - val_loss: 1158.9352
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 228.5295 - val_loss: 1146.1330
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 226.5247 - val_loss: 953.4251
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 225.0214 - val_loss: 928.9279
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 223.0271 - val_loss: 1117.9769
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 221.6310 - val_loss: 944.6351
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 219.9475 - val_loss: 964.3187
Epoch 00016: val_loss did not improve
X_train[0].shape = (6210, 40, 23)

training guangzhou2
Train on 6210 samples, validate on 1940 samples
Before training:
          guangzhou2 1555.3170      0.00  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.54275 nan 2.54275
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
          guangzhou2 3365.8038      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
abs_mean, abs_mean+, abs_mean-: 2.99625 nan 2.99625
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
Epoch 1/300
1s - loss: 906.4204 - val_loss: 1430.8006
Epoch 00000: val_loss improved from inf to 1430.80062, saving model to guangzhou2_weights.hdf5
          guangzhou2  429.8455      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou2 1430.8006      0.05  -nan  0.05      0.06  -nan  0.05      0.06  -nan  0.05
forget mean min: 0.797452 0.286529
abs_mean, abs_mean+, abs_mean-: 4.06841 1.58261 5.1906
U_c = [[-0.13774538]] U_f = [[ 0.]] b_c = [ 0.09791239] b_f = [ 1.]
Epoch 2/300
1s - loss: 330.0560 - val_loss: 1142.4703
Epoch 00001: val_loss improved from 1430.80062 to 1142.47025, saving model to guangzhou2_weights.hdf5
          guangzhou2  271.4388      0.03  -nan  0.03      0.05  -nan  0.04      0.06  -nan  0.05
          guangzhou2 1142.4703      0.06  -nan  0.05      0.07  -nan  0.06      0.07  -nan  0.07
forget mean min: 0.910373 0.431306
abs_mean, abs_mean+, abs_mean-: 2.65166 1.88547 3.31837
U_c = [[-0.16006568]] U_f = [[ 0.]] b_c = [ 0.17337675] b_f = [ 1.]
Epoch 3/300
1s - loss: 254.8859 - val_loss: 1262.3074
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 244.1110 - val_loss: 1131.4968
Epoch 00003: val_loss improved from 1142.47025 to 1131.49683, saving model to guangzhou2_weights.hdf5
          guangzhou2  244.0266      0.07  0.21  0.06      0.10  0.18  0.08      0.12  -nan  0.10
          guangzhou2 1131.4968      0.06  -nan  0.05      0.07  -nan  0.06      0.07  -nan  0.07
forget mean min: 0.886919 0.545648
abs_mean, abs_mean+, abs_mean-: 2.26867 1.59764 2.74901
U_c = [[-0.09151672]] U_f = [[ 0.]] b_c = [ 0.2708441] b_f = [ 1.]
Epoch 5/300
1s - loss: 240.3726 - val_loss: 1152.8010
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 239.0533 - val_loss: 1089.1484
Epoch 00005: val_loss improved from 1131.49683 to 1089.14842, saving model to guangzhou2_weights.hdf5
          guangzhou2  246.1507      0.11  0.31  0.10      0.17  0.21  0.15      0.22  0.17  0.19
          guangzhou2 1089.1484      0.07  -nan  0.06      0.07  -nan  0.06      0.08  -nan  0.07
forget mean min: 0.879216 0.546678
abs_mean, abs_mean+, abs_mean-: 2.42012 1.83905 2.83798
U_c = [[-0.07745047]] U_f = [[ 0.]] b_c = [ 0.31788364] b_f = [ 1.]
Epoch 7/300
1s - loss: 237.7754 - val_loss: 1171.8189
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 236.8569 - val_loss: 980.6146
Epoch 00007: val_loss improved from 1089.14842 to 980.61457, saving model to guangzhou2_weights.hdf5
          guangzhou2  238.3159      0.16  0.33  0.15      0.25  0.24  0.22      0.33  0.18  0.29
          guangzhou2  980.6146      0.09  -nan  0.08      0.10  -nan  0.08      0.09  -nan  0.08
forget mean min: 0.883904 0.549411
abs_mean, abs_mean+, abs_mean-: 2.5956 2.1073 3.0611
U_c = [[-0.07812569]] U_f = [[ 0.]] b_c = [ 0.35633963] b_f = [ 1.]
Epoch 9/300
1s - loss: 235.2030 - val_loss: 1008.0453
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 232.9961 - val_loss: 1151.5199
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 231.0745 - val_loss: 991.9152
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 228.6071 - val_loss: 1095.3247
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 226.2931 - val_loss: 1057.9657
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 224.2602 - val_loss: 990.7893
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 221.9094 - val_loss: 947.5730
Epoch 00014: val_loss improved from 980.61457 to 947.57303, saving model to guangzhou2_weights.hdf5
          guangzhou2  221.1606      0.25  0.37  0.22      0.39  0.28  0.34      0.52  0.20  0.46
          guangzhou2  947.5730      0.10  -nan  0.09      0.11  -nan  0.09      0.11  -nan  0.09
forget mean min: 0.868734 0.537675
abs_mean, abs_mean+, abs_mean-: 2.82806 2.42513 3.16524
U_c = [[-0.05686992]] U_f = [[ 0.]] b_c = [ 0.45389694] b_f = [ 1.]
Epoch 16/300
1s - loss: 220.1171 - val_loss: 1109.2912
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 218.8353 - val_loss: 900.9907
Epoch 00016: val_loss improved from 947.57303 to 900.99068, saving model to guangzhou2_weights.hdf5
          guangzhou2  258.3823      0.44  0.58  0.27      0.57  0.59  0.31      0.74  0.56  0.38
          guangzhou2  900.9907      0.10  -nan  0.09      0.10  -nan  0.09      0.10  -nan  0.09
forget mean min: 0.870467 0.534093
abs_mean, abs_mean+, abs_mean-: 3.05293 2.77825 3.28481
U_c = [[-0.05519358]] U_f = [[ 0.]] b_c = [ 0.4793922] b_f = [ 1.]
Epoch 18/300
1s - loss: 217.5360 - val_loss: 1004.8607
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 215.8471 - val_loss: 981.6092
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 213.6765 - val_loss: 991.5225
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 212.1470 - val_loss: 993.9220
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 209.2108 - val_loss: 897.6673
Epoch 00021: val_loss improved from 900.99068 to 897.66730, saving model to guangzhou2_weights.hdf5
          guangzhou2  226.6697      0.36  0.52  0.26      0.51  0.49  0.34      0.69  0.39  0.48
          guangzhou2  897.6673      0.11  0.17  0.10      0.12  -nan  0.10      0.11  -nan  0.10
forget mean min: 0.860461 0.564872
abs_mean, abs_mean+, abs_mean-: 3.01105 2.70974 3.25129
U_c = [[-0.04805574]] U_f = [[ 0.]] b_c = [ 0.52690071] b_f = [ 1.]
Epoch 23/300
1s - loss: 206.5311 - val_loss: 1077.4554
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 204.0761 - val_loss: 966.0978
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 201.5171 - val_loss: 861.2075
Epoch 00024: val_loss improved from 897.66730 to 861.20751, saving model to guangzhou2_weights.hdf5
          guangzhou2  220.3224      0.38  0.50  0.28      0.54  0.45  0.38      0.71  0.40  0.49
          guangzhou2  861.2075      0.17  0.22  0.15      0.17  0.09  0.15      0.16  0.04  0.14
forget mean min: 0.866201 0.569533
abs_mean, abs_mean+, abs_mean-: 3.13406 2.90331 3.33482
U_c = [[-0.05113609]] U_f = [[ 0.]] b_c = [ 0.55512595] b_f = [ 1.]
Epoch 26/300
1s - loss: 198.8167 - val_loss: 1098.6540
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 195.6748 - val_loss: 1068.3168
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 192.5696 - val_loss: 925.5857
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 188.9542 - val_loss: 1075.1988
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 186.7798 - val_loss: 1150.8128
Epoch 00029: val_loss did not improve
Epoch 31/300
1s - loss: 183.3567 - val_loss: 973.2140
Epoch 00030: val_loss did not improve
Epoch 32/300
1s - loss: 181.1710 - val_loss: 877.2242
Epoch 00031: val_loss did not improve
Epoch 33/300
1s - loss: 178.2768 - val_loss: 846.2134
Epoch 00032: val_loss improved from 861.20751 to 846.21344, saving model to guangzhou2_weights.hdf5
          guangzhou2  201.8981      0.39  0.46  0.30      0.54  0.43  0.38      0.71  0.40  0.48
          guangzhou2  846.2134      0.23  0.29  0.20      0.23  0.19  0.20      0.22  0.10  0.20
forget mean min: 0.85971 0.55197
abs_mean, abs_mean+, abs_mean-: 3.54189 3.27796 3.78328
U_c = [[-0.05050607]] U_f = [[ 0.]] b_c = [ 0.61905831] b_f = [ 1.]
Epoch 34/300
1s - loss: 176.1857 - val_loss: 967.6190
Epoch 00033: val_loss did not improve
Epoch 35/300
1s - loss: 173.8687 - val_loss: 945.3622
Epoch 00034: val_loss did not improve
Epoch 36/300
1s - loss: 172.3120 - val_loss: 1076.5168
Epoch 00035: val_loss did not improve
Epoch 37/300
1s - loss: 170.7553 - val_loss: 818.5305
Epoch 00036: val_loss improved from 846.21344 to 818.53051, saving model to guangzhou2_weights.hdf5
          guangzhou2  170.8066      0.34  0.38  0.28      0.49  0.30  0.40      0.66  0.18  0.58
          guangzhou2  818.5305      0.34  0.26  0.30      0.34  0.23  0.29      0.32  0.16  0.29
forget mean min: 0.856516 0.563992
abs_mean, abs_mean+, abs_mean-: 3.8132 3.5278 4.08316
U_c = [[-0.06037508]] U_f = [[ 0.]] b_c = [ 0.65857166] b_f = [ 1.]
Epoch 38/300
1s - loss: 169.2498 - val_loss: 862.8637
Epoch 00037: val_loss did not improve
Epoch 39/300
1s - loss: 167.3986 - val_loss: 957.8985
Epoch 00038: val_loss did not improve
Epoch 40/300
1s - loss: 166.3219 - val_loss: 848.7437
Epoch 00039: val_loss did not improve
Epoch 41/300
1s - loss: 164.3247 - val_loss: 916.5278
Epoch 00040: val_loss did not improve
Epoch 42/300
1s - loss: 163.9719 - val_loss: 831.2950
Epoch 00041: val_loss did not improve
Epoch 43/300
1s - loss: 162.7369 - val_loss: 882.8702
Epoch 00042: val_loss did not improve
Epoch 44/300
1s - loss: 161.6905 - val_loss: 874.2088
Epoch 00043: val_loss did not improve
Epoch 45/300
1s - loss: 160.1562 - val_loss: 774.8217
Epoch 00044: val_loss improved from 818.53051 to 774.82169, saving model to guangzhou2_weights.hdf5
          guangzhou2  185.6834      0.43  0.50  0.30      0.59  0.45  0.40      0.73  0.35  0.52
          guangzhou2  774.8217      0.51  0.32  0.41      0.52  0.32  0.42      0.52  0.25  0.44
forget mean min: 0.846538 0.547164
abs_mean, abs_mean+, abs_mean-: 4.51121 4.295 4.71743
U_c = [[-0.06811227]] U_f = [[ 0.]] b_c = [ 0.74008274] b_f = [ 1.]
Epoch 46/300
1s - loss: 159.6165 - val_loss: 969.9434
Epoch 00045: val_loss did not improve
Epoch 47/300
1s - loss: 158.5133 - val_loss: 911.6189
Epoch 00046: val_loss did not improve
Epoch 48/300
1s - loss: 156.9481 - val_loss: 782.7362
Epoch 00047: val_loss did not improve
Epoch 49/300
1s - loss: 155.9895 - val_loss: 818.3861
Epoch 00048: val_loss did not improve
Epoch 50/300
1s - loss: 155.0899 - val_loss: 727.1003
Epoch 00049: val_loss improved from 774.82169 to 727.10030, saving model to guangzhou2_weights.hdf5
          guangzhou2  160.8369      0.41  0.47  0.30      0.58  0.38  0.43      0.73  0.26  0.58
          guangzhou2  727.1003      0.47  0.29  0.40      0.49  0.23  0.43      0.49  0.17  0.44
forget mean min: 0.843534 0.572483
abs_mean, abs_mean+, abs_mean-: 4.48144 4.30639 4.6415
U_c = [[-0.07044455]] U_f = [[ 0.]] b_c = [ 0.78467661] b_f = [ 1.]
Epoch 51/300
1s - loss: 154.0422 - val_loss: 862.1447
Epoch 00050: val_loss did not improve
Epoch 52/300
1s - loss: 153.1328 - val_loss: 683.9974
Epoch 00051: val_loss improved from 727.10030 to 683.99738, saving model to guangzhou2_weights.hdf5
          guangzhou2  184.1159      0.60  0.55  0.34      0.73  0.58  0.36      0.91  0.50  0.47
          guangzhou2  683.9974      0.56  0.30  0.45      0.57  0.26  0.47      0.56  0.19  0.49
forget mean min: 0.841413 0.545966
abs_mean, abs_mean+, abs_mean-: 4.72039 4.56211 4.86706
U_c = [[-0.06829366]] U_f = [[ 0.]] b_c = [ 0.80273014] b_f = [ 1.]
Epoch 53/300
1s - loss: 152.4315 - val_loss: 938.5236
Epoch 00052: val_loss did not improve
Epoch 54/300
1s - loss: 151.4734 - val_loss: 795.0657
Epoch 00053: val_loss did not improve
Epoch 55/300
1s - loss: 150.6812 - val_loss: 848.6068
Epoch 00054: val_loss did not improve
Epoch 56/300
1s - loss: 149.6779 - val_loss: 856.9616
Epoch 00055: val_loss did not improve
Epoch 57/300
1s - loss: 148.6290 - val_loss: 970.0795
Epoch 00056: val_loss did not improve
Epoch 58/300
1s - loss: 148.0260 - val_loss: 729.2443
Epoch 00057: val_loss did not improve
Epoch 59/300
1s - loss: 147.0303 - val_loss: 751.5401
Epoch 00058: val_loss did not improve
Epoch 60/300
1s - loss: 146.8942 - val_loss: 646.5230
Epoch 00059: val_loss improved from 683.99738 to 646.52300, saving model to guangzhou2_weights.hdf5
          guangzhou2  174.9914      0.55  0.52  0.34      0.67  0.53  0.38      0.84  0.43  0.51
          guangzhou2  646.5230      0.60  0.31  0.48      0.66  0.27  0.53      0.65  0.21  0.55
forget mean min: 0.842554 0.563442
abs_mean, abs_mean+, abs_mean-: 4.97536 4.95274 4.99703
U_c = [[-0.07359318]] U_f = [[ 0.]] b_c = [ 0.86867267] b_f = [ 1.]
Epoch 61/300
1s - loss: 145.7292 - val_loss: 816.0863
Epoch 00060: val_loss did not improve
Epoch 62/300
1s - loss: 145.2168 - val_loss: 748.8699
Epoch 00061: val_loss did not improve
Epoch 63/300
1s - loss: 144.2832 - val_loss: 956.7979
Epoch 00062: val_loss did not improve
Epoch 64/300
1s - loss: 143.5155 - val_loss: 715.4808
Epoch 00063: val_loss did not improve
Epoch 65/300
1s - loss: 143.4666 - val_loss: 745.8809
Epoch 00064: val_loss did not improve
Epoch 66/300
1s - loss: 142.8362 - val_loss: 789.9208
Epoch 00065: val_loss did not improve
Epoch 67/300
1s - loss: 142.0133 - val_loss: 741.5200
Epoch 00066: val_loss did not improve
Epoch 68/300
1s - loss: 141.0666 - val_loss: 722.5785
Epoch 00067: val_loss did not improve
Epoch 69/300
1s - loss: 140.3916 - val_loss: 685.5031
Epoch 00068: val_loss did not improve
Epoch 70/300
1s - loss: 140.2253 - val_loss: 814.7269
Epoch 00069: val_loss did not improve
Epoch 71/300
1s - loss: 139.5514 - val_loss: 663.6903
Epoch 00070: val_loss did not improve

haerbin0
            haerbin013840.0507      0.56  0.22  0.48      0.56  0.18  0.50      0.54  0.16  0.50
            haerbin0 8626.5290      0.82  0.41  0.52      0.81  0.40  0.52      0.83  0.40  0.54
forget mean min: 0.947189 0.433373
abs_mean, abs_mean+, abs_mean-: 5.90158 2.19084 12.9753
U_c = [[-0.14267339]] U_f = [[ 0.]] b_c = [ 0.11538202] b_f = [ 1.]

haerbin1
            haerbin113833.7341      0.56  0.22  0.48      0.56  0.19  0.50      0.54  0.16  0.49
            haerbin1 8783.2021      0.83  0.41  0.52      0.82  0.40  0.53      0.84  0.40  0.54
forget mean min: 0.951315 0.409426
abs_mean, abs_mean+, abs_mean-: 5.65934 2.21362 13.4548
U_c = [[-0.13580847]] U_f = [[ 0.]] b_c = [ 0.11598462] b_f = [ 1.]

haerbin2
            haerbin213837.2132      0.55  0.22  0.48      0.55  0.19  0.49      0.54  0.16  0.49
            haerbin2 8694.3589      0.81  0.41  0.52      0.80  0.40  0.52      0.81  0.40  0.53
forget mean min: 0.945167 0.398026
abs_mean, abs_mean+, abs_mean-: 5.99451 2.20594 13.0283
U_c = [[-0.14043349]] U_f = [[ 0.]] b_c = [ 0.11602437] b_f = [ 1.]

changchun0
          changchun014208.5441      0.58  0.45  0.39      0.58  0.39  0.42      0.58  0.34  0.45
          changchun0 6189.5412      0.44  0.53  0.30      0.43  0.53  0.29      0.41  0.54  0.28
forget mean min: 0.915119 0.58595
abs_mean, abs_mean+, abs_mean-: 5.03794 2.02546 7.1249
U_c = [[-0.13120505]] U_f = [[ 0.]] b_c = [ 0.19943056] b_f = [ 1.]

changchun1
          changchun114218.3092      0.61  0.45  0.40      0.61  0.40  0.43      0.59  0.37  0.44
          changchun1 5635.0720      0.38  0.40  0.31      0.40  0.37  0.33      0.37  0.37  0.31
forget mean min: 0.915352 0.658762
abs_mean, abs_mean+, abs_mean-: 5.18915 1.97681 6.77717
U_c = [[-0.13057391]] U_f = [[ 0.]] b_c = [ 0.19888201] b_f = [ 1.]

changchun2
          changchun214162.2195      0.60  0.45  0.40      0.60  0.40  0.43      0.60  0.35  0.46
          changchun2 6399.8265      0.41  0.53  0.28      0.41  0.53  0.28      0.39  0.53  0.28
forget mean min: 0.913261 0.636646
abs_mean, abs_mean+, abs_mean-: 4.91915 1.83808 6.60722
U_c = [[-0.12925006]] U_f = [[ 0.]] b_c = [ 0.19695595] b_f = [ 1.]

shenyang0
           shenyang011427.3881      0.56  0.27  0.47      0.57  0.22  0.49      0.57  0.17  0.52
           shenyang0 4956.6872      0.79  0.40  0.51      0.79  0.38  0.53      0.80  0.37  0.54
forget mean min: 0.957068 0.304901
abs_mean, abs_mean+, abs_mean-: 5.3268 3.32036 11.4969
U_c = [[-0.1215517]] U_f = [[ 0.]] b_c = [ 0.17765169] b_f = [ 1.]

shenyang1
           shenyang111398.1514      0.56  0.26  0.47      0.56  0.21  0.49      0.57  0.16  0.52
           shenyang1 4972.1687      0.78  0.41  0.51      0.79  0.38  0.53      0.79  0.37  0.54
forget mean min: 0.957499 0.317072
abs_mean, abs_mean+, abs_mean-: 5.20238 3.2891 10.4712
U_c = [[-0.11755361]] U_f = [[ 0.]] b_c = [ 0.17816271] b_f = [ 1.]

shenyang2
           shenyang211419.8352      0.56  0.27  0.47      0.57  0.22  0.49      0.57  0.17  0.51
           shenyang2 5036.8602      0.81  0.42  0.51      0.81  0.40  0.52      0.81  0.39  0.53
forget mean min: 0.963151 0.314337
abs_mean, abs_mean+, abs_mean-: 5.05305 3.2774 11.4988
U_c = [[-0.12511423]] U_f = [[ 0.]] b_c = [ 0.17553027] b_f = [ 1.]

beijing0
            beijing0 3377.9325      0.92  0.21  0.73      0.91  0.19  0.75      0.91  0.17  0.77
            beijing014605.8655      0.83  0.23  0.67      0.84  0.19  0.70      0.85  0.17  0.72
forget mean min: 0.885691 0.331323
abs_mean, abs_mean+, abs_mean-: 13.9227 9.31338 22.3136
U_c = [[-0.01964052]] U_f = [[ 0.]] b_c = [ 0.4896051] b_f = [ 1.]

beijing1
            beijing1 3388.7392      0.92  0.21  0.73      0.92  0.19  0.75      0.91  0.17  0.77
            beijing114587.8916      0.83  0.23  0.66      0.84  0.20  0.70      0.85  0.19  0.71
forget mean min: 0.890766 0.334834
abs_mean, abs_mean+, abs_mean-: 13.6743 9.12978 22.1257
U_c = [[-0.01993527]] U_f = [[ 0.]] b_c = [ 0.48082152] b_f = [ 1.]

beijing2
            beijing2 3459.3127      0.91  0.21  0.73      0.90  0.18  0.75      0.90  0.16  0.77
            beijing214616.6306      0.83  0.24  0.66      0.85  0.21  0.69      0.85  0.19  0.71
forget mean min: 0.895476 0.358363
abs_mean, abs_mean+, abs_mean-: 13.3026 8.94606 21.2293
U_c = [[-0.01877299]] U_f = [[ 0.]] b_c = [ 0.4761889] b_f = [ 1.]

tianjin0
            tianjin0 2144.7951      0.88  0.24  0.69      0.89  0.19  0.74      0.90  0.15  0.78
            tianjin0 8793.0851      0.86  0.14  0.75      0.86  0.13  0.76      0.86  0.11  0.78
forget mean min: 0.86731 0.371364
abs_mean, abs_mean+, abs_mean-: 11.8221 6.44608 22.4534
U_c = [[-0.07166336]] U_f = [[ 0.]] b_c = [ 0.33515498] b_f = [ 1.]

tianjin1
            tianjin1 2100.7004      0.89  0.24  0.69      0.90  0.19  0.74      0.90  0.14  0.78
            tianjin1 8921.2907      0.85  0.13  0.76      0.85  0.11  0.77      0.85  0.09  0.79
forget mean min: 0.858784 0.366317
abs_mean, abs_mean+, abs_mean-: 12.605 6.84905 22.9734
U_c = [[-0.07889187]] U_f = [[ 0.]] b_c = [ 0.37323794] b_f = [ 1.]

tianjin2
            tianjin2 2125.9153      0.90  0.24  0.70      0.91  0.20  0.74      0.91  0.15  0.78
            tianjin2 8641.3080      0.86  0.13  0.76      0.87  0.12  0.78      0.87  0.10  0.79
forget mean min: 0.862665 0.353192
abs_mean, abs_mean+, abs_mean-: 12.9166 7.07014 24.5769
U_c = [[-0.08347644]] U_f = [[ 0.]] b_c = [ 0.36758977] b_f = [ 1.]

tangshan0
           tangshan0 1844.4091      0.89  0.19  0.74      0.92  0.16  0.78      0.91  0.15  0.79
           tangshan0 6198.6703      0.93  0.19  0.77      0.96  0.13  0.83      0.96  0.11  0.86
forget mean min: 0.92008 0.331596
abs_mean, abs_mean+, abs_mean-: 10.9792 7.22611 19.956
U_c = [[-0.06615102]] U_f = [[ 0.]] b_c = [ 0.43320939] b_f = [ 1.]

tangshan1
           tangshan1 1794.9264      0.90  0.19  0.74      0.92  0.15  0.79      0.92  0.14  0.80
           tangshan1 6190.4923      0.93  0.17  0.78      0.96  0.11  0.86      0.96  0.08  0.88
forget mean min: 0.914711 0.332512
abs_mean, abs_mean+, abs_mean-: 11.7685 7.51712 22.1374
U_c = [[-0.06649411]] U_f = [[ 0.]] b_c = [ 0.48736101] b_f = [ 1.]

tangshan2
           tangshan2 1896.6283      0.89  0.20  0.73      0.92  0.17  0.77      0.92  0.16  0.78
           tangshan2 6185.0817      0.95  0.21  0.75      0.96  0.17  0.80      0.97  0.16  0.82
forget mean min: 0.929044 0.35401
abs_mean, abs_mean+, abs_mean-: 10.3906 6.97488 18.7624
U_c = [[-0.06248041]] U_f = [[ 0.]] b_c = [ 0.3945998] b_f = [ 1.]

baoding0
            baoding0 5677.3583      0.89  0.26  0.68      0.92  0.23  0.72      0.92  0.21  0.74
            baoding013305.8002      0.98  0.11  0.88      0.99  0.07  0.92      1.00  0.04  0.95
forget mean min: 0.938822 0.3427
abs_mean, abs_mean+, abs_mean-: 21.5631 13.7621 42.9361
U_c = [[-0.04459242]] U_f = [[ 0.]] b_c = [ 0.69873297] b_f = [ 1.]

baoding1
            baoding1 6295.8675      0.90  0.21  0.72      0.92  0.17  0.77      0.92  0.14  0.80
            baoding113616.3391      0.98  0.10  0.89      0.99  0.06  0.93      0.99  0.03  0.96
forget mean min: 0.948799 0.359914
abs_mean, abs_mean+, abs_mean-: 15.4644 9.44166 34.6386
U_c = [[-0.0518078]] U_f = [[ 0.]] b_c = [ 0.47340882] b_f = [ 1.]

baoding2
            baoding2 6058.5482      0.91  0.24  0.71      0.93  0.22  0.74      0.94  0.19  0.77
            baoding213944.6435      0.96  0.11  0.86      0.97  0.07  0.90      0.98  0.04  0.94
forget mean min: 0.937238 0.362326
abs_mean, abs_mean+, abs_mean-: 19.9856 12.5336 40.537
U_c = [[-0.04330651]] U_f = [[ 0.]] b_c = [ 0.63874739] b_f = [ 1.]

shijiazhuang0
       shijiazhuang0 2678.6584      0.88  0.25  0.68      0.90  0.23  0.71      0.90  0.21  0.72
       shijiazhuang015373.0118      0.89  0.20  0.73      0.89  0.16  0.77      0.91  0.12  0.82
forget mean min: 0.916212 0.284883
abs_mean, abs_mean+, abs_mean-: 16.9177 10.1773 34.7027
U_c = [[-0.06060189]] U_f = [[ 0.]] b_c = [ 0.55428737] b_f = [ 1.]

shijiazhuang1
       shijiazhuang1 2685.9478      0.87  0.24  0.68      0.89  0.22  0.71      0.89  0.20  0.73
       shijiazhuang115631.2066      0.88  0.20  0.72      0.89  0.16  0.76      0.91  0.12  0.81
forget mean min: 0.916429 0.30732
abs_mean, abs_mean+, abs_mean-: 16.2583 9.69136 33.6143
U_c = [[-0.05785783]] U_f = [[ 0.]] b_c = [ 0.51939124] b_f = [ 1.]

shijiazhuang2
       shijiazhuang2 2691.9598      0.86  0.24  0.68      0.88  0.22  0.70      0.87  0.19  0.72
       shijiazhuang215746.6347      0.87  0.20  0.72      0.88  0.16  0.75      0.90  0.11  0.81
forget mean min: 0.914734 0.307895
abs_mean, abs_mean+, abs_mean-: 16.0829 9.60102 32.6018
U_c = [[-0.05602229]] U_f = [[ 0.]] b_c = [ 0.51735234] b_f = [ 1.]

xingtai+handan0
     xingtai+handan0 3922.3950      0.87  0.26  0.67      0.89  0.22  0.71      0.89  0.20  0.73
     xingtai+handan015208.1215      0.91  0.16  0.77      0.90  0.13  0.80      0.90  0.11  0.81
forget mean min: 0.930464 0.330343
abs_mean, abs_mean+, abs_mean-: 12.952 7.90564 26.0984
U_c = [[-0.06286415]] U_f = [[ 0.]] b_c = [ 0.40357533] b_f = [ 1.]

xingtai+handan1
     xingtai+handan1 3994.8957      0.86  0.25  0.66      0.87  0.22  0.70      0.87  0.19  0.72
     xingtai+handan115596.1218      0.91  0.17  0.76      0.91  0.14  0.79      0.90  0.11  0.81
forget mean min: 0.937199 0.280269
abs_mean, abs_mean+, abs_mean-: 12.2133 7.22561 29.7137
U_c = [[-0.06173662]] U_f = [[ 0.]] b_c = [ 0.36302638] b_f = [ 1.]

xingtai+handan2
     xingtai+handan2 3940.7953      0.85  0.25  0.66      0.87  0.22  0.70      0.87  0.19  0.72
     xingtai+handan215485.5720      0.91  0.17  0.77      0.91  0.14  0.79      0.91  0.11  0.82
forget mean min: 0.930986 0.320732
abs_mean, abs_mean+, abs_mean-: 12.7766 7.74969 25.5628
U_c = [[-0.0661608]] U_f = [[ 0.]] b_c = [ 0.39283475] b_f = [ 1.]

jinan0
              jinan0 2933.4753      0.86  0.25  0.67      0.87  0.22  0.69      0.86  0.21  0.70
              jinan0 9916.9454      0.96  0.12  0.85      0.96  0.09  0.87      0.96  0.08  0.88
forget mean min: 0.923594 0.474104
abs_mean, abs_mean+, abs_mean-: 11.2983 7.88104 16.417
U_c = [[-0.07638421]] U_f = [[ 0.]] b_c = [ 0.7567625] b_f = [ 1.]

jinan1
              jinan1 3166.7187      0.89  0.27  0.67      0.90  0.23  0.71      0.89  0.21  0.72
              jinan111093.1829      0.98  0.14  0.85      0.99  0.11  0.88      0.98  0.09  0.89
forget mean min: 0.960393 0.363114
abs_mean, abs_mean+, abs_mean-: 7.74792 5.32864 15.1372
U_c = [[-0.09751972]] U_f = [[ 0.]] b_c = [ 0.27824554] b_f = [ 1.]

jinan2
              jinan2 2648.7926      0.87  0.26  0.67      0.87  0.23  0.69      0.86  0.22  0.70
              jinan2 9316.8202      0.95  0.12  0.84      0.95  0.10  0.86      0.95  0.08  0.88
forget mean min: 0.918417 0.465564
abs_mean, abs_mean+, abs_mean-: 11.3321 8.87075 14.2571
U_c = [[-0.04463811]] U_f = [[ 0.]] b_c = [ 0.95453] b_f = [ 1.]

xian0
               xian0 1527.4215      0.72  0.35  0.52      0.75  0.34  0.54      0.76  0.33  0.55
               xian0 7591.8538      0.86  0.07  0.81      0.87  0.04  0.83      0.87  0.03  0.85
forget mean min: 0.930382 0.385947
abs_mean, abs_mean+, abs_mean-: 5.57244 3.49063 8.98859
U_c = [[-0.05604139]] U_f = [[ 0.]] b_c = [ 0.20953034] b_f = [ 1.]

xian1
               xian1 1386.4091      0.78  0.38  0.53      0.82  0.37  0.55      0.84  0.37  0.56
               xian1 7161.9584      0.87  0.07  0.82      0.88  0.04  0.85      0.88  0.02  0.87
forget mean min: 0.943082 0.553185
abs_mean, abs_mean+, abs_mean-: 6.35877 4.33564 9.47809
U_c = [[-0.01518877]] U_f = [[ 0.]] b_c = [ 0.33499885] b_f = [ 1.]

xian2
               xian2 1545.1599      0.75  0.37  0.52      0.78  0.36  0.54      0.79  0.36  0.55
               xian2 7346.7434      0.87  0.07  0.81      0.87  0.04  0.84      0.87  0.03  0.85
forget mean min: 0.93179 0.385669
abs_mean, abs_mean+, abs_mean-: 5.6466 3.60445 9.35205
U_c = [[-0.05060286]] U_f = [[ 0.]] b_c = [ 0.21410862] b_f = [ 1.]

nanjing0
            nanjing0  867.6246      0.51  0.40  0.38      0.52  0.39  0.39      0.50  0.37  0.38
            nanjing0 2404.5177      0.93  0.15  0.80      0.93  0.12  0.83      0.92  0.09  0.84
forget mean min: 0.929115 0.288135
abs_mean, abs_mean+, abs_mean-: 6.25567 4.12179 12.3174
U_c = [[-0.1047155]] U_f = [[ 0.]] b_c = [ 0.22416565] b_f = [ 1.]

nanjing1
            nanjing1  868.8073      0.53  0.41  0.39      0.54  0.40  0.40      0.52  0.39  0.39
            nanjing1 2376.2814      0.93  0.15  0.80      0.93  0.12  0.83      0.93  0.10  0.84
forget mean min: 0.930294 0.285281
abs_mean, abs_mean+, abs_mean-: 6.27041 4.17179 12.4096
U_c = [[-0.10395339]] U_f = [[ 0.]] b_c = [ 0.22853011] b_f = [ 1.]

nanjing2
            nanjing2  847.9907      0.58  0.39  0.42      0.59  0.38  0.43      0.59  0.36  0.44
            nanjing2 2385.8575      0.91  0.14  0.80      0.91  0.10  0.82      0.90  0.09  0.83
forget mean min: 0.925949 0.294112
abs_mean, abs_mean+, abs_mean-: 6.82205 4.5137 12.8379
U_c = [[-0.10776101]] U_f = [[ 0.]] b_c = [ 0.26696709] b_f = [ 1.]

shanghai0
           shanghai0  733.9436      0.59  0.38  0.44      0.62  0.35  0.47      0.67  0.30  0.52
           shanghai0 1945.2847      0.74  0.29  0.57      0.74  0.28  0.57      0.72  0.25  0.58
forget mean min: 0.900393 0.435466
abs_mean, abs_mean+, abs_mean-: 6.29592 5.34949 7.39614
U_c = [[-0.07841355]] U_f = [[ 0.]] b_c = [ 0.43860167] b_f = [ 1.]

shanghai1
           shanghai1  746.0661      0.53  0.36  0.41      0.55  0.33  0.43      0.59  0.28  0.48
           shanghai1 1935.3271      0.74  0.29  0.57      0.73  0.28  0.57      0.72  0.24  0.58
forget mean min: 0.902169 0.442039
abs_mean, abs_mean+, abs_mean-: 6.01578 5.07606 7.08911
U_c = [[-0.07727881]] U_f = [[ 0.]] b_c = [ 0.40195069] b_f = [ 1.]

shanghai2
           shanghai2  736.8150      0.50  0.32  0.41      0.53  0.27  0.44      0.56  0.22  0.49
           shanghai2 1961.5370      0.72  0.28  0.56      0.71  0.27  0.56      0.69  0.24  0.57
forget mean min: 0.898919 0.447381
abs_mean, abs_mean+, abs_mean-: 6.10504 5.11727 7.19509
U_c = [[-0.07992202]] U_f = [[ 0.]] b_c = [ 0.43753377] b_f = [ 1.]

hangzhou0
           hangzhou0  745.2415      0.42  0.38  0.33      0.46  0.35  0.37      0.48  0.29  0.40
           hangzhou0 2396.7262      0.89  0.25  0.68      0.90  0.22  0.72      0.92  0.19  0.76
forget mean min: 0.961603 0.641429
abs_mean, abs_mean+, abs_mean-: 3.47702 2.84602 4.517
U_c = [[-0.07936877]] U_f = [[ 0.]] b_c = [ 0.21564193] b_f = [ 1.]

hangzhou1
           hangzhou1  742.4160      0.39  0.36  0.32      0.43  0.32  0.36      0.45  0.26  0.38
           hangzhou1 2387.6688      0.85  0.24  0.67      0.86  0.21  0.70      0.88  0.18  0.74
forget mean min: 0.957013 0.645149
abs_mean, abs_mean+, abs_mean-: 3.38436 2.70652 4.36751
U_c = [[-0.0762668]] U_f = [[ 0.]] b_c = [ 0.21540923] b_f = [ 1.]

hangzhou2
           hangzhou2  823.5793      0.25  0.33  0.22      0.27  0.31  0.23      0.28  0.24  0.25
           hangzhou2 2393.6935      0.85  0.23  0.68      0.86  0.19  0.72      0.88  0.15  0.76
forget mean min: 0.928995 0.4294
abs_mean, abs_mean+, abs_mean-: 4.45443 2.89898 7.28674
U_c = [[-0.11988696]] U_f = [[ 0.]] b_c = [ 0.18942098] b_f = [ 1.]

hefei0
              hefei0 1860.5763      0.70  0.46  0.44      0.73  0.45  0.45      0.74  0.42  0.48
              hefei0 3608.1898      0.97  0.24  0.74      0.97  0.19  0.79      0.96  0.17  0.81
forget mean min: 0.955869 0.345542
abs_mean, abs_mean+, abs_mean-: 6.36631 5.23446 9.31059
U_c = [[-0.1440554]] U_f = [[ 0.]] b_c = [ 0.2822676] b_f = [ 1.]

hefei1
              hefei1 1902.4811      0.64  0.45  0.42      0.68  0.44  0.44      0.69  0.41  0.46
              hefei1 3611.6504      0.96  0.24  0.74      0.95  0.20  0.77      0.95  0.17  0.80
forget mean min: 0.948676 0.333376
abs_mean, abs_mean+, abs_mean-: 6.15449 4.66928 9.87491
U_c = [[-0.16303495]] U_f = [[ 0.]] b_c = [ 0.23936346] b_f = [ 1.]

hefei2
              hefei2 1906.2336      0.62  0.45  0.41      0.65  0.44  0.43      0.66  0.41  0.46
              hefei2 3615.5973      0.96  0.24  0.74      0.96  0.20  0.77      0.95  0.17  0.80
forget mean min: 0.951056 0.331726
abs_mean, abs_mean+, abs_mean-: 6.01726 4.70099 9.0669
U_c = [[-0.16560988]] U_f = [[ 0.]] b_c = [ 0.23979864] b_f = [ 1.]

wuhan0
              wuhan0 1425.4888      0.69  0.49  0.41      0.71  0.48  0.43      0.69  0.48  0.42
              wuhan0 5083.3404      0.91  0.12  0.81      0.90  0.08  0.84      0.90  0.05  0.86
forget mean min: 0.966478 0.382976
abs_mean, abs_mean+, abs_mean-: 4.63612 3.4294 7.36854
U_c = [[-0.03676471]] U_f = [[ 0.]] b_c = [ 0.27508292] b_f = [ 1.]

wuhan1
              wuhan1 1469.7906      0.71  0.50  0.41      0.74  0.49  0.43      0.74  0.48  0.44
              wuhan1 5212.4241      0.91  0.12  0.81      0.91  0.08  0.84      0.91  0.05  0.86
forget mean min: 0.967636 0.344686
abs_mean, abs_mean+, abs_mean-: 4.44985 3.43058 6.64138
U_c = [[-0.04148889]] U_f = [[ 0.]] b_c = [ 0.25436601] b_f = [ 1.]

wuhan2
              wuhan2 1403.0524      0.63  0.46  0.41      0.66  0.44  0.44      0.66  0.43  0.44
              wuhan2 5247.2138      0.90  0.12  0.80      0.90  0.08  0.83      0.90  0.05  0.85
forget mean min: 0.961829 0.350507
abs_mean, abs_mean+, abs_mean-: 4.39873 3.22988 6.50755
U_c = [[-0.04554087]] U_f = [[ 0.]] b_c = [ 0.25595471] b_f = [ 1.]

chongqing0
          chongqing0  328.3432      0.14  0.37  0.12      0.17  0.34  0.14      0.19  0.35  0.16
          chongqing0 1201.4207      0.76  0.33  0.55      0.77  0.32  0.57      0.78  0.31  0.58
forget mean min: 0.990256 0.496366
abs_mean, abs_mean+, abs_mean-: 2.02022 1.57622 7.86297
U_c = [[-0.06488934]] U_f = [[ 0.]] b_c = [ 0.11809569] b_f = [ 1.]

chongqing1
          chongqing1  339.8713      0.13  0.37  0.11      0.15  0.36  0.13      0.17  0.37  0.14
          chongqing1 1144.1849      0.78  0.31  0.58      0.79  0.30  0.59      0.80  0.30  0.60
forget mean min: 0.989208 0.790097
abs_mean, abs_mean+, abs_mean-: 2.04071 1.72254 4.15352
U_c = [[-0.06687689]] U_f = [[ 0.]] b_c = [ 0.12322207] b_f = [ 1.]

chongqing2
          chongqing2  333.5610      0.14  0.38  0.12      0.17  0.36  0.14      0.20  0.37  0.16
          chongqing2 1189.1129      0.78  0.33  0.57      0.79  0.32  0.58      0.80  0.32  0.59
forget mean min: 0.990712 0.722324
abs_mean, abs_mean+, abs_mean-: 1.98899 1.64558 5.25909
U_c = [[-0.06401688]] U_f = [[ 0.]] b_c = [ 0.10738797] b_f = [ 1.]

chengdu0
            chengdu0  509.6825      0.43  0.31  0.36      0.47  0.28  0.40      0.49  0.22  0.42
            chengdu0 1996.7963      0.90  0.22  0.71      0.91  0.21  0.73      0.92  0.18  0.76
forget mean min: 0.971691 0.763293
abs_mean, abs_mean+, abs_mean-: 3.74245 3.32136 4.7621
U_c = [[-0.03433074]] U_f = [[ 0.]] b_c = [ 0.23826095] b_f = [ 1.]

chengdu1
            chengdu1  468.0718      0.51  0.30  0.41      0.56  0.27  0.46      0.59  0.20  0.51
            chengdu1 2032.1977      0.88  0.19  0.73      0.89  0.18  0.75      0.90  0.15  0.78
forget mean min: 0.961745 0.71203
abs_mean, abs_mean+, abs_mean-: 3.95308 3.36028 5.07967
U_c = [[-0.01838142]] U_f = [[ 0.]] b_c = [ 0.30808905] b_f = [ 1.]

chengdu2
            chengdu2  517.7442      0.51  0.35  0.40      0.56  0.31  0.45      0.60  0.25  0.50
            chengdu2 2037.3487      0.93  0.25  0.71      0.94  0.24  0.72      0.95  0.22  0.75
forget mean min: 0.975858 0.72143
abs_mean, abs_mean+, abs_mean-: 3.75005 3.41202 4.7424
U_c = [[-0.03868558]] U_f = [[ 0.]] b_c = [ 0.22047909] b_f = [ 1.]

nanchang0
           nanchang0 1037.7766      0.22  0.48  0.18      0.24  0.43  0.20      0.24  0.42  0.20
           nanchang0 1809.4304      0.64  0.38  0.46      0.63  0.36  0.47      0.65  0.35  0.48
forget mean min: 0.952906 0.214144
abs_mean, abs_mean+, abs_mean-: 3.43657 2.40937 6.43178
U_c = [[-0.08622906]] U_f = [[ 0.]] b_c = [ 0.1469724] b_f = [ 1.]

nanchang1
           nanchang1 1031.8663      0.22  0.47  0.18      0.25  0.42  0.21      0.25  0.40  0.21
           nanchang1 1826.3187      0.65  0.38  0.47      0.64  0.37  0.47      0.66  0.35  0.48
forget mean min: 0.954267 0.221344
abs_mean, abs_mean+, abs_mean-: 3.51031 2.47458 6.57641
U_c = [[-0.08326694]] U_f = [[ 0.]] b_c = [ 0.15097022] b_f = [ 1.]

nanchang2
           nanchang2  909.9107      0.25  0.32  0.22      0.29  0.24  0.25      0.28  0.20  0.25
           nanchang2 1828.7076      0.62  0.35  0.47      0.62  0.34  0.47      0.65  0.32  0.50
forget mean min: 0.964663 0.342146
abs_mean, abs_mean+, abs_mean-: 3.03685 2.26254 4.73332
U_c = [[-0.0313106]] U_f = [[ 0.]] b_c = [ 0.1813755] b_f = [ 1.]

changsha0
           changsha0  758.5723      0.64  0.41  0.45      0.70  0.33  0.52      0.73  0.28  0.56
           changsha0 3160.6129      0.42  0.29  0.37      0.42  0.27  0.37      0.41  0.24  0.37
forget mean min: 0.938786 0.788317
abs_mean, abs_mean+, abs_mean-: 3.30828 2.56444 3.90672
U_c = [[-0.05898638]] U_f = [[ 0.]] b_c = [ 0.25948638] b_f = [ 1.]

changsha1
           changsha1  893.8819      0.39  0.35  0.32      0.44  0.26  0.38      0.45  0.19  0.41
           changsha1 3437.9317      0.34  0.23  0.31      0.35  0.18  0.32      0.34  0.11  0.32
forget mean min: 0.926874 0.635557
abs_mean, abs_mean+, abs_mean-: 3.69562 2.08695 4.61336
U_c = [[-0.11735117]] U_f = [[ 0.]] b_c = [ 0.17619322] b_f = [ 1.]

changsha2
           changsha2  846.7704      0.71  0.45  0.45      0.76  0.39  0.51      0.79  0.36  0.54
           changsha2 3229.9011      0.43  0.19  0.39      0.43  0.16  0.40      0.42  0.12  0.39
forget mean min: 0.929045 0.763492
abs_mean, abs_mean+, abs_mean-: 3.79695 3.17574 4.27863
U_c = [[-0.03750661]] U_f = [[ 0.]] b_c = [ 0.30536434] b_f = [ 1.]

guangzhou0
          guangzhou0  189.1313      0.48  0.54  0.31      0.65  0.53  0.38      0.85  0.44  0.51
          guangzhou0  741.9891      0.44  0.24  0.39      0.47  0.19  0.42      0.45  0.12  0.41
forget mean min: 0.853652 0.514821
abs_mean, abs_mean+, abs_mean-: 3.94579 3.80827 4.06687
U_c = [[-0.06159347]] U_f = [[ 0.]] b_c = [ 0.68233627] b_f = [ 1.]

guangzhou1
          guangzhou1  270.4492      0.31  0.57  0.22      0.46  0.54  0.30      0.65  0.48  0.40
          guangzhou1  906.5924      0.11  -nan  0.09      0.11  -nan  0.09      0.11  -nan  0.10
forget mean min: 0.892715 0.516585
abs_mean, abs_mean+, abs_mean-: 2.62073 2.12569 3.16566
U_c = [[-0.07750149]] U_f = [[ 0.]] b_c = [ 0.31950605] b_f = [ 1.]

guangzhou2
          guangzhou2  174.9914      0.55  0.52  0.34      0.67  0.53  0.38      0.84  0.43  0.51
          guangzhou2  646.5230      0.60  0.31  0.48      0.66  0.27  0.53      0.65  0.21  0.55
forget mean min: 0.842554 0.563442
abs_mean, abs_mean+, abs_mean-: 4.97536 4.95274 4.99703
U_c = [[-0.07359318]] U_f = [[ 0.]] b_c = [ 0.86867267] b_f = [ 1.]
