X_train[0].shape = (6552, 40, 23)

training nanjing0
Train on 6552 samples, validate on 387 samples
Before training:
            nanjing0 3335.5625      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.03708 nan 3.03708
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            nanjing016408.7151      0.03  -nan  0.03      0.03  -nan  0.03      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.2789 nan 6.2789
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2196.9914 - val_loss: 10148.7230
Epoch 00000: val_loss improved from inf to 10148.72304, saving model to nanjing0_weights.hdf5
            nanjing0 1319.8256      0.10  0.39  0.09      0.10  0.49  0.09      0.10  0.59  0.09
            nanjing010148.7229      0.30  0.03  0.29      0.28  0.01  0.28      0.22  0.00  0.22
forget mean min: 0.77316 0.317765
incx.max(), incx.min(), incx.mean() 2.58083 -2.1264 0.681945
fgtx.max(), fgtx.min(), fgtx.mean() 2.11534 -1.91117 0.491065
abs_mean, abs_mean+, abs_mean-: 8.44691 2.17253 11.9125
U_c = [[-0.14149183]] U_f = [[ 0.]] b_c = [ 0.10786457] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.131932 -0.132534 -0.0262175 0.130356
W_f max, min, mean, abs_mean: 0.11264 -0.11402 -0.0228398 0.111504
Epoch 2/300
1s - loss: 968.7927 - val_loss: 4593.9447
Epoch 00001: val_loss improved from 10148.72304 to 4593.94467, saving model to nanjing0_weights.hdf5
            nanjing0  820.7374      0.32  0.38  0.27      0.32  0.37  0.27      0.32  0.32  0.27
            nanjing0 4593.9446      0.89  0.19  0.74      0.88  0.16  0.75      0.89  0.14  0.78
forget mean min: 0.975766 0.65766
incx.max(), incx.min(), incx.mean() 3.87943 -0.1646 3.00299
fgtx.max(), fgtx.min(), fgtx.mean() 2.2667 -0.211701 1.72958
abs_mean, abs_mean+, abs_mean-: 4.05266 3.30102 6.49756
U_c = [[-0.132211]] U_f = [[ 0.]] b_c = [ 0.18084459] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.206951 -0.207539 -0.0412158 0.205383
W_f max, min, mean, abs_mean: 0.127 -0.128488 -0.0257245 0.12587
Epoch 3/300
1s - loss: 792.6770 - val_loss: 5339.3747
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 759.4504 - val_loss: 5646.8994
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 743.0596 - val_loss: 5649.9079
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 736.4574 - val_loss: 5793.7470
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 734.4549 - val_loss: 6111.5634
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 731.5889 - val_loss: 6166.2230
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 728.4233 - val_loss: 6315.0761
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 724.2319 - val_loss: 6322.9900
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 718.8259 - val_loss: 6308.6310
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 710.9523 - val_loss: 6582.1354
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 696.9483 - val_loss: 6440.0870
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 682.4374 - val_loss: 6530.8452
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 671.0342 - val_loss: 6658.1993
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 664.8963 - val_loss: 6807.0943
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 659.6033 - val_loss: 6504.8665
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 653.1331 - val_loss: 6691.6092
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 647.5850 - val_loss: 6247.9343
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 641.3140 - val_loss: 6243.3170
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 633.7264 - val_loss: 6288.3645
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 623.8671 - val_loss: 6561.2501
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 610.9723 - val_loss: 6547.7831
Epoch 00022: val_loss did not improve
X_train[0].shape = (6552, 40, 23)

training shanghai0
Train on 6552 samples, validate on 387 samples
Before training:
           shanghai0 2955.7240      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.04769 nan 3.04769
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           shanghai014602.3560      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.22998 nan 5.22998
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1927.9619 - val_loss: 7202.4647
Epoch 00000: val_loss improved from inf to 7202.46466, saving model to shanghai0_weights.hdf5
           shanghai0 1140.5130      0.08  0.46  0.07      0.08  0.41  0.07      0.07  0.47  0.07
           shanghai0 7202.4647      0.25  0.31  0.22      0.24  0.26  0.22      0.20  0.14  0.20
forget mean min: 0.874054 0.341599
incx.max(), incx.min(), incx.mean() 2.55426 -1.95672 1.30519
fgtx.max(), fgtx.min(), fgtx.mean() 2.12346 -1.79201 1.03928
abs_mean, abs_mean+, abs_mean-: 6.15583 2.13961 10.5139
U_c = [[-0.14490113]] U_f = [[ 0.]] b_c = [ 0.10784708] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.133455 -0.133576 -0.0130061 0.131718
W_f max, min, mean, abs_mean: 0.116093 -0.115995 -0.0114768 0.11433
Epoch 2/300
1s - loss: 870.1949 - val_loss: 5254.5627
Epoch 00001: val_loss improved from 7202.46466 to 5254.56271, saving model to shanghai0_weights.hdf5
           shanghai0  749.8049      0.24  0.36  0.21      0.25  0.35  0.21      0.24  0.38  0.20
           shanghai0 5254.5627      0.54  0.23  0.46      0.52  0.19  0.46      0.46  0.13  0.43
forget mean min: 0.949796 0.671469
incx.max(), incx.min(), incx.mean() 4.11205 -0.0904773 2.89206
fgtx.max(), fgtx.min(), fgtx.mean() 1.96941 -0.142655 1.35627
abs_mean, abs_mean+, abs_mean-: 4.20906 3.16553 5.61531
U_c = [[-0.11873113]] U_f = [[ 0.]] b_c = [ 0.19339187] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.220854 -0.220987 -0.0217517 0.219133
W_f max, min, mean, abs_mean: 0.111992 -0.11207 -0.0111178 0.110131
Epoch 3/300
1s - loss: 724.1267 - val_loss: 5506.6263
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 707.1310 - val_loss: 5333.7426
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 702.8966 - val_loss: 5244.3604
Epoch 00004: val_loss improved from 5254.56271 to 5244.36040, saving model to shanghai0_weights.hdf5
           shanghai0  707.2170      0.47  0.41  0.36      0.50  0.38  0.39      0.53  0.34  0.41
           shanghai0 5244.3604      0.57  0.21  0.49      0.54  0.17  0.48      0.49  0.12  0.45
forget mean min: 0.927517 0.56817
incx.max(), incx.min(), incx.mean() 6.74006 -1.90284 4.32732
fgtx.max(), fgtx.min(), fgtx.mean() 1.89497 -0.659152 1.18195
abs_mean, abs_mean+, abs_mean-: 5.82086 4.61335 7.33818
U_c = [[-0.07798683]] U_f = [[ 0.]] b_c = [ 0.3276991] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.349076 -0.349252 -0.0346018 0.347407
W_f max, min, mean, abs_mean: 0.104639 -0.104768 -0.0103937 0.102666
Epoch 6/300
1s - loss: 700.4011 - val_loss: 5106.5395
Epoch 00005: val_loss improved from 5244.36040 to 5106.53951, saving model to shanghai0_weights.hdf5
           shanghai0  697.5871      0.50  0.40  0.38      0.54  0.36  0.42      0.57  0.32  0.44
           shanghai0 5106.5395      0.59  0.19  0.51      0.57  0.17  0.50      0.50  0.12  0.46
forget mean min: 0.927052 0.546181
incx.max(), incx.min(), incx.mean() 7.15023 -2.3552 4.52132
fgtx.max(), fgtx.min(), fgtx.mean() 1.93136 -0.769096 1.18448
abs_mean, abs_mean+, abs_mean-: 5.99779 4.83693 7.47883
U_c = [[-0.07842009]] U_f = [[ 0.]] b_c = [ 0.35199752] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.367973 -0.368169 -0.0364982 0.366314
W_f max, min, mean, abs_mean: 0.10607 -0.106208 -0.010539 0.10407
Epoch 7/300
1s - loss: 694.3039 - val_loss: 5048.8482
Epoch 00006: val_loss improved from 5106.53951 to 5048.84822, saving model to shanghai0_weights.hdf5
           shanghai0  696.9574      0.43  0.37  0.34      0.46  0.33  0.37      0.48  0.29  0.40
           shanghai0 5048.8482      0.61  0.20  0.52      0.58  0.17  0.51      0.52  0.12  0.48
forget mean min: 0.929599 0.539635
incx.max(), incx.min(), incx.mean() 7.41102 -2.52837 4.69418
fgtx.max(), fgtx.min(), fgtx.mean() 1.94222 -0.801825 1.19214
abs_mean, abs_mean+, abs_mean-: 5.94341 4.80988 7.49908
U_c = [[-0.08221409]] U_f = [[ 0.]] b_c = [ 0.3759867] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.385305 -0.385537 -0.0382381 0.383651
W_f max, min, mean, abs_mean: 0.107939 -0.108088 -0.0107294 0.105918
Epoch 8/300
1s - loss: 685.2115 - val_loss: 5309.1494
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 671.1636 - val_loss: 5153.0859
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 659.5474 - val_loss: 5097.5100
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 652.5068 - val_loss: 5404.7653
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 644.4070 - val_loss: 5572.5698
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 637.4285 - val_loss: 5242.2512
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 627.7510 - val_loss: 5353.0733
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 618.2728 - val_loss: 5086.7584
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 606.8780 - val_loss: 5299.9761
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 590.4905 - val_loss: 5327.9723
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 571.5269 - val_loss: 5332.1316
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 548.6976 - val_loss: 5510.6757
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 527.1401 - val_loss: 5595.1812
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 507.6378 - val_loss: 5492.7587
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 492.1218 - val_loss: 5798.7905
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 478.5556 - val_loss: 5904.6464
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 465.6135 - val_loss: 5644.0782
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 453.9849 - val_loss: 5599.3089
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 443.7653 - val_loss: 5655.9146
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 433.9879 - val_loss: 5571.4621
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 426.7374 - val_loss: 5550.4767
Epoch 00027: val_loss did not improve
X_train[0].shape = (8008, 40, 23)

training hangzhou0
Train on 8008 samples, validate on 473 samples
Before training:
           hangzhou0 2918.2103      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.11296 nan 3.11296
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           hangzhou014404.7389      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.98728 nan 5.98728
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1697.8189 - val_loss: 8672.4477
Epoch 00000: val_loss improved from inf to 8672.44772, saving model to hangzhou0_weights.hdf5
           hangzhou0  932.3839      0.08  0.38  0.07      0.08  0.38  0.07      0.09  0.34  0.08
           hangzhou0 8672.4479      0.28  0.42  0.24      0.25  0.43  0.22      0.20  0.44  0.19
forget mean min: 0.857783 0.279977
incx.max(), incx.min(), incx.mean() 2.80019 -2.66526 1.33389
fgtx.max(), fgtx.min(), fgtx.mean() 2.01426 -2.10012 0.910443
abs_mean, abs_mean+, abs_mean-: 6.92474 2.24947 12.0746
U_c = [[-0.16482796]] U_f = [[ 0.]] b_c = [ 0.12449906] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.148811 -0.148862 0.0287454 0.146745
W_f max, min, mean, abs_mean: 0.112003 -0.111718 0.0215223 0.110467
Epoch 2/300
1s - loss: 740.8519 - val_loss: 6187.4264
Epoch 00001: val_loss improved from 8672.44772 to 6187.42636, saving model to hangzhou0_weights.hdf5
           hangzhou0  675.8059      0.21  0.40  0.18      0.23  0.38  0.20      0.24  0.33  0.21
           hangzhou0 6187.4265      0.60  0.43  0.42      0.61  0.39  0.45      0.63  0.34  0.50
forget mean min: 0.955721 0.418719
incx.max(), incx.min(), incx.mean() 4.03217 -2.61449 2.97212
fgtx.max(), fgtx.min(), fgtx.mean() 1.90975 -1.40641 1.38088
abs_mean, abs_mean+, abs_mean-: 4.57973 3.05752 8.75604
U_c = [[-0.14184439]] U_f = [[ 0.]] b_c = [ 0.20440683] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.214879 -0.214922 0.0419644 0.212826
W_f max, min, mean, abs_mean: 0.107779 -0.107221 0.0206913 0.106182
Epoch 3/300
1s - loss: 640.9825 - val_loss: 5916.6986
Epoch 00002: val_loss improved from 6187.42636 to 5916.69863, saving model to hangzhou0_weights.hdf5
           hangzhou0  632.1857      0.16  0.47  0.13      0.18  0.44  0.15      0.19  0.39  0.16
           hangzhou0 5916.6986      0.55  0.39  0.42      0.55  0.36  0.44      0.56  0.31  0.47
forget mean min: 0.953742 0.615686
incx.max(), incx.min(), incx.mean() 3.6617 -0.555533 2.53301
fgtx.max(), fgtx.min(), fgtx.mean() 1.96532 -0.421568 1.32652
abs_mean, abs_mean+, abs_mean-: 3.79409 2.56667 5.32178
U_c = [[-0.09149881]] U_f = [[ 0.]] b_c = [ 0.18931755] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.200138 -0.200144 0.0390328 0.198095
W_f max, min, mean, abs_mean: 0.113756 -0.113102 0.0218959 0.112118
Epoch 4/300
1s - loss: 624.1320 - val_loss: 5474.8758
Epoch 00003: val_loss improved from 5916.69863 to 5474.87584, saving model to hangzhou0_weights.hdf5
           hangzhou0  628.3173      0.35  0.40  0.28      0.39  0.38  0.31      0.42  0.34  0.34
           hangzhou0 5474.8760      0.80  0.40  0.53      0.82  0.36  0.56      0.85  0.32  0.61
forget mean min: 0.971931 0.583994
incx.max(), incx.min(), incx.mean() 3.63434 -0.690193 2.51898
fgtx.max(), fgtx.min(), fgtx.mean() 2.29329 -0.580032 1.55224
abs_mean, abs_mean+, abs_mean-: 3.47159 2.68288 5.10417
U_c = [[-0.07575598]] U_f = [[ 0.]] b_c = [ 0.18279685] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.195759 -0.19572 0.0381726 0.19371
W_f max, min, mean, abs_mean: 0.130344 -0.129686 0.0252167 0.128705
Epoch 5/300
1s - loss: 618.9336 - val_loss: 5228.7655
Epoch 00004: val_loss improved from 5474.87584 to 5228.76554, saving model to hangzhou0_weights.hdf5
           hangzhou0  617.1057      0.37  0.39  0.30      0.43  0.35  0.34      0.47  0.31  0.38
           hangzhou0 5228.7655      0.81  0.39  0.54      0.83  0.35  0.58      0.85  0.31  0.62
forget mean min: 0.971299 0.622222
incx.max(), incx.min(), incx.mean() 3.63112 -0.37848 2.46039
fgtx.max(), fgtx.min(), fgtx.mean() 2.40029 -0.388889 1.58592
abs_mean, abs_mean+, abs_mean-: 3.65111 2.67425 5.79781
U_c = [[-0.06853242]] U_f = [[ 0.]] b_c = [ 0.18057367] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.196319 -0.196227 0.0382993 0.194253
W_f max, min, mean, abs_mean: 0.136769 -0.136104 0.0265035 0.135127
Epoch 6/300
1s - loss: 613.8078 - val_loss: 5270.8026
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 606.9624 - val_loss: 4982.4029
Epoch 00006: val_loss improved from 5228.76554 to 4982.40291, saving model to hangzhou0_weights.hdf5
           hangzhou0  604.1863      0.41  0.39  0.33      0.47  0.35  0.37      0.50  0.32  0.41
           hangzhou0 4982.4028      0.89  0.39  0.56      0.90  0.36  0.60      0.93  0.32  0.64
forget mean min: 0.977155 0.567772
incx.max(), incx.min(), incx.mean() 3.65862 -0.683716 2.44523
fgtx.max(), fgtx.min(), fgtx.mean() 2.6692 -0.661139 1.73861
abs_mean, abs_mean+, abs_mean-: 3.55637 2.67216 6.05248
U_c = [[-0.06327032]] U_f = [[ 0.]] b_c = [ 0.17834987] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.199096 -0.19887 0.0388748 0.196965
W_f max, min, mean, abs_mean: 0.152727 -0.152041 0.029683 0.151062
Epoch 8/300
1s - loss: 602.0281 - val_loss: 5203.5272
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 594.8832 - val_loss: 5444.2833
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 588.3904 - val_loss: 5356.7696
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 580.4582 - val_loss: 5667.4502
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 573.4292 - val_loss: 5710.9905
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 566.8327 - val_loss: 5591.9848
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 560.3247 - val_loss: 5651.3742
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 553.6196 - val_loss: 5376.6305
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 548.4545 - val_loss: 5758.5603
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 543.5877 - val_loss: 5534.4246
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 537.7066 - val_loss: 5522.5490
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 533.9089 - val_loss: 5877.7828
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 526.8245 - val_loss: 5512.0470
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 520.3364 - val_loss: 5570.8512
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 509.2901 - val_loss: 5265.1354
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 494.6305 - val_loss: 5701.4958
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 483.7820 - val_loss: 5917.2871
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 471.0094 - val_loss: 5795.4994
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 460.9044 - val_loss: 6019.9392
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 447.5038 - val_loss: 6240.0706
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 433.6321 - val_loss: 6502.2335
Epoch 00027: val_loss did not improve
X_train[0].shape = (6552, 40, 23)

training hefei0
Train on 6552 samples, validate on 387 samples
Before training:
              hefei0 5262.8136      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.76109 nan 3.76109
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              hefei020206.4077      0.03  -nan  0.03      0.03  -nan  0.03      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 7.31785 nan 7.31785
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3667.5327 - val_loss: 10677.3575
Epoch 00000: val_loss improved from inf to 10677.35748, saving model to hefei0_weights.hdf5
              hefei0 2144.0064      0.23  0.37  0.20      0.26  0.31  0.23      0.25  0.26  0.22
              hefei010677.3574      0.50  0.19  0.45      0.50  0.11  0.47      0.42  0.08  0.40
forget mean min: 0.829149 0.310359
incx.max(), incx.min(), incx.mean() 2.62436 -2.00915 1.12673
fgtx.max(), fgtx.min(), fgtx.mean() 2.31485 -1.94821 0.936962
abs_mean, abs_mean+, abs_mean-: 9.21972 2.28527 17.6291
U_c = [[-0.14808443]] U_f = [[ 0.]] b_c = [ 0.10836019] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.134879 -0.134553 0.0135278 0.13165
W_f max, min, mean, abs_mean: 0.123094 -0.122698 0.0128575 0.121125
Epoch 2/300
1s - loss: 1636.6884 - val_loss: 6763.1586
Epoch 00001: val_loss improved from 10677.35748 to 6763.15856, saving model to hefei0_weights.hdf5
              hefei0 1465.1500      0.47  0.42  0.35      0.51  0.40  0.38      0.52  0.35  0.40
              hefei0 6763.1583      0.91  0.26  0.69      0.96  0.20  0.77      0.96  0.14  0.83
forget mean min: 0.966073 0.557518
incx.max(), incx.min(), incx.mean() 4.4189 -1.26632 3.41449
fgtx.max(), fgtx.min(), fgtx.mean() 2.06488 -0.712409 1.57422
abs_mean, abs_mean+, abs_mean-: 5.38609 3.77588 9.4551
U_c = [[-0.19490831]] U_f = [[ 0.]] b_c = [ 0.19203109] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.2211 -0.220773 0.0221396 0.21788
W_f max, min, mean, abs_mean: 0.108441 -0.107935 0.011391 0.106438
Epoch 3/300
1s - loss: 1394.5654 - val_loss: 6616.3476
Epoch 00002: val_loss improved from 6763.15856 to 6616.34765, saving model to hefei0_weights.hdf5
              hefei0 1346.2482      0.58  0.44  0.40      0.63  0.42  0.43      0.64  0.38  0.46
              hefei0 6616.3476      0.99  0.27  0.72      0.99  0.23  0.76      1.00  0.15  0.85
forget mean min: 0.981622 0.745823
incx.max(), incx.min(), incx.mean() 5.73504 0.925887 4.78211
fgtx.max(), fgtx.min(), fgtx.mean() 1.86682 0.229115 1.5423
abs_mean, abs_mean+, abs_mean-: 5.01596 4.82881 5.83094
U_c = [[-0.18948731]] U_f = [[ 0.]] b_c = [ 0.25312644] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.282071 -0.281739 0.0282327 0.27886
W_f max, min, mean, abs_mean: 0.0970292 -0.0964261 0.0102389 0.094964
Epoch 4/300
1s - loss: 1337.1127 - val_loss: 6807.5267
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1317.8812 - val_loss: 7089.4803
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1305.6138 - val_loss: 7492.2267
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1294.7979 - val_loss: 7571.5957
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1287.0485 - val_loss: 7842.8777
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1285.8690 - val_loss: 7683.2405
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1284.6260 - val_loss: 7724.2260
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1277.4386 - val_loss: 7900.5310
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1275.3126 - val_loss: 7959.8476
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1272.2108 - val_loss: 8047.9801
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1268.7679 - val_loss: 7983.6916
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1261.0961 - val_loss: 7876.9587
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1253.2234 - val_loss: 8015.0020
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1247.5279 - val_loss: 8399.7371
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1237.2075 - val_loss: 8198.7878
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1227.8006 - val_loss: 8413.1893
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1222.1363 - val_loss: 8568.4149
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1217.5290 - val_loss: 8343.9674
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1201.7480 - val_loss: 8703.5253
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1191.3974 - val_loss: 8396.2597
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1176.2687 - val_loss: 8483.0253
Epoch 00023: val_loss did not improve
X_train[0].shape = (7280, 40, 23)

training wuhan0
Train on 7280 samples, validate on 430 samples
Before training:
              wuhan0 4646.7894      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.77183 nan 3.77183
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              wuhan023819.0397      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.22035 nan 6.22035
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3005.4663 - val_loss: 15970.0109
Epoch 00000: val_loss improved from inf to 15970.01094, saving model to wuhan0_weights.hdf5
              wuhan0 1782.6496      0.22  0.46  0.18      0.25  0.40  0.21      0.24  0.37  0.21
              wuhan015970.0105      0.28  0.19  0.26      0.26  0.17  0.25      0.23  0.14  0.23
forget mean min: 0.806826 0.380682
incx.max(), incx.min(), incx.mean() 2.60625 -1.69977 0.879404
fgtx.max(), fgtx.min(), fgtx.mean() 2.18965 -1.59659 0.671306
abs_mean, abs_mean+, abs_mean-: 8.36571 2.10861 12.3907
U_c = [[-0.15297785]] U_f = [[ 0.]] b_c = [ 0.11593582] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.140168 -0.140192 0.000651375 0.137566
W_f max, min, mean, abs_mean: 0.122585 -0.122593 -0.000188592 0.120952
Epoch 2/300
1s - loss: 1268.7907 - val_loss: 8870.7655
Epoch 00001: val_loss improved from 15970.01094 to 8870.76550, saving model to wuhan0_weights.hdf5
              wuhan0 1152.8380      0.56  0.46  0.38      0.61  0.42  0.42      0.61  0.41  0.43
              wuhan0 8870.7653      0.83  0.13  0.74      0.84  0.08  0.78      0.85  0.05  0.81
forget mean min: 0.973814 0.811362
incx.max(), incx.min(), incx.mean() 4.02151 1.27508 3.05034
fgtx.max(), fgtx.min(), fgtx.mean() 1.96964 0.55681 1.47007
abs_mean, abs_mean+, abs_mean-: 3.76758 3.10072 5.38467
U_c = [[-0.12099563]] U_f = [[ 0.]] b_c = [ 0.19270098] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.213542 -0.213565 0.000654066 0.210941
W_f max, min, mean, abs_mean: 0.110139 -0.110148 -0.000216454 0.108512
Epoch 3/300
1s - loss: 1136.3045 - val_loss: 8860.1123
Epoch 00002: val_loss improved from 8870.76550 to 8860.11234, saving model to wuhan0_weights.hdf5
              wuhan0 1116.3312      0.61  0.48  0.39      0.65  0.45  0.42      0.65  0.44  0.43
              wuhan0 8860.1123      0.78  0.12  0.71      0.79  0.08  0.75      0.81  0.05  0.78
forget mean min: 0.97169 0.797212
incx.max(), incx.min(), incx.mean() 4.14044 1.18338 3.0886
fgtx.max(), fgtx.min(), fgtx.mean() 1.96748 0.486062 1.44054
abs_mean, abs_mean+, abs_mean-: 3.55412 2.95801 4.77336
U_c = [[-0.0837175]] U_f = [[ 0.]] b_c = [ 0.21315025] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.221284 -0.221303 0.000650479 0.218687
W_f max, min, mean, abs_mean: 0.1112 -0.111197 -0.00022377 0.109555
Epoch 4/300
1s - loss: 1112.0390 - val_loss: 9850.9385
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1105.3256 - val_loss: 9531.5789
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1099.0836 - val_loss: 9411.3875
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1094.9290 - val_loss: 9978.4900
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1083.3494 - val_loss: 9237.3185
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1064.5694 - val_loss: 8049.9495
Epoch 00008: val_loss improved from 8860.11234 to 8049.94950, saving model to wuhan0_weights.hdf5
              wuhan0 1042.2219      0.59  0.44  0.40      0.62  0.42  0.43      0.61  0.42  0.43
              wuhan0 8049.9496      0.86  0.12  0.77      0.87  0.07  0.82      0.88  0.05  0.84
forget mean min: 0.972413 0.748465
incx.max(), incx.min(), incx.mean() 4.59562 0.792049 3.4026
fgtx.max(), fgtx.min(), fgtx.mean() 2.02959 0.242327 1.46906
abs_mean, abs_mean+, abs_mean-: 4.1456 3.29953 6.14849
U_c = [[-0.04039029]] U_f = [[ 0.]] b_c = [ 0.27511472] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.245276 -0.245275 0.000647589 0.242689
W_f max, min, mean, abs_mean: 0.115644 -0.115695 -0.000224211 0.114
Epoch 10/300
1s - loss: 1026.6188 - val_loss: 9135.9126
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 985.2668 - val_loss: 9154.3733
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 942.0444 - val_loss: 9014.7470
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 905.0155 - val_loss: 9255.1062
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 876.8280 - val_loss: 9909.3694
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 844.6660 - val_loss: 10803.9039
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 818.8884 - val_loss: 10660.3212
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 788.1266 - val_loss: 10657.0973
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 761.1566 - val_loss: 11001.9038
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 742.4230 - val_loss: 10940.1022
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 720.8086 - val_loss: 10969.7534
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 704.2141 - val_loss: 11398.8015
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 682.4314 - val_loss: 11500.0261
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 667.5096 - val_loss: 11546.0688
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 651.6594 - val_loss: 11907.6161
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 639.1149 - val_loss: 11665.1856
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 630.8824 - val_loss: 11956.2041
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 619.4130 - val_loss: 11869.5320
Epoch 00026: val_loss did not improve
Epoch 28/300
1s - loss: 609.7471 - val_loss: 11845.5780
Epoch 00027: val_loss did not improve
Epoch 29/300
1s - loss: 604.6039 - val_loss: 11643.3245
Epoch 00028: val_loss did not improve
Epoch 30/300
1s - loss: 597.3768 - val_loss: 11976.6128
Epoch 00029: val_loss did not improve
X_train[0].shape = (6552, 40, 23)

training nanchang0
Train on 6552 samples, validate on 387 samples
Before training:
           nanchang0 2288.8435      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 2.46303 nan 2.46303
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           nanchang0 6694.9588      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.22558 nan 4.22558
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1538.4338 - val_loss: 4335.1130
Epoch 00000: val_loss improved from inf to 4335.11301, saving model to nanchang0_weights.hdf5
           nanchang0 1065.4383      0.08  0.56  0.07      0.10  0.46  0.09      0.10  0.48  0.09
           nanchang0 4335.1130      0.05  -nan  0.05      0.04  -nan  0.04      0.02  -nan  0.02
forget mean min: 0.743629 0.295086
incx.max(), incx.min(), incx.mean() 2.3564 -2.19954 0.440851
fgtx.max(), fgtx.min(), fgtx.mean() 1.98259 -2.02457 0.297783
abs_mean, abs_mean+, abs_mean-: 5.90079 1.90079 8.02844
U_c = [[-0.1283862]] U_f = [[ 0.]] b_c = [ 0.10229391] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.123776 -0.123822 0.0123593 0.121055
W_f max, min, mean, abs_mean: 0.108898 -0.108691 0.0109389 0.106471
Epoch 2/300
1s - loss: 882.4894 - val_loss: 2921.9750
Epoch 00001: val_loss improved from 4335.11301 to 2921.97502, saving model to nanchang0_weights.hdf5
           nanchang0  761.3843      0.20  0.41  0.17      0.23  0.34  0.19      0.23  0.32  0.20
           nanchang0 2921.9750      0.46  0.35  0.37      0.45  0.33  0.37      0.46  0.29  0.39
forget mean min: 0.943859 0.265596
incx.max(), incx.min(), incx.mean() 3.0071 -2.68425 2.0289
fgtx.max(), fgtx.min(), fgtx.mean() 2.16923 -2.17202 1.42311
abs_mean, abs_mean+, abs_mean-: 3.65537 2.32506 7.89379
U_c = [[-0.07489569]] U_f = [[ 0.]] b_c = [ 0.16324604] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.162375 -0.162417 0.0162242 0.159698
W_f max, min, mean, abs_mean: 0.124229 -0.123872 0.0124662 0.121811
Epoch 3/300
1s - loss: 725.7005 - val_loss: 2728.1586
Epoch 00002: val_loss improved from 2921.97502 to 2728.15861, saving model to nanchang0_weights.hdf5
           nanchang0  699.0080      0.28  0.41  0.22      0.32  0.36  0.26      0.33  0.32  0.27
           nanchang0 2728.1586      0.50  0.35  0.39      0.49  0.33  0.39      0.50  0.29  0.42
forget mean min: 0.961938 0.471785
incx.max(), incx.min(), incx.mean() 2.72292 -1.26359 1.98271
fgtx.max(), fgtx.min(), fgtx.mean() 2.03067 -1.14108 1.44178
abs_mean, abs_mean+, abs_mean-: 3.26361 2.08523 6.65925
U_c = [[-0.03195314]] U_f = [[ 0.]] b_c = [ 0.17055196] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.156809 -0.15686 0.0156694 0.154144
W_f max, min, mean, abs_mean: 0.125055 -0.124691 0.0125446 0.122633
Epoch 4/300
1s - loss: 698.5275 - val_loss: 2632.9597
Epoch 00003: val_loss improved from 2728.15861 to 2632.95974, saving model to nanchang0_weights.hdf5
           nanchang0  711.3777      0.39  0.45  0.29      0.45  0.41  0.34      0.46  0.38  0.36
           nanchang0 2632.9598      0.50  0.35  0.39      0.49  0.34  0.39      0.50  0.29  0.41
forget mean min: 0.961725 0.509286
incx.max(), incx.min(), incx.mean() 2.7921 -1.0143 2.00853
fgtx.max(), fgtx.min(), fgtx.mean() 2.0947 -0.95357 1.46723
abs_mean, abs_mean+, abs_mean-: 3.40144 2.16126 6.6636
U_c = [[-0.02401697]] U_f = [[ 0.]] b_c = [ 0.17638026] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.158045 -0.158108 0.0157918 0.155381
W_f max, min, mean, abs_mean: 0.126848 -0.12648 0.012724 0.124426
Epoch 5/300
1s - loss: 691.3355 - val_loss: 2515.0185
Epoch 00004: val_loss improved from 2632.95974 to 2515.01847, saving model to nanchang0_weights.hdf5
           nanchang0  689.7168      0.21  0.37  0.18      0.25  0.29  0.21      0.25  0.23  0.21
           nanchang0 2515.0185      0.50  0.35  0.39      0.50  0.33  0.40      0.51  0.29  0.42
forget mean min: 0.96379 0.573875
incx.max(), incx.min(), incx.mean() 2.85587 -0.631636 2.06794
fgtx.max(), fgtx.min(), fgtx.mean() 2.06969 -0.630625 1.45965
abs_mean, abs_mean+, abs_mean-: 3.30484 2.13493 6.49147
U_c = [[-0.02558716]] U_f = [[ 0.]] b_c = [ 0.18276741] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.160871 -0.160947 0.0160718 0.158206
W_f max, min, mean, abs_mean: 0.12491 -0.124537 0.0125308 0.122489
Epoch 6/300
1s - loss: 687.8807 - val_loss: 2671.0110
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 684.6453 - val_loss: 2565.6180
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 680.0932 - val_loss: 2706.6674
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 677.8799 - val_loss: 2870.4183
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 675.6658 - val_loss: 2746.0495
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 674.1131 - val_loss: 2774.7433
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 670.0432 - val_loss: 2891.8955
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 661.4969 - val_loss: 2841.8145
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 654.8636 - val_loss: 2999.7993
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 645.3621 - val_loss: 2934.9697
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 634.3934 - val_loss: 3152.0022
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 621.1971 - val_loss: 3118.3346
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 611.4170 - val_loss: 2882.0080
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 603.4792 - val_loss: 2906.5327
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 595.3850 - val_loss: 3012.8085
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 587.6788 - val_loss: 3155.8244
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 582.5456 - val_loss: 3160.4472
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 575.6936 - val_loss: 3199.5410
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 569.5392 - val_loss: 3150.6956
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 565.6544 - val_loss: 3169.7909
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 558.0084 - val_loss: 3364.1624
Epoch 00025: val_loss did not improve
X_train[0].shape = (7280, 40, 23)

training changsha0
Train on 7280 samples, validate on 430 samples
Before training:
           changsha0 3186.1051      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.48079 nan 3.48079
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           changsha012880.4564      0.01  -nan  0.00      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.10846 nan 4.10846
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1803.1252 - val_loss: 8751.8072
Epoch 00000: val_loss improved from inf to 8751.80716, saving model to changsha0_weights.hdf5
           changsha0  968.6258      0.26  0.40  0.22      0.28  0.35  0.25      0.29  0.30  0.26
           changsha0 8751.8072      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.751494 0.323715
incx.max(), incx.min(), incx.mean() 2.4856 -2.13719 0.507945
fgtx.max(), fgtx.min(), fgtx.mean() 1.9852 -1.88142 0.331035
abs_mean, abs_mean+, abs_mean-: 6.19731 2.01566 8.35149
U_c = [[-0.14614612]] U_f = [[ 0.]] b_c = [ 0.11217213] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.131897 -0.13165 -0.0131722 0.130774
W_f max, min, mean, abs_mean: 0.110321 -0.110429 -0.0112347 0.109384
Epoch 2/300
1s - loss: 749.2399 - val_loss: 6229.1205
Epoch 00001: val_loss improved from 8751.80716 to 6229.12052, saving model to changsha0_weights.hdf5
           changsha0  664.7471      0.45  0.34  0.36      0.51  0.25  0.44      0.54  0.18  0.48
           changsha0 6229.1205      0.04  -nan  0.04      0.04  -nan  0.04      0.01  -nan  0.01
forget mean min: 0.910557 0.721505
incx.max(), incx.min(), incx.mean() 3.71427 0.426496 2.4139
fgtx.max(), fgtx.min(), fgtx.mean() 1.68249 0.107527 1.05956
abs_mean, abs_mean+, abs_mean-: 3.16138 2.03143 3.72453
U_c = [[-0.12177101]] U_f = [[ 0.]] b_c = [ 0.20204076] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.213438 -0.213189 -0.0213248 0.212313
W_f max, min, mean, abs_mean: 0.102713 -0.102802 -0.0104551 0.101708
Epoch 3/300
1s - loss: 598.5550 - val_loss: 6745.3870
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 574.1798 - val_loss: 6719.4385
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 567.5236 - val_loss: 6397.2721
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 558.4229 - val_loss: 6418.3764
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 547.2326 - val_loss: 6778.3407
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 534.0640 - val_loss: 6922.3883
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 519.4428 - val_loss: 6861.4067
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 506.6330 - val_loss: 6614.8250
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 493.5569 - val_loss: 6788.7977
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 483.0977 - val_loss: 6989.9015
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 475.5276 - val_loss: 6737.6375
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 466.3441 - val_loss: 6577.9658
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 458.0306 - val_loss: 6731.3607
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 451.7483 - val_loss: 6599.5856
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 446.1203 - val_loss: 6469.5226
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 442.0731 - val_loss: 6436.4723
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 438.3687 - val_loss: 6470.7291
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 434.5385 - val_loss: 6416.6877
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 430.5526 - val_loss: 6375.1660
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 427.2069 - val_loss: 6317.1467
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 423.9485 - val_loss: 6274.9128
Epoch 00022: val_loss did not improve

nanjing
            nanjing0  820.7374      0.32  0.38  0.27      0.32  0.37  0.27      0.32  0.32  0.27
            nanjing0 4593.9446      0.89  0.19  0.74      0.88  0.16  0.75      0.89  0.14  0.78
forget mean min: 0.975766 0.65766
incx.max(), incx.min(), incx.mean() 3.87943 -0.1646 3.00299
fgtx.max(), fgtx.min(), fgtx.mean() 2.2667 -0.211701 1.72958
abs_mean, abs_mean+, abs_mean-: 4.05266 3.30102 6.49756
U_c = [[-0.132211]] U_f = [[ 0.]] b_c = [ 0.18084459] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.206951 -0.207539 -0.0412158 0.205383
W_f max, min, mean, abs_mean: 0.127 -0.128488 -0.0257245 0.12587

shanghai
           shanghai0  696.9574      0.43  0.37  0.34      0.46  0.33  0.37      0.48  0.29  0.40
           shanghai0 5048.8482      0.61  0.20  0.52      0.58  0.17  0.51      0.52  0.12  0.48
forget mean min: 0.929599 0.539635
incx.max(), incx.min(), incx.mean() 7.41102 -2.52837 4.69418
fgtx.max(), fgtx.min(), fgtx.mean() 1.94222 -0.801825 1.19214
abs_mean, abs_mean+, abs_mean-: 5.94341 4.80988 7.49908
U_c = [[-0.08221409]] U_f = [[ 0.]] b_c = [ 0.3759867] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.385305 -0.385537 -0.0382381 0.383651
W_f max, min, mean, abs_mean: 0.107939 -0.108088 -0.0107294 0.105918

hangzhou
           hangzhou0  604.1863      0.41  0.39  0.33      0.47  0.35  0.37      0.50  0.32  0.41
           hangzhou0 4982.4028      0.89  0.39  0.56      0.90  0.36  0.60      0.93  0.32  0.64
forget mean min: 0.977155 0.567772
incx.max(), incx.min(), incx.mean() 3.65862 -0.683716 2.44523
fgtx.max(), fgtx.min(), fgtx.mean() 2.6692 -0.661139 1.73861
abs_mean, abs_mean+, abs_mean-: 3.55637 2.67216 6.05248
U_c = [[-0.06327032]] U_f = [[ 0.]] b_c = [ 0.17834987] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.199096 -0.19887 0.0388748 0.196965
W_f max, min, mean, abs_mean: 0.152727 -0.152041 0.029683 0.151062

hefei
              hefei0 1346.2482      0.58  0.44  0.40      0.63  0.42  0.43      0.64  0.38  0.46
              hefei0 6616.3476      0.99  0.27  0.72      0.99  0.23  0.76      1.00  0.15  0.85
forget mean min: 0.981622 0.745823
incx.max(), incx.min(), incx.mean() 5.73504 0.925887 4.78211
fgtx.max(), fgtx.min(), fgtx.mean() 1.86682 0.229115 1.5423
abs_mean, abs_mean+, abs_mean-: 5.01596 4.82881 5.83094
U_c = [[-0.18948731]] U_f = [[ 0.]] b_c = [ 0.25312644] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.282071 -0.281739 0.0282327 0.27886
W_f max, min, mean, abs_mean: 0.0970292 -0.0964261 0.0102389 0.094964

wuhan
              wuhan0 1042.2219      0.59  0.44  0.40      0.62  0.42  0.43      0.61  0.42  0.43
              wuhan0 8049.9496      0.86  0.12  0.77      0.87  0.07  0.82      0.88  0.05  0.84
forget mean min: 0.972413 0.748465
incx.max(), incx.min(), incx.mean() 4.59562 0.792049 3.4026
fgtx.max(), fgtx.min(), fgtx.mean() 2.02959 0.242327 1.46906
abs_mean, abs_mean+, abs_mean-: 4.1456 3.29953 6.14849
U_c = [[-0.04039029]] U_f = [[ 0.]] b_c = [ 0.27511472] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.245276 -0.245275 0.000647589 0.242689
W_f max, min, mean, abs_mean: 0.115644 -0.115695 -0.000224211 0.114

nanchang
           nanchang0  689.7168      0.21  0.37  0.18      0.25  0.29  0.21      0.25  0.23  0.21
           nanchang0 2515.0185      0.50  0.35  0.39      0.50  0.33  0.40      0.51  0.29  0.42
forget mean min: 0.96379 0.573875
incx.max(), incx.min(), incx.mean() 2.85587 -0.631636 2.06794
fgtx.max(), fgtx.min(), fgtx.mean() 2.06969 -0.630625 1.45965
abs_mean, abs_mean+, abs_mean-: 3.30484 2.13493 6.49147
U_c = [[-0.02558716]] U_f = [[ 0.]] b_c = [ 0.18276741] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.160871 -0.160947 0.0160718 0.158206
W_f max, min, mean, abs_mean: 0.12491 -0.124537 0.0125308 0.122489

changsha
           changsha0  664.7471      0.45  0.34  0.36      0.51  0.25  0.44      0.54  0.18  0.48
           changsha0 6229.1205      0.04  -nan  0.04      0.04  -nan  0.04      0.01  -nan  0.01
forget mean min: 0.910557 0.721505
incx.max(), incx.min(), incx.mean() 3.71427 0.426496 2.4139
fgtx.max(), fgtx.min(), fgtx.mean() 1.68249 0.107527 1.05956
abs_mean, abs_mean+, abs_mean-: 3.16138 2.03143 3.72453
U_c = [[-0.12177101]] U_f = [[ 0.]] b_c = [ 0.20204076] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.213438 -0.213189 -0.0213248 0.212313
W_f max, min, mean, abs_mean: 0.102713 -0.102802 -0.0104551 0.101708
