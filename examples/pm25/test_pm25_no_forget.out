trainset.shape, testset.shape = (60075, 48, 11) (20025, 48, 11)

training rlstm_no_forget0
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 285.9687 - val_loss: 1147.4964
Epoch 00000: val_loss improved from inf to 1147.49637, saving model to rlstm_no_forget0_weights.hdf5
Epoch 2/300
10s - loss: 222.3711 - val_loss: 917.8077
Epoch 00001: val_loss improved from 1147.49637 to 917.80767, saving model to rlstm_no_forget0_weights.hdf5
Epoch 3/300
10s - loss: 201.3974 - val_loss: 744.5903
Epoch 00002: val_loss improved from 917.80767 to 744.59030, saving model to rlstm_no_forget0_weights.hdf5
Epoch 4/300
10s - loss: 186.9641 - val_loss: 786.2146
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 177.2780 - val_loss: 760.9352
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 170.8612 - val_loss: 787.8840
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 165.9456 - val_loss: 776.4557
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 162.2300 - val_loss: 747.1029
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 159.0001 - val_loss: 776.5552
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 156.3395 - val_loss: 749.9550
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 153.9350 - val_loss: 749.0934
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 151.7822 - val_loss: 707.3181
Epoch 00011: val_loss improved from 744.59030 to 707.31812, saving model to rlstm_no_forget0_weights.hdf5
Epoch 13/300
10s - loss: 149.7541 - val_loss: 761.3370
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 148.1494 - val_loss: 781.1200
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 146.4309 - val_loss: 765.8599
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 144.8470 - val_loss: 721.2927
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 143.2993 - val_loss: 783.1035
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 141.8724 - val_loss: 775.3072
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 140.5319 - val_loss: 716.0703
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 139.2461 - val_loss: 703.9399
Epoch 00019: val_loss improved from 707.31812 to 703.93994, saving model to rlstm_no_forget0_weights.hdf5
Epoch 21/300
10s - loss: 138.0478 - val_loss: 745.5727
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 136.9220 - val_loss: 726.8831
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 135.8143 - val_loss: 812.8733
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 134.7633 - val_loss: 773.0825
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 133.7067 - val_loss: 768.1303
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 132.7512 - val_loss: 790.9118
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 131.8084 - val_loss: 797.1415
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 130.8796 - val_loss: 785.8140
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 129.8106 - val_loss: 849.1110
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 128.8042 - val_loss: 752.6971
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 127.8120 - val_loss: 816.9121
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 126.8918 - val_loss: 784.3779
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 125.8841 - val_loss: 776.4683
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 124.9712 - val_loss: 748.0292
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 124.0922 - val_loss: 777.1342
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 123.2651 - val_loss: 818.0732
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 122.5372 - val_loss: 770.6182
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 121.7433 - val_loss: 772.8357
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 121.0396 - val_loss: 826.3104
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 120.3973 - val_loss: 792.9070
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 119.7378 - val_loss: 827.0809
Epoch 00040: val_loss did not improve

training rlstm_no_forget1
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 285.2955 - val_loss: 1098.3296
Epoch 00000: val_loss improved from inf to 1098.32962, saving model to rlstm_no_forget1_weights.hdf5
Epoch 2/300
10s - loss: 220.4869 - val_loss: 858.1297
Epoch 00001: val_loss improved from 1098.32962 to 858.12966, saving model to rlstm_no_forget1_weights.hdf5
Epoch 3/300
10s - loss: 197.6840 - val_loss: 727.2710
Epoch 00002: val_loss improved from 858.12966 to 727.27097, saving model to rlstm_no_forget1_weights.hdf5
Epoch 4/300
10s - loss: 183.8791 - val_loss: 785.0267
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 176.4796 - val_loss: 776.0299
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 170.4553 - val_loss: 754.5763
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 165.8026 - val_loss: 763.2542
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 162.4548 - val_loss: 780.9968
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 159.6827 - val_loss: 716.9544
Epoch 00008: val_loss improved from 727.27097 to 716.95443, saving model to rlstm_no_forget1_weights.hdf5
Epoch 10/300
10s - loss: 157.1958 - val_loss: 726.1438
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 154.8670 - val_loss: 713.1283
Epoch 00010: val_loss improved from 716.95443 to 713.12827, saving model to rlstm_no_forget1_weights.hdf5
Epoch 12/300
10s - loss: 152.6556 - val_loss: 725.9504
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 150.7347 - val_loss: 735.3571
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 148.9451 - val_loss: 725.5164
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 147.1750 - val_loss: 702.0025
Epoch 00014: val_loss improved from 713.12827 to 702.00252, saving model to rlstm_no_forget1_weights.hdf5
Epoch 16/300
10s - loss: 145.4974 - val_loss: 701.6265
Epoch 00015: val_loss improved from 702.00252 to 701.62646, saving model to rlstm_no_forget1_weights.hdf5
Epoch 17/300
10s - loss: 143.9554 - val_loss: 694.4526
Epoch 00016: val_loss improved from 701.62646 to 694.45256, saving model to rlstm_no_forget1_weights.hdf5
Epoch 18/300
10s - loss: 142.7289 - val_loss: 688.7139
Epoch 00017: val_loss improved from 694.45256 to 688.71385, saving model to rlstm_no_forget1_weights.hdf5
Epoch 19/300
10s - loss: 141.4484 - val_loss: 677.1622
Epoch 00018: val_loss improved from 688.71385 to 677.16217, saving model to rlstm_no_forget1_weights.hdf5
Epoch 20/300
10s - loss: 140.2040 - val_loss: 681.9812
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 139.0565 - val_loss: 690.0128
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 137.8575 - val_loss: 677.1387
Epoch 00021: val_loss improved from 677.16217 to 677.13873, saving model to rlstm_no_forget1_weights.hdf5
Epoch 23/300
10s - loss: 136.7833 - val_loss: 665.9985
Epoch 00022: val_loss improved from 677.13873 to 665.99849, saving model to rlstm_no_forget1_weights.hdf5
Epoch 24/300
10s - loss: 135.7295 - val_loss: 672.0774
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 134.7056 - val_loss: 672.0848
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 133.6462 - val_loss: 707.8098
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 132.6693 - val_loss: 686.0039
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 131.6663 - val_loss: 668.3518
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 130.8171 - val_loss: 669.1879
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 129.8872 - val_loss: 694.1201
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 129.0380 - val_loss: 703.2256
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 128.1118 - val_loss: 656.2512
Epoch 00031: val_loss improved from 665.99849 to 656.25123, saving model to rlstm_no_forget1_weights.hdf5
Epoch 33/300
10s - loss: 127.2549 - val_loss: 668.9490
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 126.4598 - val_loss: 690.1185
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 125.7221 - val_loss: 663.0365
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 125.0104 - val_loss: 684.8865
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 124.3453 - val_loss: 654.3167
Epoch 00036: val_loss improved from 656.25123 to 654.31667, saving model to rlstm_no_forget1_weights.hdf5
Epoch 38/300
10s - loss: 123.6799 - val_loss: 694.2628
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 122.9337 - val_loss: 676.1551
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 122.4221 - val_loss: 682.0686
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 121.7340 - val_loss: 694.2205
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 121.1054 - val_loss: 672.0696
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 120.6020 - val_loss: 711.1802
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 119.9774 - val_loss: 685.7501
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 119.3985 - val_loss: 671.1433
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 118.7236 - val_loss: 676.1544
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 118.0911 - val_loss: 742.8962
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 117.3453 - val_loss: 643.6747
Epoch 00047: val_loss improved from 654.31667 to 643.67468, saving model to rlstm_no_forget1_weights.hdf5
Epoch 49/300
10s - loss: 116.7052 - val_loss: 689.9246
Epoch 00048: val_loss did not improve
Epoch 50/300
10s - loss: 116.0128 - val_loss: 722.0424
Epoch 00049: val_loss did not improve
Epoch 51/300
10s - loss: 115.4711 - val_loss: 713.9701
Epoch 00050: val_loss did not improve
Epoch 52/300
10s - loss: 114.8531 - val_loss: 695.5356
Epoch 00051: val_loss did not improve
Epoch 53/300
10s - loss: 114.4303 - val_loss: 656.2509
Epoch 00052: val_loss did not improve
Epoch 54/300
10s - loss: 113.8686 - val_loss: 669.3686
Epoch 00053: val_loss did not improve
Epoch 55/300
10s - loss: 113.4058 - val_loss: 667.9325
Epoch 00054: val_loss did not improve
Epoch 56/300
10s - loss: 112.9957 - val_loss: 671.6209
Epoch 00055: val_loss did not improve
Epoch 57/300
10s - loss: 112.5397 - val_loss: 692.3258
Epoch 00056: val_loss did not improve
Epoch 58/300
10s - loss: 112.2449 - val_loss: 705.1972
Epoch 00057: val_loss did not improve
Epoch 59/300
10s - loss: 111.7189 - val_loss: 741.9342
Epoch 00058: val_loss did not improve
Epoch 60/300
10s - loss: 111.4374 - val_loss: 713.4583
Epoch 00059: val_loss did not improve
Epoch 61/300
10s - loss: 111.1219 - val_loss: 714.6906
Epoch 00060: val_loss did not improve
Epoch 62/300
10s - loss: 110.7121 - val_loss: 752.8462
Epoch 00061: val_loss did not improve
Epoch 63/300
10s - loss: 110.3566 - val_loss: 687.7898
Epoch 00062: val_loss did not improve
Epoch 64/300
10s - loss: 110.0870 - val_loss: 689.6225
Epoch 00063: val_loss did not improve
Epoch 65/300
10s - loss: 109.7202 - val_loss: 721.8815
Epoch 00064: val_loss did not improve
Epoch 66/300
10s - loss: 109.5360 - val_loss: 735.5008
Epoch 00065: val_loss did not improve
Epoch 67/300
10s - loss: 109.2096 - val_loss: 700.1663
Epoch 00066: val_loss did not improve
Epoch 68/300
10s - loss: 108.8609 - val_loss: 707.8222
Epoch 00067: val_loss did not improve
Epoch 69/300
10s - loss: 108.6094 - val_loss: 743.7244
Epoch 00068: val_loss did not improve

training rlstm_no_forget2
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 286.7769 - val_loss: 1136.5627
Epoch 00000: val_loss improved from inf to 1136.56270, saving model to rlstm_no_forget2_weights.hdf5
Epoch 2/300
10s - loss: 222.6498 - val_loss: 865.9534
Epoch 00001: val_loss improved from 1136.56270 to 865.95338, saving model to rlstm_no_forget2_weights.hdf5
Epoch 3/300
10s - loss: 202.5532 - val_loss: 797.8027
Epoch 00002: val_loss improved from 865.95338 to 797.80270, saving model to rlstm_no_forget2_weights.hdf5
Epoch 4/300
10s - loss: 191.0821 - val_loss: 746.6971
Epoch 00003: val_loss improved from 797.80270 to 746.69710, saving model to rlstm_no_forget2_weights.hdf5
Epoch 5/300
10s - loss: 181.4256 - val_loss: 756.5677
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 175.5041 - val_loss: 766.9789
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 170.5047 - val_loss: 753.8049
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 165.7703 - val_loss: 789.7160
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 161.5020 - val_loss: 743.8163
Epoch 00008: val_loss improved from 746.69710 to 743.81625, saving model to rlstm_no_forget2_weights.hdf5
Epoch 10/300
10s - loss: 158.2973 - val_loss: 777.6022
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 155.6331 - val_loss: 765.5127
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 153.2682 - val_loss: 764.0963
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 151.0851 - val_loss: 773.8447
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 148.8860 - val_loss: 821.9331
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 146.9002 - val_loss: 787.6498
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 145.2165 - val_loss: 795.1030
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 143.4654 - val_loss: 807.6672
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 141.8744 - val_loss: 794.1700
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 140.5070 - val_loss: 809.7190
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 139.4426 - val_loss: 835.6115
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 138.1791 - val_loss: 767.2738
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 137.0841 - val_loss: 855.1953
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 136.1040 - val_loss: 839.0996
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 135.0891 - val_loss: 894.8168
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 134.1225 - val_loss: 842.5394
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 133.0763 - val_loss: 842.0615
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 132.3172 - val_loss: 825.4309
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 131.4628 - val_loss: 800.7155
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 130.7799 - val_loss: 826.3119
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 130.0322 - val_loss: 785.6642
Epoch 00029: val_loss did not improve

training rlstm_no_forget3
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
11s - loss: 287.7706 - val_loss: 1123.9404
Epoch 00000: val_loss improved from inf to 1123.94043, saving model to rlstm_no_forget3_weights.hdf5
Epoch 2/300
11s - loss: 222.9424 - val_loss: 968.4112
Epoch 00001: val_loss improved from 1123.94043 to 968.41120, saving model to rlstm_no_forget3_weights.hdf5
Epoch 3/300
11s - loss: 201.7780 - val_loss: 818.3324
Epoch 00002: val_loss improved from 968.41120 to 818.33242, saving model to rlstm_no_forget3_weights.hdf5
Epoch 4/300
11s - loss: 189.1235 - val_loss: 758.1453
Epoch 00003: val_loss improved from 818.33242 to 758.14528, saving model to rlstm_no_forget3_weights.hdf5
Epoch 5/300
11s - loss: 178.8895 - val_loss: 764.2874
Epoch 00004: val_loss did not improve
Epoch 6/300
11s - loss: 171.1733 - val_loss: 764.2400
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 166.3640 - val_loss: 727.9329
Epoch 00006: val_loss improved from 758.14528 to 727.93295, saving model to rlstm_no_forget3_weights.hdf5
Epoch 8/300
11s - loss: 162.9059 - val_loss: 750.2310
Epoch 00007: val_loss did not improve
Epoch 9/300
11s - loss: 159.8300 - val_loss: 735.2844
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 157.2413 - val_loss: 758.3686
Epoch 00009: val_loss did not improve
Epoch 11/300
11s - loss: 154.7629 - val_loss: 736.7567
Epoch 00010: val_loss did not improve
Epoch 12/300
11s - loss: 152.5137 - val_loss: 783.5760
Epoch 00011: val_loss did not improve
Epoch 13/300
11s - loss: 150.3557 - val_loss: 782.7549
Epoch 00012: val_loss did not improve
Epoch 14/300
11s - loss: 148.3836 - val_loss: 821.6803
Epoch 00013: val_loss did not improve
Epoch 15/300
11s - loss: 146.4920 - val_loss: 780.8475
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 144.8769 - val_loss: 788.2996
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 143.4137 - val_loss: 807.1360
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 141.9950 - val_loss: 801.5325
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 140.7339 - val_loss: 804.7067
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 139.5601 - val_loss: 768.3500
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 138.4692 - val_loss: 835.1751
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 137.4093 - val_loss: 782.2849
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 136.3957 - val_loss: 809.0766
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 135.3863 - val_loss: 864.0938
Epoch 00023: val_loss did not improve
Epoch 25/300
11s - loss: 134.5139 - val_loss: 849.8601
Epoch 00024: val_loss did not improve
Epoch 26/300
11s - loss: 133.6451 - val_loss: 878.8087
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 132.9195 - val_loss: 864.0465
Epoch 00026: val_loss did not improve
Epoch 28/300
11s - loss: 132.0609 - val_loss: 841.9429
Epoch 00027: val_loss did not improve

training rlstm_no_forget4
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
11s - loss: 288.8234 - val_loss: 1155.9479
Epoch 00000: val_loss improved from inf to 1155.94786, saving model to rlstm_no_forget4_weights.hdf5
Epoch 2/300
11s - loss: 221.5376 - val_loss: 884.7530
Epoch 00001: val_loss improved from 1155.94786 to 884.75303, saving model to rlstm_no_forget4_weights.hdf5
Epoch 3/300
11s - loss: 201.4503 - val_loss: 763.0137
Epoch 00002: val_loss improved from 884.75303 to 763.01374, saving model to rlstm_no_forget4_weights.hdf5
Epoch 4/300
11s - loss: 189.5008 - val_loss: 767.7761
Epoch 00003: val_loss did not improve
Epoch 5/300
11s - loss: 180.4948 - val_loss: 734.5219
Epoch 00004: val_loss improved from 763.01374 to 734.52186, saving model to rlstm_no_forget4_weights.hdf5
Epoch 6/300
11s - loss: 173.6143 - val_loss: 750.6775
Epoch 00005: val_loss did not improve
Epoch 7/300
11s - loss: 167.7209 - val_loss: 754.9662
Epoch 00006: val_loss did not improve
Epoch 8/300
11s - loss: 163.4028 - val_loss: 719.5837
Epoch 00007: val_loss improved from 734.52186 to 719.58371, saving model to rlstm_no_forget4_weights.hdf5
Epoch 9/300
11s - loss: 160.0938 - val_loss: 722.4371
Epoch 00008: val_loss did not improve
Epoch 10/300
11s - loss: 157.4830 - val_loss: 705.5472
Epoch 00009: val_loss improved from 719.58371 to 705.54722, saving model to rlstm_no_forget4_weights.hdf5
Epoch 11/300
11s - loss: 155.0053 - val_loss: 704.1332
Epoch 00010: val_loss improved from 705.54722 to 704.13324, saving model to rlstm_no_forget4_weights.hdf5
Epoch 12/300
11s - loss: 152.8149 - val_loss: 702.5619
Epoch 00011: val_loss improved from 704.13324 to 702.56192, saving model to rlstm_no_forget4_weights.hdf5
Epoch 13/300
11s - loss: 150.8725 - val_loss: 695.9532
Epoch 00012: val_loss improved from 702.56192 to 695.95322, saving model to rlstm_no_forget4_weights.hdf5
Epoch 14/300
11s - loss: 148.9912 - val_loss: 690.4566
Epoch 00013: val_loss improved from 695.95322 to 690.45655, saving model to rlstm_no_forget4_weights.hdf5
Epoch 15/300
11s - loss: 147.0732 - val_loss: 692.9972
Epoch 00014: val_loss did not improve
Epoch 16/300
11s - loss: 145.4573 - val_loss: 708.7593
Epoch 00015: val_loss did not improve
Epoch 17/300
11s - loss: 143.7377 - val_loss: 693.5967
Epoch 00016: val_loss did not improve
Epoch 18/300
11s - loss: 142.1336 - val_loss: 663.1931
Epoch 00017: val_loss improved from 690.45655 to 663.19311, saving model to rlstm_no_forget4_weights.hdf5
Epoch 19/300
11s - loss: 140.4323 - val_loss: 645.2931
Epoch 00018: val_loss improved from 663.19311 to 645.29307, saving model to rlstm_no_forget4_weights.hdf5
Epoch 20/300
11s - loss: 138.7888 - val_loss: 665.9726
Epoch 00019: val_loss did not improve
Epoch 21/300
11s - loss: 137.1815 - val_loss: 666.5591
Epoch 00020: val_loss did not improve
Epoch 22/300
11s - loss: 135.7209 - val_loss: 650.7046
Epoch 00021: val_loss did not improve
Epoch 23/300
11s - loss: 134.3157 - val_loss: 650.5524
Epoch 00022: val_loss did not improve
Epoch 24/300
11s - loss: 132.9534 - val_loss: 687.2683
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 131.9504 - val_loss: 621.9638
Epoch 00024: val_loss improved from 645.29307 to 621.96384, saving model to rlstm_no_forget4_weights.hdf5
Epoch 26/300
11s - loss: 130.8031 - val_loss: 648.4117
Epoch 00025: val_loss did not improve
Epoch 27/300
11s - loss: 129.8041 - val_loss: 664.6856
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 128.8235 - val_loss: 604.5048
Epoch 00027: val_loss improved from 621.96384 to 604.50483, saving model to rlstm_no_forget4_weights.hdf5
Epoch 29/300
10s - loss: 127.9683 - val_loss: 627.3202
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 127.0712 - val_loss: 619.3928
Epoch 00029: val_loss did not improve
Epoch 31/300
11s - loss: 126.2820 - val_loss: 639.3860
Epoch 00030: val_loss did not improve
Epoch 32/300
11s - loss: 125.4877 - val_loss: 619.6930
Epoch 00031: val_loss did not improve
Epoch 33/300
11s - loss: 124.7169 - val_loss: 627.5103
Epoch 00032: val_loss did not improve
Epoch 34/300
11s - loss: 124.1041 - val_loss: 639.8310
Epoch 00033: val_loss did not improve
Epoch 35/300
11s - loss: 123.2850 - val_loss: 662.8630
Epoch 00034: val_loss did not improve
Epoch 36/300
11s - loss: 122.6812 - val_loss: 620.8686
Epoch 00035: val_loss did not improve
Epoch 37/300
11s - loss: 122.1198 - val_loss: 643.2242
Epoch 00036: val_loss did not improve
Epoch 38/300
11s - loss: 121.5801 - val_loss: 647.5208
Epoch 00037: val_loss did not improve
Epoch 39/300
11s - loss: 120.8622 - val_loss: 649.4470
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 120.3291 - val_loss: 699.5587
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 119.9174 - val_loss: 627.0123
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 119.3556 - val_loss: 635.3236
Epoch 00041: val_loss did not improve
Epoch 43/300
10s - loss: 118.7330 - val_loss: 623.0063
Epoch 00042: val_loss did not improve
Epoch 44/300
10s - loss: 118.2404 - val_loss: 627.4097
Epoch 00043: val_loss did not improve
Epoch 45/300
10s - loss: 117.8835 - val_loss: 639.3877
Epoch 00044: val_loss did not improve
Epoch 46/300
10s - loss: 117.3785 - val_loss: 668.6232
Epoch 00045: val_loss did not improve
Epoch 47/300
10s - loss: 116.9412 - val_loss: 664.2814
Epoch 00046: val_loss did not improve
Epoch 48/300
10s - loss: 116.4224 - val_loss: 619.4258
Epoch 00047: val_loss did not improve
Epoch 49/300
10s - loss: 116.0547 - val_loss: 697.2033
Epoch 00048: val_loss did not improve

training rlstm_no_forget5
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 286.2312 - val_loss: 1191.6629
Epoch 00000: val_loss improved from inf to 1191.66289, saving model to rlstm_no_forget5_weights.hdf5
Epoch 2/300
10s - loss: 221.6423 - val_loss: 832.9039
Epoch 00001: val_loss improved from 1191.66289 to 832.90389, saving model to rlstm_no_forget5_weights.hdf5
Epoch 3/300
10s - loss: 201.2789 - val_loss: 821.8662
Epoch 00002: val_loss improved from 832.90389 to 821.86625, saving model to rlstm_no_forget5_weights.hdf5
Epoch 4/300
10s - loss: 187.9471 - val_loss: 740.8148
Epoch 00003: val_loss improved from 821.86625 to 740.81477, saving model to rlstm_no_forget5_weights.hdf5
Epoch 5/300
10s - loss: 177.7216 - val_loss: 748.8674
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 170.5254 - val_loss: 750.0185
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 165.5268 - val_loss: 754.5283
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 162.2184 - val_loss: 722.3037
Epoch 00007: val_loss improved from 740.81477 to 722.30366, saving model to rlstm_no_forget5_weights.hdf5
Epoch 9/300
10s - loss: 159.3180 - val_loss: 748.8467
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 156.9076 - val_loss: 722.6473
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 154.6428 - val_loss: 765.5712
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 152.5006 - val_loss: 720.6034
Epoch 00011: val_loss improved from 722.30366 to 720.60341, saving model to rlstm_no_forget5_weights.hdf5
Epoch 13/300
10s - loss: 150.4701 - val_loss: 740.5101
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 148.3526 - val_loss: 711.2195
Epoch 00013: val_loss improved from 720.60341 to 711.21949, saving model to rlstm_no_forget5_weights.hdf5
Epoch 15/300
10s - loss: 146.4176 - val_loss: 674.1921
Epoch 00014: val_loss improved from 711.21949 to 674.19208, saving model to rlstm_no_forget5_weights.hdf5
Epoch 16/300
10s - loss: 144.7836 - val_loss: 675.0554
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 143.1473 - val_loss: 696.3612
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 141.7270 - val_loss: 722.2785
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 140.3008 - val_loss: 725.3238
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 138.9841 - val_loss: 725.6643
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 137.8500 - val_loss: 687.8461
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 136.7225 - val_loss: 746.3378
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 135.6225 - val_loss: 704.7444
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 134.5531 - val_loss: 695.9273
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 133.6071 - val_loss: 835.7707
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 132.5576 - val_loss: 734.5371
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 131.5218 - val_loss: 820.7773
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 130.5488 - val_loss: 689.3660
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 129.5973 - val_loss: 705.1257
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 128.7081 - val_loss: 819.9929
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 127.7703 - val_loss: 807.3178
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 126.9582 - val_loss: 786.1583
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 126.1181 - val_loss: 876.4028
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 125.4716 - val_loss: 753.8585
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 124.5931 - val_loss: 799.3673
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 123.7598 - val_loss: 750.7240
Epoch 00035: val_loss did not improve

training rlstm_no_forget6
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 286.1543 - val_loss: 1199.8318
Epoch 00000: val_loss improved from inf to 1199.83184, saving model to rlstm_no_forget6_weights.hdf5
Epoch 2/300
10s - loss: 221.3174 - val_loss: 859.7432
Epoch 00001: val_loss improved from 1199.83184 to 859.74317, saving model to rlstm_no_forget6_weights.hdf5
Epoch 3/300
10s - loss: 200.7938 - val_loss: 793.8716
Epoch 00002: val_loss improved from 859.74317 to 793.87160, saving model to rlstm_no_forget6_weights.hdf5
Epoch 4/300
10s - loss: 188.1916 - val_loss: 770.7141
Epoch 00003: val_loss improved from 793.87160 to 770.71414, saving model to rlstm_no_forget6_weights.hdf5
Epoch 5/300
10s - loss: 178.9351 - val_loss: 781.0132
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 172.1106 - val_loss: 798.1366
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 166.4758 - val_loss: 809.1869
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 162.0550 - val_loss: 786.2106
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 158.7455 - val_loss: 766.3316
Epoch 00008: val_loss improved from 770.71414 to 766.33159, saving model to rlstm_no_forget6_weights.hdf5
Epoch 10/300
10s - loss: 156.1991 - val_loss: 749.8818
Epoch 00009: val_loss improved from 766.33159 to 749.88177, saving model to rlstm_no_forget6_weights.hdf5
Epoch 11/300
10s - loss: 154.0340 - val_loss: 723.3942
Epoch 00010: val_loss improved from 749.88177 to 723.39417, saving model to rlstm_no_forget6_weights.hdf5
Epoch 12/300
10s - loss: 152.1602 - val_loss: 736.4894
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 150.4214 - val_loss: 721.0222
Epoch 00012: val_loss improved from 723.39417 to 721.02222, saving model to rlstm_no_forget6_weights.hdf5
Epoch 14/300
10s - loss: 148.7734 - val_loss: 746.9133
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 147.1965 - val_loss: 716.2664
Epoch 00014: val_loss improved from 721.02222 to 716.26640, saving model to rlstm_no_forget6_weights.hdf5
Epoch 16/300
10s - loss: 145.7009 - val_loss: 727.7803
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 144.1779 - val_loss: 753.9663
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 142.7134 - val_loss: 699.0034
Epoch 00017: val_loss improved from 716.26640 to 699.00343, saving model to rlstm_no_forget6_weights.hdf5
Epoch 19/300
10s - loss: 141.2719 - val_loss: 743.6677
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 139.8135 - val_loss: 699.3682
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 138.5399 - val_loss: 723.5200
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 137.2182 - val_loss: 728.9019
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 135.8971 - val_loss: 726.5588
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 134.7020 - val_loss: 746.3513
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 133.4651 - val_loss: 793.0979
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 132.3279 - val_loss: 779.1913
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 131.2475 - val_loss: 759.5811
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 130.2413 - val_loss: 801.1950
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 129.2988 - val_loss: 805.4695
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 128.2259 - val_loss: 873.8727
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 127.3241 - val_loss: 986.6348
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 126.3629 - val_loss: 888.3942
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 125.5028 - val_loss: 868.8107
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 124.5799 - val_loss: 919.5545
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 123.7884 - val_loss: 1010.8203
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 122.9666 - val_loss: 1051.6095
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 122.3180 - val_loss: 1110.0483
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 121.5496 - val_loss: 1070.1958
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 120.8678 - val_loss: 969.3954
Epoch 00038: val_loss did not improve

training rlstm_no_forget7
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 286.3966 - val_loss: 1181.4813
Epoch 00000: val_loss improved from inf to 1181.48130, saving model to rlstm_no_forget7_weights.hdf5
Epoch 2/300
10s - loss: 222.4399 - val_loss: 916.4053
Epoch 00001: val_loss improved from 1181.48130 to 916.40529, saving model to rlstm_no_forget7_weights.hdf5
Epoch 3/300
10s - loss: 201.4895 - val_loss: 772.4989
Epoch 00002: val_loss improved from 916.40529 to 772.49888, saving model to rlstm_no_forget7_weights.hdf5
Epoch 4/300
10s - loss: 190.1675 - val_loss: 797.7868
Epoch 00003: val_loss did not improve
Epoch 5/300
10s - loss: 181.4383 - val_loss: 783.4696
Epoch 00004: val_loss did not improve
Epoch 6/300
10s - loss: 174.8607 - val_loss: 805.4257
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 168.6050 - val_loss: 816.5762
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 163.5612 - val_loss: 819.0411
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 159.9380 - val_loss: 751.0017
Epoch 00008: val_loss improved from 772.49888 to 751.00170, saving model to rlstm_no_forget7_weights.hdf5
Epoch 10/300
10s - loss: 157.0936 - val_loss: 740.5211
Epoch 00009: val_loss improved from 751.00170 to 740.52114, saving model to rlstm_no_forget7_weights.hdf5
Epoch 11/300
10s - loss: 154.4925 - val_loss: 708.6643
Epoch 00010: val_loss improved from 740.52114 to 708.66431, saving model to rlstm_no_forget7_weights.hdf5
Epoch 12/300
10s - loss: 151.9307 - val_loss: 753.0493
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 149.5472 - val_loss: 756.0876
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 147.6151 - val_loss: 735.3361
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 145.7038 - val_loss: 744.2431
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 143.8751 - val_loss: 721.8266
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 142.0486 - val_loss: 749.5777
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 140.3673 - val_loss: 718.8122
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 138.6192 - val_loss: 704.4085
Epoch 00018: val_loss improved from 708.66431 to 704.40846, saving model to rlstm_no_forget7_weights.hdf5
Epoch 20/300
10s - loss: 137.1220 - val_loss: 707.6285
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 135.8451 - val_loss: 661.6801
Epoch 00020: val_loss improved from 704.40846 to 661.68012, saving model to rlstm_no_forget7_weights.hdf5
Epoch 22/300
10s - loss: 134.6005 - val_loss: 728.0997
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 133.4726 - val_loss: 686.8702
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 132.3568 - val_loss: 711.8523
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 131.3915 - val_loss: 671.4853
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 130.4100 - val_loss: 669.3845
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 129.5780 - val_loss: 736.4742
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 128.7549 - val_loss: 682.3160
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 128.0259 - val_loss: 740.4721
Epoch 00028: val_loss did not improve
Epoch 30/300
10s - loss: 127.1413 - val_loss: 702.3106
Epoch 00029: val_loss did not improve
Epoch 31/300
10s - loss: 126.4289 - val_loss: 728.0283
Epoch 00030: val_loss did not improve
Epoch 32/300
10s - loss: 125.6399 - val_loss: 680.3855
Epoch 00031: val_loss did not improve
Epoch 33/300
10s - loss: 125.0165 - val_loss: 775.6852
Epoch 00032: val_loss did not improve
Epoch 34/300
10s - loss: 124.2969 - val_loss: 726.0207
Epoch 00033: val_loss did not improve
Epoch 35/300
10s - loss: 123.7722 - val_loss: 776.5459
Epoch 00034: val_loss did not improve
Epoch 36/300
10s - loss: 123.1267 - val_loss: 732.3090
Epoch 00035: val_loss did not improve
Epoch 37/300
10s - loss: 122.6648 - val_loss: 705.3871
Epoch 00036: val_loss did not improve
Epoch 38/300
10s - loss: 121.9247 - val_loss: 721.0722
Epoch 00037: val_loss did not improve
Epoch 39/300
10s - loss: 121.4002 - val_loss: 700.8731
Epoch 00038: val_loss did not improve
Epoch 40/300
10s - loss: 120.8429 - val_loss: 747.7194
Epoch 00039: val_loss did not improve
Epoch 41/300
10s - loss: 120.3050 - val_loss: 730.3561
Epoch 00040: val_loss did not improve
Epoch 42/300
10s - loss: 119.6895 - val_loss: 770.0669
Epoch 00041: val_loss did not improve

training rlstm_no_forget8
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 286.3282 - val_loss: 1143.4748
Epoch 00000: val_loss improved from inf to 1143.47477, saving model to rlstm_no_forget8_weights.hdf5
Epoch 2/300
10s - loss: 221.7518 - val_loss: 883.1317
Epoch 00001: val_loss improved from 1143.47477 to 883.13166, saving model to rlstm_no_forget8_weights.hdf5
Epoch 3/300
10s - loss: 202.1266 - val_loss: 800.5660
Epoch 00002: val_loss improved from 883.13166 to 800.56596, saving model to rlstm_no_forget8_weights.hdf5
Epoch 4/300
10s - loss: 190.7293 - val_loss: 766.8535
Epoch 00003: val_loss improved from 800.56596 to 766.85347, saving model to rlstm_no_forget8_weights.hdf5
Epoch 5/300
10s - loss: 181.4177 - val_loss: 733.4774
Epoch 00004: val_loss improved from 766.85347 to 733.47738, saving model to rlstm_no_forget8_weights.hdf5
Epoch 6/300
10s - loss: 175.3361 - val_loss: 748.2312
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 170.1400 - val_loss: 760.3842
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 165.0953 - val_loss: 792.3293
Epoch 00007: val_loss did not improve
Epoch 9/300
10s - loss: 160.6568 - val_loss: 781.3545
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 157.1049 - val_loss: 757.1767
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 154.1345 - val_loss: 775.4029
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 151.3405 - val_loss: 811.7254
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 148.9066 - val_loss: 775.9075
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 146.6538 - val_loss: 773.8203
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 144.6483 - val_loss: 763.1175
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 142.8647 - val_loss: 815.3337
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 141.1681 - val_loss: 751.6372
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 139.6973 - val_loss: 807.7316
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 138.2017 - val_loss: 812.4784
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 136.8764 - val_loss: 849.7188
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 135.6155 - val_loss: 820.0207
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 134.4946 - val_loss: 791.2099
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 133.2916 - val_loss: 821.5892
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 132.1918 - val_loss: 809.5018
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 131.0767 - val_loss: 815.4675
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 129.9706 - val_loss: 870.0709
Epoch 00025: val_loss did not improve

training rlstm_no_forget9
Train on 60075 samples, validate on 20025 samples
Before training:
{'val_loss': 874.14131737183993}
Epoch 1/300
10s - loss: 287.5482 - val_loss: 1188.6194
Epoch 00000: val_loss improved from inf to 1188.61942, saving model to rlstm_no_forget9_weights.hdf5
Epoch 2/300
10s - loss: 222.4654 - val_loss: 920.7816
Epoch 00001: val_loss improved from 1188.61942 to 920.78156, saving model to rlstm_no_forget9_weights.hdf5
Epoch 3/300
10s - loss: 201.6119 - val_loss: 799.1955
Epoch 00002: val_loss improved from 920.78156 to 799.19548, saving model to rlstm_no_forget9_weights.hdf5
Epoch 4/300
10s - loss: 188.0221 - val_loss: 769.9992
Epoch 00003: val_loss improved from 799.19548 to 769.99921, saving model to rlstm_no_forget9_weights.hdf5
Epoch 5/300
10s - loss: 178.4268 - val_loss: 740.1062
Epoch 00004: val_loss improved from 769.99921 to 740.10624, saving model to rlstm_no_forget9_weights.hdf5
Epoch 6/300
10s - loss: 171.8949 - val_loss: 767.3708
Epoch 00005: val_loss did not improve
Epoch 7/300
10s - loss: 166.6908 - val_loss: 788.9521
Epoch 00006: val_loss did not improve
Epoch 8/300
10s - loss: 162.7867 - val_loss: 726.5866
Epoch 00007: val_loss improved from 740.10624 to 726.58665, saving model to rlstm_no_forget9_weights.hdf5
Epoch 9/300
10s - loss: 159.8098 - val_loss: 778.4924
Epoch 00008: val_loss did not improve
Epoch 10/300
10s - loss: 157.4962 - val_loss: 751.6143
Epoch 00009: val_loss did not improve
Epoch 11/300
10s - loss: 155.4116 - val_loss: 780.6878
Epoch 00010: val_loss did not improve
Epoch 12/300
10s - loss: 153.4152 - val_loss: 799.0016
Epoch 00011: val_loss did not improve
Epoch 13/300
10s - loss: 151.3769 - val_loss: 794.0473
Epoch 00012: val_loss did not improve
Epoch 14/300
10s - loss: 149.3586 - val_loss: 808.9045
Epoch 00013: val_loss did not improve
Epoch 15/300
10s - loss: 147.3766 - val_loss: 840.2031
Epoch 00014: val_loss did not improve
Epoch 16/300
10s - loss: 145.4113 - val_loss: 789.1826
Epoch 00015: val_loss did not improve
Epoch 17/300
10s - loss: 143.7602 - val_loss: 852.4394
Epoch 00016: val_loss did not improve
Epoch 18/300
10s - loss: 142.1105 - val_loss: 842.3965
Epoch 00017: val_loss did not improve
Epoch 19/300
10s - loss: 140.7452 - val_loss: 790.7202
Epoch 00018: val_loss did not improve
Epoch 20/300
10s - loss: 139.3332 - val_loss: 903.4066
Epoch 00019: val_loss did not improve
Epoch 21/300
10s - loss: 137.9701 - val_loss: 879.7792
Epoch 00020: val_loss did not improve
Epoch 22/300
10s - loss: 136.7110 - val_loss: 933.2226
Epoch 00021: val_loss did not improve
Epoch 23/300
10s - loss: 135.4783 - val_loss: 906.5962
Epoch 00022: val_loss did not improve
Epoch 24/300
10s - loss: 134.4662 - val_loss: 875.6160
Epoch 00023: val_loss did not improve
Epoch 25/300
10s - loss: 133.5236 - val_loss: 893.8705
Epoch 00024: val_loss did not improve
Epoch 26/300
10s - loss: 132.5541 - val_loss: 916.0235
Epoch 00025: val_loss did not improve
Epoch 27/300
10s - loss: 131.5418 - val_loss: 925.4956
Epoch 00026: val_loss did not improve
Epoch 28/300
10s - loss: 130.5684 - val_loss: 1034.7799
Epoch 00027: val_loss did not improve
Epoch 29/300
10s - loss: 129.7395 - val_loss: 1055.1018
Epoch 00028: val_loss did not improve
