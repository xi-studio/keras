X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout0
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout0  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout0 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
45s - loss: 2171.6796 - val_loss: 9400.8486
Epoch 00000: val_loss improved from inf to 9400.84863, saving model to huabei_lstm20x2+dropout0_weights.hdf5
huabei_lstm20x2+dropout0  1510.8      0.73  0.34  0.53      0.71  0.20  0.61      0.72  0.13  0.65
forget mean min: 0.947725 0.670685
delta_x = 4.21881
delta_h = 2.11143
delta mean, abs_mean, abs_mean+, abs_mean-: 1.02028 4.21881 3.95526 4.73569
U_c = [[-0.07499172]] U_f = [[ 0.]] b_f = [ 1.28468394]
W_c max, min, mean, abs_mean: 0.574581 -0.643763 -0.275339 0.551108
W_f max, min, mean, abs_mean: 0.500218 -0.596691 -0.197018 0.403315
huabei_lstm20x2+dropout0  9400.8      0.86  0.24  0.67      0.84  0.16  0.72      0.85  0.11  0.76
forget mean min: 0.955424 0.720753
delta_x = 4.5027
delta_h = 3.08042
delta mean, abs_mean, abs_mean+, abs_mean-: 1.00538 4.5027 3.99953 5.61532
U_c = [[-0.07499172]] U_f = [[ 0.]] b_f = [ 1.28468394]
W_c max, min, mean, abs_mean: 0.574581 -0.643763 -0.275339 0.551108
W_f max, min, mean, abs_mean: 0.500218 -0.596691 -0.197018 0.403315
Epoch 2/500
45s - loss: 1438.9722 - val_loss: 9233.9298
Epoch 00001: val_loss improved from 9400.84863 to 9233.92982, saving model to huabei_lstm20x2+dropout0_weights.hdf5
huabei_lstm20x2+dropout0  1384.4      0.77  0.33  0.56      0.74  0.19  0.63      0.75  0.13  0.67
forget mean min: 0.937326 0.589072
delta_x = 4.67213
delta_h = 2.18761
delta mean, abs_mean, abs_mean+, abs_mean-: 1.18429 4.67213 4.49709 4.99884
U_c = [[-0.07041226]] U_f = [[ 0.]] b_f = [ 1.28668404]
W_c max, min, mean, abs_mean: 0.878516 -1.13045 -0.40096 0.797326
W_f max, min, mean, abs_mean: 0.551082 -0.728267 -0.211142 0.42935
huabei_lstm20x2+dropout0  9233.9      0.84  0.23  0.67      0.83  0.15  0.72      0.83  0.11  0.75
forget mean min: 0.944533 0.6614
delta_x = 4.64535
delta_h = 2.83717
delta mean, abs_mean, abs_mean+, abs_mean-: 0.761111 4.64535 4.28342 5.26451
U_c = [[-0.07041226]] U_f = [[ 0.]] b_f = [ 1.28668404]
W_c max, min, mean, abs_mean: 0.878516 -1.13045 -0.40096 0.797326
W_f max, min, mean, abs_mean: 0.551082 -0.728267 -0.211142 0.42935
Epoch 3/500
47s - loss: 1318.2331 - val_loss: 9177.3597
Epoch 00002: val_loss improved from 9233.92982 to 9177.35967, saving model to huabei_lstm20x2+dropout0_weights.hdf5
huabei_lstm20x2+dropout0  1256.9      0.78  0.32  0.57      0.75  0.18  0.64      0.75  0.12  0.68
forget mean min: 0.930347 0.54396
delta_x = 4.82019
delta_h = 2.09496
delta mean, abs_mean, abs_mean+, abs_mean-: 1.12519 4.82019 4.67856 5.067
U_c = [[-0.06831396]] U_f = [[ 0.]] b_f = [ 1.29105973]
W_c max, min, mean, abs_mean: 1.11402 -1.60588 -0.505334 0.999744
W_f max, min, mean, abs_mean: 0.58755 -0.774213 -0.219419 0.442762
huabei_lstm20x2+dropout0  9177.3      0.81  0.22  0.66      0.80  0.15  0.70      0.81  0.10  0.74
forget mean min: 0.938267 0.635029
delta_x = 4.49469
delta_h = 2.57763
delta mean, abs_mean, abs_mean+, abs_mean-: 0.541438 4.49469 4.24411 4.86024
U_c = [[-0.06831396]] U_f = [[ 0.]] b_f = [ 1.29105973]
W_c max, min, mean, abs_mean: 1.11402 -1.60588 -0.505334 0.999744
W_f max, min, mean, abs_mean: 0.58755 -0.774213 -0.219419 0.442762
Epoch 4/500
48s - loss: 1243.1406 - val_loss: 9216.3910
Epoch 00003: val_loss did not improve
Epoch 5/500
49s - loss: 1190.2681 - val_loss: 9793.5698
Epoch 00004: val_loss did not improve
Epoch 6/500
49s - loss: 1143.5859 - val_loss: 9255.5006
Epoch 00005: val_loss did not improve
Epoch 7/500
49s - loss: 1106.3516 - val_loss: 9504.7907
Epoch 00006: val_loss did not improve
Epoch 8/500
48s - loss: 1076.1668 - val_loss: 9226.6884
Epoch 00007: val_loss did not improve
Epoch 9/500
48s - loss: 1051.2339 - val_loss: 9251.0186
Epoch 00008: val_loss did not improve
Epoch 10/500
48s - loss: 1029.6546 - val_loss: 9141.2582
Epoch 00009: val_loss improved from 9177.35967 to 9141.25822, saving model to huabei_lstm20x2+dropout0_weights.hdf5
huabei_lstm20x2+dropout0   972.6      0.79  0.25  0.62      0.76  0.14  0.67      0.76  0.10  0.70
forget mean min: 0.902322 0.422035
delta_x = 6.4627
delta_h = 2.73149
delta mean, abs_mean, abs_mean+, abs_mean-: 1.17721 6.4627 6.87046 5.9521
U_c = [[-0.08873156]] U_f = [[ 0.]] b_f = [ 1.39151263]
W_c max, min, mean, abs_mean: 2.14227 -3.47343 -0.910318 1.81498
W_f max, min, mean, abs_mean: 1.02913 -0.957012 -0.210506 0.508255
huabei_lstm20x2+dropout0  9141.2      0.72  0.23  0.59      0.73  0.16  0.64      0.75  0.11  0.69
forget mean min: 0.917436 0.644514
delta_x = 5.31191
delta_h = 3.31119
delta mean, abs_mean, abs_mean+, abs_mean-: 0.739498 5.31191 5.6387 4.93351
U_c = [[-0.08873156]] U_f = [[ 0.]] b_f = [ 1.39151263]
W_c max, min, mean, abs_mean: 2.14227 -3.47343 -0.910318 1.81498
W_f max, min, mean, abs_mean: 1.02913 -0.957012 -0.210506 0.508255
Epoch 11/500
48s - loss: 1012.1025 - val_loss: 9589.1733
Epoch 00010: val_loss did not improve
Epoch 12/500
48s - loss: 994.7406 - val_loss: 9187.0241
Epoch 00011: val_loss did not improve
Epoch 13/500
47s - loss: 979.0158 - val_loss: 9381.3774
Epoch 00012: val_loss did not improve
Epoch 14/500
47s - loss: 963.8569 - val_loss: 9386.3780
Epoch 00013: val_loss did not improve
Epoch 15/500
48s - loss: 950.1463 - val_loss: 9437.3036
Epoch 00014: val_loss did not improve
Epoch 16/500
48s - loss: 940.2886 - val_loss: 9308.3682
Epoch 00015: val_loss did not improve
Epoch 17/500
48s - loss: 930.9380 - val_loss: 9289.2943
Epoch 00016: val_loss did not improve
Epoch 18/500
48s - loss: 920.7516 - val_loss: 9539.4870
Epoch 00017: val_loss did not improve
Epoch 19/500
48s - loss: 913.1558 - val_loss: 9428.2746
Epoch 00018: val_loss did not improve
Epoch 20/500
47s - loss: 905.4285 - val_loss: 9189.3315
Epoch 00019: val_loss did not improve
Epoch 21/500
47s - loss: 898.2808 - val_loss: 9492.7123
Epoch 00020: val_loss did not improve
Epoch 22/500
47s - loss: 891.4893 - val_loss: 9201.5025
Epoch 00021: val_loss did not improve
Epoch 23/500
48s - loss: 883.5337 - val_loss: 9670.7638
Epoch 00022: val_loss did not improve
Epoch 24/500
48s - loss: 877.4701 - val_loss: 9150.2591
Epoch 00023: val_loss did not improve
Epoch 25/500
48s - loss: 871.0502 - val_loss: 8922.5170
Epoch 00024: val_loss improved from 9141.25822 to 8922.51701, saving model to huabei_lstm20x2+dropout0_weights.hdf5
huabei_lstm20x2+dropout0   821.6      0.82  0.23  0.66      0.80  0.13  0.71      0.80  0.09  0.74
forget mean min: 0.891307 0.24842
delta_x = 8.17015
delta_h = 3.39677
delta mean, abs_mean, abs_mean+, abs_mean-: 1.52276 8.17015 9.09334 7.11662
U_c = [[-0.10656952]] U_f = [[ 0.]] b_f = [ 1.44819188]
W_c max, min, mean, abs_mean: 3.30539 -5.53561 -1.27969 2.60704
W_f max, min, mean, abs_mean: 1.40204 -1.68871 -0.241623 0.69579
huabei_lstm20x2+dropout0  8922.5      0.72  0.23  0.60      0.75  0.16  0.65      0.78  0.11  0.71
forget mean min: 0.91104 0.555182
delta_x = 6.6495
delta_h = 4.11417
delta mean, abs_mean, abs_mean+, abs_mean-: 1.17101 6.6495 7.23681 5.95913
U_c = [[-0.10656952]] U_f = [[ 0.]] b_f = [ 1.44819188]
W_c max, min, mean, abs_mean: 3.30539 -5.53561 -1.27969 2.60704
W_f max, min, mean, abs_mean: 1.40204 -1.68871 -0.241623 0.69579
Epoch 26/500
48s - loss: 866.9493 - val_loss: 9732.6504
Epoch 00025: val_loss did not improve
Epoch 27/500
48s - loss: 860.4202 - val_loss: 9511.4304
Epoch 00026: val_loss did not improve
Epoch 28/500
47s - loss: 855.6269 - val_loss: 9284.8756
Epoch 00027: val_loss did not improve
Epoch 29/500
47s - loss: 849.3367 - val_loss: 9566.4425
Epoch 00028: val_loss did not improve
Epoch 30/500
48s - loss: 845.0012 - val_loss: 9343.6212
Epoch 00029: val_loss did not improve
Epoch 31/500
48s - loss: 841.0064 - val_loss: 9668.3868
Epoch 00030: val_loss did not improve
Epoch 32/500
48s - loss: 836.1846 - val_loss: 9471.9646
Epoch 00031: val_loss did not improve
Epoch 33/500
48s - loss: 832.8293 - val_loss: 9395.8823
Epoch 00032: val_loss did not improve
Epoch 34/500
48s - loss: 827.5932 - val_loss: 9412.0893
Epoch 00033: val_loss did not improve
Epoch 35/500
48s - loss: 823.8375 - val_loss: 9266.4522
Epoch 00034: val_loss did not improve
Epoch 36/500
47s - loss: 820.2314 - val_loss: 9302.0739
Epoch 00035: val_loss did not improve
Epoch 37/500
47s - loss: 817.3343 - val_loss: 9373.1249
Epoch 00036: val_loss did not improve
Epoch 38/500
48s - loss: 813.8736 - val_loss: 10007.4479
Epoch 00037: val_loss did not improve
Epoch 39/500
48s - loss: 810.3022 - val_loss: 9632.8937
Epoch 00038: val_loss did not improve
Epoch 40/500
48s - loss: 808.6325 - val_loss: 9303.5827
Epoch 00039: val_loss did not improve
Epoch 41/500
48s - loss: 805.1671 - val_loss: 9621.9067
Epoch 00040: val_loss did not improve
Epoch 42/500
48s - loss: 802.2870 - val_loss: 9576.5643
Epoch 00041: val_loss did not improve
Epoch 43/500
48s - loss: 799.7389 - val_loss: 9805.8003
Epoch 00042: val_loss did not improve
Epoch 44/500
47s - loss: 798.2978 - val_loss: 9472.2573
Epoch 00043: val_loss did not improve
Epoch 45/500
47s - loss: 794.3221 - val_loss: 9628.6027
Epoch 00044: val_loss did not improve
Epoch 46/500
48s - loss: 793.1060 - val_loss: 9788.1492
Epoch 00045: val_loss did not improve
Epoch 47/500
48s - loss: 790.0228 - val_loss: 9674.2192
Epoch 00046: val_loss did not improve
Epoch 48/500
48s - loss: 788.8604 - val_loss: 9835.6647
Epoch 00047: val_loss did not improve
Epoch 49/500
48s - loss: 785.7493 - val_loss: 9446.5700
Epoch 00048: val_loss did not improve
Epoch 50/500
48s - loss: 783.6877 - val_loss: 9705.8322
Epoch 00049: val_loss did not improve
Epoch 51/500
48s - loss: 782.6841 - val_loss: 9937.1285
Epoch 00050: val_loss did not improve
Epoch 52/500
47s - loss: 781.1481 - val_loss: 9620.7793
Epoch 00051: val_loss did not improve
Epoch 53/500
47s - loss: 779.8142 - val_loss: 10005.8966
Epoch 00052: val_loss did not improve
Epoch 54/500
48s - loss: 775.9276 - val_loss: 9740.6920
Epoch 00053: val_loss did not improve
Epoch 55/500
48s - loss: 774.0449 - val_loss: 9738.7725
Epoch 00054: val_loss did not improve
Epoch 56/500
48s - loss: 774.1883 - val_loss: 9437.2282
Epoch 00055: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout1
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout1  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout1 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2191.1773 - val_loss: 9212.4754
Epoch 00000: val_loss improved from inf to 9212.47542, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1559.3      0.75  0.35  0.53      0.73  0.21  0.61      0.74  0.14  0.66
forget mean min: 0.949212 0.704662
delta_x = 4.20074
delta_h = 2.14082
delta mean, abs_mean, abs_mean+, abs_mean-: 1.10961 4.20074 3.95784 4.69584
U_c = [[-0.07459918]] U_f = [[ 0.]] b_f = [ 1.25751984]
W_c max, min, mean, abs_mean: 0.620665 -0.555707 -0.147592 0.53373
W_f max, min, mean, abs_mean: 0.610902 -0.450776 -0.0934443 0.391677
huabei_lstm20x2+dropout1  9212.5      0.87  0.25  0.68      0.86  0.16  0.73      0.86  0.12  0.77
forget mean min: 0.958053 0.752763
delta_x = 4.89988
delta_h = 3.23908
delta mean, abs_mean, abs_mean+, abs_mean-: 1.40736 4.89988 4.46523 5.94494
U_c = [[-0.07459918]] U_f = [[ 0.]] b_f = [ 1.25751984]
W_c max, min, mean, abs_mean: 0.620665 -0.555707 -0.147592 0.53373
W_f max, min, mean, abs_mean: 0.610902 -0.450776 -0.0934443 0.391677
Epoch 2/500
50s - loss: 1474.7598 - val_loss: 8633.5416
Epoch 00001: val_loss improved from 9212.47542 to 8633.54164, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1437.7      0.76  0.34  0.55      0.74  0.20  0.62      0.74  0.13  0.67
forget mean min: 0.941781 0.67488
delta_x = 4.49093
delta_h = 2.19957
delta mean, abs_mean, abs_mean+, abs_mean-: 1.24191 4.49093 4.37921 4.7026
U_c = [[-0.07251593]] U_f = [[ 0.]] b_f = [ 1.26609397]
W_c max, min, mean, abs_mean: 1.10566 -0.897467 -0.197539 0.766779
W_f max, min, mean, abs_mean: 0.809631 -0.469044 -0.093597 0.433951
huabei_lstm20x2+dropout1  8633.5      0.86  0.24  0.67      0.85  0.15  0.73      0.86  0.11  0.77
forget mean min: 0.951083 0.717414
delta_x = 5.45762
delta_h = 3.32758
delta mean, abs_mean, abs_mean+, abs_mean-: 1.62431 5.45762 5.27371 5.83345
U_c = [[-0.07251593]] U_f = [[ 0.]] b_f = [ 1.26609397]
W_c max, min, mean, abs_mean: 1.10566 -0.897467 -0.197539 0.766779
W_f max, min, mean, abs_mean: 0.809631 -0.469044 -0.093597 0.433951
Epoch 3/500
50s - loss: 1362.9287 - val_loss: 8547.7579
Epoch 00002: val_loss improved from 8633.54164 to 8547.75792, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1278.3      0.76  0.31  0.56      0.73  0.18  0.63      0.74  0.12  0.67
forget mean min: 0.931797 0.669238
delta_x = 4.68795
delta_h = 1.98606
delta mean, abs_mean, abs_mean+, abs_mean-: 0.933458 4.68795 4.67038 4.7145
U_c = [[-0.06695928]] U_f = [[ 0.]] b_f = [ 1.26574194]
W_c max, min, mean, abs_mean: 1.58082 -1.14584 -0.231548 0.958098
W_f max, min, mean, abs_mean: 0.883902 -0.478784 -0.0910432 0.44407
huabei_lstm20x2+dropout1  8547.8      0.84  0.22  0.68      0.83  0.14  0.73      0.84  0.10  0.76
forget mean min: 0.941692 0.703272
delta_x = 5.36353
delta_h = 2.8903
delta mean, abs_mean, abs_mean+, abs_mean-: 0.949628 5.36353 5.25786 5.52226
U_c = [[-0.06695928]] U_f = [[ 0.]] b_f = [ 1.26574194]
W_c max, min, mean, abs_mean: 1.58082 -1.14584 -0.231548 0.958098
W_f max, min, mean, abs_mean: 0.883902 -0.478784 -0.0910432 0.44407
Epoch 4/500
50s - loss: 1284.8749 - val_loss: 8374.7116
Epoch 00003: val_loss improved from 8547.75792 to 8374.71164, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1190.5      0.74  0.28  0.57      0.71  0.16  0.63      0.72  0.10  0.67
forget mean min: 0.923514 0.650422
delta_x = 4.79126
delta_h = 1.94537
delta mean, abs_mean, abs_mean+, abs_mean-: 0.731845 4.79126 4.87329 4.684
U_c = [[-0.06922258]] U_f = [[ 0.]] b_f = [ 1.25862706]
W_c max, min, mean, abs_mean: 1.98246 -1.30263 -0.255087 1.11272
W_f max, min, mean, abs_mean: 0.900531 -0.512374 -0.090303 0.445217
huabei_lstm20x2+dropout1  8374.7      0.83  0.21  0.68      0.82  0.14  0.72      0.82  0.10  0.75
forget mean min: 0.936614 0.702972
delta_x = 5.41466
delta_h = 2.97947
delta mean, abs_mean, abs_mean+, abs_mean-: 0.913729 5.41466 5.37565 5.47049
U_c = [[-0.06922258]] U_f = [[ 0.]] b_f = [ 1.25862706]
W_c max, min, mean, abs_mean: 1.98246 -1.30263 -0.255087 1.11272
W_f max, min, mean, abs_mean: 0.900531 -0.512374 -0.090303 0.445217
Epoch 5/500
50s - loss: 1227.5729 - val_loss: 8278.7083
Epoch 00004: val_loss improved from 8374.71164 to 8278.70833, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1137.0      0.75  0.27  0.58      0.73  0.16  0.64      0.74  0.11  0.68
forget mean min: 0.919237 0.633492
delta_x = 5.33194
delta_h = 2.17255
delta mean, abs_mean, abs_mean+, abs_mean-: 0.879185 5.33194 5.58549 5.01443
U_c = [[-0.07536211]] U_f = [[ 0.]] b_f = [ 1.25668395]
W_c max, min, mean, abs_mean: 2.34826 -1.42449 -0.274505 1.23759
W_f max, min, mean, abs_mean: 0.912232 -0.558831 -0.0954761 0.453228
huabei_lstm20x2+dropout1  8278.7      0.83  0.22  0.67      0.82  0.14  0.72      0.82  0.10  0.75
forget mean min: 0.935636 0.698489
delta_x = 5.7802
delta_h = 3.35395
delta mean, abs_mean, abs_mean+, abs_mean-: 1.33525 5.7802 5.9733 5.4958
U_c = [[-0.07536211]] U_f = [[ 0.]] b_f = [ 1.25668395]
W_c max, min, mean, abs_mean: 2.34826 -1.42449 -0.274505 1.23759
W_f max, min, mean, abs_mean: 0.912232 -0.558831 -0.0954761 0.453228
Epoch 6/500
49s - loss: 1182.0998 - val_loss: 8197.3253
Epoch 00005: val_loss improved from 8278.70833 to 8197.32526, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1110.4      0.77  0.28  0.59      0.74  0.16  0.65      0.75  0.11  0.69
forget mean min: 0.9178 0.617435
delta_x = 5.5656
delta_h = 2.26172
delta mean, abs_mean, abs_mean+, abs_mean-: 1.01757 5.5656 5.89748 5.1464
U_c = [[-0.07711397]] U_f = [[ 0.]] b_f = [ 1.25927913]
W_c max, min, mean, abs_mean: 2.66029 -1.51493 -0.291848 1.34614
W_f max, min, mean, abs_mean: 0.948804 -0.606815 -0.0996992 0.46501
huabei_lstm20x2+dropout1  8197.3      0.84  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.935436 0.689723
delta_x = 6.04459
delta_h = 3.54689
delta mean, abs_mean, abs_mean+, abs_mean-: 1.62801 6.04459 6.3574 5.56859
U_c = [[-0.07711397]] U_f = [[ 0.]] b_f = [ 1.25927913]
W_c max, min, mean, abs_mean: 2.66029 -1.51493 -0.291848 1.34614
W_f max, min, mean, abs_mean: 0.948804 -0.606815 -0.0996992 0.46501
Epoch 7/500
49s - loss: 1148.8139 - val_loss: 8248.5644
Epoch 00006: val_loss did not improve
Epoch 8/500
50s - loss: 1120.4844 - val_loss: 8449.3437
Epoch 00007: val_loss did not improve
Epoch 9/500
50s - loss: 1098.2107 - val_loss: 8173.2782
Epoch 00008: val_loss improved from 8197.32526 to 8173.27822, saving model to huabei_lstm20x2+dropout1_weights.hdf5
huabei_lstm20x2+dropout1  1069.7      0.80  0.29  0.61      0.78  0.16  0.68      0.78  0.11  0.71
forget mean min: 0.913084 0.564953
delta_x = 6.39137
delta_h = 2.64821
delta mean, abs_mean, abs_mean+, abs_mean-: 1.33066 6.39137 6.90307 5.74191
U_c = [[-0.0826501]] U_f = [[ 0.]] b_f = [ 1.26445866]
W_c max, min, mean, abs_mean: 3.46085 -1.72895 -0.330718 1.59986
W_f max, min, mean, abs_mean: 1.02389 -0.779202 -0.121597 0.506232
huabei_lstm20x2+dropout1  8173.3      0.83  0.23  0.67      0.82  0.15  0.72      0.83  0.11  0.75
forget mean min: 0.930451 0.671353
delta_x = 6.44742
delta_h = 3.87356
delta mean, abs_mean, abs_mean+, abs_mean-: 1.73279 6.44742 6.8899 5.80102
U_c = [[-0.0826501]] U_f = [[ 0.]] b_f = [ 1.26445866]
W_c max, min, mean, abs_mean: 3.46085 -1.72895 -0.330718 1.59986
W_f max, min, mean, abs_mean: 1.02389 -0.779202 -0.121597 0.506232
Epoch 10/500
50s - loss: 1076.1966 - val_loss: 8537.9693
Epoch 00009: val_loss did not improve
Epoch 11/500
50s - loss: 1057.0403 - val_loss: 8370.2658
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 1040.3600 - val_loss: 8762.0624
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 1023.8808 - val_loss: 8318.1152
Epoch 00012: val_loss did not improve
Epoch 14/500
48s - loss: 1009.8802 - val_loss: 8493.6658
Epoch 00013: val_loss did not improve
Epoch 15/500
50s - loss: 995.3735 - val_loss: 8522.2306
Epoch 00014: val_loss did not improve
Epoch 16/500
49s - loss: 982.3761 - val_loss: 8616.3051
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 970.9870 - val_loss: 8490.1900
Epoch 00016: val_loss did not improve
Epoch 18/500
49s - loss: 959.1941 - val_loss: 8448.7455
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 949.3189 - val_loss: 8605.0212
Epoch 00018: val_loss did not improve
Epoch 20/500
48s - loss: 939.8711 - val_loss: 8456.5366
Epoch 00019: val_loss did not improve
Epoch 21/500
48s - loss: 930.5479 - val_loss: 8345.5524
Epoch 00020: val_loss did not improve
Epoch 22/500
48s - loss: 921.6684 - val_loss: 8788.8542
Epoch 00021: val_loss did not improve
Epoch 23/500
49s - loss: 914.4872 - val_loss: 8664.5101
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 907.3841 - val_loss: 8848.1565
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 899.6042 - val_loss: 8385.7419
Epoch 00024: val_loss did not improve
Epoch 26/500
48s - loss: 894.6440 - val_loss: 8742.0691
Epoch 00025: val_loss did not improve
Epoch 27/500
48s - loss: 888.5864 - val_loss: 8648.1610
Epoch 00026: val_loss did not improve
Epoch 28/500
48s - loss: 882.7067 - val_loss: 8744.5412
Epoch 00027: val_loss did not improve
Epoch 29/500
47s - loss: 876.6041 - val_loss: 8626.0930
Epoch 00028: val_loss did not improve
Epoch 30/500
48s - loss: 872.1273 - val_loss: 8966.7427
Epoch 00029: val_loss did not improve
Epoch 31/500
49s - loss: 867.5246 - val_loss: 8865.1914
Epoch 00030: val_loss did not improve
Epoch 32/500
49s - loss: 863.9410 - val_loss: 8521.7762
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 859.1837 - val_loss: 9019.0411
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 855.6600 - val_loss: 8898.8040
Epoch 00033: val_loss did not improve
Epoch 35/500
48s - loss: 852.0183 - val_loss: 8530.5658
Epoch 00034: val_loss did not improve
Epoch 36/500
48s - loss: 849.6702 - val_loss: 8789.5586
Epoch 00035: val_loss did not improve
Epoch 37/500
48s - loss: 845.9596 - val_loss: 8533.8573
Epoch 00036: val_loss did not improve
Epoch 38/500
48s - loss: 842.0827 - val_loss: 8992.3601
Epoch 00037: val_loss did not improve
Epoch 39/500
49s - loss: 839.5200 - val_loss: 8855.0572
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 836.2815 - val_loss: 8699.6801
Epoch 00039: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout2
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout2  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout2 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2189.7946 - val_loss: 9507.1301
Epoch 00000: val_loss improved from inf to 9507.13007, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1546.8      0.74  0.35  0.53      0.72  0.20  0.61      0.73  0.13  0.66
forget mean min: 0.949613 0.708124
delta_x = 4.22361
delta_h = 2.12092
delta mean, abs_mean, abs_mean+, abs_mean-: 1.07779 4.22361 3.96821 4.73745
U_c = [[-0.07523642]] U_f = [[ 0.]] b_f = [ 1.26880574]
W_c max, min, mean, abs_mean: 0.640521 -0.602236 0.0518085 0.52834
W_f max, min, mean, abs_mean: 0.50297 -0.500529 0.0335118 0.391997
huabei_lstm20x2+dropout2  9507.1      0.87  0.26  0.66      0.86  0.18  0.72      0.86  0.13  0.76
forget mean min: 0.960141 0.742711
delta_x = 4.74671
delta_h = 3.25335
delta mean, abs_mean, abs_mean+, abs_mean-: 1.53289 4.74671 4.37995 5.67526
U_c = [[-0.07523642]] U_f = [[ 0.]] b_f = [ 1.26880574]
W_c max, min, mean, abs_mean: 0.640521 -0.602236 0.0518085 0.52834
W_f max, min, mean, abs_mean: 0.50297 -0.500529 0.0335118 0.391997
Epoch 2/500
50s - loss: 1467.5071 - val_loss: 9524.7742
Epoch 00001: val_loss did not improve
Epoch 3/500
50s - loss: 1349.3229 - val_loss: 9554.2524
Epoch 00002: val_loss did not improve
Epoch 4/500
50s - loss: 1269.4204 - val_loss: 8966.6458
Epoch 00003: val_loss improved from 9507.13007 to 8966.64576, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1219.7      0.78  0.30  0.58      0.75  0.17  0.65      0.75  0.12  0.68
forget mean min: 0.93229 0.578945
delta_x = 5.1655
delta_h = 2.48772
delta mean, abs_mean, abs_mean+, abs_mean-: 1.26686 5.1655 5.35107 4.88594
U_c = [[-0.08172926]] U_f = [[ 0.]] b_f = [ 1.31082785]
W_c max, min, mean, abs_mean: 1.88308 -1.93044 0.0919712 1.09852
W_f max, min, mean, abs_mean: 0.83263 -0.835414 0.0501847 0.470106
huabei_lstm20x2+dropout2  8966.6      0.82  0.24  0.65      0.81  0.16  0.70      0.83  0.11  0.75
forget mean min: 0.945945 0.665511
delta_x = 5.00118
delta_h = 3.22988
delta mean, abs_mean, abs_mean+, abs_mean-: 1.41401 5.00118 5.1381 4.77369
U_c = [[-0.08172926]] U_f = [[ 0.]] b_f = [ 1.31082785]
W_c max, min, mean, abs_mean: 1.88308 -1.93044 0.0919712 1.09852
W_f max, min, mean, abs_mean: 0.83263 -0.835414 0.0501847 0.470106
Epoch 5/500
50s - loss: 1216.3507 - val_loss: 8786.6392
Epoch 00004: val_loss improved from 8966.64576 to 8786.63923, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1145.3      0.77  0.29  0.59      0.73  0.16  0.64      0.74  0.11  0.68
forget mean min: 0.927093 0.55433
delta_x = 5.19854
delta_h = 2.38932
delta mean, abs_mean, abs_mean+, abs_mean-: 1.09955 5.19854 5.41758 4.89449
U_c = [[-0.08009138]] U_f = [[ 0.]] b_f = [ 1.32300103]
W_c max, min, mean, abs_mean: 2.18973 -2.26716 0.101394 1.22415
W_f max, min, mean, abs_mean: 0.926916 -0.885325 0.0549222 0.485104
huabei_lstm20x2+dropout2  8786.6      0.81  0.24  0.65      0.80  0.16  0.70      0.81  0.11  0.74
forget mean min: 0.944278 0.670229
delta_x = 5.11168
delta_h = 3.27575
delta mean, abs_mean, abs_mean+, abs_mean-: 1.56837 5.11168 5.3305 4.7445
U_c = [[-0.08009138]] U_f = [[ 0.]] b_f = [ 1.32300103]
W_c max, min, mean, abs_mean: 2.18973 -2.26716 0.101394 1.22415
W_f max, min, mean, abs_mean: 0.926916 -0.885325 0.0549222 0.485104
Epoch 6/500
50s - loss: 1176.1378 - val_loss: 8781.2324
Epoch 00005: val_loss improved from 8786.63923 to 8781.23235, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1098.5      0.76  0.27  0.59      0.73  0.15  0.65      0.73  0.10  0.68
forget mean min: 0.924723 0.533665
delta_x = 5.20048
delta_h = 2.32151
delta mean, abs_mean, abs_mean+, abs_mean-: 0.985206 5.20048 5.44968 4.87346
U_c = [[-0.07968698]] U_f = [[ 0.]] b_f = [ 1.33177519]
W_c max, min, mean, abs_mean: 2.44328 -2.54801 0.111169 1.33116
W_f max, min, mean, abs_mean: 1.0256 -0.934602 0.0615 0.5038
huabei_lstm20x2+dropout2  8781.2      0.80  0.24  0.64      0.79  0.16  0.69      0.80  0.11  0.73
forget mean min: 0.943259 0.661617
delta_x = 4.90582
delta_h = 3.19097
delta mean, abs_mean, abs_mean+, abs_mean-: 1.45258 4.90582 5.14164 4.52378
U_c = [[-0.07968698]] U_f = [[ 0.]] b_f = [ 1.33177519]
W_c max, min, mean, abs_mean: 2.44328 -2.54801 0.111169 1.33116
W_f max, min, mean, abs_mean: 1.0256 -0.934602 0.0615 0.5038
Epoch 7/500
48s - loss: 1144.6620 - val_loss: 8906.7391
Epoch 00006: val_loss did not improve
Epoch 8/500
50s - loss: 1119.8097 - val_loss: 8761.4152
Epoch 00007: val_loss improved from 8781.23235 to 8761.41519, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1055.3      0.77  0.27  0.60      0.74  0.15  0.65      0.75  0.10  0.69
forget mean min: 0.920449 0.487597
delta_x = 5.64141
delta_h = 2.49662
delta mean, abs_mean, abs_mean+, abs_mean-: 1.08798 5.64141 6.01353 5.16874
U_c = [[-0.08265781]] U_f = [[ 0.]] b_f = [ 1.34735143]
W_c max, min, mean, abs_mean: 2.89319 -3.03841 0.126548 1.51283
W_f max, min, mean, abs_mean: 1.19557 -1.02129 0.0761739 0.539037
huabei_lstm20x2+dropout2  8761.4      0.80  0.24  0.64      0.79  0.16  0.69      0.80  0.11  0.73
forget mean min: 0.942654 0.668752
delta_x = 5.12805
delta_h = 3.43676
delta mean, abs_mean, abs_mean+, abs_mean-: 1.7314 5.12805 5.44358 4.59067
U_c = [[-0.08265781]] U_f = [[ 0.]] b_f = [ 1.34735143]
W_c max, min, mean, abs_mean: 2.89319 -3.03841 0.126548 1.51283
W_f max, min, mean, abs_mean: 1.19557 -1.02129 0.0761739 0.539037
Epoch 9/500
49s - loss: 1097.1092 - val_loss: 8726.2789
Epoch 00008: val_loss improved from 8761.41519 to 8726.27887, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2  1021.4      0.76  0.25  0.60      0.72  0.14  0.65      0.72  0.09  0.67
forget mean min: 0.918444 0.474982
delta_x = 5.49311
delta_h = 2.51897
delta mean, abs_mean, abs_mean+, abs_mean-: 0.961681 5.49311 5.88764 5.01448
U_c = [[-0.0883427]] U_f = [[ 0.]] b_f = [ 1.35397482]
W_c max, min, mean, abs_mean: 3.09378 -3.24248 0.133697 1.59344
W_f max, min, mean, abs_mean: 1.26277 -1.06021 0.0845365 0.554091
huabei_lstm20x2+dropout2  8726.3      0.79  0.24  0.63      0.78  0.16  0.68      0.79  0.11  0.72
forget mean min: 0.941505 0.672728
delta_x = 5.18439
delta_h = 3.58742
delta mean, abs_mean, abs_mean+, abs_mean-: 1.73293 5.18439 5.57935 4.54023
U_c = [[-0.0883427]] U_f = [[ 0.]] b_f = [ 1.35397482]
W_c max, min, mean, abs_mean: 3.09378 -3.24248 0.133697 1.59344
W_f max, min, mean, abs_mean: 1.26277 -1.06021 0.0845365 0.554091
Epoch 10/500
49s - loss: 1077.9709 - val_loss: 8995.8206
Epoch 00009: val_loss did not improve
Epoch 11/500
50s - loss: 1061.7186 - val_loss: 8566.4216
Epoch 00010: val_loss improved from 8726.27887 to 8566.42159, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2   997.2      0.78  0.26  0.61      0.75  0.14  0.66      0.75  0.10  0.70
forget mean min: 0.913819 0.432419
delta_x = 6.12736
delta_h = 2.75772
delta mean, abs_mean, abs_mean+, abs_mean-: 1.10985 6.12736 6.68314 5.47111
U_c = [[-0.08904742]] U_f = [[ 0.]] b_f = [ 1.36730075]
W_c max, min, mean, abs_mean: 3.44486 -3.63938 0.148141 1.74112
W_f max, min, mean, abs_mean: 1.39208 -1.1382 0.101352 0.589761
huabei_lstm20x2+dropout2  8566.4      0.79  0.24  0.63      0.78  0.16  0.68      0.79  0.11  0.72
forget mean min: 0.938579 0.665147
delta_x = 5.46399
delta_h = 3.76843
delta mean, abs_mean, abs_mean+, abs_mean-: 1.8147 5.46399 6.01272 4.62257
U_c = [[-0.08904742]] U_f = [[ 0.]] b_f = [ 1.36730075]
W_c max, min, mean, abs_mean: 3.44486 -3.63938 0.148141 1.74112
W_f max, min, mean, abs_mean: 1.39208 -1.1382 0.101352 0.589761
Epoch 12/500
49s - loss: 1045.1245 - val_loss: 8485.2618
Epoch 00011: val_loss improved from 8566.42159 to 8485.26179, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2   982.9      0.79  0.26  0.62      0.76  0.15  0.67      0.76  0.10  0.70
forget mean min: 0.915132 0.419286
delta_x = 6.19616
delta_h = 2.86681
delta mean, abs_mean, abs_mean+, abs_mean-: 1.24794 6.19616 6.75163 5.51373
U_c = [[-0.09404799]] U_f = [[ 0.]] b_f = [ 1.37465167]
W_c max, min, mean, abs_mean: 3.597 -3.82727 0.154717 1.81448
W_f max, min, mean, abs_mean: 1.47043 -1.16855 0.111247 0.607096
huabei_lstm20x2+dropout2  8485.3      0.81  0.24  0.64      0.80  0.16  0.69      0.81  0.11  0.73
forget mean min: 0.940759 0.657304
delta_x = 5.3011
delta_h = 3.81879
delta mean, abs_mean, abs_mean+, abs_mean-: 1.9156 5.3011 5.7957 4.48519
U_c = [[-0.09404799]] U_f = [[ 0.]] b_f = [ 1.37465167]
W_c max, min, mean, abs_mean: 3.597 -3.82727 0.154717 1.81448
W_f max, min, mean, abs_mean: 1.47043 -1.16855 0.111247 0.607096
Epoch 13/500
49s - loss: 1032.0685 - val_loss: 8381.4447
Epoch 00012: val_loss improved from 8485.26179 to 8381.44471, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2   947.5      0.75  0.23  0.62      0.72  0.13  0.65      0.73  0.08  0.68
forget mean min: 0.910087 0.408679
delta_x = 6.07529
delta_h = 2.68153
delta mean, abs_mean, abs_mean+, abs_mean-: 0.871836 6.07529 6.61278 5.48056
U_c = [[-0.09315063]] U_f = [[ 0.]] b_f = [ 1.380036]
W_c max, min, mean, abs_mean: 3.75013 -4.00324 0.162343 1.88052
W_f max, min, mean, abs_mean: 1.53535 -1.19824 0.120009 0.620176
huabei_lstm20x2+dropout2  8381.4      0.78  0.23  0.63      0.77  0.15  0.68      0.79  0.11  0.72
forget mean min: 0.935795 0.663813
delta_x = 5.51526
delta_h = 3.84713
delta mean, abs_mean, abs_mean+, abs_mean-: 1.63337 5.51526 6.07193 4.71861
U_c = [[-0.09315063]] U_f = [[ 0.]] b_f = [ 1.380036]
W_c max, min, mean, abs_mean: 3.75013 -4.00324 0.162343 1.88052
W_f max, min, mean, abs_mean: 1.53535 -1.19824 0.120009 0.620176
Epoch 14/500
49s - loss: 1020.4827 - val_loss: 8644.4380
Epoch 00013: val_loss did not improve
Epoch 15/500
49s - loss: 1007.3487 - val_loss: 8499.7656
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 996.8539 - val_loss: 8530.3255
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 986.3121 - val_loss: 8777.4457
Epoch 00016: val_loss did not improve
Epoch 18/500
49s - loss: 977.2417 - val_loss: 8540.2469
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 967.1445 - val_loss: 8672.7462
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 957.4679 - val_loss: 8444.1638
Epoch 00019: val_loss did not improve
Epoch 21/500
49s - loss: 949.4839 - val_loss: 8722.6502
Epoch 00020: val_loss did not improve
Epoch 22/500
48s - loss: 941.1832 - val_loss: 8692.6620
Epoch 00021: val_loss did not improve
Epoch 23/500
49s - loss: 933.0384 - val_loss: 8705.3066
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 927.9882 - val_loss: 8716.0079
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 920.2327 - val_loss: 8472.6591
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 915.2975 - val_loss: 8437.1701
Epoch 00025: val_loss did not improve
Epoch 27/500
48s - loss: 909.0109 - val_loss: 8589.0197
Epoch 00026: val_loss did not improve
Epoch 28/500
48s - loss: 904.3846 - val_loss: 8642.9770
Epoch 00027: val_loss did not improve
Epoch 29/500
48s - loss: 898.7933 - val_loss: 8370.3871
Epoch 00028: val_loss improved from 8381.44471 to 8370.38711, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2   839.4      0.80  0.23  0.65      0.78  0.13  0.70      0.78  0.09  0.73
forget mean min: 0.900148 0.271338
delta_x = 7.81413
delta_h = 3.50081
delta mean, abs_mean, abs_mean+, abs_mean-: 1.4732 7.81413 8.93691 6.59971
U_c = [[-0.11309794]] U_f = [[ 0.]] b_f = [ 1.40452528]
W_c max, min, mean, abs_mean: 5.52325 -5.84328 0.260814 2.63662
W_f max, min, mean, abs_mean: 1.95186 -1.51903 0.193994 0.803074
huabei_lstm20x2+dropout2  8370.4      0.79  0.23  0.64      0.79  0.15  0.69      0.80  0.11  0.73
forget mean min: 0.926059 0.594068
delta_x = 6.89228
delta_h = 4.74879
delta mean, abs_mean, abs_mean+, abs_mean-: 2.07349 6.89228 7.85839 5.60924
U_c = [[-0.11309794]] U_f = [[ 0.]] b_f = [ 1.40452528]
W_c max, min, mean, abs_mean: 5.52325 -5.84328 0.260814 2.63662
W_f max, min, mean, abs_mean: 1.95186 -1.51903 0.193994 0.803074
Epoch 30/500
49s - loss: 894.3934 - val_loss: 8389.1038
Epoch 00029: val_loss did not improve
Epoch 31/500
49s - loss: 890.1030 - val_loss: 8532.6244
Epoch 00030: val_loss did not improve
Epoch 32/500
49s - loss: 887.1241 - val_loss: 8576.4040
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 882.2127 - val_loss: 8399.8579
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 877.2448 - val_loss: 8211.3821
Epoch 00033: val_loss improved from 8370.38711 to 8211.38215, saving model to huabei_lstm20x2+dropout2_weights.hdf5
huabei_lstm20x2+dropout2   843.9      0.83  0.25  0.65      0.81  0.14  0.71      0.82  0.10  0.75
forget mean min: 0.899401 0.25412
delta_x = 8.38777
delta_h = 3.73985
delta mean, abs_mean, abs_mean+, abs_mean-: 1.77373 8.38777 9.6126 7.0146
U_c = [[-0.11424085]] U_f = [[ 0.]] b_f = [ 1.39991534]
W_c max, min, mean, abs_mean: 5.88191 -6.24874 0.281767 2.79397
W_f max, min, mean, abs_mean: 1.95847 -1.67911 0.202168 0.856933
huabei_lstm20x2+dropout2  8211.4      0.79  0.24  0.63      0.79  0.16  0.68      0.81  0.11  0.73
forget mean min: 0.924722 0.518975
delta_x = 7.42169
delta_h = 5.0233
delta mean, abs_mean, abs_mean+, abs_mean-: 2.31428 7.42169 8.58004 5.90263
U_c = [[-0.11424085]] U_f = [[ 0.]] b_f = [ 1.39991534]
W_c max, min, mean, abs_mean: 5.88191 -6.24874 0.281767 2.79397
W_f max, min, mean, abs_mean: 1.95847 -1.67911 0.202168 0.856933
Epoch 35/500
48s - loss: 872.5522 - val_loss: 8519.2656
Epoch 00034: val_loss did not improve
Epoch 36/500
49s - loss: 869.3075 - val_loss: 8636.8954
Epoch 00035: val_loss did not improve
Epoch 37/500
48s - loss: 864.8556 - val_loss: 8262.5044
Epoch 00036: val_loss did not improve
Epoch 38/500
49s - loss: 861.0498 - val_loss: 8845.2513
Epoch 00037: val_loss did not improve
Epoch 39/500
49s - loss: 857.5067 - val_loss: 8439.1717
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 853.7386 - val_loss: 8389.9298
Epoch 00039: val_loss did not improve
Epoch 41/500
49s - loss: 851.0636 - val_loss: 8848.0022
Epoch 00040: val_loss did not improve
Epoch 42/500
49s - loss: 846.9673 - val_loss: 8233.1715
Epoch 00041: val_loss did not improve
Epoch 43/500
48s - loss: 844.4487 - val_loss: 8699.3618
Epoch 00042: val_loss did not improve
Epoch 44/500
48s - loss: 840.4933 - val_loss: 8632.4497
Epoch 00043: val_loss did not improve
Epoch 45/500
48s - loss: 837.5718 - val_loss: 8682.9843
Epoch 00044: val_loss did not improve
Epoch 46/500
48s - loss: 834.3245 - val_loss: 8661.6042
Epoch 00045: val_loss did not improve
Epoch 47/500
49s - loss: 832.1264 - val_loss: 8475.9110
Epoch 00046: val_loss did not improve
Epoch 48/500
49s - loss: 829.6253 - val_loss: 8650.9130
Epoch 00047: val_loss did not improve
Epoch 49/500
49s - loss: 826.1544 - val_loss: 8626.8466
Epoch 00048: val_loss did not improve
Epoch 50/500
49s - loss: 823.3311 - val_loss: 8977.2503
Epoch 00049: val_loss did not improve
Epoch 51/500
48s - loss: 821.9348 - val_loss: 8831.8473
Epoch 00050: val_loss did not improve
Epoch 52/500
48s - loss: 818.6348 - val_loss: 8818.6488
Epoch 00051: val_loss did not improve
Epoch 53/500
48s - loss: 815.8586 - val_loss: 8690.4988
Epoch 00052: val_loss did not improve
Epoch 54/500
49s - loss: 814.4523 - val_loss: 8531.0573
Epoch 00053: val_loss did not improve
Epoch 55/500
49s - loss: 811.9284 - val_loss: 8331.0701
Epoch 00054: val_loss did not improve
Epoch 56/500
49s - loss: 809.1931 - val_loss: 8717.2076
Epoch 00055: val_loss did not improve
Epoch 57/500
49s - loss: 808.6042 - val_loss: 8733.4529
Epoch 00056: val_loss did not improve
Epoch 58/500
48s - loss: 805.9577 - val_loss: 8804.2664
Epoch 00057: val_loss did not improve
Epoch 59/500
49s - loss: 803.9935 - val_loss: 8885.5773
Epoch 00058: val_loss did not improve
Epoch 60/500
48s - loss: 802.3908 - val_loss: 8611.5084
Epoch 00059: val_loss did not improve
Epoch 61/500
49s - loss: 800.3583 - val_loss: 8550.9601
Epoch 00060: val_loss did not improve
Epoch 62/500
49s - loss: 798.2584 - val_loss: 8859.3783
Epoch 00061: val_loss did not improve
Epoch 63/500
49s - loss: 797.0847 - val_loss: 8840.5552
Epoch 00062: val_loss did not improve
Epoch 64/500
49s - loss: 794.0298 - val_loss: 8840.7616
Epoch 00063: val_loss did not improve
Epoch 65/500
49s - loss: 794.4442 - val_loss: 8822.5453
Epoch 00064: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout3
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout3  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout3 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2180.6200 - val_loss: 9287.6836
Epoch 00000: val_loss improved from inf to 9287.68362, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1495.2      0.73  0.33  0.54      0.71  0.19  0.61      0.72  0.12  0.65
forget mean min: 0.945612 0.673602
delta_x = 4.15427
delta_h = 2.06938
delta mean, abs_mean, abs_mean+, abs_mean-: 0.922243 4.15427 3.79799 4.87214
U_c = [[-0.07492617]] U_f = [[ 0.]] b_f = [ 1.2693522]
W_c max, min, mean, abs_mean: 0.634248 -0.608555 -0.0617422 0.552857
W_f max, min, mean, abs_mean: 0.572005 -0.551405 -0.0547535 0.398264
huabei_lstm20x2+dropout3  9287.7      0.84  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.953569 0.717001
delta_x = 4.5489
delta_h = 2.94816
delta mean, abs_mean, abs_mean+, abs_mean-: 0.880845 4.5489 4.00284 5.69993
U_c = [[-0.07492617]] U_f = [[ 0.]] b_f = [ 1.2693522]
W_c max, min, mean, abs_mean: 0.634248 -0.608555 -0.0617422 0.552857
W_f max, min, mean, abs_mean: 0.572005 -0.551405 -0.0547535 0.398264
Epoch 2/500
50s - loss: 1432.0229 - val_loss: 8918.5598
Epoch 00001: val_loss improved from 9287.68362 to 8918.55982, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1337.2      0.74  0.30  0.56      0.71  0.17  0.62      0.71  0.11  0.66
forget mean min: 0.934146 0.610499
delta_x = 4.50088
delta_h = 2.03613
delta mean, abs_mean, abs_mean+, abs_mean-: 0.891256 4.50088 4.31419 4.81192
U_c = [[-0.07153065]] U_f = [[ 0.]] b_f = [ 1.27400625]
W_c max, min, mean, abs_mean: 1.04081 -0.960864 -0.0918318 0.795036
W_f max, min, mean, abs_mean: 0.636119 -0.708293 -0.064433 0.433702
huabei_lstm20x2+dropout3  8918.6      0.82  0.23  0.66      0.81  0.15  0.71      0.82  0.10  0.75
forget mean min: 0.944367 0.677744
delta_x = 4.89489
delta_h = 2.85961
delta mean, abs_mean, abs_mean+, abs_mean-: 0.856159 4.89489 4.65148 5.28901
U_c = [[-0.07153065]] U_f = [[ 0.]] b_f = [ 1.27400625]
W_c max, min, mean, abs_mean: 1.04081 -0.960864 -0.0918318 0.795036
W_f max, min, mean, abs_mean: 0.636119 -0.708293 -0.064433 0.433702
Epoch 3/500
50s - loss: 1325.6839 - val_loss: 8839.7311
Epoch 00002: val_loss improved from 8918.55982 to 8839.73108, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1233.3      0.72  0.27  0.57      0.68  0.15  0.61      0.69  0.10  0.64
forget mean min: 0.925801 0.578082
delta_x = 4.62618
delta_h = 2.04325
delta mean, abs_mean, abs_mean+, abs_mean-: 0.738266 4.62618 4.53602 4.75663
U_c = [[-0.07548662]] U_f = [[ 0.]] b_f = [ 1.28723407]
W_c max, min, mean, abs_mean: 1.44423 -1.28442 -0.115291 0.976526
W_f max, min, mean, abs_mean: 0.654375 -0.767588 -0.0681036 0.445228
huabei_lstm20x2+dropout3  8839.7      0.81  0.22  0.65      0.80  0.15  0.70      0.81  0.10  0.74
forget mean min: 0.939439 0.669157
delta_x = 4.95957
delta_h = 2.94658
delta mean, abs_mean, abs_mean+, abs_mean-: 0.847852 4.95957 4.7864 5.22664
U_c = [[-0.07548662]] U_f = [[ 0.]] b_f = [ 1.28723407]
W_c max, min, mean, abs_mean: 1.44423 -1.28442 -0.115291 0.976526
W_f max, min, mean, abs_mean: 0.654375 -0.767588 -0.0681036 0.445228
Epoch 4/500
50s - loss: 1255.7434 - val_loss: 8611.3099
Epoch 00003: val_loss improved from 8839.73108 to 8611.30990, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1191.7      0.78  0.30  0.58      0.74  0.17  0.65      0.75  0.11  0.68
forget mean min: 0.923578 0.520241
delta_x = 5.21613
delta_h = 2.14508
delta mean, abs_mean, abs_mean+, abs_mean-: 1.0697 5.21613 5.16382 5.29747
U_c = [[-0.0701789]] U_f = [[ 0.]] b_f = [ 1.30347526]
W_c max, min, mean, abs_mean: 1.87305 -1.56749 -0.131596 1.13129
W_f max, min, mean, abs_mean: 0.632379 -0.862519 -0.0803265 0.460087
huabei_lstm20x2+dropout3  8611.3      0.83  0.24  0.66      0.83  0.16  0.72      0.84  0.11  0.75
forget mean min: 0.936969 0.646307
delta_x = 5.14385
delta_h = 2.87086
delta mean, abs_mean, abs_mean+, abs_mean-: 0.971048 5.14385 4.9543 5.44937
U_c = [[-0.0701789]] U_f = [[ 0.]] b_f = [ 1.30347526]
W_c max, min, mean, abs_mean: 1.87305 -1.56749 -0.131596 1.13129
W_f max, min, mean, abs_mean: 0.632379 -0.862519 -0.0803265 0.460087
Epoch 5/500
49s - loss: 1199.5982 - val_loss: 8885.6760
Epoch 00004: val_loss did not improve
Epoch 6/500
49s - loss: 1156.5544 - val_loss: 8801.5688
Epoch 00005: val_loss did not improve
Epoch 7/500
49s - loss: 1121.8933 - val_loss: 8643.2455
Epoch 00006: val_loss did not improve
Epoch 8/500
50s - loss: 1093.3743 - val_loss: 8605.6027
Epoch 00007: val_loss improved from 8611.30990 to 8605.60269, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1023.3      0.78  0.26  0.61      0.76  0.15  0.67      0.76  0.11  0.70
forget mean min: 0.906215 0.43003
delta_x = 6.52607
delta_h = 2.3956
delta mean, abs_mean, abs_mean+, abs_mean-: 1.05713 6.52607 6.75095 6.23794
U_c = [[-0.07740649]] U_f = [[ 0.]] b_f = [ 1.32404518]
W_c max, min, mean, abs_mean: 3.20379 -2.24658 -0.16977 1.57578
W_f max, min, mean, abs_mean: 0.556026 -1.23801 -0.138788 0.488406
huabei_lstm20x2+dropout3  8605.6      0.82  0.23  0.66      0.81  0.16  0.70      0.82  0.11  0.74
forget mean min: 0.925913 0.552584
delta_x = 6.05522
delta_h = 3.25201
delta mean, abs_mean, abs_mean+, abs_mean-: 1.22202 6.05522 6.11857 5.96228
U_c = [[-0.07740649]] U_f = [[ 0.]] b_f = [ 1.32404518]
W_c max, min, mean, abs_mean: 3.20379 -2.24658 -0.16977 1.57578
W_f max, min, mean, abs_mean: 0.556026 -1.23801 -0.138788 0.488406
Epoch 9/500
50s - loss: 1069.1276 - val_loss: 8798.6282
Epoch 00008: val_loss did not improve
Epoch 10/500
50s - loss: 1046.4740 - val_loss: 8414.0174
Epoch 00009: val_loss improved from 8605.60269 to 8414.01739, saving model to huabei_lstm20x2+dropout3_weights.hdf5
huabei_lstm20x2+dropout3  1002.1      0.80  0.27  0.62      0.77  0.16  0.68      0.77  0.11  0.71
forget mean min: 0.904532 0.414082
delta_x = 7.01929
delta_h = 2.70322
delta mean, abs_mean, abs_mean+, abs_mean-: 1.34317 7.01929 7.46495 6.45182
U_c = [[-0.08614702]] U_f = [[ 0.]] b_f = [ 1.32980788]
W_c max, min, mean, abs_mean: 3.72059 -2.47043 -0.180029 1.74943
W_f max, min, mean, abs_mean: 0.559118 -1.3771 -0.15834 0.502451
huabei_lstm20x2+dropout3  8414.0      0.83  0.24  0.66      0.82  0.17  0.70      0.83  0.12  0.74
forget mean min: 0.926778 0.608475
delta_x = 6.80951
delta_h = 3.84653
delta mean, abs_mean, abs_mean+, abs_mean-: 1.9719 6.80951 7.19657 6.20384
U_c = [[-0.08614702]] U_f = [[ 0.]] b_f = [ 1.32980788]
W_c max, min, mean, abs_mean: 3.72059 -2.47043 -0.180029 1.74943
W_f max, min, mean, abs_mean: 0.559118 -1.3771 -0.15834 0.502451
Epoch 11/500
49s - loss: 1026.3490 - val_loss: 8480.7377
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 1009.3630 - val_loss: 8665.2181
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 993.7743 - val_loss: 8716.4326
Epoch 00012: val_loss did not improve
Epoch 14/500
49s - loss: 980.2452 - val_loss: 8790.6743
Epoch 00013: val_loss did not improve
Epoch 15/500
49s - loss: 968.3125 - val_loss: 8698.8677
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 957.0581 - val_loss: 9020.7654
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 946.4826 - val_loss: 8574.2566
Epoch 00016: val_loss did not improve
Epoch 18/500
49s - loss: 937.2052 - val_loss: 8549.0372
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 928.8648 - val_loss: 8744.2562
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 920.4844 - val_loss: 8615.2103
Epoch 00019: val_loss did not improve
Epoch 21/500
49s - loss: 912.0428 - val_loss: 8766.5197
Epoch 00020: val_loss did not improve
Epoch 22/500
49s - loss: 905.1195 - val_loss: 8837.1517
Epoch 00021: val_loss did not improve
Epoch 23/500
49s - loss: 899.4153 - val_loss: 9021.9725
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 892.7148 - val_loss: 8777.5640
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 886.9413 - val_loss: 8870.6607
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 882.6857 - val_loss: 8643.6032
Epoch 00025: val_loss did not improve
Epoch 27/500
49s - loss: 876.8218 - val_loss: 8901.5755
Epoch 00026: val_loss did not improve
Epoch 28/500
48s - loss: 870.8556 - val_loss: 8815.0699
Epoch 00027: val_loss did not improve
Epoch 29/500
49s - loss: 866.1172 - val_loss: 8844.4471
Epoch 00028: val_loss did not improve
Epoch 30/500
49s - loss: 862.9307 - val_loss: 8845.6490
Epoch 00029: val_loss did not improve
Epoch 31/500
49s - loss: 858.0641 - val_loss: 8617.3917
Epoch 00030: val_loss did not improve
Epoch 32/500
49s - loss: 855.3230 - val_loss: 8760.1580
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 850.9084 - val_loss: 8857.7844
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 846.9088 - val_loss: 8825.6634
Epoch 00033: val_loss did not improve
Epoch 35/500
48s - loss: 844.3225 - val_loss: 8947.9700
Epoch 00034: val_loss did not improve
Epoch 36/500
49s - loss: 840.2998 - val_loss: 8730.7377
Epoch 00035: val_loss did not improve
Epoch 37/500
49s - loss: 837.0733 - val_loss: 8952.6204
Epoch 00036: val_loss did not improve
Epoch 38/500
49s - loss: 834.3479 - val_loss: 8980.4860
Epoch 00037: val_loss did not improve
Epoch 39/500
49s - loss: 829.7571 - val_loss: 8825.4514
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 827.8542 - val_loss: 8791.6135
Epoch 00039: val_loss did not improve
Epoch 41/500
49s - loss: 824.3693 - val_loss: 8763.3892
Epoch 00040: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout4
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout4  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout4 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2191.7641 - val_loss: 9377.8187
Epoch 00000: val_loss improved from inf to 9377.81867, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4  1506.0      0.71  0.32  0.53      0.68  0.18  0.59      0.70  0.12  0.64
forget mean min: 0.944447 0.751378
delta_x = 3.99844
delta_h = 1.86002
delta mean, abs_mean, abs_mean+, abs_mean-: 0.771479 3.99844 3.74837 4.43588
U_c = [[-0.06877293]] U_f = [[ 0.]] b_f = [ 1.19942212]
W_c max, min, mean, abs_mean: 0.668224 -0.570524 0.113461 0.560343
W_f max, min, mean, abs_mean: 0.590815 -0.401948 0.0805804 0.386189
huabei_lstm20x2+dropout4  9377.8      0.84  0.22  0.67      0.82  0.15  0.72      0.83  0.11  0.75
forget mean min: 0.950258 0.766486
delta_x = 4.66477
delta_h = 2.90947
delta mean, abs_mean, abs_mean+, abs_mean-: 0.66904 4.66477 4.05049 5.8488
U_c = [[-0.06877293]] U_f = [[ 0.]] b_f = [ 1.19942212]
W_c max, min, mean, abs_mean: 0.668224 -0.570524 0.113461 0.560343
W_f max, min, mean, abs_mean: 0.590815 -0.401948 0.0805804 0.386189
Epoch 2/500
50s - loss: 1449.0109 - val_loss: 9427.7544
Epoch 00001: val_loss did not improve
Epoch 3/500
50s - loss: 1330.4659 - val_loss: 9140.1090
Epoch 00002: val_loss improved from 9377.81867 to 9140.10897, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4  1231.4      0.73  0.29  0.56      0.71  0.16  0.62      0.72  0.11  0.66
forget mean min: 0.924765 0.673067
delta_x = 4.72516
delta_h = 1.73532
delta mean, abs_mean, abs_mean+, abs_mean-: 0.735435 4.72516 4.64302 4.84241
U_c = [[-0.06223929]] U_f = [[ 0.]] b_f = [ 1.18342018]
W_c max, min, mean, abs_mean: 1.69035 -1.02111 0.234645 1.01532
W_f max, min, mean, abs_mean: 0.779939 -0.459433 0.110518 0.433357
huabei_lstm20x2+dropout4  9140.1      0.81  0.21  0.67      0.79  0.14  0.70      0.80  0.10  0.73
forget mean min: 0.934394 0.688525
delta_x = 4.88094
delta_h = 2.57736
delta mean, abs_mean, abs_mean+, abs_mean-: 0.511862 4.88094 4.62067 5.24564
U_c = [[-0.06223929]] U_f = [[ 0.]] b_f = [ 1.18342018]
W_c max, min, mean, abs_mean: 1.69035 -1.02111 0.234645 1.01532
W_f max, min, mean, abs_mean: 0.779939 -0.459433 0.110518 0.433357
Epoch 4/500
50s - loss: 1259.7179 - val_loss: 9018.9080
Epoch 00003: val_loss improved from 9140.10897 to 9018.90800, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4  1200.8      0.78  0.30  0.58      0.75  0.18  0.65      0.76  0.12  0.69
forget mean min: 0.922603 0.66524
delta_x = 5.24907
delta_h = 1.94203
delta mean, abs_mean, abs_mean+, abs_mean-: 1.03477 5.24907 5.31396 5.15522
U_c = [[-0.06387926]] U_f = [[ 0.]] b_f = [ 1.19476378]
W_c max, min, mean, abs_mean: 2.05313 -1.18634 0.274679 1.16063
W_f max, min, mean, abs_mean: 0.876306 -0.499259 0.117617 0.450314
huabei_lstm20x2+dropout4  9018.9      0.81  0.20  0.67      0.80  0.13  0.71      0.80  0.10  0.73
forget mean min: 0.931846 0.677849
delta_x = 5.01923
delta_h = 2.70223
delta mean, abs_mean, abs_mean+, abs_mean-: 0.603797 5.01923 4.89726 5.18364
U_c = [[-0.06387926]] U_f = [[ 0.]] b_f = [ 1.19476378]
W_c max, min, mean, abs_mean: 2.05313 -1.18634 0.274679 1.16063
W_f max, min, mean, abs_mean: 0.876306 -0.499259 0.117617 0.450314
Epoch 5/500
50s - loss: 1210.3467 - val_loss: 8968.3235
Epoch 00004: val_loss improved from 9018.90800 to 8968.32354, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4  1140.5      0.76  0.28  0.59      0.73  0.16  0.65      0.74  0.11  0.68
forget mean min: 0.918636 0.644875
delta_x = 5.3347
delta_h = 2.12892
delta mean, abs_mean, abs_mean+, abs_mean-: 1.00807 5.3347 5.44742 5.17765
U_c = [[-0.07322076]] U_f = [[ 0.]] b_f = [ 1.20477521]
W_c max, min, mean, abs_mean: 2.34685 -1.30352 0.304475 1.26694
W_f max, min, mean, abs_mean: 0.956394 -0.530799 0.1245 0.467251
huabei_lstm20x2+dropout4  8968.3      0.80  0.20  0.67      0.78  0.13  0.70      0.79  0.10  0.73
forget mean min: 0.930246 0.670089
delta_x = 4.9355
delta_h = 2.92031
delta mean, abs_mean, abs_mean+, abs_mean-: 0.720953 4.9355 4.8771 5.01611
U_c = [[-0.07322076]] U_f = [[ 0.]] b_f = [ 1.20477521]
W_c max, min, mean, abs_mean: 2.34685 -1.30352 0.304475 1.26694
W_f max, min, mean, abs_mean: 0.956394 -0.530799 0.1245 0.467251
Epoch 6/500
50s - loss: 1169.8359 - val_loss: 9322.4737
Epoch 00005: val_loss did not improve
Epoch 7/500
50s - loss: 1135.1012 - val_loss: 8925.1987
Epoch 00006: val_loss improved from 8968.32354 to 8925.19868, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4  1044.3      0.73  0.24  0.59      0.70  0.13  0.64      0.71  0.09  0.66
forget mean min: 0.909018 0.603853
delta_x = 5.53317
delta_h = 2.09428
delta mean, abs_mean, abs_mean+, abs_mean-: 0.677844 5.53317 5.68906 5.34578
U_c = [[-0.07592519]] U_f = [[ 0.]] b_f = [ 1.22006369]
W_c max, min, mean, abs_mean: 2.92336 -1.52722 0.357957 1.46895
W_f max, min, mean, abs_mean: 1.09723 -0.59115 0.136638 0.496878
huabei_lstm20x2+dropout4  8925.2      0.79  0.19  0.66      0.77  0.13  0.69      0.77  0.09  0.72
forget mean min: 0.9251 0.653814
delta_x = 5.10108
delta_h = 3.01427
delta mean, abs_mean, abs_mean+, abs_mean-: 0.639519 5.10108 5.14839 5.04147
U_c = [[-0.07592519]] U_f = [[ 0.]] b_f = [ 1.22006369]
W_c max, min, mean, abs_mean: 2.92336 -1.52722 0.357957 1.46895
W_f max, min, mean, abs_mean: 1.09723 -0.59115 0.136638 0.496878
Epoch 8/500
50s - loss: 1103.3014 - val_loss: 8985.7812
Epoch 00007: val_loss did not improve
Epoch 9/500
50s - loss: 1076.0343 - val_loss: 8571.6751
Epoch 00008: val_loss improved from 8925.19868 to 8571.67508, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4   997.2      0.77  0.25  0.62      0.75  0.14  0.67      0.76  0.09  0.70
forget mean min: 0.907076 0.574077
delta_x = 6.27389
delta_h = 2.37002
delta mean, abs_mean, abs_mean+, abs_mean-: 0.999917 6.27389 6.56422 5.91319
U_c = [[-0.08025471]] U_f = [[ 0.]] b_f = [ 1.22351193]
W_c max, min, mean, abs_mean: 3.40747 -1.71771 0.403016 1.6446
W_f max, min, mean, abs_mean: 1.22345 -0.646159 0.151641 0.527899
huabei_lstm20x2+dropout4  8571.7      0.80  0.20  0.67      0.79  0.13  0.70      0.80  0.09  0.73
forget mean min: 0.924948 0.64172
delta_x = 5.61714
delta_h = 3.28121
delta mean, abs_mean, abs_mean+, abs_mean-: 1.05529 5.61714 5.88585 5.26553
U_c = [[-0.08025471]] U_f = [[ 0.]] b_f = [ 1.22351193]
W_c max, min, mean, abs_mean: 3.40747 -1.71771 0.403016 1.6446
W_f max, min, mean, abs_mean: 1.22345 -0.646159 0.151641 0.527899
Epoch 10/500
50s - loss: 1054.7992 - val_loss: 8808.5630
Epoch 00009: val_loss did not improve
Epoch 11/500
50s - loss: 1034.6849 - val_loss: 8580.1545
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 1018.8699 - val_loss: 8915.6453
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 1004.2534 - val_loss: 8808.5462
Epoch 00012: val_loss did not improve
Epoch 14/500
50s - loss: 990.2402 - val_loss: 8716.2160
Epoch 00013: val_loss did not improve
Epoch 15/500
50s - loss: 978.1973 - val_loss: 8718.2243
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 967.5058 - val_loss: 8691.8568
Epoch 00015: val_loss did not improve
Epoch 17/500
50s - loss: 956.0065 - val_loss: 8440.7532
Epoch 00016: val_loss improved from 8571.67508 to 8440.75325, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4   878.0      0.80  0.24  0.64      0.78  0.13  0.70      0.78  0.09  0.73
forget mean min: 0.899808 0.463186
delta_x = 7.2243
delta_h = 2.87186
delta mean, abs_mean, abs_mean+, abs_mean-: 1.21562 7.2243 7.90329 6.44639
U_c = [[-0.09368122]] U_f = [[ 0.]] b_f = [ 1.24510717]
W_c max, min, mean, abs_mean: 4.87365 -2.27851 0.51705 2.13552
W_f max, min, mean, abs_mean: 1.79731 -0.861591 0.188153 0.662284
huabei_lstm20x2+dropout4  8440.7      0.82  0.22  0.66      0.80  0.15  0.70      0.81  0.11  0.73
forget mean min: 0.924084 0.622301
delta_x = 6.46783
delta_h = 3.97891
delta mean, abs_mean, abs_mean+, abs_mean-: 1.65676 6.46783 7.08797 5.63522
U_c = [[-0.09368122]] U_f = [[ 0.]] b_f = [ 1.24510717]
W_c max, min, mean, abs_mean: 4.87365 -2.27851 0.51705 2.13552
W_f max, min, mean, abs_mean: 1.79731 -0.861591 0.188153 0.662284
Epoch 18/500
50s - loss: 946.1482 - val_loss: 8971.2987
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 937.1409 - val_loss: 8620.1347
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 929.4870 - val_loss: 8913.3993
Epoch 00019: val_loss did not improve
Epoch 21/500
50s - loss: 920.8503 - val_loss: 8436.7725
Epoch 00020: val_loss improved from 8440.75325 to 8436.77250, saving model to huabei_lstm20x2+dropout4_weights.hdf5
huabei_lstm20x2+dropout4   865.7      0.81  0.24  0.64      0.79  0.14  0.70      0.80  0.10  0.74
forget mean min: 0.898425 0.411572
delta_x = 7.77595
delta_h = 3.19074
delta mean, abs_mean, abs_mean+, abs_mean-: 1.4272 7.77595 8.63153 6.79901
U_c = [[-0.10033062]] U_f = [[ 0.]] b_f = [ 1.24046266]
W_c max, min, mean, abs_mean: 5.33545 -2.51827 0.550618 2.31434
W_f max, min, mean, abs_mean: 2.02359 -0.957155 0.205728 0.732108
huabei_lstm20x2+dropout4  8436.8      0.82  0.22  0.67      0.80  0.15  0.70      0.81  0.11  0.74
forget mean min: 0.922221 0.618963
delta_x = 7.04873
delta_h = 4.41034
delta mean, abs_mean, abs_mean+, abs_mean-: 1.8963 7.04873 7.7367 6.10609
U_c = [[-0.10033062]] U_f = [[ 0.]] b_f = [ 1.24046266]
W_c max, min, mean, abs_mean: 5.33545 -2.51827 0.550618 2.31434
W_f max, min, mean, abs_mean: 2.02359 -0.957155 0.205728 0.732108
Epoch 22/500
50s - loss: 912.9351 - val_loss: 9069.0266
Epoch 00021: val_loss did not improve
Epoch 23/500
50s - loss: 906.4833 - val_loss: 8998.8887
Epoch 00022: val_loss did not improve
Epoch 24/500
50s - loss: 900.8848 - val_loss: 8842.4865
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 894.6906 - val_loss: 9031.8426
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 889.3995 - val_loss: 9109.8945
Epoch 00025: val_loss did not improve
Epoch 27/500
49s - loss: 883.9164 - val_loss: 8787.4791
Epoch 00026: val_loss did not improve
Epoch 28/500
49s - loss: 879.6251 - val_loss: 8784.8218
Epoch 00027: val_loss did not improve
Epoch 29/500
50s - loss: 874.8204 - val_loss: 8822.3717
Epoch 00028: val_loss did not improve
Epoch 30/500
50s - loss: 869.4426 - val_loss: 8854.4628
Epoch 00029: val_loss did not improve
Epoch 31/500
50s - loss: 867.6569 - val_loss: 8975.6032
Epoch 00030: val_loss did not improve
Epoch 32/500
50s - loss: 862.5829 - val_loss: 8852.7591
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 858.2712 - val_loss: 8793.7066
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 855.8081 - val_loss: 9136.5527
Epoch 00033: val_loss did not improve
Epoch 35/500
49s - loss: 851.6775 - val_loss: 8730.0716
Epoch 00034: val_loss did not improve
Epoch 36/500
49s - loss: 849.4177 - val_loss: 8570.4012
Epoch 00035: val_loss did not improve
Epoch 37/500
50s - loss: 846.2831 - val_loss: 8918.2464
Epoch 00036: val_loss did not improve
Epoch 38/500
50s - loss: 843.1214 - val_loss: 8880.3633
Epoch 00037: val_loss did not improve
Epoch 39/500
50s - loss: 839.6725 - val_loss: 9141.6428
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 836.5921 - val_loss: 9316.6765
Epoch 00039: val_loss did not improve
Epoch 41/500
49s - loss: 832.6070 - val_loss: 8922.2209
Epoch 00040: val_loss did not improve
Epoch 42/500
49s - loss: 830.4029 - val_loss: 9201.2614
Epoch 00041: val_loss did not improve
Epoch 43/500
49s - loss: 828.4188 - val_loss: 9212.0299
Epoch 00042: val_loss did not improve
Epoch 44/500
49s - loss: 825.3962 - val_loss: 9424.7329
Epoch 00043: val_loss did not improve
Epoch 45/500
50s - loss: 823.6275 - val_loss: 8738.8005
Epoch 00044: val_loss did not improve
Epoch 46/500
50s - loss: 819.6329 - val_loss: 9089.4317
Epoch 00045: val_loss did not improve
Epoch 47/500
50s - loss: 817.0084 - val_loss: 8958.8421
Epoch 00046: val_loss did not improve
Epoch 48/500
49s - loss: 815.1463 - val_loss: 9088.8287
Epoch 00047: val_loss did not improve
Epoch 49/500
49s - loss: 812.1165 - val_loss: 9172.8594
Epoch 00048: val_loss did not improve
Epoch 50/500
49s - loss: 809.4377 - val_loss: 8758.6454
Epoch 00049: val_loss did not improve
Epoch 51/500
49s - loss: 806.8119 - val_loss: 9014.5102
Epoch 00050: val_loss did not improve
Epoch 52/500
50s - loss: 805.1439 - val_loss: 9087.2408
Epoch 00051: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout5
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout5  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout5 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2204.0165 - val_loss: 9810.7829
Epoch 00000: val_loss improved from inf to 9810.78295, saving model to huabei_lstm20x2+dropout5_weights.hdf5
huabei_lstm20x2+dropout5  1513.5      0.69  0.31  0.52      0.66  0.18  0.58      0.67  0.11  0.62
forget mean min: 0.946226 0.668847
delta_x = 3.9142
delta_h = 1.98167
delta mean, abs_mean, abs_mean+, abs_mean-: 0.700758 3.9142 3.61909 4.4334
U_c = [[-0.07679078]] U_f = [[ 0.]] b_f = [ 1.29128635]
W_c max, min, mean, abs_mean: 0.610486 -0.582762 0.150119 0.524701
W_f max, min, mean, abs_mean: 0.530947 -0.530787 0.0882028 0.397731
huabei_lstm20x2+dropout5  9810.8      0.83  0.24  0.66      0.82  0.15  0.71      0.83  0.11  0.75
forget mean min: 0.954956 0.721404
delta_x = 4.33901
delta_h = 2.97216
delta mean, abs_mean, abs_mean+, abs_mean-: 0.839724 4.33901 3.86723 5.295
U_c = [[-0.07679078]] U_f = [[ 0.]] b_f = [ 1.29128635]
W_c max, min, mean, abs_mean: 0.610486 -0.582762 0.150119 0.524701
W_f max, min, mean, abs_mean: 0.530947 -0.530787 0.0882028 0.397731
Epoch 2/500
50s - loss: 1456.2503 - val_loss: 8888.0595
Epoch 00001: val_loss improved from 9810.78295 to 8888.05954, saving model to huabei_lstm20x2+dropout5_weights.hdf5
huabei_lstm20x2+dropout5  1447.7      0.81  0.36  0.55      0.79  0.22  0.65      0.80  0.15  0.70
forget mean min: 0.943193 0.572132
delta_x = 4.83065
delta_h = 2.28141
delta mean, abs_mean, abs_mean+, abs_mean-: 1.48824 4.83065 4.73535 5.02171
U_c = [[-0.07119378]] U_f = [[ 0.]] b_f = [ 1.31265831]
W_c max, min, mean, abs_mean: 0.974325 -1.00466 0.191137 0.779421
W_f max, min, mean, abs_mean: 0.719431 -0.652489 0.0724215 0.443943
huabei_lstm20x2+dropout5  8888.1      0.87  0.24  0.68      0.86  0.15  0.74      0.87  0.11  0.78
forget mean min: 0.951514 0.639248
delta_x = 5.14441
delta_h = 3.15069
delta mean, abs_mean, abs_mean+, abs_mean-: 1.4656 5.14441 4.92586 5.59006
U_c = [[-0.07119378]] U_f = [[ 0.]] b_f = [ 1.31265831]
W_c max, min, mean, abs_mean: 0.974325 -1.00466 0.191137 0.779421
W_f max, min, mean, abs_mean: 0.719431 -0.652489 0.0724215 0.443943
Epoch 3/500
50s - loss: 1320.9387 - val_loss: 9002.7750
Epoch 00002: val_loss did not improve
Epoch 4/500
50s - loss: 1233.6573 - val_loss: 8622.7271
Epoch 00003: val_loss improved from 8888.05954 to 8622.72709, saving model to huabei_lstm20x2+dropout5_weights.hdf5
huabei_lstm20x2+dropout5  1150.5      0.77  0.29  0.59      0.74  0.16  0.65      0.75  0.11  0.69
forget mean min: 0.923715 0.500747
delta_x = 5.3256
delta_h = 2.195
delta mean, abs_mean, abs_mean+, abs_mean-: 1.01104 5.3256 5.34143 5.30254
U_c = [[-0.07564557]] U_f = [[ 0.]] b_f = [ 1.34757197]
W_c max, min, mean, abs_mean: 1.47817 -1.63516 0.226147 1.12052
W_f max, min, mean, abs_mean: 0.732812 -0.793517 0.0376019 0.469772
huabei_lstm20x2+dropout5  8622.7      0.83  0.24  0.66      0.82  0.16  0.71      0.84  0.11  0.75
forget mean min: 0.942438 0.629273
delta_x = 5.08456
delta_h = 3.04049
delta mean, abs_mean, abs_mean+, abs_mean-: 1.32732 5.08456 5.18872 4.91616
U_c = [[-0.07564557]] U_f = [[ 0.]] b_f = [ 1.34757197]
W_c max, min, mean, abs_mean: 1.47817 -1.63516 0.226147 1.12052
W_f max, min, mean, abs_mean: 0.732812 -0.793517 0.0376019 0.469772
Epoch 5/500
50s - loss: 1177.2489 - val_loss: 9041.7094
Epoch 00004: val_loss did not improve
Epoch 6/500
50s - loss: 1134.7123 - val_loss: 8317.3167
Epoch 00005: val_loss improved from 8622.72709 to 8317.31671, saving model to huabei_lstm20x2+dropout5_weights.hdf5
huabei_lstm20x2+dropout5  1081.7      0.79  0.28  0.61      0.77  0.16  0.67      0.77  0.11  0.70
forget mean min: 0.915427 0.41985
delta_x = 6.18551
delta_h = 2.36494
delta mean, abs_mean, abs_mean+, abs_mean-: 1.16843 6.18551 6.3496 5.95976
U_c = [[-0.07678299]] U_f = [[ 0.]] b_f = [ 1.38923645]
W_c max, min, mean, abs_mean: 1.82965 -2.10096 0.252506 1.36231
W_f max, min, mean, abs_mean: 0.780414 -0.903216 0.0159531 0.49148
huabei_lstm20x2+dropout5  8317.3      0.82  0.25  0.64      0.81  0.17  0.69      0.82  0.12  0.74
forget mean min: 0.93742 0.61555
delta_x = 5.59599
delta_h = 3.22186
delta mean, abs_mean, abs_mean+, abs_mean-: 1.64099 5.59599 5.88629 5.13278
U_c = [[-0.07678299]] U_f = [[ 0.]] b_f = [ 1.38923645]
W_c max, min, mean, abs_mean: 1.82965 -2.10096 0.252506 1.36231
W_f max, min, mean, abs_mean: 0.780414 -0.903216 0.0159531 0.49148
Epoch 7/500
49s - loss: 1099.5702 - val_loss: 8456.2807
Epoch 00006: val_loss did not improve
Epoch 8/500
49s - loss: 1070.3628 - val_loss: 8341.9429
Epoch 00007: val_loss did not improve
Epoch 9/500
49s - loss: 1046.3534 - val_loss: 8461.8123
Epoch 00008: val_loss did not improve
Epoch 10/500
49s - loss: 1023.8362 - val_loss: 8398.3800
Epoch 00009: val_loss did not improve
Epoch 11/500
50s - loss: 1006.9037 - val_loss: 8510.3587
Epoch 00010: val_loss did not improve
Epoch 12/500
50s - loss: 989.0005 - val_loss: 8331.0532
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 972.8691 - val_loss: 8565.9750
Epoch 00012: val_loss did not improve
Epoch 14/500
49s - loss: 961.6681 - val_loss: 8403.5284
Epoch 00013: val_loss did not improve
Epoch 15/500
49s - loss: 948.5788 - val_loss: 8569.3089
Epoch 00014: val_loss did not improve
Epoch 16/500
49s - loss: 937.9813 - val_loss: 8507.8030
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 928.7597 - val_loss: 8652.3261
Epoch 00016: val_loss did not improve
Epoch 18/500
50s - loss: 920.4658 - val_loss: 9316.5443
Epoch 00017: val_loss did not improve
Epoch 19/500
50s - loss: 910.8669 - val_loss: 8851.5653
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 903.7940 - val_loss: 8790.9730
Epoch 00019: val_loss did not improve
Epoch 21/500
49s - loss: 895.4222 - val_loss: 9103.3167
Epoch 00020: val_loss did not improve
Epoch 22/500
49s - loss: 890.2284 - val_loss: 9201.2754
Epoch 00021: val_loss did not improve
Epoch 23/500
49s - loss: 883.2725 - val_loss: 8879.4577
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 877.9385 - val_loss: 8817.8777
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 870.8570 - val_loss: 9172.2725
Epoch 00024: val_loss did not improve
Epoch 26/500
50s - loss: 866.8508 - val_loss: 9065.0774
Epoch 00025: val_loss did not improve
Epoch 27/500
50s - loss: 862.8526 - val_loss: 9164.3721
Epoch 00026: val_loss did not improve
Epoch 28/500
49s - loss: 858.6604 - val_loss: 8732.3851
Epoch 00027: val_loss did not improve
Epoch 29/500
49s - loss: 853.9342 - val_loss: 8837.2026
Epoch 00028: val_loss did not improve
Epoch 30/500
48s - loss: 850.1303 - val_loss: 8927.6541
Epoch 00029: val_loss did not improve
Epoch 31/500
48s - loss: 845.7695 - val_loss: 9068.9711
Epoch 00030: val_loss did not improve
Epoch 32/500
48s - loss: 842.5415 - val_loss: 9025.8827
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 839.3913 - val_loss: 8935.7666
Epoch 00032: val_loss did not improve
Epoch 34/500
50s - loss: 835.6487 - val_loss: 8974.7753
Epoch 00033: val_loss did not improve
Epoch 35/500
49s - loss: 832.4994 - val_loss: 8866.0116
Epoch 00034: val_loss did not improve
Epoch 36/500
49s - loss: 828.9328 - val_loss: 9046.4619
Epoch 00035: val_loss did not improve
Epoch 37/500
49s - loss: 825.9421 - val_loss: 8970.9753
Epoch 00036: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout6
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout6  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout6 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
49s - loss: 2198.6710 - val_loss: 9193.1565
Epoch 00000: val_loss improved from inf to 9193.15652, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6  1550.5      0.72  0.34  0.53      0.70  0.20  0.60      0.71  0.13  0.64
forget mean min: 0.95016 0.673741
delta_x = 4.09239
delta_h = 2.19538
delta mean, abs_mean, abs_mean+, abs_mean-: 1.01447 4.09239 3.79926 4.6932
U_c = [[-0.08000325]] U_f = [[ 0.]] b_f = [ 1.29226398]
W_c max, min, mean, abs_mean: 0.58555 -0.526678 0.0598736 0.509769
W_f max, min, mean, abs_mean: 0.558536 -0.542385 0.0546088 0.395907
huabei_lstm20x2+dropout6  9193.2      0.87  0.24  0.68      0.85  0.16  0.73      0.86  0.11  0.77
forget mean min: 0.958518 0.708337
delta_x = 4.6095
delta_h = 3.24481
delta mean, abs_mean, abs_mean+, abs_mean-: 1.20268 4.6095 4.14062 5.71325
U_c = [[-0.08000325]] U_f = [[ 0.]] b_f = [ 1.29226398]
W_c max, min, mean, abs_mean: 0.58555 -0.526678 0.0598736 0.509769
W_f max, min, mean, abs_mean: 0.558536 -0.542385 0.0546088 0.395907
Epoch 2/500
50s - loss: 1470.1666 - val_loss: 9121.3833
Epoch 00001: val_loss improved from 9193.15652 to 9121.38333, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6  1346.0      0.74  0.32  0.55      0.72  0.18  0.62      0.73  0.12  0.66
forget mean min: 0.93715 0.630885
delta_x = 4.50557
delta_h = 1.97491
delta mean, abs_mean, abs_mean+, abs_mean-: 0.928198 4.50557 4.3579 4.75005
U_c = [[-0.06974754]] U_f = [[ 0.]] b_f = [ 1.30336833]
W_c max, min, mean, abs_mean: 1.09527 -0.788421 0.1197 0.781992
W_f max, min, mean, abs_mean: 0.729121 -0.627026 0.0609445 0.422853
huabei_lstm20x2+dropout6  9121.4      0.84  0.23  0.68      0.83  0.14  0.73      0.84  0.10  0.76
forget mean min: 0.947168 0.640694
delta_x = 4.62303
delta_h = 2.83208
delta mean, abs_mean, abs_mean+, abs_mean-: 0.802496 4.62303 4.31061 5.15344
U_c = [[-0.06974754]] U_f = [[ 0.]] b_f = [ 1.30336833]
W_c max, min, mean, abs_mean: 1.09527 -0.788421 0.1197 0.781992
W_f max, min, mean, abs_mean: 0.729121 -0.627026 0.0609445 0.422853
Epoch 3/500
50s - loss: 1335.5571 - val_loss: 8517.4358
Epoch 00002: val_loss improved from 9121.38333 to 8517.43575, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6  1290.8      0.78  0.32  0.57      0.76  0.18  0.65      0.76  0.12  0.69
forget mean min: 0.930707 0.618305
delta_x = 5.14289
delta_h = 2.18316
delta mean, abs_mean, abs_mean+, abs_mean-: 1.20975 5.14289 5.17648 5.08956
U_c = [[-0.07077783]] U_f = [[ 0.]] b_f = [ 1.30901754]
W_c max, min, mean, abs_mean: 1.54331 -1.01257 0.171191 0.994857
W_f max, min, mean, abs_mean: 0.870137 -0.638499 0.0668101 0.432493
huabei_lstm20x2+dropout6  8517.4      0.85  0.21  0.69      0.83  0.13  0.74      0.84  0.09  0.77
forget mean min: 0.941552 0.653096
delta_x = 5.02988
delta_h = 3.03394
delta mean, abs_mean, abs_mean+, abs_mean-: 1.00503 5.02988 4.84062 5.34311
U_c = [[-0.07077783]] U_f = [[ 0.]] b_f = [ 1.30901754]
W_c max, min, mean, abs_mean: 1.54331 -1.01257 0.171191 0.994857
W_f max, min, mean, abs_mean: 0.870137 -0.638499 0.0668101 0.432493
Epoch 4/500
50s - loss: 1257.3999 - val_loss: 9235.3873
Epoch 00003: val_loss did not improve
Epoch 5/500
50s - loss: 1202.4157 - val_loss: 8952.6044
Epoch 00004: val_loss did not improve
Epoch 6/500
50s - loss: 1161.7755 - val_loss: 8582.0717
Epoch 00005: val_loss did not improve
Epoch 7/500
50s - loss: 1126.7756 - val_loss: 8322.5183
Epoch 00006: val_loss improved from 8517.43575 to 8322.51831, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6  1087.0      0.81  0.29  0.61      0.78  0.17  0.68      0.79  0.11  0.71
forget mean min: 0.91869 0.528861
delta_x = 6.02673
delta_h = 2.47579
delta mean, abs_mean, abs_mean+, abs_mean-: 1.37534 6.02673 6.32827 5.60194
U_c = [[-0.07870371]] U_f = [[ 0.]] b_f = [ 1.34691334]
W_c max, min, mean, abs_mean: 2.69865 -1.51029 0.297045 1.47039
W_f max, min, mean, abs_mean: 1.39935 -0.653676 0.0951054 0.478748
huabei_lstm20x2+dropout6  8322.5      0.85  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.935608 0.678397
delta_x = 5.15888
delta_h = 3.1586
delta mean, abs_mean, abs_mean+, abs_mean-: 1.22601 5.15888 5.23837 5.03482
U_c = [[-0.07870371]] U_f = [[ 0.]] b_f = [ 1.34691334]
W_c max, min, mean, abs_mean: 2.69865 -1.51029 0.297045 1.47039
W_f max, min, mean, abs_mean: 1.39935 -0.653676 0.0951054 0.478748
Epoch 8/500
50s - loss: 1098.1025 - val_loss: 8311.9818
Epoch 00007: val_loss improved from 8322.51831 to 8311.98180, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6  1010.1      0.76  0.25  0.61      0.73  0.14  0.66      0.74  0.09  0.69
forget mean min: 0.90984 0.491024
delta_x = 6.08524
delta_h = 2.37293
delta mean, abs_mean, abs_mean+, abs_mean-: 0.935786 6.08524 6.40676 5.69553
U_c = [[-0.08135685]] U_f = [[ 0.]] b_f = [ 1.3556422]
W_c max, min, mean, abs_mean: 2.91072 -1.60409 0.316899 1.55191
W_f max, min, mean, abs_mean: 1.48276 -0.65651 0.099674 0.487426
huabei_lstm20x2+dropout6  8312.0      0.82  0.21  0.67      0.80  0.14  0.71      0.81  0.09  0.75
forget mean min: 0.929805 0.669135
delta_x = 5.34461
delta_h = 3.21633
delta mean, abs_mean, abs_mean+, abs_mean-: 0.975074 5.34461 5.3976 5.26979
U_c = [[-0.08135685]] U_f = [[ 0.]] b_f = [ 1.3556422]
W_c max, min, mean, abs_mean: 2.91072 -1.60409 0.316899 1.55191
W_f max, min, mean, abs_mean: 1.48276 -0.65651 0.099674 0.487426
Epoch 9/500
50s - loss: 1072.2312 - val_loss: 8586.3363
Epoch 00008: val_loss did not improve
Epoch 10/500
50s - loss: 1049.6626 - val_loss: 8326.2135
Epoch 00009: val_loss did not improve
Epoch 11/500
49s - loss: 1029.7102 - val_loss: 8275.6323
Epoch 00010: val_loss improved from 8311.98180 to 8275.63225, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6   935.8      0.76  0.23  0.62      0.73  0.12  0.67      0.74  0.08  0.69
forget mean min: 0.903388 0.410799
delta_x = 6.53284
delta_h = 2.47572
delta mean, abs_mean, abs_mean+, abs_mean-: 0.84815 6.53284 6.94575 6.06472
U_c = [[-0.08609749]] U_f = [[ 0.]] b_f = [ 1.38880014]
W_c max, min, mean, abs_mean: 3.54401 -1.89211 0.374639 1.79285
W_f max, min, mean, abs_mean: 1.6839 -0.705598 0.112441 0.522757
huabei_lstm20x2+dropout6  8275.6      0.80  0.20  0.67      0.79  0.13  0.71      0.80  0.09  0.74
forget mean min: 0.924752 0.666457
delta_x = 5.60275
delta_h = 3.29305
delta mean, abs_mean, abs_mean+, abs_mean-: 0.86081 5.60275 5.71465 5.45709
U_c = [[-0.08609749]] U_f = [[ 0.]] b_f = [ 1.38880014]
W_c max, min, mean, abs_mean: 3.54401 -1.89211 0.374639 1.79285
W_f max, min, mean, abs_mean: 1.6839 -0.705598 0.112441 0.522757
Epoch 12/500
49s - loss: 1012.2806 - val_loss: 8588.4881
Epoch 00011: val_loss did not improve
Epoch 13/500
50s - loss: 996.2333 - val_loss: 8254.4511
Epoch 00012: val_loss improved from 8275.63225 to 8254.45114, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6   930.8      0.81  0.26  0.63      0.78  0.15  0.69      0.78  0.10  0.72
forget mean min: 0.905403 0.377041
delta_x = 6.96395
delta_h = 2.70108
delta mean, abs_mean, abs_mean+, abs_mean-: 1.24256 6.96395 7.52963 6.28652
U_c = [[-0.0869934]] U_f = [[ 0.]] b_f = [ 1.40969229]
W_c max, min, mean, abs_mean: 3.93084 -2.05683 0.409187 1.9299
W_f max, min, mean, abs_mean: 1.751 -0.773259 0.113655 0.541554
huabei_lstm20x2+dropout6  8254.4      0.84  0.22  0.68      0.83  0.14  0.72      0.83  0.10  0.76
forget mean min: 0.927193 0.666131
delta_x = 5.69766
delta_h = 3.3719
delta mean, abs_mean, abs_mean+, abs_mean-: 1.21094 5.69766 5.92516 5.3796
U_c = [[-0.0869934]] U_f = [[ 0.]] b_f = [ 1.40969229]
W_c max, min, mean, abs_mean: 3.93084 -2.05683 0.409187 1.9299
W_f max, min, mean, abs_mean: 1.751 -0.773259 0.113655 0.541554
Epoch 14/500
50s - loss: 983.8914 - val_loss: 8612.5901
Epoch 00013: val_loss did not improve
Epoch 15/500
50s - loss: 971.1082 - val_loss: 8770.1543
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 959.4987 - val_loss: 8444.0285
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 950.6919 - val_loss: 8385.7877
Epoch 00016: val_loss did not improve
Epoch 18/500
49s - loss: 941.3690 - val_loss: 8645.6576
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 933.9600 - val_loss: 8758.7400
Epoch 00018: val_loss did not improve
Epoch 20/500
50s - loss: 923.3156 - val_loss: 7928.3532
Epoch 00019: val_loss improved from 8254.45114 to 7928.35318, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6   846.6      0.79  0.22  0.65      0.77  0.13  0.70      0.78  0.08  0.73
forget mean min: 0.895743 0.322272
delta_x = 7.71365
delta_h = 3.00165
delta mean, abs_mean, abs_mean+, abs_mean-: 1.17517 7.71365 8.51906 6.83516
U_c = [[-0.0982877]] U_f = [[ 0.]] b_f = [ 1.44715345]
W_c max, min, mean, abs_mean: 4.90722 -2.46405 0.488571 2.272
W_f max, min, mean, abs_mean: 1.91021 -1.00326 0.110387 0.611476
huabei_lstm20x2+dropout6  7928.3      0.82  0.21  0.67      0.81  0.14  0.72      0.83  0.10  0.76
forget mean min: 0.921207 0.563718
delta_x = 6.39608
delta_h = 3.8486
delta mean, abs_mean, abs_mean+, abs_mean-: 1.37242 6.39608 6.77169 5.89081
U_c = [[-0.0982877]] U_f = [[ 0.]] b_f = [ 1.44715345]
W_c max, min, mean, abs_mean: 4.90722 -2.46405 0.488571 2.272
W_f max, min, mean, abs_mean: 1.91021 -1.00326 0.110387 0.611476
Epoch 21/500
50s - loss: 918.7013 - val_loss: 8692.3247
Epoch 00020: val_loss did not improve
Epoch 22/500
50s - loss: 911.4661 - val_loss: 8106.5466
Epoch 00021: val_loss did not improve
Epoch 23/500
50s - loss: 904.5716 - val_loss: 8351.9483
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 898.9050 - val_loss: 8215.5665
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 894.2928 - val_loss: 8398.7758
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 889.0033 - val_loss: 8581.8250
Epoch 00025: val_loss did not improve
Epoch 27/500
49s - loss: 885.0827 - val_loss: 8257.5695
Epoch 00026: val_loss did not improve
Epoch 28/500
49s - loss: 878.3409 - val_loss: 8450.5705
Epoch 00027: val_loss did not improve
Epoch 29/500
50s - loss: 874.2540 - val_loss: 7943.7932
Epoch 00028: val_loss did not improve
Epoch 30/500
50s - loss: 870.2296 - val_loss: 8772.0679
Epoch 00029: val_loss did not improve
Epoch 31/500
50s - loss: 866.7766 - val_loss: 7871.5182
Epoch 00030: val_loss improved from 7928.35318 to 7871.51821, saving model to huabei_lstm20x2+dropout6_weights.hdf5
huabei_lstm20x2+dropout6   828.6      0.81  0.23  0.66      0.79  0.13  0.71      0.79  0.08  0.74
forget mean min: 0.893786 0.208003
delta_x = 8.24362
delta_h = 3.31202
delta mean, abs_mean, abs_mean+, abs_mean-: 1.45663 8.24362 9.29905 7.09301
U_c = [[-0.10330884]] U_f = [[ 0.]] b_f = [ 1.47086799]
W_c max, min, mean, abs_mean: 5.81504 -2.88041 0.549547 2.60103
W_f max, min, mean, abs_mean: 2.20523 -1.41516 0.0831537 0.770392
huabei_lstm20x2+dropout6  7871.5      0.80  0.21  0.66      0.80  0.14  0.70      0.81  0.10  0.74
forget mean min: 0.920117 0.571027
delta_x = 6.78195
delta_h = 4.13076
delta mean, abs_mean, abs_mean+, abs_mean-: 1.63397 6.78195 7.39179 5.97596
U_c = [[-0.10330884]] U_f = [[ 0.]] b_f = [ 1.47086799]
W_c max, min, mean, abs_mean: 5.81504 -2.88041 0.549547 2.60103
W_f max, min, mean, abs_mean: 2.20523 -1.41516 0.0831537 0.770392
Epoch 32/500
49s - loss: 862.7240 - val_loss: 7959.8911
Epoch 00031: val_loss did not improve
Epoch 33/500
48s - loss: 859.1766 - val_loss: 8108.0816
Epoch 00032: val_loss did not improve
Epoch 34/500
48s - loss: 855.6713 - val_loss: 8529.7742
Epoch 00033: val_loss did not improve
Epoch 35/500
49s - loss: 852.6868 - val_loss: 8546.8444
Epoch 00034: val_loss did not improve
Epoch 36/500
50s - loss: 849.0525 - val_loss: 8817.5274
Epoch 00035: val_loss did not improve
Epoch 37/500
50s - loss: 845.5896 - val_loss: 8491.4541
Epoch 00036: val_loss did not improve
Epoch 38/500
50s - loss: 841.8023 - val_loss: 8291.9467
Epoch 00037: val_loss did not improve
Epoch 39/500
50s - loss: 839.5285 - val_loss: 8476.7044
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 837.0307 - val_loss: 8610.8137
Epoch 00039: val_loss did not improve
Epoch 41/500
49s - loss: 833.8410 - val_loss: 8406.4107
Epoch 00040: val_loss did not improve
Epoch 42/500
48s - loss: 830.2697 - val_loss: 8567.9850
Epoch 00041: val_loss did not improve
Epoch 43/500
50s - loss: 828.5956 - val_loss: 8176.5774
Epoch 00042: val_loss did not improve
Epoch 44/500
50s - loss: 825.5123 - val_loss: 8231.9353
Epoch 00043: val_loss did not improve
Epoch 45/500
50s - loss: 823.0337 - val_loss: 8632.7327
Epoch 00044: val_loss did not improve
Epoch 46/500
50s - loss: 820.4881 - val_loss: 8585.9162
Epoch 00045: val_loss did not improve
Epoch 47/500
49s - loss: 818.7421 - val_loss: 8658.0783
Epoch 00046: val_loss did not improve
Epoch 48/500
48s - loss: 816.6482 - val_loss: 8552.3457
Epoch 00047: val_loss did not improve
Epoch 49/500
49s - loss: 814.8288 - val_loss: 8433.6110
Epoch 00048: val_loss did not improve
Epoch 50/500
49s - loss: 811.6880 - val_loss: 8891.4097
Epoch 00049: val_loss did not improve
Epoch 51/500
49s - loss: 810.0300 - val_loss: 8543.7610
Epoch 00050: val_loss did not improve
Epoch 52/500
50s - loss: 808.5623 - val_loss: 8431.8904
Epoch 00051: val_loss did not improve
Epoch 53/500
50s - loss: 806.7531 - val_loss: 8512.8789
Epoch 00052: val_loss did not improve
Epoch 54/500
49s - loss: 804.3329 - val_loss: 8550.8636
Epoch 00053: val_loss did not improve
Epoch 55/500
49s - loss: 802.9679 - val_loss: 8549.8170
Epoch 00054: val_loss did not improve
Epoch 56/500
49s - loss: 799.8411 - val_loss: 8618.7669
Epoch 00055: val_loss did not improve
Epoch 57/500
49s - loss: 799.3055 - val_loss: 8891.3727
Epoch 00056: val_loss did not improve
Epoch 58/500
49s - loss: 797.3866 - val_loss: 8836.2351
Epoch 00057: val_loss did not improve
Epoch 59/500
49s - loss: 795.9604 - val_loss: 8574.4364
Epoch 00058: val_loss did not improve
Epoch 60/500
50s - loss: 795.0785 - val_loss: 8730.7111
Epoch 00059: val_loss did not improve
Epoch 61/500
50s - loss: 792.5868 - val_loss: 8778.6959
Epoch 00060: val_loss did not improve
Epoch 62/500
50s - loss: 792.0587 - val_loss: 8682.5804
Epoch 00061: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout7
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout7  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout7 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
49s - loss: 2190.7309 - val_loss: 10285.9412
Epoch 00000: val_loss improved from inf to 10285.94123, saving model to huabei_lstm20x2+dropout7_weights.hdf5
huabei_lstm20x2+dropout7  1547.1      0.68  0.32  0.52      0.66  0.18  0.58      0.67  0.11  0.62
forget mean min: 0.94776 0.707582
delta_x = 3.86793
delta_h = 1.99666
delta mean, abs_mean, abs_mean+, abs_mean-: 0.714174 3.86793 3.50506 4.55276
U_c = [[-0.07906117]] U_f = [[ 0.]] b_f = [ 1.29302526]
W_c max, min, mean, abs_mean: 0.511551 -0.626018 -0.21131 0.511614
W_f max, min, mean, abs_mean: 0.420159 -0.522314 -0.162928 0.386818
huabei_lstm20x2+dropout7 10285.9      0.84  0.25  0.65      0.83  0.16  0.71      0.84  0.11  0.76
forget mean min: 0.956232 0.752931
delta_x = 4.1213
delta_h = 2.89592
delta mean, abs_mean, abs_mean+, abs_mean-: 0.797419 4.1213 3.62782 5.15994
U_c = [[-0.07906117]] U_f = [[ 0.]] b_f = [ 1.29302526]
W_c max, min, mean, abs_mean: 0.511551 -0.626018 -0.21131 0.511614
W_f max, min, mean, abs_mean: 0.420159 -0.522314 -0.162928 0.386818
Epoch 2/500
50s - loss: 1486.8939 - val_loss: 9636.3100
Epoch 00001: val_loss improved from 10285.94123 to 9636.31000, saving model to huabei_lstm20x2+dropout7_weights.hdf5
huabei_lstm20x2+dropout7  1411.8      0.75  0.33  0.55      0.73  0.19  0.62      0.73  0.12  0.66
forget mean min: 0.940452 0.645752
delta_x = 4.48911
delta_h = 2.11298
delta mean, abs_mean, abs_mean+, abs_mean-: 1.12813 4.48911 4.28034 4.88752
U_c = [[-0.07098819]] U_f = [[ 0.]] b_f = [ 1.29663205]
W_c max, min, mean, abs_mean: 0.754268 -1.09729 -0.326428 0.75639
W_f max, min, mean, abs_mean: 0.455831 -0.708001 -0.196801 0.432275
huabei_lstm20x2+dropout7  9636.3      0.83  0.24  0.66      0.82  0.15  0.71      0.83  0.11  0.75
forget mean min: 0.948541 0.677165
delta_x = 4.83854
delta_h = 2.92138
delta mean, abs_mean, abs_mean+, abs_mean-: 1.06996 4.83854 4.44909 5.60819
U_c = [[-0.07098819]] U_f = [[ 0.]] b_f = [ 1.29663205]
W_c max, min, mean, abs_mean: 0.754268 -1.09729 -0.326428 0.75639
W_f max, min, mean, abs_mean: 0.455831 -0.708001 -0.196801 0.432275
Epoch 3/500
50s - loss: 1357.0735 - val_loss: 9043.4912
Epoch 00002: val_loss improved from 9636.31000 to 9043.49116, saving model to huabei_lstm20x2+dropout7_weights.hdf5
huabei_lstm20x2+dropout7  1321.9      0.79  0.33  0.57      0.76  0.19  0.64      0.76  0.13  0.69
forget mean min: 0.932696 0.620351
delta_x = 5.03069
delta_h = 2.17044
delta mean, abs_mean, abs_mean+, abs_mean-: 1.24547 5.03069 4.93507 5.19767
U_c = [[-0.06867136]] U_f = [[ 0.]] b_f = [ 1.30222762]
W_c max, min, mean, abs_mean: 0.985677 -1.48642 -0.42046 0.962973
W_f max, min, mean, abs_mean: 0.471625 -0.824539 -0.212717 0.450378
huabei_lstm20x2+dropout7  9043.5      0.82  0.23  0.65      0.81  0.15  0.70      0.82  0.10  0.74
forget mean min: 0.942164 0.655271
delta_x = 5.00877
delta_h = 2.92708
delta mean, abs_mean, abs_mean+, abs_mean-: 1.12547 5.00877 4.7986 5.38106
U_c = [[-0.06867136]] U_f = [[ 0.]] b_f = [ 1.30222762]
W_c max, min, mean, abs_mean: 0.985677 -1.48642 -0.42046 0.962973
W_f max, min, mean, abs_mean: 0.471625 -0.824539 -0.212717 0.450378
Epoch 4/500
50s - loss: 1270.2125 - val_loss: 9070.8004
Epoch 00003: val_loss did not improve
Epoch 5/500
50s - loss: 1206.5679 - val_loss: 9141.6539
Epoch 00004: val_loss did not improve
Epoch 6/500
50s - loss: 1156.2133 - val_loss: 9058.1961
Epoch 00005: val_loss did not improve
Epoch 7/500
50s - loss: 1115.2572 - val_loss: 9220.8964
Epoch 00006: val_loss did not improve
Epoch 8/500
50s - loss: 1082.2556 - val_loss: 9451.1773
Epoch 00007: val_loss did not improve
Epoch 9/500
50s - loss: 1054.3653 - val_loss: 9387.6481
Epoch 00008: val_loss did not improve
Epoch 10/500
50s - loss: 1034.1614 - val_loss: 9226.9502
Epoch 00009: val_loss did not improve
Epoch 11/500
49s - loss: 1013.8737 - val_loss: 9638.6643
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 997.7888 - val_loss: 9528.6033
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 984.3623 - val_loss: 9340.5280
Epoch 00012: val_loss did not improve
Epoch 14/500
49s - loss: 969.5418 - val_loss: 9577.6918
Epoch 00013: val_loss did not improve
Epoch 15/500
50s - loss: 959.2959 - val_loss: 9520.3360
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 948.0133 - val_loss: 9588.4497
Epoch 00015: val_loss did not improve
Epoch 17/500
50s - loss: 937.8749 - val_loss: 9353.9384
Epoch 00016: val_loss did not improve
Epoch 18/500
50s - loss: 929.3460 - val_loss: 9417.2668
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 920.1858 - val_loss: 9278.2060
Epoch 00018: val_loss did not improve
Epoch 20/500
48s - loss: 912.6421 - val_loss: 9321.5808
Epoch 00019: val_loss did not improve
Epoch 21/500
50s - loss: 905.5930 - val_loss: 9466.9437
Epoch 00020: val_loss did not improve
Epoch 22/500
49s - loss: 897.1127 - val_loss: 9654.6175
Epoch 00021: val_loss did not improve
Epoch 23/500
50s - loss: 890.6608 - val_loss: 9533.0121
Epoch 00022: val_loss did not improve
Epoch 24/500
50s - loss: 885.8473 - val_loss: 9612.7657
Epoch 00023: val_loss did not improve
Epoch 25/500
50s - loss: 877.9283 - val_loss: 9786.0410
Epoch 00024: val_loss did not improve
Epoch 26/500
50s - loss: 874.0257 - val_loss: 9563.4298
Epoch 00025: val_loss did not improve
Epoch 27/500
49s - loss: 869.1858 - val_loss: 9927.4709
Epoch 00026: val_loss did not improve
Epoch 28/500
49s - loss: 864.7618 - val_loss: 9669.7695
Epoch 00027: val_loss did not improve
Epoch 29/500
50s - loss: 858.6230 - val_loss: 9441.8937
Epoch 00028: val_loss did not improve
Epoch 30/500
50s - loss: 854.4188 - val_loss: 9536.1385
Epoch 00029: val_loss did not improve
Epoch 31/500
50s - loss: 849.4128 - val_loss: 9694.3247
Epoch 00030: val_loss did not improve
Epoch 32/500
50s - loss: 846.3093 - val_loss: 9692.6303
Epoch 00031: val_loss did not improve
Epoch 33/500
50s - loss: 842.5693 - val_loss: 9372.5164
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 838.0612 - val_loss: 9593.8043
Epoch 00033: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout8
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout8  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout8 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2187.4540 - val_loss: 9243.1163
Epoch 00000: val_loss improved from inf to 9243.11632, saving model to huabei_lstm20x2+dropout8_weights.hdf5
huabei_lstm20x2+dropout8  1535.1      0.74  0.35  0.53      0.73  0.20  0.61      0.74  0.13  0.66
forget mean min: 0.949293 0.687292
delta_x = 4.23914
delta_h = 2.1496
delta mean, abs_mean, abs_mean+, abs_mean-: 1.09122 4.23914 3.93242 4.88421
U_c = [[-0.07614554]] U_f = [[ 0.]] b_f = [ 1.28883255]
W_c max, min, mean, abs_mean: 0.631766 -0.572947 0.00892856 0.539942
W_f max, min, mean, abs_mean: 0.554763 -0.531825 0.00868323 0.397518
huabei_lstm20x2+dropout8  9243.1      0.87  0.24  0.67      0.85  0.16  0.73      0.86  0.11  0.77
forget mean min: 0.956609 0.718437
delta_x = 4.91257
delta_h = 3.24876
delta mean, abs_mean, abs_mean+, abs_mean-: 1.27519 4.91257 4.38299 6.18358
U_c = [[-0.07614554]] U_f = [[ 0.]] b_f = [ 1.28883255]
W_c max, min, mean, abs_mean: 0.631766 -0.572947 0.00892856 0.539942
W_f max, min, mean, abs_mean: 0.554763 -0.531825 0.00868323 0.397518
Epoch 2/500
50s - loss: 1452.0198 - val_loss: 9050.8063
Epoch 00001: val_loss improved from 9243.11632 to 9050.80633, saving model to huabei_lstm20x2+dropout8_weights.hdf5
huabei_lstm20x2+dropout8  1329.4      0.71  0.29  0.55      0.68  0.16  0.60      0.69  0.11  0.64
forget mean min: 0.935958 0.609122
delta_x = 4.29518
delta_h = 1.81143
delta mean, abs_mean, abs_mean+, abs_mean-: 0.669243 4.29518 4.06725 4.65214
U_c = [[-0.06604531]] U_f = [[ 0.]] b_f = [ 1.30342066]
W_c max, min, mean, abs_mean: 1.11665 -0.905579 0.020664 0.785542
W_f max, min, mean, abs_mean: 0.744327 -0.739987 0.00933329 0.441518
huabei_lstm20x2+dropout8  9050.8      0.78  0.21  0.65      0.77  0.14  0.69      0.78  0.10  0.72
forget mean min: 0.94179 0.651151
delta_x = 4.49945
delta_h = 2.52839
delta mean, abs_mean, abs_mean+, abs_mean-: 0.174409 4.49945 4.17448 4.91273
U_c = [[-0.06604531]] U_f = [[ 0.]] b_f = [ 1.30342066]
W_c max, min, mean, abs_mean: 1.11665 -0.905579 0.020664 0.785542
W_f max, min, mean, abs_mean: 0.744327 -0.739987 0.00933329 0.441518
Epoch 3/500
50s - loss: 1332.1952 - val_loss: 8720.2509
Epoch 00002: val_loss improved from 9050.80633 to 8720.25090, saving model to huabei_lstm20x2+dropout8_weights.hdf5
huabei_lstm20x2+dropout8  1257.3      0.77  0.31  0.57      0.74  0.18  0.64      0.75  0.12  0.68
forget mean min: 0.933342 0.580008
delta_x = 4.77209
delta_h = 1.98358
delta mean, abs_mean, abs_mean+, abs_mean-: 0.999663 4.77209 4.6851 4.91161
U_c = [[-0.06668422]] U_f = [[ 0.]] b_f = [ 1.31867826]
W_c max, min, mean, abs_mean: 1.58592 -1.21553 0.0361284 0.973386
W_f max, min, mean, abs_mean: 0.789431 -0.941664 0.00185867 0.462787
huabei_lstm20x2+dropout8  8720.2      0.80  0.23  0.65      0.80  0.15  0.70      0.81  0.11  0.74
forget mean min: 0.941557 0.64171
delta_x = 4.88984
delta_h = 2.78235
delta mean, abs_mean, abs_mean+, abs_mean-: 0.650097 4.88984 4.84601 4.94832
U_c = [[-0.06668422]] U_f = [[ 0.]] b_f = [ 1.31867826]
W_c max, min, mean, abs_mean: 1.58592 -1.21553 0.0361284 0.973386
W_f max, min, mean, abs_mean: 0.789431 -0.941664 0.00185867 0.462787
Epoch 4/500
50s - loss: 1257.0042 - val_loss: 8988.6401
Epoch 00003: val_loss did not improve
Epoch 5/500
50s - loss: 1205.0811 - val_loss: 9154.9268
Epoch 00004: val_loss did not improve
Epoch 6/500
50s - loss: 1164.4807 - val_loss: 9276.1906
Epoch 00005: val_loss did not improve
Epoch 7/500
50s - loss: 1131.4684 - val_loss: 9037.0492
Epoch 00006: val_loss did not improve
Epoch 8/500
50s - loss: 1106.0981 - val_loss: 8625.5699
Epoch 00007: val_loss improved from 8720.25090 to 8625.56991, saving model to huabei_lstm20x2+dropout8_weights.hdf5
huabei_lstm20x2+dropout8  1050.0      0.80  0.28  0.61      0.77  0.16  0.67      0.77  0.11  0.71
forget mean min: 0.917596 0.454337
delta_x = 5.89343
delta_h = 2.48524
delta mean, abs_mean, abs_mean+, abs_mean-: 1.23388 5.89343 6.15531 5.53335
U_c = [[-0.08001467]] U_f = [[ 0.]] b_f = [ 1.39022017]
W_c max, min, mean, abs_mean: 3.30315 -2.14378 0.118104 1.58007
W_f max, min, mean, abs_mean: 0.83827 -1.42143 -0.0530369 0.512291
huabei_lstm20x2+dropout8  8625.6      0.81  0.25  0.64      0.81  0.17  0.70      0.83  0.12  0.74
forget mean min: 0.937844 0.657515
delta_x = 4.99033
delta_h = 3.15827
delta mean, abs_mean, abs_mean+, abs_mean-: 1.29718 4.99033 5.15838 4.72811
U_c = [[-0.08001467]] U_f = [[ 0.]] b_f = [ 1.39022017]
W_c max, min, mean, abs_mean: 3.30315 -2.14378 0.118104 1.58007
W_f max, min, mean, abs_mean: 0.83827 -1.42143 -0.0530369 0.512291
Epoch 9/500
50s - loss: 1084.0679 - val_loss: 8889.0690
Epoch 00008: val_loss did not improve
Epoch 10/500
49s - loss: 1063.6842 - val_loss: 8932.2231
Epoch 00009: val_loss did not improve
Epoch 11/500
49s - loss: 1045.5330 - val_loss: 9158.5169
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 1029.4727 - val_loss: 8467.4987
Epoch 00011: val_loss improved from 8625.56991 to 8467.49874, saving model to huabei_lstm20x2+dropout8_weights.hdf5
huabei_lstm20x2+dropout8   999.9      0.82  0.28  0.62      0.80  0.16  0.69      0.80  0.11  0.73
forget mean min: 0.912883 0.420347
delta_x = 6.86453
delta_h = 2.93652
delta mean, abs_mean, abs_mean+, abs_mean-: 1.51337 6.86453 7.34538 6.22638
U_c = [[-0.09116643]] U_f = [[ 0.]] b_f = [ 1.41107869]
W_c max, min, mean, abs_mean: 4.06884 -2.59321 0.154286 1.87587
W_f max, min, mean, abs_mean: 0.945372 -1.62887 -0.0938958 0.546237
huabei_lstm20x2+dropout8  8467.5      0.82  0.25  0.64      0.82  0.16  0.70      0.83  0.12  0.74
forget mean min: 0.935548 0.615528
delta_x = 5.70846
delta_h = 3.64343
delta mean, abs_mean, abs_mean+, abs_mean-: 1.70214 5.70846 6.0963 5.10742
U_c = [[-0.09116643]] U_f = [[ 0.]] b_f = [ 1.41107869]
W_c max, min, mean, abs_mean: 4.06884 -2.59321 0.154286 1.87587
W_f max, min, mean, abs_mean: 0.945372 -1.62887 -0.0938958 0.546237
Epoch 13/500
50s - loss: 1015.4269 - val_loss: 8972.8776
Epoch 00012: val_loss did not improve
Epoch 14/500
50s - loss: 1001.0564 - val_loss: 8965.7733
Epoch 00013: val_loss did not improve
Epoch 15/500
50s - loss: 989.3870 - val_loss: 8510.3977
Epoch 00014: val_loss did not improve
Epoch 16/500
50s - loss: 978.1704 - val_loss: 8632.6562
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 967.6270 - val_loss: 9149.5062
Epoch 00016: val_loss did not improve
Epoch 18/500
49s - loss: 957.2202 - val_loss: 8811.4589
Epoch 00017: val_loss did not improve
Epoch 19/500
49s - loss: 946.8602 - val_loss: 8843.8228
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 940.3085 - val_loss: 9126.4116
Epoch 00019: val_loss did not improve
Epoch 21/500
50s - loss: 930.2208 - val_loss: 8927.4404
Epoch 00020: val_loss did not improve
Epoch 22/500
50s - loss: 922.6914 - val_loss: 9066.0733
Epoch 00021: val_loss did not improve
Epoch 23/500
50s - loss: 914.7391 - val_loss: 8853.1797
Epoch 00022: val_loss did not improve
Epoch 24/500
50s - loss: 908.6863 - val_loss: 9137.7242
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 902.1104 - val_loss: 8812.0198
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 896.5657 - val_loss: 8996.3279
Epoch 00025: val_loss did not improve
Epoch 27/500
49s - loss: 890.4075 - val_loss: 9351.4099
Epoch 00026: val_loss did not improve
Epoch 28/500
49s - loss: 885.6372 - val_loss: 9173.9330
Epoch 00027: val_loss did not improve
Epoch 29/500
49s - loss: 879.7746 - val_loss: 9236.2306
Epoch 00028: val_loss did not improve
Epoch 30/500
50s - loss: 875.7511 - val_loss: 9209.0492
Epoch 00029: val_loss did not improve
Epoch 31/500
50s - loss: 870.0780 - val_loss: 9077.6069
Epoch 00030: val_loss did not improve
Epoch 32/500
49s - loss: 865.3464 - val_loss: 9342.3790
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 862.3989 - val_loss: 9178.9442
Epoch 00032: val_loss did not improve
Epoch 34/500
49s - loss: 857.7336 - val_loss: 9597.3482
Epoch 00033: val_loss did not improve
Epoch 35/500
49s - loss: 853.4166 - val_loss: 9458.0295
Epoch 00034: val_loss did not improve
Epoch 36/500
50s - loss: 849.5924 - val_loss: 9468.4245
Epoch 00035: val_loss did not improve
Epoch 37/500
50s - loss: 846.1932 - val_loss: 9777.8853
Epoch 00036: val_loss did not improve
Epoch 38/500
50s - loss: 841.4921 - val_loss: 9546.9366
Epoch 00037: val_loss did not improve
Epoch 39/500
50s - loss: 838.1652 - val_loss: 9554.1909
Epoch 00038: val_loss did not improve
Epoch 40/500
49s - loss: 834.3425 - val_loss: 9758.4795
Epoch 00039: val_loss did not improve
Epoch 41/500
49s - loss: 832.3755 - val_loss: 9474.2061
Epoch 00040: val_loss did not improve
Epoch 42/500
49s - loss: 828.6232 - val_loss: 9951.7918
Epoch 00041: val_loss did not improve
Epoch 43/500
49s - loss: 826.6532 - val_loss: 9783.5131
Epoch 00042: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm20x2+dropout9
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm20x2+dropout9  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm20x2+dropout9 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
48s - loss: 2198.5650 - val_loss: 9288.9925
Epoch 00000: val_loss improved from inf to 9288.99250, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1600.9      0.78  0.38  0.53      0.76  0.22  0.62      0.78  0.15  0.68
forget mean min: 0.952549 0.692769
delta_x = 4.42472
delta_h = 2.3338
delta mean, abs_mean, abs_mean+, abs_mean-: 1.39732 4.42472 4.21877 4.88314
U_c = [[-0.07738505]] U_f = [[ 0.]] b_f = [ 1.27479398]
W_c max, min, mean, abs_mean: 0.619779 -0.531524 -0.0880914 0.53023
W_f max, min, mean, abs_mean: 0.54659 -0.40156 -0.04395 0.392613
huabei_lstm20x2+dropout9  9289.0      0.87  0.24  0.68      0.86  0.16  0.74      0.86  0.11  0.77
forget mean min: 0.956824 0.72861
delta_x = 4.91568
delta_h = 3.32291
delta mean, abs_mean, abs_mean+, abs_mean-: 1.34437 4.91568 4.45674 5.99842
U_c = [[-0.07738505]] U_f = [[ 0.]] b_f = [ 1.27479398]
W_c max, min, mean, abs_mean: 0.619779 -0.531524 -0.0880914 0.53023
W_f max, min, mean, abs_mean: 0.54659 -0.40156 -0.04395 0.392613
Epoch 2/500
50s - loss: 1453.5797 - val_loss: 9118.4133
Epoch 00001: val_loss improved from 9288.99250 to 9118.41332, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1346.1      0.75  0.32  0.55      0.72  0.18  0.62      0.72  0.12  0.66
forget mean min: 0.938452 0.629922
delta_x = 4.38912
delta_h = 2.17215
delta mean, abs_mean, abs_mean+, abs_mean-: 1.04183 4.38912 4.23408 4.66635
U_c = [[-0.07680292]] U_f = [[ 0.]] b_f = [ 1.27536559]
W_c max, min, mean, abs_mean: 1.12848 -0.780837 -0.100492 0.793118
W_f max, min, mean, abs_mean: 0.685574 -0.454795 -0.034779 0.426079
huabei_lstm20x2+dropout9  9118.4      0.81  0.22  0.66      0.80  0.14  0.70      0.80  0.10  0.73
forget mean min: 0.94511 0.661078
delta_x = 4.89007
delta_h = 3.16366
delta mean, abs_mean, abs_mean+, abs_mean-: 0.975272 4.89007 4.51804 5.57829
U_c = [[-0.07680292]] U_f = [[ 0.]] b_f = [ 1.27536559]
W_c max, min, mean, abs_mean: 1.12848 -0.780837 -0.100492 0.793118
W_f max, min, mean, abs_mean: 0.685574 -0.454795 -0.034779 0.426079
Epoch 3/500
50s - loss: 1331.1558 - val_loss: 8987.6282
Epoch 00002: val_loss improved from 9118.41332 to 8987.62816, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1225.5      0.71  0.27  0.57      0.68  0.14  0.61      0.68  0.09  0.64
forget mean min: 0.926273 0.594902
delta_x = 4.50493
delta_h = 2.05708
delta mean, abs_mean, abs_mean+, abs_mean-: 0.676686 4.50493 4.37369 4.69565
U_c = [[-0.07599493]] U_f = [[ 0.]] b_f = [ 1.2799958]
W_c max, min, mean, abs_mean: 1.60783 -1.01154 -0.102146 0.994401
W_f max, min, mean, abs_mean: 0.713633 -0.493889 -0.0309244 0.43933
huabei_lstm20x2+dropout9  8987.6      0.77  0.20  0.65      0.75  0.13  0.68      0.76  0.09  0.71
forget mean min: 0.935954 0.637118
delta_x = 4.54385
delta_h = 2.90218
delta mean, abs_mean, abs_mean+, abs_mean-: 0.424133 4.54385 4.17644 5.08308
U_c = [[-0.07599493]] U_f = [[ 0.]] b_f = [ 1.2799958]
W_c max, min, mean, abs_mean: 1.60783 -1.01154 -0.102146 0.994401
W_f max, min, mean, abs_mean: 0.713633 -0.493889 -0.0309244 0.43933
Epoch 4/500
50s - loss: 1254.4030 - val_loss: 8818.2292
Epoch 00003: val_loss improved from 8987.62816 to 8818.22925, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1172.7      0.76  0.29  0.58      0.73  0.16  0.64      0.73  0.11  0.67
forget mean min: 0.924854 0.584931
delta_x = 4.98261
delta_h = 2.3235
delta mean, abs_mean, abs_mean+, abs_mean-: 1.05389 4.98261 5.00371 4.95055
U_c = [[-0.0803472]] U_f = [[ 0.]] b_f = [ 1.28963172]
W_c max, min, mean, abs_mean: 2.01164 -1.21034 -0.0985952 1.15094
W_f max, min, mean, abs_mean: 0.803202 -0.530881 -0.0322184 0.452362
huabei_lstm20x2+dropout9  8818.2      0.80  0.21  0.66      0.79  0.14  0.70      0.80  0.10  0.73
forget mean min: 0.935931 0.657349
delta_x = 4.74026
delta_h = 3.1233
delta mean, abs_mean, abs_mean+, abs_mean-: 0.837766 4.74026 4.57405 4.99995
U_c = [[-0.0803472]] U_f = [[ 0.]] b_f = [ 1.28963172]
W_c max, min, mean, abs_mean: 2.01164 -1.21034 -0.0985952 1.15094
W_f max, min, mean, abs_mean: 0.803202 -0.530881 -0.0322184 0.452362
Epoch 5/500
50s - loss: 1201.9295 - val_loss: 8666.0537
Epoch 00004: val_loss improved from 8818.22925 to 8666.05373, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1109.7      0.75  0.26  0.59      0.71  0.14  0.63      0.71  0.10  0.66
forget mean min: 0.919255 0.555891
delta_x = 5.19715
delta_h = 2.29374
delta mean, abs_mean, abs_mean+, abs_mean-: 0.916707 5.19715 5.29005 5.06999
U_c = [[-0.08196414]] U_f = [[ 0.]] b_f = [ 1.3021667]
W_c max, min, mean, abs_mean: 2.34792 -1.38371 -0.0929668 1.2786
W_f max, min, mean, abs_mean: 0.861142 -0.558222 -0.0315105 0.463827
huabei_lstm20x2+dropout9  8666.0      0.77  0.20  0.65      0.76  0.13  0.68      0.77  0.09  0.71
forget mean min: 0.932191 0.645868
delta_x = 4.89843
delta_h = 3.1554
delta mean, abs_mean, abs_mean+, abs_mean-: 0.704138 4.89843 4.81108 5.02017
U_c = [[-0.08196414]] U_f = [[ 0.]] b_f = [ 1.3021667]
W_c max, min, mean, abs_mean: 2.34792 -1.38371 -0.0929668 1.2786
W_f max, min, mean, abs_mean: 0.861142 -0.558222 -0.0315105 0.463827
Epoch 6/500
50s - loss: 1154.4834 - val_loss: 8510.2693
Epoch 00005: val_loss improved from 8666.05373 to 8510.26933, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1076.6      0.77  0.27  0.60      0.74  0.15  0.65      0.74  0.10  0.68
forget mean min: 0.917581 0.525726
delta_x = 5.5242
delta_h = 2.35383
delta mean, abs_mean, abs_mean+, abs_mean-: 1.07435 5.5242 5.7257 5.25021
U_c = [[-0.07984269]] U_f = [[ 0.]] b_f = [ 1.31495571]
W_c max, min, mean, abs_mean: 2.65236 -1.56086 -0.0897414 1.40219
W_f max, min, mean, abs_mean: 0.907266 -0.604821 -0.0319278 0.474292
huabei_lstm20x2+dropout9  8510.3      0.78  0.20  0.65      0.76  0.13  0.69      0.78  0.09  0.72
forget mean min: 0.929548 0.639081
delta_x = 5.0362
delta_h = 3.13652
delta mean, abs_mean, abs_mean+, abs_mean-: 0.655072 5.0362 5.07224 4.99013
U_c = [[-0.07984269]] U_f = [[ 0.]] b_f = [ 1.31495571]
W_c max, min, mean, abs_mean: 2.65236 -1.56086 -0.0897414 1.40219
W_f max, min, mean, abs_mean: 0.907266 -0.604821 -0.0319278 0.474292
Epoch 7/500
49s - loss: 1114.5704 - val_loss: 8136.2647
Epoch 00006: val_loss improved from 8510.26933 to 8136.26475, saving model to huabei_lstm20x2+dropout9_weights.hdf5
huabei_lstm20x2+dropout9  1080.7      0.81  0.29  0.60      0.78  0.17  0.67      0.78  0.12  0.71
forget mean min: 0.917583 0.489106
delta_x = 6.09609
delta_h = 2.64771
delta mean, abs_mean, abs_mean+, abs_mean-: 1.42704 6.09609 6.40011 5.66266
U_c = [[-0.08288572]] U_f = [[ 0.]] b_f = [ 1.32978511]
W_c max, min, mean, abs_mean: 2.90973 -1.71888 -0.0867888 1.51233
W_f max, min, mean, abs_mean: 0.92102 -0.665515 -0.035455 0.482937
huabei_lstm20x2+dropout9  8136.3      0.81  0.21  0.66      0.80  0.14  0.71      0.81  0.10  0.75
forget mean min: 0.931218 0.636158
delta_x = 5.53911
delta_h = 3.48354
delta mean, abs_mean, abs_mean+, abs_mean-: 1.17342 5.53911 5.8184 5.15839
U_c = [[-0.08288572]] U_f = [[ 0.]] b_f = [ 1.32978511]
W_c max, min, mean, abs_mean: 2.90973 -1.71888 -0.0867888 1.51233
W_f max, min, mean, abs_mean: 0.92102 -0.665515 -0.035455 0.482937
Epoch 8/500
49s - loss: 1083.7305 - val_loss: 8616.3019
Epoch 00007: val_loss did not improve
Epoch 9/500
49s - loss: 1057.4707 - val_loss: 8803.3913
Epoch 00008: val_loss did not improve
Epoch 10/500
49s - loss: 1034.4533 - val_loss: 9091.8089
Epoch 00009: val_loss did not improve
Epoch 11/500
49s - loss: 1013.5238 - val_loss: 9601.3996
Epoch 00010: val_loss did not improve
Epoch 12/500
49s - loss: 994.9982 - val_loss: 8995.6760
Epoch 00011: val_loss did not improve
Epoch 13/500
49s - loss: 978.2189 - val_loss: 9545.4592
Epoch 00012: val_loss did not improve
Epoch 14/500
49s - loss: 963.1388 - val_loss: 9349.4689
Epoch 00013: val_loss did not improve
Epoch 15/500
49s - loss: 950.3872 - val_loss: 9516.0176
Epoch 00014: val_loss did not improve
Epoch 16/500
49s - loss: 936.2168 - val_loss: 9024.7578
Epoch 00015: val_loss did not improve
Epoch 17/500
49s - loss: 927.1218 - val_loss: 9001.9017
Epoch 00016: val_loss did not improve
Epoch 18/500
50s - loss: 915.9362 - val_loss: 8960.5641
Epoch 00017: val_loss did not improve
Epoch 19/500
50s - loss: 906.6134 - val_loss: 8966.6132
Epoch 00018: val_loss did not improve
Epoch 20/500
49s - loss: 897.5323 - val_loss: 9038.8170
Epoch 00019: val_loss did not improve
Epoch 21/500
49s - loss: 890.3837 - val_loss: 9009.8801
Epoch 00020: val_loss did not improve
Epoch 22/500
48s - loss: 884.1304 - val_loss: 8865.6604
Epoch 00021: val_loss did not improve
Epoch 23/500
48s - loss: 877.3171 - val_loss: 8807.9349
Epoch 00022: val_loss did not improve
Epoch 24/500
49s - loss: 871.0428 - val_loss: 9357.2117
Epoch 00023: val_loss did not improve
Epoch 25/500
49s - loss: 864.4555 - val_loss: 9344.9088
Epoch 00024: val_loss did not improve
Epoch 26/500
49s - loss: 860.4263 - val_loss: 8997.7175
Epoch 00025: val_loss did not improve
Epoch 27/500
50s - loss: 855.8729 - val_loss: 9053.7344
Epoch 00026: val_loss did not improve
Epoch 28/500
50s - loss: 852.4629 - val_loss: 8881.0164
Epoch 00027: val_loss did not improve
Epoch 29/500
49s - loss: 846.0869 - val_loss: 9333.2775
Epoch 00028: val_loss did not improve
Epoch 30/500
49s - loss: 842.3038 - val_loss: 9052.0206
Epoch 00029: val_loss did not improve
Epoch 31/500
49s - loss: 838.4419 - val_loss: 9265.2899
Epoch 00030: val_loss did not improve
Epoch 32/500
49s - loss: 833.7301 - val_loss: 9369.1849
Epoch 00031: val_loss did not improve
Epoch 33/500
49s - loss: 829.6773 - val_loss: 9335.4120
Epoch 00032: val_loss did not improve
Epoch 34/500
50s - loss: 826.8876 - val_loss: 9673.8452
Epoch 00033: val_loss did not improve
Epoch 35/500
50s - loss: 823.2528 - val_loss: 10058.6337
Epoch 00034: val_loss did not improve
Epoch 36/500
49s - loss: 820.8645 - val_loss: 9245.1915
Epoch 00035: val_loss did not improve
Epoch 37/500
49s - loss: 816.8589 - val_loss: 9346.4006
Epoch 00036: val_loss did not improve
Epoch 38/500
49s - loss: 814.0764 - val_loss: 9326.7302
Epoch 00037: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout0
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout0  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout0 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
55s - loss: 1976.4887 - val_loss: 9667.6178
Epoch 00000: val_loss improved from inf to 9667.61779, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0  1430.8      0.72  0.32  0.54      0.69  0.18  0.60      0.70  0.11  0.64
forget mean min: 0.944071 0.61859
delta_x = 4.01341
delta_h = 2.06117
delta mean, abs_mean, abs_mean+, abs_mean-: 0.945874 4.01341 3.69684 4.65834
U_c = [[-0.07716458]] U_f = [[ 0.]] b_f = [ 1.1945349]
W_c max, min, mean, abs_mean: 0.595293 -0.595382 -0.0467089 0.443815
W_f max, min, mean, abs_mean: 0.446318 -0.395136 -0.0204402 0.27757
huabei_lstm30x2+dropout0  9667.6      0.85  0.24  0.67      0.84  0.15  0.72      0.85  0.11  0.76
forget mean min: 0.95196 0.674792
delta_x = 4.11428
delta_h = 2.86084
delta mean, abs_mean, abs_mean+, abs_mean-: 0.793641 4.11428 3.61755 5.16185
U_c = [[-0.07716458]] U_f = [[ 0.]] b_f = [ 1.1945349]
W_c max, min, mean, abs_mean: 0.595293 -0.595382 -0.0467089 0.443815
W_f max, min, mean, abs_mean: 0.446318 -0.395136 -0.0204402 0.27757
Epoch 2/500
55s - loss: 1354.5656 - val_loss: 9751.1435
Epoch 00001: val_loss did not improve
Epoch 3/500
56s - loss: 1225.2297 - val_loss: 9384.0812
Epoch 00002: val_loss improved from 9667.61779 to 9384.08122, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0  1115.8      0.73  0.25  0.59      0.70  0.13  0.63      0.70  0.09  0.65
forget mean min: 0.918462 0.544984
delta_x = 4.84234
delta_h = 2.0222
delta mean, abs_mean, abs_mean+, abs_mean-: 0.681977 4.84234 4.73942 4.98612
U_c = [[-0.07379904]] U_f = [[ 0.]] b_f = [ 1.19552577]
W_c max, min, mean, abs_mean: 1.30945 -1.40299 -0.0696372 0.802616
W_f max, min, mean, abs_mean: 0.687348 -0.572469 0.00161296 0.29631
huabei_lstm30x2+dropout0  9384.1      0.81  0.23  0.66      0.80  0.15  0.70      0.81  0.10  0.74
forget mean min: 0.932251 0.619418
delta_x = 4.66607
delta_h = 2.78044
delta mean, abs_mean, abs_mean+, abs_mean-: 0.651623 4.66607 4.37731 5.11284
U_c = [[-0.07379904]] U_f = [[ 0.]] b_f = [ 1.19552577]
W_c max, min, mean, abs_mean: 1.30945 -1.40299 -0.0696372 0.802616
W_f max, min, mean, abs_mean: 0.687348 -0.572469 0.00161296 0.29631
Epoch 4/500
56s - loss: 1150.4163 - val_loss: 9274.6055
Epoch 00003: val_loss improved from 9384.08122 to 9274.60549, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0  1076.0      0.69  0.21  0.59      0.65  0.11  0.61      0.65  0.07  0.62
forget mean min: 0.90761 0.50267
delta_x = 5.02546
delta_h = 1.92065
delta mean, abs_mean, abs_mean+, abs_mean-: 0.346928 5.02546 4.92739 5.143
U_c = [[-0.07271826]] U_f = [[ 0.]] b_f = [ 1.19942868]
W_c max, min, mean, abs_mean: 1.55619 -1.69658 -0.0791821 0.919973
W_f max, min, mean, abs_mean: 0.696707 -0.671988 0.00676646 0.304085
huabei_lstm30x2+dropout0  9274.6      0.79  0.22  0.64      0.78  0.15  0.68      0.79  0.10  0.72
forget mean min: 0.926111 0.601938
delta_x = 4.8198
delta_h = 2.74444
delta mean, abs_mean, abs_mean+, abs_mean-: 0.487825 4.8198 4.55008 5.19728
U_c = [[-0.07271826]] U_f = [[ 0.]] b_f = [ 1.19942868]
W_c max, min, mean, abs_mean: 1.55619 -1.69658 -0.0791821 0.919973
W_f max, min, mean, abs_mean: 0.696707 -0.671988 0.00676646 0.304085
Epoch 5/500
56s - loss: 1095.8178 - val_loss: 8857.6198
Epoch 00004: val_loss improved from 9274.60549 to 8857.61980, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0  1020.1      0.74  0.23  0.61      0.70  0.12  0.64      0.70  0.08  0.66
forget mean min: 0.906994 0.495084
delta_x = 5.37939
delta_h = 2.11897
delta mean, abs_mean, abs_mean+, abs_mean-: 0.646033 5.37939 5.41377 5.33625
U_c = [[-0.0774416]] U_f = [[ 0.]] b_f = [ 1.20304739]
W_c max, min, mean, abs_mean: 1.73491 -1.93799 -0.0868091 1.01212
W_f max, min, mean, abs_mean: 0.693077 -0.704322 0.0129803 0.308909
huabei_lstm30x2+dropout0  8857.6      0.83  0.23  0.66      0.82  0.16  0.71      0.83  0.11  0.75
forget mean min: 0.928444 0.620184
delta_x = 5.17221
delta_h = 3.11246
delta mean, abs_mean, abs_mean+, abs_mean-: 1.13436 5.17221 5.13502 5.2314
U_c = [[-0.0774416]] U_f = [[ 0.]] b_f = [ 1.20304739]
W_c max, min, mean, abs_mean: 1.73491 -1.93799 -0.0868091 1.01212
W_f max, min, mean, abs_mean: 0.693077 -0.704322 0.0129803 0.308909
Epoch 6/500
56s - loss: 1053.6089 - val_loss: 8976.8137
Epoch 00005: val_loss did not improve
Epoch 7/500
56s - loss: 1016.4889 - val_loss: 8802.1339
Epoch 00006: val_loss improved from 8857.61980 to 8802.13387, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0   926.5      0.75  0.21  0.63      0.72  0.12  0.66      0.73  0.08  0.69
forget mean min: 0.898815 0.454061
delta_x = 6.23183
delta_h = 2.33961
delta mean, abs_mean, abs_mean+, abs_mean-: 0.723136 6.23183 6.41155 6.01882
U_c = [[-0.08351253]] U_f = [[ 0.]] b_f = [ 1.21189022]
W_c max, min, mean, abs_mean: 2.02135 -2.27643 -0.100832 1.17564
W_f max, min, mean, abs_mean: 0.685838 -0.778594 0.0236234 0.319339
huabei_lstm30x2+dropout0  8802.1      0.80  0.24  0.64      0.80  0.16  0.69      0.81  0.11  0.73
forget mean min: 0.923827 0.607817
delta_x = 5.5495
delta_h = 3.27627
delta mean, abs_mean, abs_mean+, abs_mean-: 1.26144 5.5495 5.67527 5.36079
U_c = [[-0.08351253]] U_f = [[ 0.]] b_f = [ 1.21189022]
W_c max, min, mean, abs_mean: 2.02135 -2.27643 -0.100832 1.17564
W_f max, min, mean, abs_mean: 0.685838 -0.778594 0.0236234 0.319339
Epoch 8/500
55s - loss: 986.4352 - val_loss: 8654.1034
Epoch 00007: val_loss improved from 8802.13387 to 8654.10341, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0   895.6      0.78  0.23  0.64      0.76  0.13  0.68      0.76  0.09  0.71
forget mean min: 0.897139 0.438241
delta_x = 6.70486
delta_h = 2.52294
delta mean, abs_mean, abs_mean+, abs_mean-: 0.965971 6.70486 6.97979 6.36952
U_c = [[-0.08501747]] U_f = [[ 0.]] b_f = [ 1.21754384]
W_c max, min, mean, abs_mean: 2.152 -2.41973 -0.106437 1.24934
W_f max, min, mean, abs_mean: 0.665626 -0.79466 0.027468 0.323522
huabei_lstm30x2+dropout0  8654.1      0.82  0.24  0.65      0.81  0.16  0.70      0.82  0.12  0.74
forget mean min: 0.92449 0.617302
delta_x = 5.85443
delta_h = 3.46303
delta mean, abs_mean, abs_mean+, abs_mean-: 1.63002 5.85443 6.08966 5.47944
U_c = [[-0.08501747]] U_f = [[ 0.]] b_f = [ 1.21754384]
W_c max, min, mean, abs_mean: 2.152 -2.41973 -0.106437 1.24934
W_f max, min, mean, abs_mean: 0.665626 -0.79466 0.027468 0.323522
Epoch 9/500
54s - loss: 959.2780 - val_loss: 8947.2516
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 935.3240 - val_loss: 8688.6271
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 915.7943 - val_loss: 8715.2969
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 895.7434 - val_loss: 8615.7663
Epoch 00011: val_loss improved from 8654.10341 to 8615.76633, saving model to huabei_lstm30x2+dropout0_weights.hdf5
huabei_lstm30x2+dropout0   856.0      0.82  0.24  0.65      0.80  0.14  0.71      0.80  0.10  0.74
forget mean min: 0.889013 0.376383
delta_x = 8.05624
delta_h = 3.00293
delta mean, abs_mean, abs_mean+, abs_mean-: 1.35784 8.05624 8.62161 7.3764
U_c = [[-0.09239534]] U_f = [[ 0.]] b_f = [ 1.24058294]
W_c max, min, mean, abs_mean: 2.65797 -2.97134 -0.121623 1.52943
W_f max, min, mean, abs_mean: 0.761679 -0.912212 0.0382701 0.354192
huabei_lstm30x2+dropout0  8615.8      0.81  0.25  0.64      0.82  0.17  0.69      0.83  0.12  0.74
forget mean min: 0.919748 0.615655
delta_x = 6.94812
delta_h = 3.88527
delta mean, abs_mean, abs_mean+, abs_mean-: 2.04885 6.94812 7.47359 6.15359
U_c = [[-0.09239534]] U_f = [[ 0.]] b_f = [ 1.24058294]
W_c max, min, mean, abs_mean: 2.65797 -2.97134 -0.121623 1.52943
W_f max, min, mean, abs_mean: 0.761679 -0.912212 0.0382701 0.354192
Epoch 13/500
55s - loss: 879.7874 - val_loss: 8822.7032
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 863.8647 - val_loss: 8812.1346
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 850.6627 - val_loss: 8831.1326
Epoch 00014: val_loss did not improve
Epoch 16/500
54s - loss: 836.8287 - val_loss: 9344.4116
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 823.8441 - val_loss: 8886.2322
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 813.8749 - val_loss: 8850.7117
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 803.6073 - val_loss: 8939.3400
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 794.5152 - val_loss: 9003.9266
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 785.1403 - val_loss: 8981.1767
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 776.3545 - val_loss: 8894.7174
Epoch 00021: val_loss did not improve
Epoch 23/500
54s - loss: 769.1968 - val_loss: 8958.7587
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 761.9574 - val_loss: 8739.5346
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 755.4042 - val_loss: 9116.2891
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 749.5515 - val_loss: 8966.2335
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 743.5818 - val_loss: 8789.6463
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 738.0507 - val_loss: 8696.5077
Epoch 00027: val_loss did not improve
Epoch 29/500
54s - loss: 733.1524 - val_loss: 9006.9433
Epoch 00028: val_loss did not improve
Epoch 30/500
54s - loss: 728.0917 - val_loss: 8974.5412
Epoch 00029: val_loss did not improve
Epoch 31/500
55s - loss: 722.3870 - val_loss: 9152.2522
Epoch 00030: val_loss did not improve
Epoch 32/500
56s - loss: 717.9705 - val_loss: 8858.9857
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 713.1437 - val_loss: 9261.3360
Epoch 00032: val_loss did not improve
Epoch 34/500
55s - loss: 709.1942 - val_loss: 8801.5869
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 705.4934 - val_loss: 9032.4433
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 701.1517 - val_loss: 8965.8627
Epoch 00035: val_loss did not improve
Epoch 37/500
54s - loss: 697.6934 - val_loss: 9311.2618
Epoch 00036: val_loss did not improve
Epoch 38/500
55s - loss: 695.0270 - val_loss: 9191.6723
Epoch 00037: val_loss did not improve
Epoch 39/500
55s - loss: 690.6227 - val_loss: 9257.3447
Epoch 00038: val_loss did not improve
Epoch 40/500
55s - loss: 688.1539 - val_loss: 9438.4437
Epoch 00039: val_loss did not improve
Epoch 41/500
55s - loss: 684.3512 - val_loss: 9575.6455
Epoch 00040: val_loss did not improve
Epoch 42/500
55s - loss: 682.1551 - val_loss: 9456.9666
Epoch 00041: val_loss did not improve
Epoch 43/500
55s - loss: 679.6945 - val_loss: 9537.3220
Epoch 00042: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout1
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout1  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout1 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 1984.8486 - val_loss: 9168.6795
Epoch 00000: val_loss improved from inf to 9168.67951, saving model to huabei_lstm30x2+dropout1_weights.hdf5
huabei_lstm30x2+dropout1  1459.9      0.75  0.33  0.54      0.72  0.19  0.62      0.73  0.13  0.66
forget mean min: 0.942837 0.66671
delta_x = 4.40575
delta_h = 2.07712
delta mean, abs_mean, abs_mean+, abs_mean-: 1.01619 4.40575 4.10413 4.99269
U_c = [[-0.07065376]] U_f = [[ 0.]] b_f = [ 1.17997909]
W_c max, min, mean, abs_mean: 0.501719 -0.45755 -0.0201531 0.428576
W_f max, min, mean, abs_mean: 0.451012 -0.43204 -0.00783711 0.280664
huabei_lstm30x2+dropout1  9168.7      0.84  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.949268 0.690146
delta_x = 5.10307
delta_h = 3.0643
delta mean, abs_mean, abs_mean+, abs_mean-: 1.0093 5.10307 4.59328 6.11669
U_c = [[-0.07065376]] U_f = [[ 0.]] b_f = [ 1.17997909]
W_c max, min, mean, abs_mean: 0.501719 -0.45755 -0.0201531 0.428576
W_f max, min, mean, abs_mean: 0.451012 -0.43204 -0.00783711 0.280664
Epoch 2/500
55s - loss: 1364.9810 - val_loss: 8766.9035
Epoch 00001: val_loss improved from 9168.67951 to 8766.90353, saving model to huabei_lstm30x2+dropout1_weights.hdf5
huabei_lstm30x2+dropout1  1278.7      0.78  0.31  0.57      0.75  0.18  0.65      0.75  0.12  0.68
forget mean min: 0.93071 0.582869
delta_x = 4.96515
delta_h = 2.09745
delta mean, abs_mean, abs_mean+, abs_mean-: 1.10271 4.96515 4.85241 5.15325
U_c = [[-0.06805497]] U_f = [[ 0.]] b_f = [ 1.18144238]
W_c max, min, mean, abs_mean: 0.875037 -0.721796 -0.00996469 0.631936
W_f max, min, mean, abs_mean: 0.540058 -0.480149 -0.00430351 0.29723
huabei_lstm30x2+dropout1  8766.9      0.85  0.25  0.66      0.84  0.16  0.72      0.85  0.12  0.76
forget mean min: 0.941462 0.641342
delta_x = 5.41765
delta_h = 2.936
delta mean, abs_mean, abs_mean+, abs_mean-: 1.09702 5.41765 5.32004 5.57179
U_c = [[-0.06805497]] U_f = [[ 0.]] b_f = [ 1.18144238]
W_c max, min, mean, abs_mean: 0.875037 -0.721796 -0.00996469 0.631936
W_f max, min, mean, abs_mean: 0.540058 -0.480149 -0.00430351 0.29723
Epoch 3/500
56s - loss: 1228.9869 - val_loss: 9023.8379
Epoch 00002: val_loss did not improve
Epoch 4/500
55s - loss: 1137.7005 - val_loss: 9504.9958
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1073.2194 - val_loss: 9160.7119
Epoch 00004: val_loss did not improve
Epoch 6/500
56s - loss: 1022.2669 - val_loss: 9539.1380
Epoch 00005: val_loss did not improve
Epoch 7/500
56s - loss: 982.3299 - val_loss: 9214.1192
Epoch 00006: val_loss did not improve
Epoch 8/500
55s - loss: 951.2325 - val_loss: 9157.5844
Epoch 00007: val_loss did not improve
Epoch 9/500
55s - loss: 925.3798 - val_loss: 9544.6692
Epoch 00008: val_loss did not improve
Epoch 10/500
54s - loss: 904.1179 - val_loss: 9263.4585
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 886.6175 - val_loss: 9382.6242
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 869.0791 - val_loss: 9166.0779
Epoch 00011: val_loss did not improve
Epoch 13/500
55s - loss: 856.0260 - val_loss: 9735.0356
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 843.9838 - val_loss: 9250.8628
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 831.7984 - val_loss: 9563.7351
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 819.4989 - val_loss: 9381.8567
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 810.8757 - val_loss: 9268.9050
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 800.0154 - val_loss: 9351.1160
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 792.8591 - val_loss: 9328.5896
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 784.1168 - val_loss: 9011.0312
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 777.3877 - val_loss: 9071.9333
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 770.9435 - val_loss: 9094.2483
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 764.8254 - val_loss: 9418.2928
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 757.5255 - val_loss: 9258.6495
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 751.8304 - val_loss: 9038.5017
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 746.1911 - val_loss: 9208.8617
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 741.1569 - val_loss: 9242.9692
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 736.7996 - val_loss: 9237.0524
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 731.7862 - val_loss: 9245.8780
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 727.1124 - val_loss: 9114.4828
Epoch 00029: val_loss did not improve
Epoch 31/500
54s - loss: 723.1558 - val_loss: 9377.8082
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 718.5873 - val_loss: 9111.1823
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 715.4087 - val_loss: 9510.2346
Epoch 00032: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout2
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout2  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout2 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 2033.4022 - val_loss: 9522.4323
Epoch 00000: val_loss improved from inf to 9522.43228, saving model to huabei_lstm30x2+dropout2_weights.hdf5
huabei_lstm30x2+dropout2  1472.4      0.71  0.32  0.53      0.68  0.18  0.59      0.69  0.12  0.63
forget mean min: 0.943296 0.622817
delta_x = 4.11062
delta_h = 2.12855
delta mean, abs_mean, abs_mean+, abs_mean-: 0.867754 4.11062 3.78444 4.73747
U_c = [[-0.07874075]] U_f = [[ 0.]] b_f = [ 1.18495142]
W_c max, min, mean, abs_mean: 0.489148 -0.55281 -0.063389 0.421185
W_f max, min, mean, abs_mean: 0.462041 -0.422318 -0.0401417 0.280314
huabei_lstm30x2+dropout2  9522.4      0.86  0.23  0.68      0.84  0.14  0.74      0.85  0.10  0.77
forget mean min: 0.951457 0.653403
delta_x = 4.53272
delta_h = 3.11016
delta mean, abs_mean, abs_mean+, abs_mean-: 0.888509 4.53272 3.91134 5.93546
U_c = [[-0.07874075]] U_f = [[ 0.]] b_f = [ 1.18495142]
W_c max, min, mean, abs_mean: 0.489148 -0.55281 -0.063389 0.421185
W_f max, min, mean, abs_mean: 0.462041 -0.422318 -0.0401417 0.280314
Epoch 2/500
55s - loss: 1404.2512 - val_loss: 8979.5807
Epoch 00001: val_loss improved from 9522.43228 to 8979.58068, saving model to huabei_lstm30x2+dropout2_weights.hdf5
huabei_lstm30x2+dropout2  1277.2      0.73  0.29  0.56      0.70  0.16  0.62      0.70  0.10  0.65
forget mean min: 0.931797 0.579302
delta_x = 4.48287
delta_h = 2.16724
delta mean, abs_mean, abs_mean+, abs_mean-: 0.869162 4.48287 4.27993 4.82145
U_c = [[-0.07750144]] U_f = [[ 0.]] b_f = [ 1.19404626]
W_c max, min, mean, abs_mean: 0.91826 -0.988517 -0.101963 0.628736
W_f max, min, mean, abs_mean: 0.591115 -0.514738 -0.0400282 0.296923
huabei_lstm30x2+dropout2  8979.6      0.83  0.22  0.67      0.82  0.15  0.72      0.83  0.10  0.76
forget mean min: 0.943917 0.597247
delta_x = 5.07398
delta_h = 3.19523
delta mean, abs_mean, abs_mean+, abs_mean-: 1.1154 5.07398 4.79521 5.5813
U_c = [[-0.07750144]] U_f = [[ 0.]] b_f = [ 1.19404626]
W_c max, min, mean, abs_mean: 0.91826 -0.988517 -0.101963 0.628736
W_f max, min, mean, abs_mean: 0.591115 -0.514738 -0.0400282 0.296923
Epoch 3/500
55s - loss: 1261.6452 - val_loss: 9179.0542
Epoch 00002: val_loss did not improve
Epoch 4/500
55s - loss: 1176.1606 - val_loss: 8741.2334
Epoch 00003: val_loss improved from 8979.58068 to 8741.23343, saving model to huabei_lstm30x2+dropout2_weights.hdf5
huabei_lstm30x2+dropout2  1081.1      0.75  0.26  0.60      0.72  0.14  0.64      0.72  0.09  0.67
forget mean min: 0.919731 0.52453
delta_x = 5.08672
delta_h = 2.19083
delta mean, abs_mean, abs_mean+, abs_mean-: 0.851639 5.08672 5.30275 4.81185
U_c = [[-0.07637957]] U_f = [[ 0.]] b_f = [ 1.21439803]
W_c max, min, mean, abs_mean: 1.49163 -1.71155 -0.155124 0.904549
W_f max, min, mean, abs_mean: 0.771372 -0.567087 -0.033542 0.312826
huabei_lstm30x2+dropout2  8741.2      0.81  0.25  0.64      0.80  0.17  0.69      0.81  0.11  0.73
forget mean min: 0.940666 0.62573
delta_x = 4.76886
delta_h = 3.10498
delta mean, abs_mean, abs_mean+, abs_mean-: 1.41548 4.76886 5.08311 4.28079
U_c = [[-0.07637957]] U_f = [[ 0.]] b_f = [ 1.21439803]
W_c max, min, mean, abs_mean: 1.49163 -1.71155 -0.155124 0.904549
W_f max, min, mean, abs_mean: 0.771372 -0.567087 -0.033542 0.312826
Epoch 5/500
56s - loss: 1113.2006 - val_loss: 8280.4398
Epoch 00004: val_loss improved from 8741.23343 to 8280.43984, saving model to huabei_lstm30x2+dropout2_weights.hdf5
huabei_lstm30x2+dropout2  1093.8      0.81  0.29  0.61      0.78  0.17  0.67      0.78  0.11  0.71
forget mean min: 0.919428 0.47829
delta_x = 5.87262
delta_h = 2.56965
delta mean, abs_mean, abs_mean+, abs_mean-: 1.38021 5.87262 6.24791 5.35348
U_c = [[-0.07834064]] U_f = [[ 0.]] b_f = [ 1.21875823]
W_c max, min, mean, abs_mean: 1.68847 -1.9981 -0.177998 1.00909
W_f max, min, mean, abs_mean: 0.868314 -0.596453 -0.0327198 0.321822
huabei_lstm30x2+dropout2  8280.4      0.85  0.26  0.65      0.84  0.17  0.71      0.85  0.12  0.75
forget mean min: 0.942333 0.617339
delta_x = 5.31877
delta_h = 3.53377
delta mean, abs_mean, abs_mean+, abs_mean-: 2.08722 5.31877 5.81232 4.45232
U_c = [[-0.07834064]] U_f = [[ 0.]] b_f = [ 1.21875823]
W_c max, min, mean, abs_mean: 1.68847 -1.9981 -0.177998 1.00909
W_f max, min, mean, abs_mean: 0.868314 -0.596453 -0.0327198 0.321822
Epoch 6/500
54s - loss: 1064.7171 - val_loss: 8645.1735
Epoch 00005: val_loss did not improve
Epoch 7/500
55s - loss: 1025.7008 - val_loss: 8534.4099
Epoch 00006: val_loss did not improve
Epoch 8/500
55s - loss: 994.4692 - val_loss: 8753.3315
Epoch 00007: val_loss did not improve
Epoch 9/500
55s - loss: 965.1792 - val_loss: 8723.1609
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 942.0661 - val_loss: 8451.4028
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 918.7357 - val_loss: 8620.9059
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 900.4283 - val_loss: 8866.4513
Epoch 00011: val_loss did not improve
Epoch 13/500
54s - loss: 884.3071 - val_loss: 8846.1133
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 867.7233 - val_loss: 8438.3057
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 852.6853 - val_loss: 8682.5653
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 841.3233 - val_loss: 8489.8816
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 829.3106 - val_loss: 8416.3804
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 818.1296 - val_loss: 8761.5270
Epoch 00017: val_loss did not improve
Epoch 19/500
54s - loss: 807.9551 - val_loss: 8839.2886
Epoch 00018: val_loss did not improve
Epoch 20/500
54s - loss: 799.8562 - val_loss: 8570.8897
Epoch 00019: val_loss did not improve
Epoch 21/500
54s - loss: 791.5301 - val_loss: 8563.6344
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 783.7423 - val_loss: 8675.6996
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 776.5443 - val_loss: 8880.9752
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 770.1247 - val_loss: 8989.4751
Epoch 00023: val_loss did not improve
Epoch 25/500
54s - loss: 762.8754 - val_loss: 8917.7052
Epoch 00024: val_loss did not improve
Epoch 26/500
54s - loss: 756.6822 - val_loss: 8735.3864
Epoch 00025: val_loss did not improve
Epoch 27/500
54s - loss: 751.7190 - val_loss: 8914.1136
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 745.8376 - val_loss: 8736.9182
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 740.4751 - val_loss: 9217.3420
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 735.6184 - val_loss: 8944.2552
Epoch 00029: val_loss did not improve
Epoch 31/500
55s - loss: 731.1188 - val_loss: 8903.5214
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 727.2566 - val_loss: 9067.4689
Epoch 00031: val_loss did not improve
Epoch 33/500
54s - loss: 722.4068 - val_loss: 8740.9192
Epoch 00032: val_loss did not improve
Epoch 34/500
54s - loss: 718.2284 - val_loss: 8715.4986
Epoch 00033: val_loss did not improve
Epoch 35/500
54s - loss: 714.7250 - val_loss: 8601.6076
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 711.2516 - val_loss: 8900.0390
Epoch 00035: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout3
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout3  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout3 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 2008.7296 - val_loss: 9176.3982
Epoch 00000: val_loss improved from inf to 9176.39823, saving model to huabei_lstm30x2+dropout3_weights.hdf5
huabei_lstm30x2+dropout3  1446.1      0.75  0.34  0.54      0.72  0.19  0.62      0.73  0.13  0.66
forget mean min: 0.943391 0.64497
delta_x = 4.32933
delta_h = 2.04664
delta mean, abs_mean, abs_mean+, abs_mean-: 0.965632 4.32933 4.1281 4.68914
U_c = [[-0.07004686]] U_f = [[ 0.]] b_f = [ 1.18488944]
W_c max, min, mean, abs_mean: 0.535516 -0.551312 0.166533 0.430756
W_f max, min, mean, abs_mean: 0.449677 -0.439177 0.101605 0.280134
huabei_lstm30x2+dropout3  9176.4      0.85  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.95091 0.673322
delta_x = 4.82013
delta_h = 2.94985
delta mean, abs_mean, abs_mean+, abs_mean-: 0.833372 4.82013 4.35917 5.67046
U_c = [[-0.07004686]] U_f = [[ 0.]] b_f = [ 1.18488944]
W_c max, min, mean, abs_mean: 0.535516 -0.551312 0.166533 0.430756
W_f max, min, mean, abs_mean: 0.449677 -0.439177 0.101605 0.280134
Epoch 2/500
56s - loss: 1356.0590 - val_loss: 8863.9248
Epoch 00001: val_loss improved from 9176.39823 to 8863.92475, saving model to huabei_lstm30x2+dropout3_weights.hdf5
huabei_lstm30x2+dropout3  1269.5      0.78  0.32  0.57      0.75  0.18  0.65      0.76  0.12  0.69
forget mean min: 0.93371 0.573721
delta_x = 4.78778
delta_h = 2.00022
delta mean, abs_mean, abs_mean+, abs_mean-: 1.11651 4.78778 4.65996 5.00873
U_c = [[-0.06611127]] U_f = [[ 0.]] b_f = [ 1.18820214]
W_c max, min, mean, abs_mean: 0.941608 -1.01183 0.246436 0.643882
W_f max, min, mean, abs_mean: 0.562147 -0.500537 0.108974 0.302266
huabei_lstm30x2+dropout3  8863.9      0.83  0.23  0.66      0.83  0.15  0.72      0.83  0.11  0.75
forget mean min: 0.944594 0.643929
delta_x = 4.87764
delta_h = 2.78953
delta mean, abs_mean, abs_mean+, abs_mean-: 0.940199 4.87764 4.67094 5.21887
U_c = [[-0.06611127]] U_f = [[ 0.]] b_f = [ 1.18820214]
W_c max, min, mean, abs_mean: 0.941608 -1.01183 0.246436 0.643882
W_f max, min, mean, abs_mean: 0.562147 -0.500537 0.108974 0.302266
Epoch 3/500
55s - loss: 1226.4308 - val_loss: 8888.2151
Epoch 00002: val_loss did not improve
Epoch 4/500
55s - loss: 1150.6936 - val_loss: 8555.1997
Epoch 00003: val_loss improved from 8863.92475 to 8555.19972, saving model to huabei_lstm30x2+dropout3_weights.hdf5
huabei_lstm30x2+dropout3  1060.5      0.75  0.25  0.60      0.71  0.13  0.64      0.71  0.09  0.67
forget mean min: 0.912012 0.524025
delta_x = 5.33105
delta_h = 2.02627
delta mean, abs_mean, abs_mean+, abs_mean-: 0.680124 5.33105 5.30423 5.36612
U_c = [[-0.07211577]] U_f = [[ 0.]] b_f = [ 1.19723809]
W_c max, min, mean, abs_mean: 1.61779 -1.72794 0.348746 0.922604
W_f max, min, mean, abs_mean: 0.630213 -0.634971 0.111267 0.306114
huabei_lstm30x2+dropout3  8555.2      0.81  0.23  0.65      0.80  0.15  0.70      0.80  0.11  0.73
forget mean min: 0.93219 0.641156
delta_x = 5.21429
delta_h = 3.03317
delta mean, abs_mean, abs_mean+, abs_mean-: 0.976616 5.21429 5.23132 5.18962
U_c = [[-0.07211577]] U_f = [[ 0.]] b_f = [ 1.19723809]
W_c max, min, mean, abs_mean: 1.61779 -1.72794 0.348746 0.922604
W_f max, min, mean, abs_mean: 0.630213 -0.634971 0.111267 0.306114
Epoch 5/500
56s - loss: 1093.1313 - val_loss: 8687.2549
Epoch 00004: val_loss did not improve
Epoch 6/500
55s - loss: 1046.8400 - val_loss: 8650.2834
Epoch 00005: val_loss did not improve
Epoch 7/500
54s - loss: 1009.8303 - val_loss: 8550.6797
Epoch 00006: val_loss improved from 8555.19972 to 8550.67972, saving model to huabei_lstm30x2+dropout3_weights.hdf5
huabei_lstm30x2+dropout3   932.2      0.77  0.23  0.63      0.74  0.13  0.67      0.75  0.09  0.70
forget mean min: 0.899899 0.475604
delta_x = 6.40506
delta_h = 2.38627
delta mean, abs_mean, abs_mean+, abs_mean-: 0.844188 6.40506 6.63086 6.13278
U_c = [[-0.08201936]] U_f = [[ 0.]] b_f = [ 1.22498727]
W_c max, min, mean, abs_mean: 2.31739 -2.46363 0.458849 1.21595
W_f max, min, mean, abs_mean: 0.682302 -0.754359 0.121449 0.314167
huabei_lstm30x2+dropout3  8550.7      0.79  0.22  0.64      0.78  0.15  0.69      0.80  0.10  0.73
forget mean min: 0.922334 0.607378
delta_x = 5.97683
delta_h = 3.5139
delta mean, abs_mean, abs_mean+, abs_mean-: 1.28787 5.97683 6.21874 5.63708
U_c = [[-0.08201936]] U_f = [[ 0.]] b_f = [ 1.22498727]
W_c max, min, mean, abs_mean: 2.31739 -2.46363 0.458849 1.21595
W_f max, min, mean, abs_mean: 0.682302 -0.754359 0.121449 0.314167
Epoch 8/500
55s - loss: 979.9566 - val_loss: 8507.4493
Epoch 00007: val_loss improved from 8550.67972 to 8507.44927, saving model to huabei_lstm30x2+dropout3_weights.hdf5
huabei_lstm30x2+dropout3   942.6      0.82  0.26  0.63      0.80  0.15  0.70      0.81  0.11  0.73
forget mean min: 0.902095 0.459655
delta_x = 7.19021
delta_h = 2.67623
delta mean, abs_mean, abs_mean+, abs_mean-: 1.35589 7.19021 7.54176 6.73065
U_c = [[-0.08332449]] U_f = [[ 0.]] b_f = [ 1.23735082]
W_c max, min, mean, abs_mean: 2.49807 -2.66366 0.487234 1.29467
W_f max, min, mean, abs_mean: 0.718029 -0.774086 0.126448 0.31976
huabei_lstm30x2+dropout3  8507.4      0.80  0.24  0.64      0.80  0.16  0.69      0.81  0.11  0.74
forget mean min: 0.923663 0.599994
delta_x = 6.04605
delta_h = 3.52631
delta mean, abs_mean, abs_mean+, abs_mean-: 1.47 6.04605 6.35065 5.60454
U_c = [[-0.08332449]] U_f = [[ 0.]] b_f = [ 1.23735082]
W_c max, min, mean, abs_mean: 2.49807 -2.66366 0.487234 1.29467
W_f max, min, mean, abs_mean: 0.718029 -0.774086 0.126448 0.31976
Epoch 9/500
55s - loss: 953.3406 - val_loss: 8695.9903
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 930.5961 - val_loss: 8802.4098
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 910.9084 - val_loss: 9418.4186
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 891.7827 - val_loss: 9227.4925
Epoch 00011: val_loss did not improve
Epoch 13/500
54s - loss: 876.0364 - val_loss: 9029.1343
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 859.9171 - val_loss: 9359.7967
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 847.7297 - val_loss: 8936.4732
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 834.1874 - val_loss: 9103.3057
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 823.3677 - val_loss: 8862.5535
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 811.9149 - val_loss: 9025.5755
Epoch 00017: val_loss did not improve
Epoch 19/500
54s - loss: 802.4273 - val_loss: 8892.5330
Epoch 00018: val_loss did not improve
Epoch 20/500
54s - loss: 794.1051 - val_loss: 9232.5527
Epoch 00019: val_loss did not improve
Epoch 21/500
54s - loss: 785.2345 - val_loss: 9059.7427
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 777.9191 - val_loss: 9019.5818
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 770.8725 - val_loss: 9246.9579
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 764.0858 - val_loss: 9266.6754
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 757.6933 - val_loss: 9323.2057
Epoch 00024: val_loss did not improve
Epoch 26/500
54s - loss: 751.6160 - val_loss: 9108.0547
Epoch 00025: val_loss did not improve
Epoch 27/500
54s - loss: 745.4472 - val_loss: 9239.1261
Epoch 00026: val_loss did not improve
Epoch 28/500
54s - loss: 740.4705 - val_loss: 9313.0294
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 735.6085 - val_loss: 9234.7340
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 730.5291 - val_loss: 9180.4332
Epoch 00029: val_loss did not improve
Epoch 31/500
55s - loss: 725.1129 - val_loss: 9185.7252
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 721.8810 - val_loss: 9355.2763
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 717.8881 - val_loss: 9284.2723
Epoch 00032: val_loss did not improve
Epoch 34/500
54s - loss: 713.7037 - val_loss: 9592.7403
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 710.4756 - val_loss: 8748.1119
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 706.7782 - val_loss: 9199.7709
Epoch 00035: val_loss did not improve
Epoch 37/500
55s - loss: 702.9923 - val_loss: 9463.4374
Epoch 00036: val_loss did not improve
Epoch 38/500
55s - loss: 699.0283 - val_loss: 8895.9697
Epoch 00037: val_loss did not improve
Epoch 39/500
55s - loss: 696.2648 - val_loss: 8985.1634
Epoch 00038: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout4
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout4  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout4 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
55s - loss: 2004.3075 - val_loss: 9791.5805
Epoch 00000: val_loss improved from inf to 9791.58050, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4  1439.5      0.72  0.31  0.54      0.69  0.18  0.60      0.70  0.12  0.64
forget mean min: 0.940297 0.669806
delta_x = 4.22095
delta_h = 1.91462
delta mean, abs_mean, abs_mean+, abs_mean-: 0.827956 4.22095 3.97618 4.64659
U_c = [[-0.06945307]] U_f = [[ 0.]] b_f = [ 1.16040719]
W_c max, min, mean, abs_mean: 0.564151 -0.549133 0.175415 0.453028
W_f max, min, mean, abs_mean: 0.498731 -0.413663 0.103364 0.27451
huabei_lstm30x2+dropout4  9791.6      0.83  0.25  0.65      0.82  0.16  0.70      0.82  0.11  0.75
forget mean min: 0.94972 0.703888
delta_x = 4.53864
delta_h = 2.78056
delta mean, abs_mean, abs_mean+, abs_mean-: 0.968187 4.53864 4.27114 5.02392
U_c = [[-0.06945307]] U_f = [[ 0.]] b_f = [ 1.16040719]
W_c max, min, mean, abs_mean: 0.564151 -0.549133 0.175415 0.453028
W_f max, min, mean, abs_mean: 0.498731 -0.413663 0.103364 0.27451
Epoch 2/500
56s - loss: 1374.5106 - val_loss: 9355.0918
Epoch 00001: val_loss improved from 9791.58050 to 9355.09180, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4  1268.1      0.76  0.31  0.57      0.73  0.17  0.63      0.74  0.12  0.67
forget mean min: 0.929504 0.603771
delta_x = 4.78117
delta_h = 1.93071
delta mean, abs_mean, abs_mean+, abs_mean-: 0.987568 4.78117 4.65868 4.98029
U_c = [[-0.06619172]] U_f = [[ 0.]] b_f = [ 1.16151905]
W_c max, min, mean, abs_mean: 0.894444 -0.977819 0.250079 0.662951
W_f max, min, mean, abs_mean: 0.600732 -0.477303 0.106433 0.289776
huabei_lstm30x2+dropout4  9355.1      0.80  0.24  0.64      0.79  0.16  0.69      0.80  0.11  0.73
forget mean min: 0.94 0.652959
delta_x = 5.00812
delta_h = 2.81974
delta mean, abs_mean, abs_mean+, abs_mean-: 1.1449 5.00812 4.98172 5.05073
U_c = [[-0.06619172]] U_f = [[ 0.]] b_f = [ 1.16151905]
W_c max, min, mean, abs_mean: 0.894444 -0.977819 0.250079 0.662951
W_f max, min, mean, abs_mean: 0.600732 -0.477303 0.106433 0.289776
Epoch 3/500
55s - loss: 1246.0059 - val_loss: 9664.0617
Epoch 00002: val_loss did not improve
Epoch 4/500
55s - loss: 1157.8692 - val_loss: 9382.7775
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1091.4911 - val_loss: 9350.5011
Epoch 00004: val_loss improved from 9355.09180 to 9350.50112, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4   992.2      0.74  0.22  0.61      0.71  0.12  0.65      0.72  0.08  0.67
forget mean min: 0.90062 0.542595
delta_x = 6.04697
delta_h = 2.01599
delta mean, abs_mean, abs_mean+, abs_mean-: 0.575701 6.04697 6.17843 5.89515
U_c = [[-0.07311063]] U_f = [[ 0.]] b_f = [ 1.15735602]
W_c max, min, mean, abs_mean: 1.53393 -1.82895 0.385921 1.04511
W_f max, min, mean, abs_mean: 0.765051 -0.600211 0.102354 0.303152
huabei_lstm30x2+dropout4  9350.5      0.74  0.24  0.60      0.74  0.16  0.65      0.76  0.11  0.70
forget mean min: 0.920833 0.600437
delta_x = 5.57441
delta_h = 2.98473
delta mean, abs_mean, abs_mean+, abs_mean-: 0.925501 5.57441 5.73417 5.3654
U_c = [[-0.07311063]] U_f = [[ 0.]] b_f = [ 1.15735602]
W_c max, min, mean, abs_mean: 1.53393 -1.82895 0.385921 1.04511
W_f max, min, mean, abs_mean: 0.765051 -0.600211 0.102354 0.303152
Epoch 6/500
56s - loss: 1038.5529 - val_loss: 9036.0223
Epoch 00005: val_loss improved from 9350.50112 to 9036.02230, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4   936.4      0.78  0.23  0.63      0.75  0.13  0.68      0.76  0.09  0.71
forget mean min: 0.897633 0.522731
delta_x = 6.65948
delta_h = 2.19147
delta mean, abs_mean, abs_mean+, abs_mean-: 0.836762 6.65948 6.93337 6.33719
U_c = [[-0.07505365]] U_f = [[ 0.]] b_f = [ 1.15548527]
W_c max, min, mean, abs_mean: 1.70092 -2.01873 0.424439 1.14884
W_f max, min, mean, abs_mean: 0.799323 -0.659793 0.0985665 0.306267
huabei_lstm30x2+dropout4  9036.0      0.76  0.24  0.62      0.77  0.16  0.67      0.79  0.11  0.72
forget mean min: 0.917926 0.591077
delta_x = 5.87198
delta_h = 3.09218
delta mean, abs_mean, abs_mean+, abs_mean-: 1.07022 5.87198 6.11852 5.54873
U_c = [[-0.07505365]] U_f = [[ 0.]] b_f = [ 1.15548527]
W_c max, min, mean, abs_mean: 1.70092 -2.01873 0.424439 1.14884
W_f max, min, mean, abs_mean: 0.799323 -0.659793 0.0985665 0.306267
Epoch 7/500
56s - loss: 997.3520 - val_loss: 9041.0333
Epoch 00006: val_loss did not improve
Epoch 8/500
56s - loss: 965.9985 - val_loss: 9207.5429
Epoch 00007: val_loss did not improve
Epoch 9/500
55s - loss: 940.3590 - val_loss: 8933.8405
Epoch 00008: val_loss improved from 9036.02230 to 8933.84051, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4   852.9      0.76  0.20  0.64      0.75  0.12  0.68      0.75  0.08  0.71
forget mean min: 0.885027 0.460383
delta_x = 7.2897
delta_h = 2.36845
delta mean, abs_mean, abs_mean+, abs_mean-: 0.692721 7.2897 7.76976 6.78261
U_c = [[-0.08344389]] U_f = [[ 0.]] b_f = [ 1.16490817]
W_c max, min, mean, abs_mean: 2.08757 -2.42326 0.517593 1.39471
W_f max, min, mean, abs_mean: 0.92281 -0.91032 0.0912725 0.330439
huabei_lstm30x2+dropout4  8933.8      0.74  0.22  0.61      0.75  0.15  0.67      0.77  0.10  0.71
forget mean min: 0.907767 0.571327
delta_x = 6.2559
delta_h = 3.24801
delta mean, abs_mean, abs_mean+, abs_mean-: 0.868164 6.2559 6.574 5.8797
U_c = [[-0.08344389]] U_f = [[ 0.]] b_f = [ 1.16490817]
W_c max, min, mean, abs_mean: 2.08757 -2.42326 0.517593 1.39471
W_f max, min, mean, abs_mean: 0.92281 -0.91032 0.0912725 0.330439
Epoch 10/500
55s - loss: 918.5086 - val_loss: 8671.9731
Epoch 00009: val_loss improved from 8933.84051 to 8671.97307, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4   837.0      0.78  0.21  0.65      0.76  0.12  0.69      0.77  0.08  0.72
forget mean min: 0.884228 0.439668
delta_x = 7.61912
delta_h = 2.53891
delta mean, abs_mean, abs_mean+, abs_mean-: 0.864614 7.61912 8.22184 6.97674
U_c = [[-0.08427174]] U_f = [[ 0.]] b_f = [ 1.17213809]
W_c max, min, mean, abs_mean: 2.18269 -2.52696 0.541971 1.45806
W_f max, min, mean, abs_mean: 0.965761 -0.981444 0.0919339 0.342422
huabei_lstm30x2+dropout4  8672.0      0.75  0.21  0.63      0.76  0.14  0.68      0.79  0.10  0.72
forget mean min: 0.905668 0.566419
delta_x = 6.5707
delta_h = 3.45372
delta mean, abs_mean, abs_mean+, abs_mean-: 0.913935 6.5707 6.93383 6.14491
U_c = [[-0.08427174]] U_f = [[ 0.]] b_f = [ 1.17213809]
W_c max, min, mean, abs_mean: 2.18269 -2.52696 0.541971 1.45806
W_f max, min, mean, abs_mean: 0.965761 -0.981444 0.0919339 0.342422
Epoch 11/500
55s - loss: 900.6825 - val_loss: 9027.6481
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 885.3615 - val_loss: 8880.9030
Epoch 00011: val_loss did not improve
Epoch 13/500
55s - loss: 869.6340 - val_loss: 8654.2872
Epoch 00012: val_loss improved from 8671.97307 to 8654.28725, saving model to huabei_lstm30x2+dropout4_weights.hdf5
huabei_lstm30x2+dropout4   786.3      0.80  0.21  0.66      0.79  0.12  0.71      0.79  0.09  0.74
forget mean min: 0.881613 0.372996
delta_x = 8.15833
delta_h = 2.69472
delta mean, abs_mean, abs_mean+, abs_mean-: 0.994481 8.15833 8.8885 7.3834
U_c = [[-0.08971034]] U_f = [[ 0.]] b_f = [ 1.19932246]
W_c max, min, mean, abs_mean: 2.42561 -2.7877 0.606017 1.62391
W_f max, min, mean, abs_mean: 1.0703 -1.13846 0.0917283 0.37485
huabei_lstm30x2+dropout4  8654.3      0.76  0.22  0.62      0.77  0.15  0.68      0.80  0.10  0.73
forget mean min: 0.904603 0.550981
delta_x = 6.74984
delta_h = 3.47616
delta mean, abs_mean, abs_mean+, abs_mean-: 1.02825 6.74984 7.21765 6.20327
U_c = [[-0.08971034]] U_f = [[ 0.]] b_f = [ 1.19932246]
W_c max, min, mean, abs_mean: 2.42561 -2.7877 0.606017 1.62391
W_f max, min, mean, abs_mean: 1.0703 -1.13846 0.0917283 0.37485
Epoch 14/500
55s - loss: 856.9266 - val_loss: 8759.8530
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 844.6181 - val_loss: 8903.5145
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 832.1856 - val_loss: 9356.5415
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 822.3914 - val_loss: 8786.8845
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 811.7475 - val_loss: 9067.2048
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 802.0910 - val_loss: 9047.8046
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 794.0118 - val_loss: 8904.5741
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 786.6310 - val_loss: 9134.2044
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 778.9909 - val_loss: 9307.2638
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 771.7286 - val_loss: 9316.0533
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 766.6414 - val_loss: 9092.6340
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 759.3822 - val_loss: 9179.1347
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 754.1354 - val_loss: 9161.3135
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 748.5745 - val_loss: 8716.1480
Epoch 00026: val_loss did not improve
Epoch 28/500
56s - loss: 742.9948 - val_loss: 9236.5580
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 738.0612 - val_loss: 9090.2307
Epoch 00028: val_loss did not improve
Epoch 30/500
54s - loss: 733.0032 - val_loss: 9217.7970
Epoch 00029: val_loss did not improve
Epoch 31/500
55s - loss: 728.3920 - val_loss: 9021.6036
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 725.0159 - val_loss: 9184.2726
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 720.1047 - val_loss: 9129.6216
Epoch 00032: val_loss did not improve
Epoch 34/500
55s - loss: 716.4676 - val_loss: 9438.0883
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 713.3311 - val_loss: 9701.6958
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 709.5307 - val_loss: 9462.9533
Epoch 00035: val_loss did not improve
Epoch 37/500
54s - loss: 706.7946 - val_loss: 9362.4346
Epoch 00036: val_loss did not improve
Epoch 38/500
55s - loss: 702.7541 - val_loss: 9742.7221
Epoch 00037: val_loss did not improve
Epoch 39/500
55s - loss: 699.5715 - val_loss: 9378.0888
Epoch 00038: val_loss did not improve
Epoch 40/500
55s - loss: 697.0472 - val_loss: 9420.9737
Epoch 00039: val_loss did not improve
Epoch 41/500
55s - loss: 693.8066 - val_loss: 9328.7580
Epoch 00040: val_loss did not improve
Epoch 42/500
55s - loss: 691.0279 - val_loss: 9302.0417
Epoch 00041: val_loss did not improve
Epoch 43/500
55s - loss: 688.5583 - val_loss: 9672.8761
Epoch 00042: val_loss did not improve
Epoch 44/500
55s - loss: 686.2477 - val_loss: 10024.7394
Epoch 00043: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout5
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout5  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout5 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 1986.4473 - val_loss: 9256.4074
Epoch 00000: val_loss improved from inf to 9256.40745, saving model to huabei_lstm30x2+dropout5_weights.hdf5
huabei_lstm30x2+dropout5  1449.0      0.76  0.33  0.55      0.73  0.19  0.63      0.74  0.13  0.67
forget mean min: 0.945129 0.633337
delta_x = 4.38653
delta_h = 2.07858
delta mean, abs_mean, abs_mean+, abs_mean-: 1.05231 4.38653 4.14793 4.84077
U_c = [[-0.07025436]] U_f = [[ 0.]] b_f = [ 1.19554305]
W_c max, min, mean, abs_mean: 0.559264 -0.528524 0.085225 0.424518
W_f max, min, mean, abs_mean: 0.455828 -0.332065 0.0712473 0.28318
huabei_lstm30x2+dropout5  9256.4      0.85  0.24  0.67      0.84  0.16  0.73      0.85  0.11  0.77
forget mean min: 0.954178 0.685911
delta_x = 4.95448
delta_h = 2.95052
delta mean, abs_mean, abs_mean+, abs_mean-: 1.15027 4.95448 4.58566 5.68871
U_c = [[-0.07025436]] U_f = [[ 0.]] b_f = [ 1.19554305]
W_c max, min, mean, abs_mean: 0.559264 -0.528524 0.085225 0.424518
W_f max, min, mean, abs_mean: 0.455828 -0.332065 0.0712473 0.28318
Epoch 2/500
56s - loss: 1359.9726 - val_loss: 9403.9417
Epoch 00001: val_loss did not improve
Epoch 3/500
55s - loss: 1232.6781 - val_loss: 9249.7816
Epoch 00002: val_loss improved from 9256.40745 to 9249.78155, saving model to huabei_lstm30x2+dropout5_weights.hdf5
huabei_lstm30x2+dropout5  1129.7      0.74  0.26  0.59      0.70  0.14  0.63      0.71  0.09  0.66
forget mean min: 0.920106 0.545155
delta_x = 4.82853
delta_h = 1.98864
delta mean, abs_mean, abs_mean+, abs_mean-: 0.693874 4.82853 4.78069 4.89394
U_c = [[-0.07022611]] U_f = [[ 0.]] b_f = [ 1.19589305]
W_c max, min, mean, abs_mean: 1.42621 -1.17449 0.164995 0.780986
W_f max, min, mean, abs_mean: 0.582056 -0.495446 0.0950461 0.302367
huabei_lstm30x2+dropout5  9249.8      0.81  0.24  0.64      0.80  0.16  0.69      0.81  0.11  0.73
forget mean min: 0.938239 0.628901
delta_x = 4.99835
delta_h = 2.85621
delta mean, abs_mean, abs_mean+, abs_mean-: 1.13082 4.99835 4.96861 5.04621
U_c = [[-0.07022611]] U_f = [[ 0.]] b_f = [ 1.19589305]
W_c max, min, mean, abs_mean: 1.42621 -1.17449 0.164995 0.780986
W_f max, min, mean, abs_mean: 0.582056 -0.495446 0.0950461 0.302367
Epoch 4/500
55s - loss: 1155.4836 - val_loss: 9343.2418
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1097.1955 - val_loss: 9427.6217
Epoch 00004: val_loss did not improve
Epoch 6/500
56s - loss: 1052.7419 - val_loss: 9303.9682
Epoch 00005: val_loss did not improve
Epoch 7/500
56s - loss: 1017.0476 - val_loss: 9020.7219
Epoch 00006: val_loss improved from 9249.78155 to 9020.72192, saving model to huabei_lstm30x2+dropout5_weights.hdf5
huabei_lstm30x2+dropout5   934.6      0.78  0.24  0.63      0.74  0.12  0.67      0.75  0.08  0.70
forget mean min: 0.905205 0.4212
delta_x = 6.13964
delta_h = 2.45105
delta mean, abs_mean, abs_mean+, abs_mean-: 0.91395 6.13964 6.38968 5.8316
U_c = [[-0.08112483]] U_f = [[ 0.]] b_f = [ 1.24440503]
W_c max, min, mean, abs_mean: 2.61241 -1.90876 0.265713 1.16887
W_f max, min, mean, abs_mean: 0.795759 -0.63561 0.12445 0.325754
huabei_lstm30x2+dropout5  9020.7      0.79  0.26  0.62      0.79  0.18  0.67      0.80  0.12  0.71
forget mean min: 0.93116 0.62736
delta_x = 5.10076
delta_h = 3.08204
delta mean, abs_mean, abs_mean+, abs_mean-: 1.35262 5.10076 5.42637 4.62312
U_c = [[-0.08112483]] U_f = [[ 0.]] b_f = [ 1.24440503]
W_c max, min, mean, abs_mean: 2.61241 -1.90876 0.265713 1.16887
W_f max, min, mean, abs_mean: 0.795759 -0.63561 0.12445 0.325754
Epoch 8/500
55s - loss: 987.6017 - val_loss: 8826.1209
Epoch 00007: val_loss improved from 9020.72192 to 8826.12093, saving model to huabei_lstm30x2+dropout5_weights.hdf5
huabei_lstm30x2+dropout5   906.0      0.79  0.24  0.64      0.76  0.13  0.69      0.77  0.09  0.71
forget mean min: 0.902684 0.400104
delta_x = 6.53001
delta_h = 2.55281
delta mean, abs_mean, abs_mean+, abs_mean-: 1.00297 6.53001 6.83543 6.15517
U_c = [[-0.08326181]] U_f = [[ 0.]] b_f = [ 1.25712109]
W_c max, min, mean, abs_mean: 2.87898 -2.06213 0.28703 1.24809
W_f max, min, mean, abs_mean: 0.840899 -0.687905 0.130397 0.335856
huabei_lstm30x2+dropout5  8826.1      0.80  0.25  0.62      0.80  0.18  0.68      0.81  0.12  0.73
forget mean min: 0.928682 0.621049
delta_x = 5.34804
delta_h = 3.1457
delta mean, abs_mean, abs_mean+, abs_mean-: 1.29443 5.34804 5.66391 4.90023
U_c = [[-0.08326181]] U_f = [[ 0.]] b_f = [ 1.25712109]
W_c max, min, mean, abs_mean: 2.87898 -2.06213 0.28703 1.24809
W_f max, min, mean, abs_mean: 0.840899 -0.687905 0.130397 0.335856
Epoch 9/500
55s - loss: 960.0123 - val_loss: 9244.2554
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 936.4231 - val_loss: 9459.1391
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 915.1964 - val_loss: 8961.5311
Epoch 00010: val_loss did not improve
Epoch 12/500
56s - loss: 896.9047 - val_loss: 9295.8942
Epoch 00011: val_loss did not improve
Epoch 13/500
56s - loss: 880.9924 - val_loss: 9396.4616
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 864.6887 - val_loss: 8984.8476
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 852.2185 - val_loss: 9576.6546
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 838.8272 - val_loss: 9483.1358
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 827.7740 - val_loss: 9204.6579
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 817.4883 - val_loss: 9498.6810
Epoch 00017: val_loss did not improve
Epoch 19/500
56s - loss: 808.8875 - val_loss: 9244.5945
Epoch 00018: val_loss did not improve
Epoch 20/500
56s - loss: 799.6443 - val_loss: 9179.0635
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 790.8878 - val_loss: 8902.4987
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 783.7635 - val_loss: 9688.8205
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 777.0502 - val_loss: 9510.3511
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 769.2982 - val_loss: 9049.7151
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 763.3963 - val_loss: 9317.9077
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 757.5234 - val_loss: 9649.0981
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 750.8258 - val_loss: 9153.8335
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 746.0166 - val_loss: 9525.5540
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 740.8231 - val_loss: 9393.3095
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 736.8592 - val_loss: 9223.9900
Epoch 00029: val_loss did not improve
Epoch 31/500
54s - loss: 732.2569 - val_loss: 9694.7292
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 727.3013 - val_loss: 9806.0092
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 723.3084 - val_loss: 9637.4704
Epoch 00032: val_loss did not improve
Epoch 34/500
55s - loss: 719.2194 - val_loss: 9247.8805
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 715.3805 - val_loss: 9509.4406
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 711.3937 - val_loss: 9989.9152
Epoch 00035: val_loss did not improve
Epoch 37/500
54s - loss: 708.3028 - val_loss: 9548.8465
Epoch 00036: val_loss did not improve
Epoch 38/500
55s - loss: 704.8628 - val_loss: 10011.8453
Epoch 00037: val_loss did not improve
Epoch 39/500
55s - loss: 701.7472 - val_loss: 9822.1276
Epoch 00038: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout6
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout6  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout6 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 2014.6899 - val_loss: 9523.0975
Epoch 00000: val_loss improved from inf to 9523.09746, saving model to huabei_lstm30x2+dropout6_weights.hdf5
huabei_lstm30x2+dropout6  1433.6      0.71  0.31  0.54      0.68  0.17  0.59      0.68  0.11  0.63
forget mean min: 0.942721 0.652618
delta_x = 4.05918
delta_h = 2.00262
delta mean, abs_mean, abs_mean+, abs_mean-: 0.806354 4.05918 3.85226 4.41381
U_c = [[-0.07416789]] U_f = [[ 0.]] b_f = [ 1.16967285]
W_c max, min, mean, abs_mean: 0.532521 -0.506592 0.000958704 0.433329
W_f max, min, mean, abs_mean: 0.395368 -0.502766 -0.0114973 0.285403
huabei_lstm30x2+dropout6  9523.1      0.80  0.22  0.65      0.79  0.15  0.69      0.80  0.10  0.73
forget mean min: 0.950131 0.69966
delta_x = 4.6522
delta_h = 2.96698
delta mean, abs_mean, abs_mean+, abs_mean-: 0.759338 4.6522 4.20159 5.46732
U_c = [[-0.07416789]] U_f = [[ 0.]] b_f = [ 1.16967285]
W_c max, min, mean, abs_mean: 0.532521 -0.506592 0.000958704 0.433329
W_f max, min, mean, abs_mean: 0.395368 -0.502766 -0.0114973 0.285403
Epoch 2/500
56s - loss: 1353.6378 - val_loss: 9244.0408
Epoch 00001: val_loss improved from 9523.09746 to 9244.04079, saving model to huabei_lstm30x2+dropout6_weights.hdf5
huabei_lstm30x2+dropout6  1252.4      0.66  0.24  0.55      0.63  0.13  0.58      0.63  0.08  0.60
forget mean min: 0.920757 0.60052
delta_x = 4.44416
delta_h = 1.65983
delta mean, abs_mean, abs_mean+, abs_mean-: 0.224812 4.44416 4.23384 4.70266
U_c = [[-0.06475356]] U_f = [[ 0.]] b_f = [ 1.15900779]
W_c max, min, mean, abs_mean: 0.97377 -0.852134 0.022245 0.650881
W_f max, min, mean, abs_mean: 0.481104 -0.618408 -0.0128904 0.30051
huabei_lstm30x2+dropout6  9244.0      0.75  0.21  0.63      0.74  0.14  0.66      0.76  0.10  0.70
forget mean min: 0.936264 0.650397
delta_x = 4.86534
delta_h = 2.60272
delta mean, abs_mean, abs_mean+, abs_mean-: 0.405344 4.86534 4.63506 5.16882
U_c = [[-0.06475356]] U_f = [[ 0.]] b_f = [ 1.15900779]
W_c max, min, mean, abs_mean: 0.97377 -0.852134 0.022245 0.650881
W_f max, min, mean, abs_mean: 0.481104 -0.618408 -0.0128904 0.30051
Epoch 3/500
56s - loss: 1217.3363 - val_loss: 8600.2974
Epoch 00002: val_loss improved from 9244.04079 to 8600.29743, saving model to huabei_lstm30x2+dropout6_weights.hdf5
huabei_lstm30x2+dropout6  1185.3      0.81  0.32  0.59      0.78  0.19  0.66      0.79  0.13  0.71
forget mean min: 0.925388 0.577092
delta_x = 5.5913
delta_h = 2.23538
delta mean, abs_mean, abs_mean+, abs_mean-: 1.30855 5.5913 5.68322 5.44929
U_c = [[-0.07014244]] U_f = [[ 0.]] b_f = [ 1.15744948]
W_c max, min, mean, abs_mean: 1.34281 -1.16222 0.0383178 0.805889
W_f max, min, mean, abs_mean: 0.493459 -0.788159 -0.0138578 0.314071
huabei_lstm30x2+dropout6  8600.3      0.83  0.23  0.66      0.82  0.15  0.71      0.82  0.11  0.75
forget mean min: 0.939046 0.662246
delta_x = 5.40807
delta_h = 3.1783
delta mean, abs_mean, abs_mean+, abs_mean-: 1.41603 5.40807 5.45067 5.33676
U_c = [[-0.07014244]] U_f = [[ 0.]] b_f = [ 1.15744948]
W_c max, min, mean, abs_mean: 1.34281 -1.16222 0.0383178 0.805889
W_f max, min, mean, abs_mean: 0.493459 -0.788159 -0.0138578 0.314071
Epoch 4/500
56s - loss: 1137.1786 - val_loss: 9418.8630
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1082.7752 - val_loss: 9520.7700
Epoch 00004: val_loss did not improve
Epoch 6/500
55s - loss: 1040.0460 - val_loss: 8709.3906
Epoch 00005: val_loss did not improve
Epoch 7/500
55s - loss: 1006.2923 - val_loss: 8917.2402
Epoch 00006: val_loss did not improve
Epoch 8/500
56s - loss: 973.8455 - val_loss: 8634.0431
Epoch 00007: val_loss did not improve
Epoch 9/500
55s - loss: 947.9387 - val_loss: 9032.7589
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 923.8506 - val_loss: 8760.1333
Epoch 00009: val_loss did not improve
Epoch 11/500
56s - loss: 903.5343 - val_loss: 8610.9112
Epoch 00010: val_loss did not improve
Epoch 12/500
54s - loss: 885.7438 - val_loss: 9142.7456
Epoch 00011: val_loss did not improve
Epoch 13/500
54s - loss: 869.5308 - val_loss: 9289.2040
Epoch 00012: val_loss did not improve
Epoch 14/500
54s - loss: 853.9114 - val_loss: 9461.3349
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 841.0285 - val_loss: 9389.3072
Epoch 00014: val_loss did not improve
Epoch 16/500
55s - loss: 828.7520 - val_loss: 9237.1391
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 817.0684 - val_loss: 9516.6917
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 808.0825 - val_loss: 9417.8779
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 799.9097 - val_loss: 9299.3708
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 789.5291 - val_loss: 9675.5299
Epoch 00019: val_loss did not improve
Epoch 21/500
54s - loss: 781.8569 - val_loss: 9658.2871
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 775.1090 - val_loss: 9441.9043
Epoch 00021: val_loss did not improve
Epoch 23/500
56s - loss: 767.1713 - val_loss: 9554.8709
Epoch 00022: val_loss did not improve
Epoch 24/500
55s - loss: 761.7886 - val_loss: 9739.1485
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 755.2389 - val_loss: 9995.6878
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 748.6523 - val_loss: 9851.0388
Epoch 00025: val_loss did not improve
Epoch 27/500
54s - loss: 743.3097 - val_loss: 9748.4348
Epoch 00026: val_loss did not improve
Epoch 28/500
54s - loss: 737.7106 - val_loss: 9971.8935
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 733.0783 - val_loss: 10150.3550
Epoch 00028: val_loss did not improve
Epoch 30/500
56s - loss: 728.6766 - val_loss: 9721.6585
Epoch 00029: val_loss did not improve
Epoch 31/500
56s - loss: 723.4962 - val_loss: 9864.2257
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 719.3572 - val_loss: 9884.2431
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 716.9895 - val_loss: 9660.9575
Epoch 00032: val_loss did not improve
Epoch 34/500
54s - loss: 711.7861 - val_loss: 9850.7982
Epoch 00033: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout7
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout7  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout7 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 1984.0972 - val_loss: 9192.4248
Epoch 00000: val_loss improved from inf to 9192.42475, saving model to huabei_lstm30x2+dropout7_weights.hdf5
huabei_lstm30x2+dropout7  1475.9      0.76  0.35  0.54      0.74  0.20  0.62      0.75  0.14  0.67
forget mean min: 0.945052 0.587548
delta_x = 4.44595
delta_h = 2.21354
delta mean, abs_mean, abs_mean+, abs_mean-: 1.22604 4.44595 4.26132 4.81331
U_c = [[-0.07474367]] U_f = [[ 0.]] b_f = [ 1.18250883]
W_c max, min, mean, abs_mean: 0.532832 -0.564184 -0.117381 0.446382
W_f max, min, mean, abs_mean: 0.454095 -0.453169 -0.0653742 0.280749
huabei_lstm30x2+dropout7  9192.4      0.84  0.23  0.67      0.83  0.15  0.72      0.84  0.11  0.76
forget mean min: 0.951225 0.652542
delta_x = 5.06537
delta_h = 3.10832
delta mean, abs_mean, abs_mean+, abs_mean-: 1.11143 5.06537 4.63022 5.93704
U_c = [[-0.07474367]] U_f = [[ 0.]] b_f = [ 1.18250883]
W_c max, min, mean, abs_mean: 0.532832 -0.564184 -0.117381 0.446382
W_f max, min, mean, abs_mean: 0.454095 -0.453169 -0.0653742 0.280749
Epoch 2/500
56s - loss: 1358.0590 - val_loss: 9227.9136
Epoch 00001: val_loss did not improve
Epoch 3/500
55s - loss: 1214.7172 - val_loss: 9403.9270
Epoch 00002: val_loss did not improve
Epoch 4/500
56s - loss: 1128.6443 - val_loss: 9303.1162
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1070.1258 - val_loss: 9572.6108
Epoch 00004: val_loss did not improve
Epoch 6/500
56s - loss: 1026.7647 - val_loss: 9809.5656
Epoch 00005: val_loss did not improve
Epoch 7/500
56s - loss: 989.3646 - val_loss: 9669.7242
Epoch 00006: val_loss did not improve
Epoch 8/500
56s - loss: 959.9658 - val_loss: 9543.9460
Epoch 00007: val_loss did not improve
Epoch 9/500
54s - loss: 934.9659 - val_loss: 9542.9310
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 913.8836 - val_loss: 9299.7826
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 894.3956 - val_loss: 9538.6753
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 877.5016 - val_loss: 9439.9073
Epoch 00011: val_loss did not improve
Epoch 13/500
55s - loss: 862.0807 - val_loss: 9316.3659
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 848.0221 - val_loss: 9022.0349
Epoch 00013: val_loss improved from 9192.42475 to 9022.03494, saving model to huabei_lstm30x2+dropout7_weights.hdf5
huabei_lstm30x2+dropout7   795.8      0.82  0.23  0.66      0.81  0.13  0.72      0.82  0.09  0.75
forget mean min: 0.889648 0.298026
delta_x = 8.70028
delta_h = 3.17576
delta mean, abs_mean, abs_mean+, abs_mean-: 1.40515 8.70028 9.51288 7.77974
U_c = [[-0.09862539]] U_f = [[ 0.]] b_f = [ 1.30718338]
W_c max, min, mean, abs_mean: 2.88254 -3.81341 -0.410251 1.67947
W_f max, min, mean, abs_mean: 1.10583 -1.14256 -0.0809948 0.376843
huabei_lstm30x2+dropout7  9022.0      0.75  0.21  0.62      0.76  0.14  0.68      0.79  0.10  0.73
forget mean min: 0.907537 0.448314
delta_x = 7.06632
delta_h = 3.6853
delta mean, abs_mean, abs_mean+, abs_mean-: 0.837629 7.06632 7.39161 6.69258
U_c = [[-0.09862539]] U_f = [[ 0.]] b_f = [ 1.30718338]
W_c max, min, mean, abs_mean: 2.88254 -3.81341 -0.410251 1.67947
W_f max, min, mean, abs_mean: 1.10583 -1.14256 -0.0809948 0.376843
Epoch 15/500
55s - loss: 836.2488 - val_loss: 9024.9375
Epoch 00014: val_loss did not improve
Epoch 16/500
54s - loss: 824.0106 - val_loss: 9295.6515
Epoch 00015: val_loss did not improve
Epoch 17/500
55s - loss: 814.7103 - val_loss: 9282.0835
Epoch 00016: val_loss did not improve
Epoch 18/500
55s - loss: 802.7515 - val_loss: 9330.3669
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 795.1446 - val_loss: 9053.6591
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 786.6217 - val_loss: 9097.8814
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 780.1074 - val_loss: 9420.9901
Epoch 00020: val_loss did not improve
Epoch 22/500
54s - loss: 772.6736 - val_loss: 9192.1013
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 765.4997 - val_loss: 9238.6986
Epoch 00022: val_loss did not improve
Epoch 24/500
54s - loss: 758.9995 - val_loss: 9210.1388
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 752.4309 - val_loss: 9061.8565
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 748.0499 - val_loss: 9237.4673
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 742.6498 - val_loss: 9469.8226
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 736.8501 - val_loss: 9263.8843
Epoch 00027: val_loss did not improve
Epoch 29/500
54s - loss: 732.8978 - val_loss: 9482.8331
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 728.6806 - val_loss: 9079.3724
Epoch 00029: val_loss did not improve
Epoch 31/500
55s - loss: 723.6752 - val_loss: 9160.5243
Epoch 00030: val_loss did not improve
Epoch 32/500
55s - loss: 719.6247 - val_loss: 9385.5568
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 715.9007 - val_loss: 9430.1244
Epoch 00032: val_loss did not improve
Epoch 34/500
55s - loss: 711.7733 - val_loss: 9183.4409
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 709.9334 - val_loss: 9023.8100
Epoch 00034: val_loss did not improve
Epoch 36/500
55s - loss: 705.9135 - val_loss: 9332.8289
Epoch 00035: val_loss did not improve
Epoch 37/500
54s - loss: 702.7450 - val_loss: 9359.1244
Epoch 00036: val_loss did not improve
Epoch 38/500
54s - loss: 699.9981 - val_loss: 9168.5033
Epoch 00037: val_loss did not improve
Epoch 39/500
55s - loss: 695.7705 - val_loss: 9341.5146
Epoch 00038: val_loss did not improve
Epoch 40/500
55s - loss: 694.5047 - val_loss: 9343.5414
Epoch 00039: val_loss did not improve
Epoch 41/500
55s - loss: 690.7625 - val_loss: 9228.4299
Epoch 00040: val_loss did not improve
Epoch 42/500
55s - loss: 688.4455 - val_loss: 9453.7085
Epoch 00041: val_loss did not improve
Epoch 43/500
54s - loss: 687.3453 - val_loss: 9297.3281
Epoch 00042: val_loss did not improve
Epoch 44/500
55s - loss: 684.1236 - val_loss: 9302.1659
Epoch 00043: val_loss did not improve
Epoch 45/500
55s - loss: 681.6884 - val_loss: 9472.7458
Epoch 00044: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout8
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout8  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout8 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 1996.3971 - val_loss: 9705.6125
Epoch 00000: val_loss improved from inf to 9705.61245, saving model to huabei_lstm30x2+dropout8_weights.hdf5
huabei_lstm30x2+dropout8  1458.3      0.74  0.33  0.54      0.71  0.19  0.61      0.72  0.12  0.65
forget mean min: 0.944348 0.649438
delta_x = 4.14145
delta_h = 1.94407
delta mean, abs_mean, abs_mean+, abs_mean-: 0.949113 4.14145 3.82645 4.76727
U_c = [[-0.06945419]] U_f = [[ 0.]] b_f = [ 1.16592371]
W_c max, min, mean, abs_mean: 0.549003 -0.441568 0.0127116 0.428483
W_f max, min, mean, abs_mean: 0.492879 -0.386001 0.0178715 0.280703
huabei_lstm30x2+dropout8  9705.6      0.85  0.25  0.66      0.84  0.16  0.72      0.84  0.11  0.76
forget mean min: 0.954141 0.682319
delta_x = 4.31474
delta_h = 2.70572
delta mean, abs_mean, abs_mean+, abs_mean-: 0.960404 4.31474 3.91943 5.12813
U_c = [[-0.06945419]] U_f = [[ 0.]] b_f = [ 1.16592371]
W_c max, min, mean, abs_mean: 0.549003 -0.441568 0.0127116 0.428483
W_f max, min, mean, abs_mean: 0.492879 -0.386001 0.0178715 0.280703
Epoch 2/500
55s - loss: 1361.4010 - val_loss: 9407.5655
Epoch 00001: val_loss improved from 9705.61245 to 9407.56545, saving model to huabei_lstm30x2+dropout8_weights.hdf5
huabei_lstm30x2+dropout8  1247.3      0.77  0.30  0.58      0.74  0.17  0.64      0.74  0.11  0.67
forget mean min: 0.930928 0.573771
delta_x = 4.70528
delta_h = 2.01262
delta mean, abs_mean, abs_mean+, abs_mean-: 0.989913 4.70528 4.60945 4.86015
U_c = [[-0.06867012]] U_f = [[ 0.]] b_f = [ 1.16791236]
W_c max, min, mean, abs_mean: 1.02354 -0.693744 0.0325366 0.647069
W_f max, min, mean, abs_mean: 0.574405 -0.457798 0.0236696 0.295389
huabei_lstm30x2+dropout8  9407.6      0.84  0.24  0.66      0.83  0.16  0.71      0.83  0.11  0.75
forget mean min: 0.944168 0.634439
delta_x = 4.46242
delta_h = 2.61501
delta mean, abs_mean, abs_mean+, abs_mean-: 0.806555 4.46242 4.44738 4.48427
U_c = [[-0.06867012]] U_f = [[ 0.]] b_f = [ 1.16791236]
W_c max, min, mean, abs_mean: 1.02354 -0.693744 0.0325366 0.647069
W_f max, min, mean, abs_mean: 0.574405 -0.457798 0.0236696 0.295389
Epoch 3/500
55s - loss: 1225.0376 - val_loss: 9323.6795
Epoch 00002: val_loss improved from 9407.56545 to 9323.67954, saving model to huabei_lstm30x2+dropout8_weights.hdf5
huabei_lstm30x2+dropout8  1133.9      0.71  0.23  0.58      0.67  0.12  0.61      0.67  0.08  0.64
forget mean min: 0.916108 0.491347
delta_x = 4.84308
delta_h = 1.90176
delta mean, abs_mean, abs_mean+, abs_mean-: 0.462665 4.84308 4.8029 4.89265
U_c = [[-0.07238139]] U_f = [[ 0.]] b_f = [ 1.17658234]
W_c max, min, mean, abs_mean: 1.3853 -0.902525 0.0497073 0.800048
W_f max, min, mean, abs_mean: 0.542329 -0.444726 0.0291109 0.299888
huabei_lstm30x2+dropout8  9323.7      0.80  0.23  0.64      0.79  0.15  0.69      0.80  0.10  0.73
forget mean min: 0.934675 0.627242
delta_x = 4.39534
delta_h = 2.51936
delta mean, abs_mean, abs_mean+, abs_mean-: 0.425121 4.39534 4.40567 4.38285
U_c = [[-0.07238139]] U_f = [[ 0.]] b_f = [ 1.17658234]
W_c max, min, mean, abs_mean: 1.3853 -0.902525 0.0497073 0.800048
W_f max, min, mean, abs_mean: 0.542329 -0.444726 0.0291109 0.299888
Epoch 4/500
55s - loss: 1142.9421 - val_loss: 8297.1098
Epoch 00003: val_loss improved from 9323.67954 to 8297.10981, saving model to huabei_lstm30x2+dropout8_weights.hdf5
huabei_lstm30x2+dropout8  1132.2      0.81  0.29  0.60      0.77  0.16  0.67      0.78  0.11  0.71
forget mean min: 0.918772 0.454319
delta_x = 5.89036
delta_h = 2.356
delta mean, abs_mean, abs_mean+, abs_mean-: 1.29969 5.89036 6.05088 5.65537
U_c = [[-0.07258222]] U_f = [[ 0.]] b_f = [ 1.18532896]
W_c max, min, mean, abs_mean: 1.70708 -1.07225 0.0655814 0.926039
W_f max, min, mean, abs_mean: 0.493763 -0.508217 0.0298489 0.304408
huabei_lstm30x2+dropout8  8297.1      0.86  0.24  0.67      0.85  0.16  0.73      0.85  0.11  0.76
forget mean min: 0.937181 0.634436
delta_x = 5.15202
delta_h = 3.12886
delta mean, abs_mean, abs_mean+, abs_mean-: 1.46054 5.15202 5.42492 4.72613
U_c = [[-0.07258222]] U_f = [[ 0.]] b_f = [ 1.18532896]
W_c max, min, mean, abs_mean: 1.70708 -1.07225 0.0655814 0.926039
W_f max, min, mean, abs_mean: 0.493763 -0.508217 0.0298489 0.304408
Epoch 5/500
56s - loss: 1083.3821 - val_loss: 8377.7801
Epoch 00004: val_loss did not improve
Epoch 6/500
56s - loss: 1037.2536 - val_loss: 8720.3326
Epoch 00005: val_loss did not improve
Epoch 7/500
56s - loss: 998.8972 - val_loss: 8477.1352
Epoch 00006: val_loss did not improve
Epoch 8/500
55s - loss: 968.4741 - val_loss: 8899.1232
Epoch 00007: val_loss did not improve
Epoch 9/500
54s - loss: 942.3956 - val_loss: 8909.5278
Epoch 00008: val_loss did not improve
Epoch 10/500
54s - loss: 919.5230 - val_loss: 8839.9020
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 899.2286 - val_loss: 9486.6158
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 881.1874 - val_loss: 8931.5435
Epoch 00011: val_loss did not improve
Epoch 13/500
55s - loss: 864.7321 - val_loss: 9230.2231
Epoch 00012: val_loss did not improve
Epoch 14/500
55s - loss: 850.7567 - val_loss: 9548.1936
Epoch 00013: val_loss did not improve
Epoch 15/500
55s - loss: 837.2336 - val_loss: 8962.9663
Epoch 00014: val_loss did not improve
Epoch 16/500
54s - loss: 826.5755 - val_loss: 9184.5680
Epoch 00015: val_loss did not improve
Epoch 17/500
54s - loss: 813.5225 - val_loss: 9362.7070
Epoch 00016: val_loss did not improve
Epoch 18/500
54s - loss: 805.8995 - val_loss: 9332.0625
Epoch 00017: val_loss did not improve
Epoch 19/500
55s - loss: 796.2179 - val_loss: 9121.5052
Epoch 00018: val_loss did not improve
Epoch 20/500
55s - loss: 788.0077 - val_loss: 9228.2945
Epoch 00019: val_loss did not improve
Epoch 21/500
55s - loss: 780.3545 - val_loss: 9217.6142
Epoch 00020: val_loss did not improve
Epoch 22/500
55s - loss: 772.6652 - val_loss: 9397.7255
Epoch 00021: val_loss did not improve
Epoch 23/500
55s - loss: 766.2525 - val_loss: 9287.6697
Epoch 00022: val_loss did not improve
Epoch 24/500
54s - loss: 760.3030 - val_loss: 9596.2800
Epoch 00023: val_loss did not improve
Epoch 25/500
55s - loss: 754.7733 - val_loss: 9519.9238
Epoch 00024: val_loss did not improve
Epoch 26/500
55s - loss: 748.2258 - val_loss: 9524.5999
Epoch 00025: val_loss did not improve
Epoch 27/500
55s - loss: 742.4551 - val_loss: 9667.2141
Epoch 00026: val_loss did not improve
Epoch 28/500
55s - loss: 737.5549 - val_loss: 9634.2235
Epoch 00027: val_loss did not improve
Epoch 29/500
55s - loss: 732.7875 - val_loss: 9412.8709
Epoch 00028: val_loss did not improve
Epoch 30/500
55s - loss: 728.5829 - val_loss: 9570.6172
Epoch 00029: val_loss did not improve
Epoch 31/500
54s - loss: 723.9283 - val_loss: 9432.3233
Epoch 00030: val_loss did not improve
Epoch 32/500
54s - loss: 719.9835 - val_loss: 9705.5485
Epoch 00031: val_loss did not improve
Epoch 33/500
55s - loss: 716.3937 - val_loss: 9570.4099
Epoch 00032: val_loss did not improve
Epoch 34/500
55s - loss: 711.6245 - val_loss: 9573.6439
Epoch 00033: val_loss did not improve
Epoch 35/500
55s - loss: 708.6311 - val_loss: 9959.0116
Epoch 00034: val_loss did not improve
X_train[0].shape = (98420, 40, 17)

training huabei_lstm30x2+dropout9
Train on 98420 samples, validate on 11655 samples
Before training:
huabei_lstm30x2+dropout9  6184.9      0.02  -nan  0.02      0.04  -nan  0.04      0.06  -nan  0.06
forget mean min: 0.731057 0.731059
delta_x = 3.94437
delta_h = 2.50113
delta mean, abs_mean, abs_mean+, abs_mean-: -3.94437 3.94437 nan 3.94437
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
huabei_lstm30x2+dropout9 24783.3      0.04  -nan  0.04      0.06  -nan  0.06      0.11  -nan  0.11
forget mean min: 0.731059 0.731059
delta_x = 6.03627
delta_h = 3.45949
delta mean, abs_mean, abs_mean+, abs_mean-: -6.03627 6.03627 nan 6.03627
U_c = [[-0.05]] U_f = [[ 0.]] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/500
54s - loss: 1976.0210 - val_loss: 9824.4921
Epoch 00000: val_loss improved from inf to 9824.49211, saving model to huabei_lstm30x2+dropout9_weights.hdf5
huabei_lstm30x2+dropout9  1439.5      0.74  0.33  0.54      0.72  0.19  0.61      0.72  0.12  0.66
forget mean min: 0.943965 0.660085
delta_x = 4.16802
delta_h = 1.94655
delta mean, abs_mean, abs_mean+, abs_mean-: 0.981639 4.16802 3.9125 4.65984
U_c = [[-0.06939408]] U_f = [[ 0.]] b_f = [ 1.18209434]
W_c max, min, mean, abs_mean: 0.556492 -0.554035 0.00457218 0.434815
W_f max, min, mean, abs_mean: 0.414394 -0.432714 0.00174408 0.27298
huabei_lstm30x2+dropout9  9824.5      0.85  0.24  0.66      0.84  0.16  0.72      0.84  0.11  0.76
forget mean min: 0.951997 0.691398
delta_x = 4.83264
delta_h = 2.78586
delta mean, abs_mean, abs_mean+, abs_mean-: 0.977858 4.83264 4.3633 5.76781
U_c = [[-0.06939408]] U_f = [[ 0.]] b_f = [ 1.18209434]
W_c max, min, mean, abs_mean: 0.556492 -0.554035 0.00457218 0.434815
W_f max, min, mean, abs_mean: 0.414394 -0.432714 0.00174408 0.27298
Epoch 2/500
56s - loss: 1364.0458 - val_loss: 9277.0555
Epoch 00001: val_loss improved from 9824.49211 to 9277.05546, saving model to huabei_lstm30x2+dropout9_weights.hdf5
huabei_lstm30x2+dropout9  1232.2      0.74  0.29  0.57      0.71  0.16  0.63      0.72  0.10  0.66
forget mean min: 0.928804 0.590742
delta_x = 4.57601
delta_h = 1.85676
delta mean, abs_mean, abs_mean+, abs_mean-: 0.74808 4.57601 4.42705 4.80066
U_c = [[-0.0651373]] U_f = [[ 0.]] b_f = [ 1.17420423]
W_c max, min, mean, abs_mean: 0.92706 -0.93716 0.0104326 0.621861
W_f max, min, mean, abs_mean: 0.591853 -0.512165 0.00381552 0.295155
huabei_lstm30x2+dropout9  9277.0      0.80  0.22  0.65      0.79  0.14  0.70      0.80  0.10  0.73
forget mean min: 0.938939 0.648075
delta_x = 4.7421
delta_h = 2.54873
delta mean, abs_mean, abs_mean+, abs_mean-: 0.487317 4.7421 4.56188 4.98409
U_c = [[-0.0651373]] U_f = [[ 0.]] b_f = [ 1.17420423]
W_c max, min, mean, abs_mean: 0.92706 -0.93716 0.0104326 0.621861
W_f max, min, mean, abs_mean: 0.591853 -0.512165 0.00381552 0.295155
Epoch 3/500
56s - loss: 1230.1177 - val_loss: 8987.7845
Epoch 00002: val_loss improved from 9277.05546 to 8987.78452, saving model to huabei_lstm30x2+dropout9_weights.hdf5
huabei_lstm30x2+dropout9  1134.0      0.70  0.24  0.58      0.66  0.12  0.61      0.67  0.08  0.63
forget mean min: 0.916436 0.54249
delta_x = 4.67851
delta_h = 1.90438
delta mean, abs_mean, abs_mean+, abs_mean-: 0.442946 4.67851 4.54934 4.84483
U_c = [[-0.07190027]] U_f = [[ 0.]] b_f = [ 1.17472506]
W_c max, min, mean, abs_mean: 1.21667 -1.24494 0.0142707 0.769043
W_f max, min, mean, abs_mean: 0.70963 -0.644931 0.0055096 0.3094
huabei_lstm30x2+dropout9  8987.8      0.79  0.21  0.65      0.78  0.14  0.69      0.79  0.09  0.73
forget mean min: 0.932672 0.639666
delta_x = 4.69239
delta_h = 2.76332
delta mean, abs_mean, abs_mean+, abs_mean-: 0.512809 4.69239 4.54958 4.8833
U_c = [[-0.07190027]] U_f = [[ 0.]] b_f = [ 1.17472506]
W_c max, min, mean, abs_mean: 1.21667 -1.24494 0.0142707 0.769043
W_f max, min, mean, abs_mean: 0.70963 -0.644931 0.0055096 0.3094
Epoch 4/500
56s - loss: 1146.1244 - val_loss: 9001.3875
Epoch 00003: val_loss did not improve
Epoch 5/500
56s - loss: 1086.8313 - val_loss: 8658.3163
Epoch 00004: val_loss improved from 8987.78452 to 8658.31634, saving model to huabei_lstm30x2+dropout9_weights.hdf5
huabei_lstm30x2+dropout9  1020.2      0.80  0.27  0.62      0.77  0.15  0.68      0.77  0.10  0.71
forget mean min: 0.915169 0.474367
delta_x = 5.75583
delta_h = 2.40499
delta mean, abs_mean, abs_mean+, abs_mean-: 1.18565 5.75583 5.86518 5.59733
U_c = [[-0.07890984]] U_f = [[ 0.]] b_f = [ 1.18551862]
W_c max, min, mean, abs_mean: 1.61899 -1.7776 0.01822 0.99258
W_f max, min, mean, abs_mean: 0.929037 -0.842446 0.00691115 0.328008
huabei_lstm30x2+dropout9  8658.3      0.83  0.22  0.67      0.82  0.14  0.72      0.83  0.10  0.76
forget mean min: 0.930785 0.627423
delta_x = 5.63234
delta_h = 3.51228
delta mean, abs_mean, abs_mean+, abs_mean-: 1.44388 5.63234 5.771 5.41263
U_c = [[-0.07890984]] U_f = [[ 0.]] b_f = [ 1.18551862]
W_c max, min, mean, abs_mean: 1.61899 -1.7776 0.01822 0.99258
W_f max, min, mean, abs_mean: 0.929037 -0.842446 0.00691115 0.328008
Epoch 6/500
55s - loss: 1042.0052 - val_loss: 8713.1173
Epoch 00005: val_loss did not improve
Epoch 7/500
55s - loss: 1007.7745 - val_loss: 8986.6660
Epoch 00006: val_loss did not improve
Epoch 8/500
55s - loss: 976.4406 - val_loss: 8971.4503
Epoch 00007: val_loss did not improve
Epoch 9/500
56s - loss: 950.2234 - val_loss: 9329.3520
Epoch 00008: val_loss did not improve
Epoch 10/500
55s - loss: 928.2394 - val_loss: 9136.9254
Epoch 00009: val_loss did not improve
Epoch 11/500
55s - loss: 909.4044 - val_loss: 9194.2838
Epoch 00010: val_loss did not improve
Epoch 12/500
55s - loss: 891.2376 - val_loss: 9330.4636
Epoch 00011: val_loss did not improve
Epoch 13/500
55s - loss: 874.3078 - val_loss: 9398.4188
Epoch 00012: val_loss did not improve
Epoch 14/500
54s - loss: 860.5956 - val_loss: 9555.8163
Epoch 00013: val_loss did not improve
Epoch 15/500
54s - loss: 847.0588 - val_loss: 9536.2773
Epoch 00014: val_loss did not improve
Epoch 16/500
54s - loss: 834.3171 - val_loss: 9711.8858
Epoch 00015: val_loss did not improve
Epoch 17/500
54s - loss: 823.0391 - val_loss: 9656.4977
Epoch 00016: val_loss did not improve
Epoch 18/500
54s - loss: 813.5705 - val_loss: 9725.7757
Epoch 00017: val_loss did not improve
Epoch 19/500
54s - loss: 804.7120 - val_loss: 9795.1586
Epoch 00018: val_loss did not improve
Epoch 20/500
54s - loss: 795.4625 - val_loss: 9796.7612
Epoch 00019: val_loss did not improve
Epoch 21/500
54s - loss: 787.3439 - val_loss: 9806.8686
Epoch 00020: val_loss did not improve
Epoch 22/500
54s - loss: 778.9178 - val_loss: 9979.4135
Epoch 00021: val_loss did not improve
Epoch 23/500
54s - loss: 771.2013 - val_loss: 9865.6755
Epoch 00022: val_loss did not improve
Epoch 24/500
54s - loss: 765.4952 - val_loss: 10025.5818
Epoch 00023: val_loss did not improve
Epoch 25/500
54s - loss: 758.3028 - val_loss: 9987.0586
Epoch 00024: val_loss did not improve
Epoch 26/500
54s - loss: 753.0887 - val_loss: 9988.1804
Epoch 00025: val_loss did not improve
Epoch 27/500
54s - loss: 747.1901 - val_loss: 10085.2301
Epoch 00026: val_loss did not improve
Epoch 28/500
54s - loss: 742.7020 - val_loss: 10037.1334
Epoch 00027: val_loss did not improve
Epoch 29/500
54s - loss: 736.7877 - val_loss: 10118.4029
Epoch 00028: val_loss did not improve
Epoch 30/500
54s - loss: 732.3191 - val_loss: 9929.5351
Epoch 00029: val_loss did not improve
Epoch 31/500
54s - loss: 728.7914 - val_loss: 9730.2507
Epoch 00030: val_loss did not improve
Epoch 32/500
54s - loss: 723.6186 - val_loss: 9880.1386
Epoch 00031: val_loss did not improve
Epoch 33/500
54s - loss: 719.9772 - val_loss: 9781.2022
Epoch 00032: val_loss did not improve
Epoch 34/500
54s - loss: 716.1943 - val_loss: 10052.4213
Epoch 00033: val_loss did not improve
Epoch 35/500
54s - loss: 712.8452 - val_loss: 9891.6414
Epoch 00034: val_loss did not improve
Epoch 36/500
54s - loss: 708.8205 - val_loss: 9654.6327
Epoch 00035: val_loss did not improve
huabei_lstm20x2+dropout0   821.6      0.82  0.23  0.66      0.80  0.13  0.71      0.80  0.09  0.74
forget mean min: 0.891307 0.24842
huabei_lstm20x2+dropout0  8922.5      0.72  0.23  0.60      0.75  0.16  0.65      0.78  0.11  0.71
forget mean min: 0.91104 0.555182
huabei_lstm20x2+dropout1  1069.7      0.80  0.29  0.61      0.78  0.16  0.68      0.78  0.11  0.71
forget mean min: 0.913084 0.564953
huabei_lstm20x2+dropout1  8173.3      0.83  0.23  0.67      0.82  0.15  0.72      0.83  0.11  0.75
forget mean min: 0.930451 0.671353
huabei_lstm20x2+dropout2   843.9      0.83  0.25  0.65      0.81  0.14  0.71      0.82  0.10  0.75
forget mean min: 0.899401 0.25412
huabei_lstm20x2+dropout2  8211.4      0.79  0.24  0.63      0.79  0.16  0.68      0.81  0.11  0.73
forget mean min: 0.924722 0.518975
huabei_lstm20x2+dropout3  1002.1      0.80  0.27  0.62      0.77  0.16  0.68      0.77  0.11  0.71
forget mean min: 0.904532 0.414082
huabei_lstm20x2+dropout3  8414.0      0.83  0.24  0.66      0.82  0.17  0.70      0.83  0.12  0.74
forget mean min: 0.926778 0.608475
huabei_lstm20x2+dropout4   865.7      0.81  0.24  0.64      0.79  0.14  0.70      0.80  0.10  0.74
forget mean min: 0.898425 0.411572
huabei_lstm20x2+dropout4  8436.8      0.82  0.22  0.67      0.80  0.15  0.70      0.81  0.11  0.74
forget mean min: 0.922221 0.618963
huabei_lstm20x2+dropout5  1081.7      0.79  0.28  0.61      0.77  0.16  0.67      0.77  0.11  0.70
forget mean min: 0.915427 0.41985
huabei_lstm20x2+dropout5  8317.3      0.82  0.25  0.64      0.81  0.17  0.69      0.82  0.12  0.74
forget mean min: 0.93742 0.61555
huabei_lstm20x2+dropout6   828.6      0.81  0.23  0.66      0.79  0.13  0.71      0.79  0.08  0.74
forget mean min: 0.893786 0.208003
huabei_lstm20x2+dropout6  7871.5      0.80  0.21  0.66      0.80  0.14  0.70      0.81  0.10  0.74
forget mean min: 0.920117 0.571027
huabei_lstm20x2+dropout7  1321.9      0.79  0.33  0.57      0.76  0.19  0.64      0.76  0.13  0.69
forget mean min: 0.932696 0.620351
huabei_lstm20x2+dropout7  9043.5      0.82  0.23  0.65      0.81  0.15  0.70      0.82  0.10  0.74
forget mean min: 0.942164 0.655271
huabei_lstm20x2+dropout8   999.9      0.82  0.28  0.62      0.80  0.16  0.69      0.80  0.11  0.73
forget mean min: 0.912883 0.420347
huabei_lstm20x2+dropout8  8467.5      0.82  0.25  0.64      0.82  0.16  0.70      0.83  0.12  0.74
forget mean min: 0.935548 0.615528
huabei_lstm20x2+dropout9  1080.7      0.81  0.29  0.60      0.78  0.17  0.67      0.78  0.12  0.71
forget mean min: 0.917583 0.489106
huabei_lstm20x2+dropout9  8136.3      0.81  0.21  0.66      0.80  0.14  0.71      0.81  0.10  0.75
forget mean min: 0.931218 0.636158
huabei_lstm30x2+dropout0   856.0      0.82  0.24  0.65      0.80  0.14  0.71      0.80  0.10  0.74
forget mean min: 0.889013 0.376383
huabei_lstm30x2+dropout0  8615.8      0.81  0.25  0.64      0.82  0.17  0.69      0.83  0.12  0.74
forget mean min: 0.919748 0.615655
huabei_lstm30x2+dropout1  1278.7      0.78  0.31  0.57      0.75  0.18  0.65      0.75  0.12  0.68
forget mean min: 0.93071 0.582869
huabei_lstm30x2+dropout1  8766.9      0.85  0.25  0.66      0.84  0.16  0.72      0.85  0.12  0.76
forget mean min: 0.941462 0.641342
huabei_lstm30x2+dropout2  1093.8      0.81  0.29  0.61      0.78  0.17  0.67      0.78  0.11  0.71
forget mean min: 0.919428 0.47829
huabei_lstm30x2+dropout2  8280.4      0.85  0.26  0.65      0.84  0.17  0.71      0.85  0.12  0.75
forget mean min: 0.942333 0.617339
huabei_lstm30x2+dropout3   942.6      0.82  0.26  0.63      0.80  0.15  0.70      0.81  0.11  0.73
forget mean min: 0.902095 0.459655
huabei_lstm30x2+dropout3  8507.4      0.80  0.24  0.64      0.80  0.16  0.69      0.81  0.11  0.74
forget mean min: 0.923663 0.599994
huabei_lstm30x2+dropout4   786.3      0.80  0.21  0.66      0.79  0.12  0.71      0.79  0.09  0.74
forget mean min: 0.881613 0.372996
huabei_lstm30x2+dropout4  8654.3      0.76  0.22  0.62      0.77  0.15  0.68      0.80  0.10  0.73
forget mean min: 0.904603 0.550981
huabei_lstm30x2+dropout5   906.0      0.79  0.24  0.64      0.76  0.13  0.69      0.77  0.09  0.71
forget mean min: 0.902684 0.400104
huabei_lstm30x2+dropout5  8826.1      0.80  0.25  0.62      0.80  0.18  0.68      0.81  0.12  0.73
forget mean min: 0.928682 0.621049
huabei_lstm30x2+dropout6  1185.3      0.81  0.32  0.59      0.78  0.19  0.66      0.79  0.13  0.71
forget mean min: 0.925388 0.577092
huabei_lstm30x2+dropout6  8600.3      0.83  0.23  0.66      0.82  0.15  0.71      0.82  0.11  0.75
forget mean min: 0.939046 0.662246
huabei_lstm30x2+dropout7   795.8      0.82  0.23  0.66      0.81  0.13  0.72      0.82  0.09  0.75
forget mean min: 0.889648 0.298026
huabei_lstm30x2+dropout7  9022.0      0.75  0.21  0.62      0.76  0.14  0.68      0.79  0.10  0.73
forget mean min: 0.907537 0.448314
huabei_lstm30x2+dropout8  1132.2      0.81  0.29  0.60      0.77  0.16  0.67      0.78  0.11  0.71
forget mean min: 0.918772 0.454319
huabei_lstm30x2+dropout8  8297.1      0.86  0.24  0.67      0.85  0.16  0.73      0.85  0.11  0.76
forget mean min: 0.937181 0.634436
huabei_lstm30x2+dropout9  1020.2      0.80  0.27  0.62      0.77  0.15  0.68      0.77  0.10  0.71
forget mean min: 0.915169 0.474367
huabei_lstm30x2+dropout9  8658.3      0.83  0.22  0.67      0.82  0.14  0.72      0.83  0.10  0.76
forget mean min: 0.930785 0.627423
