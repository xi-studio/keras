X_train[0].shape = (7656, 40, 23)

training beijing0
Train on 7656 samples, validate on 2040 samples
Before training:
            beijing014532.6243      0.04  -nan  0.04      0.04  -nan  0.04      0.03  -nan  0.03
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.12625 nan 5.12625
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            beijing025522.9680      0.06  -nan  0.05      0.06  -nan  0.06      0.06  -nan  0.06
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 9.18519 nan 9.18519
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 7933.9996 - val_loss: 10439.1853
Epoch 00000: val_loss improved from inf to 10439.18527, saving model to beijing0_weights.hdf5
            beijing0 3720.1752      0.87  0.26  0.66      0.87  0.24  0.68      0.86  0.23  0.69
            beijing010439.1852      0.78  0.20  0.65      0.78  0.17  0.68      0.79  0.15  0.70
forget mean min: 0.898375 0.786413
incx.max(), incx.min(), incx.mean() 12.0999 0.438574 3.69627
fgtx.max(), fgtx.min(), fgtx.mean() 8.99189 0.240568 2.68533
abs_mean, abs_mean+, abs_mean-: 10.3626 6.42402 13.7958
U_c = [[-0.08294744]] U_f = [[ 0.]] b_c = [ 0.11802678] b_f = [ 1.06287134]
W_c max, min, mean, abs_mean: 0.152428 0.148389 0.151455 0.151455
W_f max, min, mean, abs_mean: 0.114226 0.11139 0.113664 0.113664
Epoch 2/300
1s - loss: 2995.8869 - val_loss: 8711.6376
Epoch 00001: val_loss improved from 10439.18527 to 8711.63756, saving model to beijing0_weights.hdf5
            beijing0 2665.0591      0.90  0.21  0.72      0.91  0.19  0.75      0.91  0.18  0.76
            beijing0 8711.6375      0.83  0.21  0.68      0.84  0.19  0.70      0.85  0.20  0.70
forget mean min: 0.891703 0.736533
incx.max(), incx.min(), incx.mean() 19.4351 0.250838 6.17966
fgtx.max(), fgtx.min(), fgtx.mean() 10.8975 0.0611629 3.41009
abs_mean, abs_mean+, abs_mean-: 13.9127 10.1566 18.5447
U_c = [[-0.07051634]] U_f = [[ 0.]] b_c = [ 0.14255403] b_f = [ 0.96686053]
W_c max, min, mean, abs_mean: 0.187266 0.183255 0.186305 0.186305
W_f max, min, mean, abs_mean: 0.105881 0.102222 0.105235 0.105235
Epoch 3/300
1s - loss: 2630.2619 - val_loss: 8435.6385
Epoch 00002: val_loss improved from 8711.63756 to 8435.63853, saving model to beijing0_weights.hdf5
            beijing0 2571.7261      0.90  0.21  0.73      0.91  0.19  0.75      0.91  0.17  0.77
            beijing0 8435.6384      0.83  0.19  0.69      0.83  0.17  0.71      0.84  0.18  0.71
forget mean min: 0.886198 0.707594
incx.max(), incx.min(), incx.mean() 19.6318 0.143919 6.1646
fgtx.max(), fgtx.min(), fgtx.mean() 13.8509 0.0 4.27916
abs_mean, abs_mean+, abs_mean-: 14.3435 10.1304 19.9015
U_c = [[-0.06666119]] U_f = [[ 0.]] b_c = [ 0.14391868] b_f = [ 0.88372862]
W_c max, min, mean, abs_mean: 0.189361 0.185365 0.188404 0.188404
W_f max, min, mean, abs_mean: 0.134557 0.130529 0.133908 0.133908
Epoch 4/300
1s - loss: 2564.0581 - val_loss: 8359.7065
Epoch 00003: val_loss improved from 8435.63853 to 8359.70654, saving model to beijing0_weights.hdf5
            beijing0 2527.3094      0.91  0.22  0.73      0.92  0.20  0.75      0.92  0.18  0.76
            beijing0 8359.7064      0.83  0.19  0.70      0.83  0.16  0.72      0.84  0.17  0.72
forget mean min: 0.885304 0.691451
incx.max(), incx.min(), incx.mean() 19.9156 0.144162 6.23721
fgtx.max(), fgtx.min(), fgtx.mean() 16.2661 0.00132322 5.0137
abs_mean, abs_mean+, abs_mean-: 14.477 10.1699 20.3994
U_c = [[-0.06204975]] U_f = [[ 0.]] b_c = [ 0.14255419] b_f = [ 0.80559033]
W_c max, min, mean, abs_mean: 0.192085 0.188072 0.191095 0.191095
W_f max, min, mean, abs_mean: 0.157897 0.153781 0.157204 0.157204
Epoch 5/300
1s - loss: 2503.4066 - val_loss: 8279.2733
Epoch 00004: val_loss improved from 8359.70654 to 8279.27333, saving model to beijing0_weights.hdf5
            beijing0 2456.3119      0.91  0.21  0.73      0.91  0.19  0.75      0.92  0.17  0.77
            beijing0 8279.2732      0.83  0.19  0.70      0.83  0.16  0.72      0.84  0.17  0.72
forget mean min: 0.885993 0.672067
incx.max(), incx.min(), incx.mean() 19.725 0.137518 6.22264
fgtx.max(), fgtx.min(), fgtx.mean() 18.2328 0.0 5.66425
abs_mean, abs_mean+, abs_mean-: 14.4063 9.99718 20.7137
U_c = [[-0.05938251]] U_f = [[ 0.]] b_c = [ 0.13751808] b_f = [ 0.71754777]
W_c max, min, mean, abs_mean: 0.193216 0.189185 0.192193 0.192193
W_f max, min, mean, abs_mean: 0.179785 0.175425 0.178902 0.178902
Epoch 6/300
1s - loss: 2445.5842 - val_loss: 8207.9286
Epoch 00005: val_loss improved from 8279.27333 to 8207.92857, saving model to beijing0_weights.hdf5
            beijing0 2400.9565      0.91  0.21  0.73      0.92  0.19  0.75      0.93  0.17  0.77
            beijing0 8207.9286      0.84  0.19  0.70      0.84  0.16  0.73      0.85  0.17  0.72
forget mean min: 0.886948 0.652914
incx.max(), incx.min(), incx.mean() 20.0301 0.134414 6.33244
fgtx.max(), fgtx.min(), fgtx.mean() 21.1963 0.0 6.60318
abs_mean, abs_mean+, abs_mean-: 14.4947 10.0502 21.1171
U_c = [[-0.05665717]] U_f = [[ 0.]] b_c = [ 0.13441356] b_f = [ 0.63187063]
W_c max, min, mean, abs_mean: 0.196132 0.192047 0.195031 0.195031
W_f max, min, mean, abs_mean: 0.208926 0.204267 0.207783 0.207783
Epoch 7/300
1s - loss: 2393.1498 - val_loss: 8352.2599
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 2340.6090 - val_loss: 8407.0389
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 2283.5448 - val_loss: 8434.7619
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 2180.1611 - val_loss: 8773.7847
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 2107.5402 - val_loss: 8907.7503
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 2065.9277 - val_loss: 9234.0535
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 2025.7964 - val_loss: 9400.2329
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 2001.9492 - val_loss: 9673.3305
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1980.8777 - val_loss: 9718.1862
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1963.9578 - val_loss: 9873.0615
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1943.8074 - val_loss: 9977.7907
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1935.5820 - val_loss: 10227.9695
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1911.3633 - val_loss: 10251.8295
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1878.8286 - val_loss: 10263.7520
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1863.8958 - val_loss: 10506.2147
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1847.5932 - val_loss: 10506.8533
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1834.9386 - val_loss: 10511.7884
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1819.0623 - val_loss: 10707.6166
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1814.9359 - val_loss: 10936.1056
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 1798.4183 - val_loss: 10926.3779
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 1785.1515 - val_loss: 11033.8913
Epoch 00026: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training tianjin0
Train on 6380 samples, validate on 1700 samples
Before training:
            tianjin0 8451.1172      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.19338 nan 4.19338
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            tianjin025941.3774      0.05  -nan  0.05      0.06  -nan  0.06      0.06  -nan  0.06
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.52006 nan 8.52006
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 5058.6635 - val_loss: 8771.6114
Epoch 00000: val_loss improved from inf to 8771.61135, saving model to tianjin0_weights.hdf5
            tianjin0 2175.7241      0.69  0.22  0.58      0.71  0.17  0.62      0.71  0.14  0.64
            tianjin0 8771.6115      0.84  0.14  0.74      0.84  0.12  0.76      0.85  0.09  0.79
forget mean min: 0.918199 0.796276
incx.max(), incx.min(), incx.mean() 7.63414 0.414407 2.86427
fgtx.max(), fgtx.min(), fgtx.mean() 6.61312 0.27167 2.4235
abs_mean, abs_mean+, abs_mean-: 7.97825 4.02284 11.565
U_c = [[-0.09419163]] U_f = [[ 0.]] b_c = [ 0.10513052] b_f = [ 1.09151244]
W_c max, min, mean, abs_mean: 0.136559 0.125187 0.13528 0.13528
W_f max, min, mean, abs_mean: 0.120144 0.109547 0.118828 0.118828
Epoch 2/300
1s - loss: 1908.2230 - val_loss: 7169.2292
Epoch 00001: val_loss improved from 8771.61135 to 7169.22917, saving model to tianjin0_weights.hdf5
            tianjin0 1811.8529      0.84  0.25  0.66      0.87  0.21  0.71      0.88  0.17  0.75
            tianjin0 7169.2293      0.90  0.17  0.76      0.90  0.15  0.78      0.92  0.12  0.82
forget mean min: 0.921197 0.767697
incx.max(), incx.min(), incx.mean() 12.2515 0.367014 4.45426
fgtx.max(), fgtx.min(), fgtx.mean() 9.21852 0.172253 3.28338
abs_mean, abs_mean+, abs_mean-: 9.94294 6.28903 15.1863
U_c = [[-0.10069458]] U_f = [[ 0.]] b_c = [ 0.1407177] b_f = [ 1.02309811]
W_c max, min, mean, abs_mean: 0.161221 0.150127 0.159937 0.159937
W_f max, min, mean, abs_mean: 0.123008 0.11129 0.12173 0.12173
Epoch 3/300
1s - loss: 1784.9499 - val_loss: 7142.4699
Epoch 00002: val_loss improved from 7169.22917 to 7142.46988, saving model to tianjin0_weights.hdf5
            tianjin0 1746.5228      0.85  0.25  0.67      0.87  0.20  0.72      0.88  0.16  0.75
            tianjin0 7142.4698      0.88  0.15  0.76      0.89  0.13  0.78      0.91  0.09  0.83
forget mean min: 0.912175 0.723499
incx.max(), incx.min(), incx.mean() 12.9744 0.19088 4.38367
fgtx.max(), fgtx.min(), fgtx.mean() 11.9229 0.0230826 3.92601
abs_mean, abs_mean+, abs_mean-: 10.5286 6.3667 16.9389
U_c = [[-0.09764315]] U_f = [[ 0.]] b_c = [ 0.16608602] b_f = [ 0.93880427]
W_c max, min, mean, abs_mean: 0.161795 0.150676 0.160503 0.160503
W_f max, min, mean, abs_mean: 0.150892 0.139278 0.149407 0.149407
Epoch 4/300
1s - loss: 1728.9864 - val_loss: 7037.6300
Epoch 00003: val_loss improved from 7142.46988 to 7037.62998, saving model to tianjin0_weights.hdf5
            tianjin0 1707.7711      0.87  0.26  0.67      0.89  0.21  0.71      0.89  0.17  0.75
            tianjin0 7037.6299      0.88  0.15  0.76      0.88  0.13  0.78      0.91  0.09  0.83
forget mean min: 0.908171 0.701996
incx.max(), incx.min(), incx.mean() 14.0445 0.195572 4.63608
fgtx.max(), fgtx.min(), fgtx.mean() 14.0714 0.0 4.51184
abs_mean, abs_mean+, abs_mean-: 11.0447 6.82002 17.7572
U_c = [[-0.09436464]] U_f = [[ 0.]] b_c = [ 0.19557169] b_f = [ 0.85682219]
W_c max, min, mean, abs_mean: 0.169564 0.15841 0.168271 0.168271
W_f max, min, mean, abs_mean: 0.172603 0.161619 0.170983 0.170983
Epoch 5/300
1s - loss: 1684.5466 - val_loss: 7490.2658
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1644.5312 - val_loss: 7467.7402
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1607.1618 - val_loss: 7568.8547
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1565.8821 - val_loss: 7672.4595
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1520.2647 - val_loss: 8095.8161
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1464.1233 - val_loss: 8454.2987
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1407.1065 - val_loss: 8996.1669
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1359.8661 - val_loss: 9516.6216
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1318.2768 - val_loss: 9360.5808
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1287.4932 - val_loss: 9305.8286
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1263.4167 - val_loss: 9554.2973
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1242.3769 - val_loss: 9575.4756
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1224.0158 - val_loss: 9527.1084
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1204.9368 - val_loss: 9472.5255
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1194.3647 - val_loss: 9283.9085
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1179.6534 - val_loss: 9349.4301
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1161.8973 - val_loss: 9975.3925
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1154.3991 - val_loss: 9548.9098
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1141.9966 - val_loss: 9895.1074
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1129.5942 - val_loss: 9881.0309
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1118.6591 - val_loss: 9864.3159
Epoch 00024: val_loss did not improve
X_train[0].shape = (3828, 40, 23)

training tangshan0
Train on 3828 samples, validate on 1020 samples
Before training:
           tangshan010397.0685      0.03  -nan  0.03      0.03  -nan  0.03      0.01  -nan  0.01
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.66735 nan 4.66735
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           tangshan026276.1441      0.05  -nan  0.05      0.06  -nan  0.06      0.06  -nan  0.06
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.92406 nan 8.92406
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 7889.4398 - val_loss: 13832.7015
Epoch 00000: val_loss improved from inf to 13832.70148, saving model to tangshan0_weights.hdf5
           tangshan0 4620.6404      0.34  0.06  0.33      0.36  0.03  0.35      0.37  0.03  0.36
           tangshan013832.7013      0.49  0.05  0.47      0.48  0.01  0.47      0.48  0.01  0.48
forget mean min: 0.860517 0.772883
incx.max(), incx.min(), incx.mean() 4.48571 0.232914 1.09723
fgtx.max(), fgtx.min(), fgtx.mean() 4.2434 0.155897 0.986615
abs_mean, abs_mean+, abs_mean-: 9.40566 1.425 10.0699
U_c = [[-0.11205819]] U_f = [[ 0.]] b_c = [ 0.07072686] b_f = [ 1.06876647]
W_c max, min, mean, abs_mean: 0.0977645 0.0940826 0.0971549 0.0971549
W_f max, min, mean, abs_mean: 0.0937866 0.0918545 0.093385 0.093385
Epoch 2/300
0s - loss: 3004.8050 - val_loss: 6501.3439
Epoch 00001: val_loss improved from 13832.70148 to 6501.34393, saving model to tangshan0_weights.hdf5
           tangshan0 2048.8372      0.83  0.22  0.67      0.86  0.19  0.71      0.87  0.18  0.73
           tangshan0 6501.3440      0.92  0.15  0.79      0.93  0.10  0.85      0.94  0.09  0.86
forget mean min: 0.936283 0.804438
incx.max(), incx.min(), incx.mean() 11.5941 0.494353 3.88543
fgtx.max(), fgtx.min(), fgtx.mean() 9.82362 0.320403 3.22374
abs_mean, abs_mean+, abs_mean-: 7.98545 5.15031 11.8155
U_c = [[-0.09025364]] U_f = [[ 0.]] b_c = [ 0.12013803] b_f = [ 1.09386253]
W_c max, min, mean, abs_mean: 0.152484 0.148933 0.151913 0.151913
W_f max, min, mean, abs_mean: 0.130575 0.128652 0.130067 0.130067
Epoch 3/300
0s - loss: 1906.3137 - val_loss: 5859.0508
Epoch 00002: val_loss improved from 6501.34393 to 5859.05083, saving model to tangshan0_weights.hdf5
           tangshan0 1809.7964      0.89  0.24  0.70      0.92  0.21  0.74      0.94  0.19  0.76
           tangshan0 5859.0508      0.97  0.21  0.77      0.97  0.17  0.81      0.98  0.18  0.81
forget mean min: 0.945124 0.782527
incx.max(), incx.min(), incx.mean() 14.2684 0.446627 5.49127
fgtx.max(), fgtx.min(), fgtx.mean() 11.161 0.23784 4.22459
abs_mean, abs_mean+, abs_mean-: 9.81417 7.15707 15.2257
U_c = [[-0.09980291]] U_f = [[ 0.]] b_c = [ 0.14568046] b_f = [ 1.04261386]
W_c max, min, mean, abs_mean: 0.169659 0.166168 0.1691 0.1691
W_f max, min, mean, abs_mean: 0.134267 0.13168 0.13364 0.13364
Epoch 4/300
0s - loss: 1781.5160 - val_loss: 5738.1790
Epoch 00003: val_loss improved from 5859.05083 to 5738.17898, saving model to tangshan0_weights.hdf5
           tangshan0 1747.5087      0.88  0.23  0.70      0.92  0.20  0.75      0.93  0.18  0.77
           tangshan0 5738.1790      0.97  0.21  0.77      0.98  0.17  0.81      0.99  0.18  0.81
forget mean min: 0.944311 0.752211
incx.max(), incx.min(), incx.mean() 15.0622 0.316499 5.86696
fgtx.max(), fgtx.min(), fgtx.mean() 11.8054 0.121855 4.51968
abs_mean, abs_mean+, abs_mean-: 10.378 7.53327 16.7624
U_c = [[-0.10243578]] U_f = [[ 0.]] b_c = [ 0.16270456] b_f = [ 0.98858547]
W_c max, min, mean, abs_mean: 0.172852 0.169399 0.172296 0.172296
W_f max, min, mean, abs_mean: 0.137416 0.133713 0.136516 0.136516
Epoch 5/300
0s - loss: 1737.8359 - val_loss: 5609.9275
Epoch 00004: val_loss improved from 5738.17898 to 5609.92754, saving model to tangshan0_weights.hdf5
           tangshan0 1712.8986      0.88  0.23  0.70      0.92  0.19  0.76      0.93  0.18  0.77
           tangshan0 5609.9276      0.98  0.20  0.78      0.98  0.16  0.82      0.99  0.16  0.83
forget mean min: 0.941615 0.719849
incx.max(), incx.min(), incx.mean() 15.6903 0.189134 5.94256
fgtx.max(), fgtx.min(), fgtx.mean() 13.1498 0.007626 4.88551
abs_mean, abs_mean+, abs_mean-: 10.7089 7.60913 18.0552
U_c = [[-0.10088377]] U_f = [[ 0.]] b_c = [ 0.18013546] b_f = [ 0.93608671]
W_c max, min, mean, abs_mean: 0.174787 0.171361 0.174225 0.174225
W_f max, min, mean, abs_mean: 0.148829 0.144258 0.147711 0.147711
Epoch 6/300
0s - loss: 1707.7795 - val_loss: 5683.0982
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 1681.5643 - val_loss: 5511.6937
Epoch 00006: val_loss improved from 5609.92754 to 5511.69375, saving model to tangshan0_weights.hdf5
           tangshan0 1668.3362      0.89  0.23  0.70      0.93  0.20  0.76      0.94  0.19  0.77
           tangshan0 5511.6938      0.98  0.20  0.79      0.98  0.16  0.83      0.99  0.16  0.83
forget mean min: 0.94027 0.695927
incx.max(), incx.min(), incx.mean() 16.4093 0.213915 6.04925
fgtx.max(), fgtx.min(), fgtx.mean() 15.0553 0.0 5.42456
abs_mean, abs_mean+, abs_mean-: 10.9601 7.71399 18.9943
U_c = [[-0.09478337]] U_f = [[ 0.]] b_c = [ 0.21391451] b_f = [ 0.8279773]
W_c max, min, mean, abs_mean: 0.179195 0.175829 0.178596 0.178596
W_f max, min, mean, abs_mean: 0.167418 0.162901 0.166024 0.166024
Epoch 8/300
0s - loss: 1658.1061 - val_loss: 5673.3398
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 1639.1229 - val_loss: 5509.3271
Epoch 00008: val_loss improved from 5511.69375 to 5509.32714, saving model to tangshan0_weights.hdf5
           tangshan0 1625.5208      0.89  0.23  0.71      0.93  0.19  0.76      0.94  0.18  0.78
           tangshan0 5509.3271      0.98  0.19  0.79      0.98  0.15  0.83      0.99  0.15  0.84
forget mean min: 0.938505 0.672285
incx.max(), incx.min(), incx.mean() 16.145 0.237037 5.94668
fgtx.max(), fgtx.min(), fgtx.mean() 16.0521 0.0 5.7614
abs_mean, abs_mean+, abs_mean-: 10.9674 7.59353 19.3009
U_c = [[-0.09055942]] U_f = [[ 0.]] b_c = [ 0.23703657] b_f = [ 0.71853983]
W_c max, min, mean, abs_mean: 0.182313 0.179021 0.181663 0.181663
W_f max, min, mean, abs_mean: 0.185032 0.180359 0.18331 0.18331
Epoch 10/300
0s - loss: 1619.1934 - val_loss: 5643.1673
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 1604.5240 - val_loss: 5643.1165
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 1586.7485 - val_loss: 5784.4721
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 1569.4854 - val_loss: 5721.9467
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 1551.2164 - val_loss: 5735.7818
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 1533.4989 - val_loss: 5938.7084
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 1516.2819 - val_loss: 6138.8381
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 1499.7254 - val_loss: 6022.7894
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 1485.9909 - val_loss: 6300.6179
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 1466.8949 - val_loss: 6303.5232
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 1444.2662 - val_loss: 6233.2353
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 1430.1424 - val_loss: 6379.8442
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 1413.3875 - val_loss: 6560.1072
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1377.3259 - val_loss: 6482.7466
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1339.8069 - val_loss: 6522.6051
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1312.1870 - val_loss: 6340.5922
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1297.4839 - val_loss: 6362.5493
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 1282.0598 - val_loss: 6396.9922
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 1276.0103 - val_loss: 6374.9903
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 1256.8047 - val_loss: 6445.1321
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 1245.6976 - val_loss: 6540.7291
Epoch 00029: val_loss did not improve
X_train[0].shape = (3828, 40, 23)

training baoding0
Train on 3828 samples, validate on 1020 samples
Before training:
            baoding016627.1196      0.04  -nan  0.04      0.04  -nan  0.04      0.03  -nan  0.03
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.76207 nan 5.76207
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            baoding040139.5757      0.07  -nan  0.07      0.08  -nan  0.08      0.10  -nan  0.10
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 13.6276 nan 13.6276
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 13181.6469 - val_loss: 16052.2600
Epoch 00000: val_loss improved from inf to 16052.25996, saving model to baoding0_weights.hdf5
            baoding0 8394.6485      0.33  0.10  0.31      0.34  0.06  0.33      0.34  0.05  0.33
            baoding016052.2600      0.93  0.11  0.83      0.94  0.09  0.86      0.96  0.06  0.90
forget mean min: 0.893415 0.776662
incx.max(), incx.min(), incx.mean() 2.98735 0.253623 1.29901
fgtx.max(), fgtx.min(), fgtx.mean() 2.83179 0.177535 1.19253
abs_mean, abs_mean+, abs_mean-: 12.7678 nan 12.7678
U_c = [[-0.11205356]] U_f = [[ 0.]] b_c = [ 0.0707972] b_f = [ 1.06878555]
W_c max, min, mean, abs_mean: 0.0980225 0.0941789 0.0971556 0.0971556
W_f max, min, mean, abs_mean: 0.0948005 0.0928189 0.0943399 0.0943399
Epoch 2/300
0s - loss: 5955.1527 - val_loss: 8094.1650
Epoch 00001: val_loss improved from 16052.25996 to 8094.16501, saving model to baoding0_weights.hdf5
            baoding0 4277.7227      0.90  0.26  0.68      0.91  0.24  0.71      0.91  0.23  0.71
            baoding0 8094.1649      0.99  0.13  0.87      0.99  0.10  0.90      1.00  0.07  0.93
forget mean min: 0.976978 0.806332
incx.max(), incx.min(), incx.mean() 9.45267 0.507884 4.49301
fgtx.max(), fgtx.min(), fgtx.mean() 7.91852 0.328236 3.7099
abs_mean, abs_mean+, abs_mean-: 6.13021 4.52109 9.27195
U_c = [[-0.08751861]] U_f = [[ 0.]] b_c = [ 0.12109259] b_f = [ 1.09811115]
W_c max, min, mean, abs_mean: 0.156297 0.152522 0.155437 0.155437
W_f max, min, mean, abs_mean: 0.132418 0.130461 0.131904 0.131904
Epoch 3/300
0s - loss: 3842.0368 - val_loss: 8876.0021
Epoch 00002: val_loss did not improve
Epoch 4/300
0s - loss: 3517.6302 - val_loss: 7591.7565
Epoch 00003: val_loss improved from 8094.16501 to 7591.75647, saving model to baoding0_weights.hdf5
            baoding0 3400.1499      0.93  0.25  0.71      0.95  0.22  0.75      0.95  0.21  0.76
            baoding0 7591.7563      0.99  0.13  0.87      0.99  0.10  0.90      1.00  0.07  0.93
forget mean min: 0.974487 0.755442
incx.max(), incx.min(), incx.mean() 17.088 0.330924 7.18545
fgtx.max(), fgtx.min(), fgtx.mean() 10.2828 0.125434 4.28033
abs_mean, abs_mean+, abs_mean-: 9.32812 7.7917 13.3001
U_c = [[-0.08087987]] U_f = [[ 0.]] b_c = [ 0.12399394] b_f = [ 1.00241566]
W_c max, min, mean, abs_mean: 0.197866 0.193983 0.196903 0.196903
W_f max, min, mean, abs_mean: 0.120432 0.11748 0.119356 0.119356
Epoch 5/300
0s - loss: 3322.1367 - val_loss: 7154.1322
Epoch 00004: val_loss improved from 7591.75647 to 7154.13216, saving model to baoding0_weights.hdf5
            baoding0 3208.5788      0.94  0.24  0.73      0.96  0.21  0.76      0.96  0.20  0.77
            baoding0 7154.1321      0.99  0.13  0.87      0.99  0.10  0.90      1.00  0.07  0.93
forget mean min: 0.971667 0.72692
incx.max(), incx.min(), incx.mean() 18.7556 0.161762 7.51112
fgtx.max(), fgtx.min(), fgtx.mean() 10.8361 0.0272402 4.29951
abs_mean, abs_mean+, abs_mean-: 10.0595 8.49945 13.4623
U_c = [[-0.07799152]] U_f = [[ 0.]] b_c = [ 0.11490025] b_f = [ 0.9518109]
W_c max, min, mean, abs_mean: 0.208579 0.204598 0.207527 0.207527
W_f max, min, mean, abs_mean: 0.121935 0.118549 0.12064 0.12064
Epoch 6/300
0s - loss: 3154.8220 - val_loss: 6450.7677
Epoch 00005: val_loss improved from 7154.13216 to 6450.76773, saving model to baoding0_weights.hdf5
            baoding0 3055.4544      0.94  0.23  0.73      0.96  0.20  0.77      0.96  0.19  0.79
            baoding0 6450.7677      0.99  0.13  0.87      0.99  0.09  0.90      0.99  0.06  0.93
forget mean min: 0.966134 0.711528
incx.max(), incx.min(), incx.mean() 20.8771 0.107045 7.66091
fgtx.max(), fgtx.min(), fgtx.mean() 11.5172 0.0 4.18871
abs_mean, abs_mean+, abs_mean-: 11.0239 9.09838 14.5383
U_c = [[-0.07195422]] U_f = [[ 0.]] b_c = [ 0.10704531] b_f = [ 0.90281677]
W_c max, min, mean, abs_mean: 0.219749 0.215618 0.218588 0.218588
W_f max, min, mean, abs_mean: 0.122653 0.118964 0.121211 0.121211
Epoch 7/300
0s - loss: 2998.5843 - val_loss: 5958.3810
Epoch 00006: val_loss improved from 6450.76773 to 5958.38098, saving model to baoding0_weights.hdf5
            baoding0 2905.7716      0.94  0.22  0.74      0.96  0.19  0.78      0.96  0.18  0.80
            baoding0 5958.3810      0.99  0.12  0.87      0.99  0.09  0.90      0.99  0.06  0.93
forget mean min: 0.95902 0.701306
incx.max(), incx.min(), incx.mean() 22.6119 0.0988704 7.72549
fgtx.max(), fgtx.min(), fgtx.mean() 11.7399 0.0 3.97708
abs_mean, abs_mean+, abs_mean-: 12.0211 9.52161 15.927
U_c = [[-0.0692074]] U_f = [[ 0.]] b_c = [ 0.09887044] b_f = [ 0.85352379]
W_c max, min, mean, abs_mean: 0.233326 0.229011 0.232036 0.232036
W_f max, min, mean, abs_mean: 0.122537 0.118619 0.121002 0.121002
Epoch 8/300
0s - loss: 2867.0565 - val_loss: 5614.7095
Epoch 00007: val_loss improved from 5958.38098 to 5614.70946, saving model to baoding0_weights.hdf5
            baoding0 2773.4338      0.95  0.23  0.74      0.97  0.20  0.78      0.97  0.19  0.79
            baoding0 5614.7094      0.99  0.10  0.89      0.99  0.08  0.92      1.00  0.05  0.94
forget mean min: 0.953835 0.692185
incx.max(), incx.min(), incx.mean() 25.0284 0.0982918 8.1594
fgtx.max(), fgtx.min(), fgtx.mean() 12.3971 0.0 4.00858
abs_mean, abs_mean+, abs_mean-: 13.2022 10.0263 18.3523
U_c = [[-0.06158846]] U_f = [[ 0.]] b_c = [ 0.09829184] b_f = [ 0.81035221]
W_c max, min, mean, abs_mean: 0.249544 0.245111 0.24817 0.24817
W_f max, min, mean, abs_mean: 0.124989 0.120922 0.12341 0.12341
Epoch 9/300
0s - loss: 2755.5145 - val_loss: 5838.2657
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 2653.8758 - val_loss: 6015.0499
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 2571.1908 - val_loss: 6385.4811
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 2510.9222 - val_loss: 6840.1481
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 2454.7779 - val_loss: 6887.0812
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 2427.4708 - val_loss: 6853.9473
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 2376.5803 - val_loss: 7146.8250
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 2344.2239 - val_loss: 7382.5704
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 2304.8541 - val_loss: 7474.8987
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 2272.2651 - val_loss: 7357.5304
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 2238.7101 - val_loss: 7358.5703
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 2201.7187 - val_loss: 7428.9898
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 2164.7245 - val_loss: 7387.6855
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 2134.7501 - val_loss: 7627.9741
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 2113.1764 - val_loss: 7544.5991
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 2081.4411 - val_loss: 7918.9079
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 2059.8759 - val_loss: 7975.0307
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 2021.9753 - val_loss: 8277.2186
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 2007.3368 - val_loss: 8162.5030
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 1985.0661 - val_loss: 8453.7922
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 1958.0352 - val_loss: 8506.7006
Epoch 00028: val_loss did not improve
X_train[0].shape = (4466, 40, 23)

training shijiazhuang0
Train on 4466 samples, validate on 1190 samples
Before training:
       shijiazhuang012465.1656      0.04  -nan  0.04      0.04  -nan  0.04      0.04  -nan  0.04
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.44271 nan 4.44271
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
       shijiazhuang031929.5598      0.06  -nan  0.05      0.06  -nan  0.06      0.07  -nan  0.07
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 10.7043 nan 10.7043
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 9070.2102 - val_loss: 14751.0516
Epoch 00000: val_loss improved from inf to 14751.05163, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 5122.8743      0.48  0.11  0.45      0.49  0.11  0.46      0.48  0.10  0.46
       shijiazhuang014751.0516      0.71  0.20  0.61      0.71  0.15  0.63      0.71  0.11  0.65
forget mean min: 0.892338 0.777736
incx.max(), incx.min(), incx.mean() 4.70228 0.272035 1.50151
fgtx.max(), fgtx.min(), fgtx.mean() 4.28593 0.178201 1.31817
abs_mean, abs_mean+, abs_mean-: 9.33153 1.40893 10.0753
U_c = [[-0.11250148]] U_f = [[ 0.]] b_c = [ 0.07985734] b_f = [ 1.07432091]
W_c max, min, mean, abs_mean: 0.106899 0.105284 0.106381 0.106381
W_f max, min, mean, abs_mean: 0.099083 0.0982097 0.0986431 0.0986431
Epoch 2/300
0s - loss: 3588.8954 - val_loss: 8856.2651
Epoch 00001: val_loss improved from 14751.05163 to 8856.26510, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2732.3882      0.75  0.24  0.61      0.76  0.23  0.62      0.75  0.23  0.62
       shijiazhuang0 8856.2650      0.95  0.23  0.74      0.95  0.19  0.78      0.95  0.14  0.82
forget mean min: 0.965847 0.806118
incx.max(), incx.min(), incx.mean() 12.2005 0.546019 4.87159
fgtx.max(), fgtx.min(), fgtx.mean() 9.8342 0.336298 3.86146
abs_mean, abs_mean+, abs_mean-: 7.27282 5.25978 12.4454
U_c = [[-0.08936635]] U_f = [[ 0.]] b_c = [ 0.13337508] b_f = [ 1.08868372]
W_c max, min, mean, abs_mean: 0.165015 0.163491 0.164516 0.164516
W_f max, min, mean, abs_mean: 0.134675 0.133525 0.134077 0.134077
Epoch 3/300
0s - loss: 2566.2639 - val_loss: 8446.2550
Epoch 00002: val_loss improved from 8856.26510 to 8446.25501, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2444.5611      0.84  0.27  0.64      0.86  0.26  0.66      0.85  0.25  0.66
       shijiazhuang0 8446.2550      0.96  0.23  0.74      0.96  0.19  0.78      0.96  0.15  0.83
forget mean min: 0.964234 0.772569
incx.max(), incx.min(), incx.mean() 15.6976 0.427257 6.32115
fgtx.max(), fgtx.min(), fgtx.mean() 10.7513 0.196323 4.27025
abs_mean, abs_mean+, abs_mean-: 9.18403 7.15563 14.932
U_c = [[-0.10321913]] U_f = [[ 0.]] b_c = [ 0.14323431] b_f = [ 1.02655172]
W_c max, min, mean, abs_mean: 0.186603 0.185059 0.186143 0.186143
W_f max, min, mean, abs_mean: 0.129193 0.128239 0.128667 0.128667
Epoch 4/300
0s - loss: 2366.2576 - val_loss: 7848.3353
Epoch 00003: val_loss improved from 8446.25501 to 7848.33526, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2276.4855      0.84  0.25  0.65      0.86  0.24  0.68      0.85  0.23  0.68
       shijiazhuang0 7848.3353      0.95  0.23  0.74      0.96  0.18  0.79      0.96  0.14  0.83
forget mean min: 0.954143 0.734635
incx.max(), incx.min(), incx.mean() 18.7528 0.238612 6.72684
fgtx.max(), fgtx.min(), fgtx.mean() 9.97127 0.0534856 3.52915
abs_mean, abs_mean+, abs_mean-: 9.76405 7.28984 15.5274
U_c = [[-0.10502755]] U_f = [[ 0.]] b_c = [ 0.13876738] b_f = [ 0.96478295]
W_c max, min, mean, abs_mean: 0.203162 0.201515 0.202689 0.202689
W_f max, min, mean, abs_mean: 0.109199 0.10803 0.108579 0.108579
Epoch 5/300
0s - loss: 2202.0248 - val_loss: 7447.2072
Epoch 00004: val_loss improved from 7848.33526 to 7447.20722, saving model to shijiazhuang0_weights.hdf5
       shijiazhuang0 2104.2877      0.84  0.24  0.66      0.86  0.23  0.69      0.86  0.21  0.70
       shijiazhuang0 7447.2072      0.96  0.21  0.76      0.96  0.17  0.80      0.96  0.12  0.85
forget mean min: 0.94142 0.711687
incx.max(), incx.min(), incx.mean() 22.0723 0.138953 7.30072
fgtx.max(), fgtx.min(), fgtx.mean() 8.49754 0.0 2.77466
abs_mean, abs_mean+, abs_mean-: 10.0567 7.41391 14.3488
U_c = [[-0.09897795]] U_f = [[ 0.]] b_c = [ 0.1389531] b_f = [ 0.90359056]
W_c max, min, mean, abs_mean: 0.2249 0.223176 0.224406 0.224406
W_f max, min, mean, abs_mean: 0.0876941 0.0862811 0.086942 0.086942
Epoch 6/300
0s - loss: 2037.9044 - val_loss: 7589.8022
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 1937.3278 - val_loss: 7727.5697
Epoch 00006: val_loss did not improve
Epoch 8/300
0s - loss: 1875.8511 - val_loss: 7854.6796
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 1834.0660 - val_loss: 8045.1083
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 1803.8533 - val_loss: 7945.1032
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 1776.7443 - val_loss: 7860.8261
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 1742.2439 - val_loss: 8122.5897
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 1720.0992 - val_loss: 7985.2936
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 1698.8525 - val_loss: 8576.0191
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 1675.5978 - val_loss: 8590.2831
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 1655.5339 - val_loss: 8917.8403
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 1629.2462 - val_loss: 8606.6665
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 1625.5838 - val_loss: 8724.1896
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 1609.2509 - val_loss: 8794.8430
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 1595.6642 - val_loss: 8665.6750
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 1586.8001 - val_loss: 8939.0647
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 1574.0411 - val_loss: 8839.1567
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1569.3108 - val_loss: 8968.9932
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1553.0742 - val_loss: 8898.5722
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1541.5424 - val_loss: 9140.8823
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1531.9975 - val_loss: 9101.1731
Epoch 00025: val_loss did not improve
X_train[0].shape = (5104, 40, 23)

training xingtai+handan0
Train on 5104 samples, validate on 1360 samples
Before training:
     xingtai+handan012469.2802      0.03  -nan  0.03      0.03  -nan  0.03      0.02  -nan  0.02
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.1359 nan 5.1359
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
     xingtai+handan034235.5225      0.06  -nan  0.05      0.06  -nan  0.06      0.07  -nan  0.07
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 11.6136 nan 11.6136
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 8489.8379 - val_loss: 11452.1241
Epoch 00000: val_loss improved from inf to 11452.12408, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 4274.4729      0.47  0.15  0.44      0.48  0.12  0.45      0.48  0.11  0.45
     xingtai+handan011452.1242      0.97  0.17  0.81      0.96  0.13  0.84      0.97  0.09  0.88
forget mean min: 0.937543 0.786724
incx.max(), incx.min(), incx.mean() 4.49275 0.328417 2.10607
fgtx.max(), fgtx.min(), fgtx.mean() 4.08436 0.221878 1.8707
abs_mean, abs_mean+, abs_mean-: 6.85016 1.42814 7.5203
U_c = [[-0.11813235]] U_f = [[ 0.]] b_c = [ 0.08922234] b_f = [ 1.08341312]
W_c max, min, mean, abs_mean: 0.11896 0.115001 0.118161 0.118161
W_f max, min, mean, abs_mean: 0.110306 0.108307 0.109604 0.109604
Epoch 2/300
0s - loss: 3192.3690 - val_loss: 8283.2313
Epoch 00001: val_loss improved from 11452.12408 to 8283.23130, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2776.4167      0.84  0.28  0.63      0.85  0.24  0.67      0.85  0.23  0.67
     xingtai+handan0 8283.2313      0.98  0.17  0.81      0.98  0.13  0.85      0.98  0.09  0.89
forget mean min: 0.971494 0.797095
incx.max(), incx.min(), incx.mean() 9.37967 0.504649 4.85398
fgtx.max(), fgtx.min(), fgtx.mean() 7.20661 0.291278 3.68023
abs_mean, abs_mean+, abs_mean-: 6.83248 5.00771 11.4026
U_c = [[-0.09433081]] U_f = [[ 0.]] b_c = [ 0.13084079] b_f = [ 1.07695723]
W_c max, min, mean, abs_mean: 0.167358 0.163447 0.166531 0.166531
W_f max, min, mean, abs_mean: 0.130605 0.128354 0.129763 0.129763
Epoch 3/300
0s - loss: 2697.3753 - val_loss: 7952.6846
Epoch 00002: val_loss improved from 8283.23130 to 7952.68455, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2614.1430      0.83  0.27  0.63      0.85  0.23  0.67      0.84  0.22  0.68
     xingtai+handan0 7952.6847      0.97  0.17  0.81      0.97  0.13  0.84      0.97  0.09  0.88
forget mean min: 0.965013 0.77232
incx.max(), incx.min(), incx.mean() 10.0188 0.406005 5.15677
fgtx.max(), fgtx.min(), fgtx.mean() 7.20047 0.19597 3.65766
abs_mean, abs_mean+, abs_mean-: 7.93797 5.49126 13.9788
U_c = [[-0.10111682]] U_f = [[ 0.]] b_c = [ 0.13706467] b_f = [ 1.02548921]
W_c max, min, mean, abs_mean: 0.177309 0.173391 0.176494 0.176494
W_f max, min, mean, abs_mean: 0.129504 0.126712 0.128606 0.128606
Epoch 4/300
0s - loss: 2557.4639 - val_loss: 7938.7469
Epoch 00003: val_loss improved from 7952.68455 to 7938.74688, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2492.4722      0.85  0.27  0.64      0.87  0.24  0.68      0.87  0.23  0.69
     xingtai+handan0 7938.7469      0.97  0.16  0.82      0.96  0.12  0.85      0.96  0.09  0.88
forget mean min: 0.964803 0.750096
incx.max(), incx.min(), incx.mean() 10.941 0.299036 5.47751
fgtx.max(), fgtx.min(), fgtx.mean() 8.16806 0.119315 4.03591
abs_mean, abs_mean+, abs_mean-: 8.58078 6.1255 14.9244
U_c = [[-0.09768877]] U_f = [[ 0.]] b_c = [ 0.14128129] b_f = [ 0.97981006]
W_c max, min, mean, abs_mean: 0.186483 0.182563 0.185724 0.185724
W_f max, min, mean, abs_mean: 0.141361 0.138255 0.140469 0.140469
Epoch 5/300
0s - loss: 2460.3843 - val_loss: 7853.9864
Epoch 00004: val_loss improved from 7938.74688 to 7853.98643, saving model to xingtai+handan0_weights.hdf5
     xingtai+handan0 2399.1903      0.85  0.27  0.65      0.87  0.23  0.69      0.87  0.22  0.70
     xingtai+handan0 7853.9863      0.97  0.16  0.82      0.96  0.12  0.85      0.96  0.08  0.88
forget mean min: 0.963675 0.723485
incx.max(), incx.min(), incx.mean() 12.196 0.17895 5.51105
fgtx.max(), fgtx.min(), fgtx.mean() 9.49358 0.0281921 4.22812
abs_mean, abs_mean+, abs_mean-: 8.80139 6.25741 15.2755
U_c = [[-0.09492071]] U_f = [[ 0.]] b_c = [ 0.14315824] b_f = [ 0.93362296]
W_c max, min, mean, abs_mean: 0.191914 0.187989 0.19119 0.19119
W_f max, min, mean, abs_mean: 0.151524 0.148119 0.150596 0.150596
Epoch 6/300
0s - loss: 2367.4931 - val_loss: 7923.5055
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 2256.8819 - val_loss: 8002.5305
Epoch 00006: val_loss did not improve
Epoch 8/300
0s - loss: 2157.4144 - val_loss: 8096.9731
Epoch 00007: val_loss did not improve
Epoch 9/300
0s - loss: 2107.4851 - val_loss: 8105.3922
Epoch 00008: val_loss did not improve
Epoch 10/300
0s - loss: 2073.1148 - val_loss: 7965.9512
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 2047.3424 - val_loss: 7945.0096
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 2016.5719 - val_loss: 7928.7810
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 1992.4558 - val_loss: 7869.8208
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 1965.3791 - val_loss: 7948.9743
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 1939.8380 - val_loss: 8086.6496
Epoch 00014: val_loss did not improve
Epoch 16/300
0s - loss: 1922.1622 - val_loss: 8155.7319
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 1902.6532 - val_loss: 8399.2581
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 1884.3148 - val_loss: 8280.1230
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 1868.8299 - val_loss: 8581.2864
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 1853.5701 - val_loss: 8751.2292
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 1835.6762 - val_loss: 8659.6076
Epoch 00020: val_loss did not improve
Epoch 22/300
0s - loss: 1821.1554 - val_loss: 8581.2030
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1812.0916 - val_loss: 8826.8380
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1797.0145 - val_loss: 8774.6245
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1788.3538 - val_loss: 8797.0624
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1774.7974 - val_loss: 8794.8124
Epoch 00025: val_loss did not improve
X_train[0].shape = (3190, 40, 23)

training jinan0
Train on 3190 samples, validate on 850 samples
Before training:
              jinan012205.9892      0.03  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.69583 nan 5.69583
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              jinan029651.5927      0.05  -nan  0.05      0.05  -nan  0.05      0.05  -nan  0.05
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 10.105 nan 10.105
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
0s - loss: 9956.2334 - val_loss: 17246.2621
Epoch 00000: val_loss improved from inf to 17246.26207, saving model to jinan0_weights.hdf5
              jinan0 6686.7635      0.18  0.12  0.18      0.18  0.09  0.18      0.18  0.05  0.18
              jinan017246.2619      0.36  0.07  0.35      0.35  0.07  0.34      0.35  0.06  0.34
forget mean min: 0.863711 0.765945
incx.max(), incx.min(), incx.mean() 2.37344 0.185705 0.914015
fgtx.max(), fgtx.min(), fgtx.mean() 2.30202 0.124847 0.849638
abs_mean, abs_mean+, abs_mean-: 10.6975 nan 10.6975
U_c = [[-0.10646064]] U_f = [[ 0.]] b_c = [ 0.06026568] b_f = [ 1.06070542]
W_c max, min, mean, abs_mean: 0.0852315 0.0825449 0.0846274 0.0846274
W_f max, min, mean, abs_mean: 0.0844978 0.0838616 0.0842254 0.0842254
Epoch 2/300
0s - loss: 4641.3384 - val_loss: 8366.0391
Epoch 00001: val_loss improved from 17246.26207 to 8366.03909, saving model to jinan0_weights.hdf5
              jinan0 3354.1806      0.70  0.26  0.56      0.70  0.22  0.58      0.71  0.18  0.61
              jinan0 8366.0391      0.99  0.13  0.86      0.99  0.11  0.88      0.99  0.08  0.91
forget mean min: 0.965549 0.799671
incx.max(), incx.min(), incx.mean() 6.78848 0.42621 2.96711
fgtx.max(), fgtx.min(), fgtx.mean() 6.03914 0.291054 2.58666
abs_mean, abs_mean+, abs_mean-: 3.55768 2.0145 4.63857
U_c = [[-0.12486675]] U_f = [[ 0.]] b_c = [ 0.10407092] b_f = [ 1.09318459]
W_c max, min, mean, abs_mean: 0.135869 0.133213 0.135265 0.135265
W_f max, min, mean, abs_mean: 0.122541 0.121915 0.122212 0.122212
Epoch 3/300
0s - loss: 2859.4996 - val_loss: 6021.1867
Epoch 00002: val_loss improved from 8366.03909 to 6021.18665, saving model to jinan0_weights.hdf5
              jinan0 2503.3803      0.83  0.28  0.63      0.83  0.24  0.66      0.83  0.21  0.68
              jinan0 6021.1865      0.99  0.10  0.89      0.99  0.08  0.91      0.99  0.06  0.92
forget mean min: 0.971008 0.793116
incx.max(), incx.min(), incx.mean() 10.8959 0.540072 5.05966
fgtx.max(), fgtx.min(), fgtx.mean() 7.2531 0.270641 3.31799
abs_mean, abs_mean+, abs_mean-: 5.58482 4.6982 7.50446
U_c = [[-0.08716805]] U_f = [[ 0.]] b_c = [ 0.13868922] b_f = [ 1.07317173]
W_c max, min, mean, abs_mean: 0.17778 0.175142 0.177181 0.177181
W_f max, min, mean, abs_mean: 0.119836 0.119113 0.119467 0.119467
Epoch 4/300
0s - loss: 2379.9193 - val_loss: 5696.5720
Epoch 00003: val_loss improved from 6021.18665 to 5696.57195, saving model to jinan0_weights.hdf5
              jinan0 2272.2242      0.81  0.25  0.63      0.82  0.22  0.67      0.82  0.18  0.69
              jinan0 5696.5720      0.98  0.09  0.89      0.98  0.07  0.91      0.98  0.05  0.93
forget mean min: 0.958783 0.770315
incx.max(), incx.min(), incx.mean() 13.8156 0.569018 6.49254
fgtx.max(), fgtx.min(), fgtx.mean() 5.73947 0.170218 2.66063
abs_mean, abs_mean+, abs_mean-: 6.51492 5.46945 8.3209
U_c = [[-0.07690371]] U_f = [[ 0.]] b_c = [ 0.16415755] b_f = [ 1.03987491]
W_c max, min, mean, abs_mean: 0.20981 0.207158 0.209204 0.209204
W_f max, min, mean, abs_mean: 0.0883377 0.0876026 0.087957 0.087957
Epoch 5/300
0s - loss: 2223.1991 - val_loss: 5519.3462
Epoch 00004: val_loss improved from 5696.57195 to 5519.34619, saving model to jinan0_weights.hdf5
              jinan0 2151.8303      0.81  0.24  0.64      0.82  0.21  0.67      0.82  0.17  0.70
              jinan0 5519.3462      0.98  0.09  0.89      0.98  0.07  0.91      0.98  0.05  0.93
forget mean min: 0.949066 0.760536
incx.max(), incx.min(), incx.mean() 16.0435 0.644178 7.8068
fgtx.max(), fgtx.min(), fgtx.mean() 4.74467 0.136034 2.27963
abs_mean, abs_mean+, abs_mean-: 6.92597 5.86232 8.5352
U_c = [[-0.0706251]] U_f = [[ 0.]] b_c = [ 0.18964048] b_f = [ 1.01958656]
W_c max, min, mean, abs_mean: 0.237413 0.234732 0.236782 0.236782
W_f max, min, mean, abs_mean: 0.0712222 0.0705173 0.0708642 0.0708642
Epoch 6/300
0s - loss: 2117.3031 - val_loss: 5678.8647
Epoch 00005: val_loss did not improve
Epoch 7/300
0s - loss: 2047.1157 - val_loss: 5584.8476
Epoch 00006: val_loss did not improve
Epoch 8/300
0s - loss: 1990.2788 - val_loss: 5466.7064
Epoch 00007: val_loss improved from 5519.34619 to 5466.70641, saving model to jinan0_weights.hdf5
              jinan0 1943.5305      0.83  0.23  0.66      0.84  0.20  0.70      0.84  0.16  0.73
              jinan0 5466.7063      0.98  0.09  0.89      0.98  0.07  0.91      0.98  0.05  0.93
forget mean min: 0.930329 0.747028
incx.max(), incx.min(), incx.mean() 20.0426 0.809593 10.2063
fgtx.max(), fgtx.min(), fgtx.mean() 3.64872 0.103905 1.83581
abs_mean, abs_mean+, abs_mean-: 7.76796 6.81882 8.85818
U_c = [[-0.0585548]] U_f = [[ 0.]] b_c = [ 0.24584568] b_f = [ 0.97891957]
W_c max, min, mean, abs_mean: 0.291233 0.288507 0.290589 0.290589
W_f max, min, mean, abs_mean: 0.0538298 0.0532004 0.053559 0.053559
Epoch 9/300
0s - loss: 1940.3899 - val_loss: 5440.5677
Epoch 00008: val_loss improved from 5466.70641 to 5440.56774, saving model to jinan0_weights.hdf5
              jinan0 1908.4100      0.84  0.24  0.66      0.85  0.20  0.70      0.86  0.16  0.73
              jinan0 5440.5677      0.98  0.09  0.89      0.98  0.07  0.91      0.98  0.05  0.93
forget mean min: 0.92748 0.743423
incx.max(), incx.min(), incx.mean() 20.4483 0.815789 10.5637
fgtx.max(), fgtx.min(), fgtx.mean() 3.51242 0.0974827 1.79307
abs_mean, abs_mean+, abs_mean-: 7.97937 6.89311 9.2397
U_c = [[-0.0563]] U_f = [[ 0.]] b_c = [ 0.25536051] b_f = [ 0.96635455]
W_c max, min, mean, abs_mean: 0.300917 0.298216 0.300303 0.300303
W_f max, min, mean, abs_mean: 0.0525299 0.0518772 0.0522362 0.0522362
Epoch 10/300
0s - loss: 1908.2838 - val_loss: 5481.9609
Epoch 00009: val_loss did not improve
Epoch 11/300
0s - loss: 1873.9816 - val_loss: 5849.7600
Epoch 00010: val_loss did not improve
Epoch 12/300
0s - loss: 1854.7412 - val_loss: 5773.7453
Epoch 00011: val_loss did not improve
Epoch 13/300
0s - loss: 1826.4517 - val_loss: 5453.2232
Epoch 00012: val_loss did not improve
Epoch 14/300
0s - loss: 1801.4434 - val_loss: 6175.7877
Epoch 00013: val_loss did not improve
Epoch 15/300
0s - loss: 1783.5218 - val_loss: 5427.6553
Epoch 00014: val_loss improved from 5440.56774 to 5427.65534, saving model to jinan0_weights.hdf5
              jinan0 1743.2014      0.86  0.23  0.69      0.87  0.18  0.73      0.88  0.15  0.76
              jinan0 5427.6553      0.97  0.09  0.88      0.97  0.07  0.90      0.97  0.05  0.93
forget mean min: 0.915684 0.71865
incx.max(), incx.min(), incx.mean() 23.5827 0.633361 11.213
fgtx.max(), fgtx.min(), fgtx.mean() 3.6813 0.0558944 1.72721
abs_mean, abs_mean+, abs_mean-: 9.59891 8.162 11.1238
U_c = [[-0.04187386]] U_f = [[ 0.]] b_c = [ 0.27953929] b_f = [ 0.88187879]
W_c max, min, mean, abs_mean: 0.339406 0.336568 0.338697 0.338697
W_f max, min, mean, abs_mean: 0.0540345 0.0531377 0.0535064 0.0535064
Epoch 16/300
0s - loss: 1759.9304 - val_loss: 5945.6899
Epoch 00015: val_loss did not improve
Epoch 17/300
0s - loss: 1737.1373 - val_loss: 5489.2556
Epoch 00016: val_loss did not improve
Epoch 18/300
0s - loss: 1720.5919 - val_loss: 5559.6470
Epoch 00017: val_loss did not improve
Epoch 19/300
0s - loss: 1709.9774 - val_loss: 5924.3464
Epoch 00018: val_loss did not improve
Epoch 20/300
0s - loss: 1696.3792 - val_loss: 6185.2048
Epoch 00019: val_loss did not improve
Epoch 21/300
0s - loss: 1683.7944 - val_loss: 5377.0328
Epoch 00020: val_loss improved from 5427.65534 to 5377.03276, saving model to jinan0_weights.hdf5
              jinan0 1665.4885      0.87  0.23  0.69      0.90  0.19  0.74      0.91  0.16  0.78
              jinan0 5377.0328      0.96  0.09  0.88      0.97  0.07  0.90      0.97  0.05  0.92
forget mean min: 0.914288 0.692269
incx.max(), incx.min(), incx.mean() 25.3546 0.337337 11.104
fgtx.max(), fgtx.min(), fgtx.mean() 4.29003 0.00824577 1.85098
abs_mean, abs_mean+, abs_mean-: 10.6479 9.13281 12.2516
U_c = [[-0.03439359]] U_f = [[ 0.]] b_c = [ 0.28914461] b_f = [ 0.80250281]
W_c max, min, mean, abs_mean: 0.365343 0.362108 0.36429 0.36429
W_f max, min, mean, abs_mean: 0.0631585 0.0617335 0.0623496 0.0623496
Epoch 22/300
0s - loss: 1668.7985 - val_loss: 5716.8161
Epoch 00021: val_loss did not improve
Epoch 23/300
0s - loss: 1661.3119 - val_loss: 6037.5772
Epoch 00022: val_loss did not improve
Epoch 24/300
0s - loss: 1650.1353 - val_loss: 5982.4106
Epoch 00023: val_loss did not improve
Epoch 25/300
0s - loss: 1636.2146 - val_loss: 6017.6068
Epoch 00024: val_loss did not improve
Epoch 26/300
0s - loss: 1624.7587 - val_loss: 6339.1647
Epoch 00025: val_loss did not improve
Epoch 27/300
0s - loss: 1620.3046 - val_loss: 6126.7949
Epoch 00026: val_loss did not improve
Epoch 28/300
0s - loss: 1611.4197 - val_loss: 5999.0331
Epoch 00027: val_loss did not improve
Epoch 29/300
0s - loss: 1599.0593 - val_loss: 6192.7648
Epoch 00028: val_loss did not improve
Epoch 30/300
0s - loss: 1589.9143 - val_loss: 6645.0318
Epoch 00029: val_loss did not improve
Epoch 31/300
0s - loss: 1581.2636 - val_loss: 6527.2705
Epoch 00030: val_loss did not improve
Epoch 32/300
0s - loss: 1573.2899 - val_loss: 6479.9359
Epoch 00031: val_loss did not improve
Epoch 33/300
0s - loss: 1569.6712 - val_loss: 6724.9018
Epoch 00032: val_loss did not improve
Epoch 34/300
0s - loss: 1557.8357 - val_loss: 6876.4080
Epoch 00033: val_loss did not improve
Epoch 35/300
0s - loss: 1545.0091 - val_loss: 6791.1189
Epoch 00034: val_loss did not improve
Epoch 36/300
0s - loss: 1538.9373 - val_loss: 7319.2818
Epoch 00035: val_loss did not improve
Epoch 37/300
0s - loss: 1537.0833 - val_loss: 7507.6673
Epoch 00036: val_loss did not improve
Epoch 38/300
0s - loss: 1524.7025 - val_loss: 7264.9175
Epoch 00037: val_loss did not improve
Epoch 39/300
0s - loss: 1515.4034 - val_loss: 7145.1762
Epoch 00038: val_loss did not improve
Epoch 40/300
0s - loss: 1512.1931 - val_loss: 7404.1995
Epoch 00039: val_loss did not improve
Epoch 41/300
0s - loss: 1505.9251 - val_loss: 7083.7542
Epoch 00040: val_loss did not improve
Epoch 42/300
0s - loss: 1495.3890 - val_loss: 7236.0628
Epoch 00041: val_loss did not improve
X_train[0].shape = (7656, 40, 23)

training xian0
Train on 7656 samples, validate on 2040 samples
Before training:
               xian0 5490.5240      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.731058 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.58612 nan 3.58612
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
               xian026180.6851      0.05  -nan  0.05      0.05  -nan  0.05      0.03  -nan  0.03
forget mean min: 0.731059 0.731059
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 8.04144 nan 8.04144
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3165.7134 - val_loss: 7945.1089
Epoch 00000: val_loss improved from inf to 7945.10885, saving model to xian0_weights.hdf5
               xian0 1630.6844      0.58  0.39  0.43      0.61  0.38  0.44      0.62  0.38  0.45
               xian0 7945.1088      0.81  0.07  0.77      0.82  0.04  0.79      0.83  0.03  0.81
forget mean min: 0.945089 0.810573
incx.max(), incx.min(), incx.mean() 9.70111 0.490719 3.32275
fgtx.max(), fgtx.min(), fgtx.mean() 8.70189 0.341531 2.91219
abs_mean, abs_mean+, abs_mean-: 6.15451 4.41717 7.97692
U_c = [[-0.11436457]] U_f = [[ 0.]] b_c = [ 0.11448671] b_f = [ 1.11220849]
W_c max, min, mean, abs_mean: 0.14349 0.139253 0.142512 0.142512
W_f max, min, mean, abs_mean: 0.130124 0.126039 0.129366 0.129366
Epoch 2/300
1s - loss: 1368.0636 - val_loss: 6729.5464
Epoch 00001: val_loss improved from 7945.10885 to 6729.54635, saving model to xian0_weights.hdf5
               xian0 1199.5428      0.74  0.33  0.54      0.78  0.32  0.57      0.81  0.31  0.59
               xian0 6729.5464      0.86  0.07  0.81      0.86  0.04  0.83      0.86  0.02  0.85
forget mean min: 0.955371 0.807341
incx.max(), incx.min(), incx.mean() 7.62194 0.542331 3.54685
fgtx.max(), fgtx.min(), fgtx.mean() 5.89907 0.329569 2.69322
abs_mean, abs_mean+, abs_mean-: 4.4564 3.35278 5.9388
U_c = [[-0.05172745]] U_f = [[ 0.]] b_c = [ 0.12342308] b_f = [ 1.1032573]
W_c max, min, mean, abs_mean: 0.160971 0.156692 0.159914 0.159914
W_f max, min, mean, abs_mean: 0.12675 0.122476 0.125809 0.125809
Epoch 3/300
1s - loss: 1141.3444 - val_loss: 7935.9740
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 1083.5511 - val_loss: 8691.5186
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1058.0120 - val_loss: 9388.4229
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1037.3466 - val_loss: 9443.8404
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1016.5035 - val_loss: 9462.9983
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1002.0348 - val_loss: 10263.8475
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 988.3807 - val_loss: 10325.6720
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 978.1270 - val_loss: 10167.3449
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 969.6634 - val_loss: 10822.0750
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 958.6446 - val_loss: 9877.6470
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 951.2287 - val_loss: 10382.7045
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 947.1297 - val_loss: 10366.8339
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 939.5922 - val_loss: 10474.1448
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 933.9387 - val_loss: 9844.1510
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 927.1540 - val_loss: 10541.5778
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 921.1269 - val_loss: 10445.0676
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 917.5893 - val_loss: 10435.6413
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 912.1988 - val_loss: 10404.1536
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 909.1232 - val_loss: 10296.3997
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 902.1020 - val_loss: 10003.8679
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 900.4681 - val_loss: 10925.6756
Epoch 00022: val_loss did not improve

beijing
            beijing0 2400.9565      0.91  0.21  0.73      0.92  0.19  0.75      0.93  0.17  0.77
            beijing0 8207.9286      0.84  0.19  0.70      0.84  0.16  0.73      0.85  0.17  0.72
forget mean min: 0.886948 0.652914
incx.max(), incx.min(), incx.mean() 20.0301 0.134414 6.33244
fgtx.max(), fgtx.min(), fgtx.mean() 21.1963 0.0 6.60318
abs_mean, abs_mean+, abs_mean-: 14.4947 10.0502 21.1171
U_c = [[-0.05665717]] U_f = [[ 0.]] b_c = [ 0.13441356] b_f = [ 0.63187063]
W_c max, min, mean, abs_mean: 0.196132 0.192047 0.195031 0.195031
W_f max, min, mean, abs_mean: 0.208926 0.204267 0.207783 0.207783

tianjin
            tianjin0 1707.7711      0.87  0.26  0.67      0.89  0.21  0.71      0.89  0.17  0.75
            tianjin0 7037.6299      0.88  0.15  0.76      0.88  0.13  0.78      0.91  0.09  0.83
forget mean min: 0.908171 0.701996
incx.max(), incx.min(), incx.mean() 14.0445 0.195572 4.63608
fgtx.max(), fgtx.min(), fgtx.mean() 14.0714 0.0 4.51184
abs_mean, abs_mean+, abs_mean-: 11.0447 6.82002 17.7572
U_c = [[-0.09436464]] U_f = [[ 0.]] b_c = [ 0.19557169] b_f = [ 0.85682219]
W_c max, min, mean, abs_mean: 0.169564 0.15841 0.168271 0.168271
W_f max, min, mean, abs_mean: 0.172603 0.161619 0.170983 0.170983

tangshan
           tangshan0 1625.5208      0.89  0.23  0.71      0.93  0.19  0.76      0.94  0.18  0.78
           tangshan0 5509.3271      0.98  0.19  0.79      0.98  0.15  0.83      0.99  0.15  0.84
forget mean min: 0.938505 0.672285
incx.max(), incx.min(), incx.mean() 16.145 0.237037 5.94668
fgtx.max(), fgtx.min(), fgtx.mean() 16.0521 0.0 5.7614
abs_mean, abs_mean+, abs_mean-: 10.9674 7.59353 19.3009
U_c = [[-0.09055942]] U_f = [[ 0.]] b_c = [ 0.23703657] b_f = [ 0.71853983]
W_c max, min, mean, abs_mean: 0.182313 0.179021 0.181663 0.181663
W_f max, min, mean, abs_mean: 0.185032 0.180359 0.18331 0.18331

baoding
            baoding0 2773.4338      0.95  0.23  0.74      0.97  0.20  0.78      0.97  0.19  0.79
            baoding0 5614.7094      0.99  0.10  0.89      0.99  0.08  0.92      1.00  0.05  0.94
forget mean min: 0.953835 0.692185
incx.max(), incx.min(), incx.mean() 25.0284 0.0982918 8.1594
fgtx.max(), fgtx.min(), fgtx.mean() 12.3971 0.0 4.00858
abs_mean, abs_mean+, abs_mean-: 13.2022 10.0263 18.3523
U_c = [[-0.06158846]] U_f = [[ 0.]] b_c = [ 0.09829184] b_f = [ 0.81035221]
W_c max, min, mean, abs_mean: 0.249544 0.245111 0.24817 0.24817
W_f max, min, mean, abs_mean: 0.124989 0.120922 0.12341 0.12341

shijiazhuang
       shijiazhuang0 2104.2877      0.84  0.24  0.66      0.86  0.23  0.69      0.86  0.21  0.70
       shijiazhuang0 7447.2072      0.96  0.21  0.76      0.96  0.17  0.80      0.96  0.12  0.85
forget mean min: 0.94142 0.711687
incx.max(), incx.min(), incx.mean() 22.0723 0.138953 7.30072
fgtx.max(), fgtx.min(), fgtx.mean() 8.49754 0.0 2.77466
abs_mean, abs_mean+, abs_mean-: 10.0567 7.41391 14.3488
U_c = [[-0.09897795]] U_f = [[ 0.]] b_c = [ 0.1389531] b_f = [ 0.90359056]
W_c max, min, mean, abs_mean: 0.2249 0.223176 0.224406 0.224406
W_f max, min, mean, abs_mean: 0.0876941 0.0862811 0.086942 0.086942

xingtai+handan
     xingtai+handan0 2399.1903      0.85  0.27  0.65      0.87  0.23  0.69      0.87  0.22  0.70
     xingtai+handan0 7853.9863      0.97  0.16  0.82      0.96  0.12  0.85      0.96  0.08  0.88
forget mean min: 0.963675 0.723485
incx.max(), incx.min(), incx.mean() 12.196 0.17895 5.51105
fgtx.max(), fgtx.min(), fgtx.mean() 9.49358 0.0281921 4.22812
abs_mean, abs_mean+, abs_mean-: 8.80139 6.25741 15.2755
U_c = [[-0.09492071]] U_f = [[ 0.]] b_c = [ 0.14315824] b_f = [ 0.93362296]
W_c max, min, mean, abs_mean: 0.191914 0.187989 0.19119 0.19119
W_f max, min, mean, abs_mean: 0.151524 0.148119 0.150596 0.150596

jinan
              jinan0 1665.4885      0.87  0.23  0.69      0.90  0.19  0.74      0.91  0.16  0.78
              jinan0 5377.0328      0.96  0.09  0.88      0.97  0.07  0.90      0.97  0.05  0.92
forget mean min: 0.914288 0.692269
incx.max(), incx.min(), incx.mean() 25.3546 0.337337 11.104
fgtx.max(), fgtx.min(), fgtx.mean() 4.29003 0.00824577 1.85098
abs_mean, abs_mean+, abs_mean-: 10.6479 9.13281 12.2516
U_c = [[-0.03439359]] U_f = [[ 0.]] b_c = [ 0.28914461] b_f = [ 0.80250281]
W_c max, min, mean, abs_mean: 0.365343 0.362108 0.36429 0.36429
W_f max, min, mean, abs_mean: 0.0631585 0.0617335 0.0623496 0.0623496

xian
               xian0 1199.5428      0.74  0.33  0.54      0.78  0.32  0.57      0.81  0.31  0.59
               xian0 6729.5464      0.86  0.07  0.81      0.86  0.04  0.83      0.86  0.02  0.85
forget mean min: 0.955371 0.807341
incx.max(), incx.min(), incx.mean() 7.62194 0.542331 3.54685
fgtx.max(), fgtx.min(), fgtx.mean() 5.89907 0.329569 2.69322
abs_mean, abs_mean+, abs_mean-: 4.4564 3.35278 5.9388
U_c = [[-0.05172745]] U_f = [[ 0.]] b_c = [ 0.12342308] b_f = [ 1.1032573]
W_c max, min, mean, abs_mean: 0.160971 0.156692 0.159914 0.159914
W_f max, min, mean, abs_mean: 0.12675 0.122476 0.125809 0.125809
