X_train[0].shape = (5742, 40, 23)

training nanjing0
Train on 5742 samples, validate on 1530 samples
Before training:
            nanjing0 3813.2267      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.1896 nan 3.1896
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
            nanjing013006.0479      0.02  -nan  0.02      0.02  -nan  0.02      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 6.18494 nan 6.18494
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2651.0093 - val_loss: 6842.6104
Epoch 00000: val_loss improved from inf to 6842.61037, saving model to nanjing0_weights.hdf5
            nanjing0 1679.4909      0.09  0.48  0.08      0.09  0.59  0.08      0.09  0.67  0.08
            nanjing0 6842.6104      0.45  0.05  0.44      0.44  0.00  0.43      0.39  0.00  0.39
forget mean min: 0.775982 0.286841
incx.max(), incx.min(), incx.mean() 2.37093 -2.20291 0.68768
fgtx.max(), fgtx.min(), fgtx.mean() 2.04332 -2.0658 0.531099
abs_mean, abs_mean+, abs_mean-: 8.03898 2.10514 12.7307
U_c = [[-0.13285619]] U_f = [[ 0.]] b_c = [ 0.09651618] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.121288 -0.121473 0.0234532 0.119341
W_f max, min, mean, abs_mean: 0.109141 -0.109028 0.0213546 0.107216
Epoch 2/300
1s - loss: 1188.8895 - val_loss: 3003.9220
Epoch 00001: val_loss improved from 6842.61037 to 3003.92200, saving model to nanjing0_weights.hdf5
            nanjing0  896.1580      0.35  0.40  0.28      0.35  0.39  0.29      0.35  0.33  0.29
            nanjing0 3003.9220      0.93  0.17  0.79      0.93  0.13  0.82      0.92  0.12  0.82
forget mean min: 0.931688 0.142307
incx.max(), incx.min(), incx.mean() 3.94724 -3.74739 2.67411
fgtx.max(), fgtx.min(), fgtx.mean() 2.68569 -2.78846 1.77996
abs_mean, abs_mean+, abs_mean-: 5.44714 3.32466 14.8433
U_c = [[-0.12979528]] U_f = [[ 0.]] b_c = [ 0.17215388] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.199194 -0.199391 0.0390422 0.197265
W_f max, min, mean, abs_mean: 0.142205 -0.142048 0.0280024 0.14034
Epoch 3/300
1s - loss: 862.8881 - val_loss: 2735.0993
Epoch 00002: val_loss improved from 3003.92200 to 2735.09930, saving model to nanjing0_weights.hdf5
            nanjing0  834.9073      0.44  0.38  0.35      0.44  0.37  0.35      0.43  0.35  0.35
            nanjing0 2735.0993      0.91  0.15  0.79      0.91  0.11  0.82      0.91  0.09  0.83
forget mean min: 0.934971 0.27281
incx.max(), incx.min(), incx.mean() 4.69372 -4.53157 3.23522
fgtx.max(), fgtx.min(), fgtx.mean() 2.01206 -2.13595 1.35627
abs_mean, abs_mean+, abs_mean-: 5.82556 3.86551 11.1456
U_c = [[-0.1152906]] U_f = [[ 0.]] b_c = [ 0.21884196] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.24419 -0.244408 0.0480512 0.242285
W_f max, min, mean, abs_mean: 0.110793 -0.110616 0.0217318 0.10894
Epoch 4/300
1s - loss: 822.9964 - val_loss: 2904.1663
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 804.3808 - val_loss: 2866.4381
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 795.7818 - val_loss: 3104.3628
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 790.8588 - val_loss: 3099.4042
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 786.2560 - val_loss: 3041.1680
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 785.2358 - val_loss: 3048.3013
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 778.4493 - val_loss: 3174.3746
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 767.5840 - val_loss: 3173.0611
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 754.1502 - val_loss: 3278.8581
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 740.5327 - val_loss: 3189.1516
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 724.9124 - val_loss: 3218.5139
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 713.8912 - val_loss: 3362.6185
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 705.2391 - val_loss: 3459.6398
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 697.6894 - val_loss: 3347.2132
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 689.0027 - val_loss: 3452.5360
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 680.7318 - val_loss: 3403.7118
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 671.5618 - val_loss: 3478.6078
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 663.8434 - val_loss: 3371.7331
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 656.9082 - val_loss: 3368.8753
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 649.2832 - val_loss: 3426.1363
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 639.7399 - val_loss: 3304.1992
Epoch 00023: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training shanghai0
Train on 5742 samples, validate on 1530 samples
Before training:
           shanghai0 3297.7934      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.07686 nan 3.07686
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           shanghai0 9199.2493      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.32448 nan 5.32448
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2284.2156 - val_loss: 3983.5226
Epoch 00000: val_loss improved from inf to 3983.52265, saving model to shanghai0_weights.hdf5
           shanghai0 1364.4994      0.07  0.46  0.06      0.07  0.56  0.06      0.07  0.59  0.06
           shanghai0 3983.5226      0.42  0.30  0.36      0.41  0.28  0.35      0.37  0.25  0.33
forget mean min: 0.827684 0.282689
incx.max(), incx.min(), incx.mean() 2.36017 -2.19238 0.939615
fgtx.max(), fgtx.min(), fgtx.mean() 2.06288 -2.08656 0.768107
abs_mean, abs_mean+, abs_mean-: 6.20723 1.94795 10.3485
U_c = [[-0.13650106]] U_f = [[ 0.]] b_c = [ 0.0968886] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.122222 -0.122441 -0.0242909 0.120493
W_f max, min, mean, abs_mean: 0.110238 -0.110512 -0.0220154 0.109824
Epoch 2/300
1s - loss: 1020.6529 - val_loss: 2567.7294
Epoch 00001: val_loss improved from 3983.52265 to 2567.72938, saving model to shanghai0_weights.hdf5
           shanghai0  826.7635      0.18  0.41  0.15      0.18  0.41  0.16      0.16  0.46  0.14
           shanghai0 2567.7293      0.71  0.33  0.53      0.70  0.31  0.54      0.67  0.27  0.53
forget mean min: 0.921326 0.36538
incx.max(), incx.min(), incx.mean() 3.7827 -2.74512 2.33995
fgtx.max(), fgtx.min(), fgtx.mean() 2.06898 -1.6731 1.24192
abs_mean, abs_mean+, abs_mean-: 4.8764 2.92654 7.92996
U_c = [[-0.13804348]] U_f = [[ 0.]] b_c = [ 0.1735158] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.201365 -0.201586 -0.040124 0.19964
W_f max, min, mean, abs_mean: 0.114784 -0.115153 -0.0229604 0.114445
Epoch 3/300
1s - loss: 778.7436 - val_loss: 2316.5121
Epoch 00002: val_loss improved from 2567.72938 to 2316.51206, saving model to shanghai0_weights.hdf5
           shanghai0  743.5353      0.43  0.35  0.35      0.46  0.33  0.37      0.47  0.30  0.39
           shanghai0 2316.5121      0.71  0.29  0.55      0.71  0.27  0.56      0.69  0.24  0.57
forget mean min: 0.926509 0.508645
incx.max(), incx.min(), incx.mean() 5.22669 -2.4211 3.46247
fgtx.max(), fgtx.min(), fgtx.mean() 1.79245 -0.956777 1.15824
abs_mean, abs_mean+, abs_mean-: 4.54581 3.32442 6.11295
U_c = [[-0.08324904]] U_f = [[ 0.]] b_c = [ 0.24049783] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.269239 -0.269459 -0.0537011 0.267519
W_f max, min, mean, abs_mean: 0.0965556 -0.0969059 -0.0193069 0.0961686
Epoch 4/300
1s - loss: 737.2977 - val_loss: 2347.1775
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 724.2759 - val_loss: 2304.7793
Epoch 00004: val_loss improved from 2316.51206 to 2304.77925, saving model to shanghai0_weights.hdf5
           shanghai0  717.2831      0.51  0.37  0.39      0.54  0.34  0.42      0.56  0.30  0.45
           shanghai0 2304.7792      0.69  0.30  0.54      0.68  0.28  0.54      0.65  0.25  0.53
forget mean min: 0.912576 0.469976
incx.max(), incx.min(), incx.mean() 7.02613 -3.89214 4.31777
fgtx.max(), fgtx.min(), fgtx.mean() 1.82471 -1.15012 1.08678
abs_mean, abs_mean+, abs_mean-: 5.58062 4.44481 6.89008
U_c = [[-0.08016121]] U_f = [[ 0.]] b_c = [ 0.32906696] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.354853 -0.355084 -0.0708332 0.353164
W_f max, min, mean, abs_mean: 0.0966651 -0.0970095 -0.0193218 0.096225
Epoch 6/300
1s - loss: 718.4502 - val_loss: 2187.9033
Epoch 00005: val_loss improved from 2304.77925 to 2187.90325, saving model to shanghai0_weights.hdf5
           shanghai0  717.4025      0.45  0.33  0.36      0.47  0.30  0.39      0.49  0.25  0.42
           shanghai0 2187.9032      0.71  0.29  0.55      0.71  0.27  0.56      0.69  0.24  0.57
forget mean min: 0.910897 0.456718
incx.max(), incx.min(), incx.mean() 7.53273 -4.38366 4.56568
fgtx.max(), fgtx.min(), fgtx.mean() 1.84048 -1.21641 1.07934
abs_mean, abs_mean+, abs_mean-: 5.76692 4.746 6.92142
U_c = [[-0.08127841]] U_f = [[ 0.]] b_c = [ 0.35817972] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.379887 -0.380133 -0.0758445 0.378213
W_f max, min, mean, abs_mean: 0.0974812 -0.0978232 -0.0194822 0.0970228
Epoch 7/300
1s - loss: 715.2452 - val_loss: 2248.9548
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 711.2965 - val_loss: 2205.5547
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 703.1012 - val_loss: 2220.3185
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 687.1732 - val_loss: 2229.5993
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 675.7218 - val_loss: 2312.8727
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 668.1593 - val_loss: 2326.3611
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 661.7255 - val_loss: 2303.0837
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 655.4069 - val_loss: 2295.2565
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 649.0491 - val_loss: 2303.4032
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 641.4885 - val_loss: 2267.2497
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 632.3816 - val_loss: 2308.3508
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 620.5736 - val_loss: 2214.8217
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 603.7535 - val_loss: 2335.9266
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 582.5969 - val_loss: 2378.4811
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 563.5973 - val_loss: 2392.2637
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 547.0649 - val_loss: 2503.7402
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 534.7483 - val_loss: 2600.9586
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 524.1264 - val_loss: 2680.4787
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 512.9198 - val_loss: 2674.7841
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 503.2907 - val_loss: 2731.6107
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 490.4395 - val_loss: 2835.1868
Epoch 00026: val_loss did not improve
X_train[0].shape = (7018, 40, 23)

training hangzhou0
Train on 7018 samples, validate on 1870 samples
Before training:
           hangzhou0 3198.3430      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.15361 nan 3.15361
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           hangzhou010896.3916      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.69005 nan 5.69005
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2011.6158 - val_loss: 4320.2729
Epoch 00000: val_loss improved from inf to 4320.27290, saving model to hangzhou0_weights.hdf5
           hangzhou0 1166.1918      0.08  0.35  0.07      0.09  0.33  0.08      0.10  0.23  0.08
           hangzhou0 4320.2730      0.54  0.17  0.49      0.53  0.12  0.50      0.50  0.10  0.47
forget mean min: 0.843685 0.282127
incx.max(), incx.min(), incx.mean() 2.60213 -2.47978 1.15866
fgtx.max(), fgtx.min(), fgtx.mean() 2.0087 -2.08936 0.844682
abs_mean, abs_mean+, abs_mean-: 6.53848 2.17029 11.1736
U_c = [[-0.15209854]] U_f = [[ 0.]] b_c = [ 0.11118875] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.136364 -0.136462 0.0132998 0.13544
W_f max, min, mean, abs_mean: 0.109733 -0.110217 0.0106871 0.10922
Epoch 2/300
1s - loss: 899.1081 - val_loss: 2746.4792
Epoch 00001: val_loss improved from 4320.27290 to 2746.47923, saving model to hangzhou0_weights.hdf5
           hangzhou0  788.1530      0.13  0.34  0.12      0.14  0.35  0.12      0.14  0.29  0.12
           hangzhou0 2746.4792      0.79  0.21  0.65      0.79  0.17  0.69      0.80  0.13  0.72
forget mean min: 0.932627 0.441284
incx.max(), incx.min(), incx.mean() 3.86388 -2.32792 2.57515
fgtx.max(), fgtx.min(), fgtx.mean() 1.88577 -1.29358 1.22403
abs_mean, abs_mean+, abs_mean-: 4.46049 2.76986 7.17703
U_c = [[-0.14976226]] U_f = [[ 0.]] b_c = [ 0.19134663] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.20484 -0.204954 0.0201496 0.203895
W_f max, min, mean, abs_mean: 0.105251 -0.105758 0.0102667 0.104696
Epoch 3/300
1s - loss: 731.9269 - val_loss: 2525.6310
Epoch 00002: val_loss improved from 2746.47923 to 2525.63101, saving model to hangzhou0_weights.hdf5
           hangzhou0  715.8098      0.33  0.40  0.27      0.36  0.36  0.30      0.37  0.32  0.31
           hangzhou0 2525.6310      0.89  0.24  0.70      0.90  0.20  0.73      0.92  0.18  0.77
forget mean min: 0.964516 0.667409
incx.max(), incx.min(), incx.mean() 4.24956 -0.120546 3.06166
fgtx.max(), fgtx.min(), fgtx.mean() 1.95021 -0.162956 1.37579
abs_mean, abs_mean+, abs_mean-: 3.45746 2.87087 4.48583
U_c = [[-0.08694396]] U_f = [[ 0.]] b_c = [ 0.21646668] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.227398 -0.227535 0.0224051 0.226428
W_f max, min, mean, abs_mean: 0.110063 -0.110592 0.0107506 0.10949
Epoch 4/300
1s - loss: 704.4694 - val_loss: 2688.5961
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 696.3499 - val_loss: 2821.1553
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 689.7449 - val_loss: 2801.5421
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 682.6091 - val_loss: 2934.6484
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 671.3160 - val_loss: 2989.6134
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 663.4454 - val_loss: 2978.2704
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 655.4328 - val_loss: 3210.9633
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 646.8616 - val_loss: 3028.3534
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 638.2527 - val_loss: 3033.7177
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 627.4791 - val_loss: 3162.5216
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 616.2805 - val_loss: 3269.3536
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 603.7303 - val_loss: 3127.9559
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 589.6890 - val_loss: 3187.3228
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 574.0307 - val_loss: 3080.1217
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 556.9402 - val_loss: 3295.1424
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 539.8438 - val_loss: 3151.0708
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 524.7924 - val_loss: 3259.6707
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 511.8967 - val_loss: 3182.4200
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 499.5196 - val_loss: 3398.6238
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 490.4060 - val_loss: 3459.2458
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 481.5852 - val_loss: 3359.6092
Epoch 00023: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training hefei0
Train on 5742 samples, validate on 1530 samples
Before training:
              hefei0 6039.4351      0.01  -nan  0.01      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.98536 nan 3.98536
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              hefei014326.6670      0.02  -nan  0.02      0.02  -nan  0.02      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 7.10216 nan 7.10216
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 4415.7793 - val_loss: 6350.3434
Epoch 00000: val_loss improved from inf to 6350.34341, saving model to hefei0_weights.hdf5
              hefei0 2645.9785      0.18  0.36  0.16      0.20  0.28  0.18      0.19  0.23  0.17
              hefei0 6350.3433      0.60  0.14  0.54      0.59  0.08  0.57      0.55  0.06  0.53
forget mean min: 0.821781 0.241972
incx.max(), incx.min(), incx.mean() 2.40216 -2.27923 0.920637
fgtx.max(), fgtx.min(), fgtx.mean() 2.22201 -2.29014 0.794049
abs_mean, abs_mean+, abs_mean-: 8.1205 1.98501 13.9285
U_c = [[-0.13715395]] U_f = [[ 0.]] b_c = [ 0.0968045] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.123671 -0.123726 -0.0118717 0.122029
W_f max, min, mean, abs_mean: 0.118872 -0.118932 -0.0115422 0.117618
Epoch 2/300
1s - loss: 1956.8629 - val_loss: 4066.2621
Epoch 00001: val_loss improved from 6350.34341 to 4066.26213, saving model to hefei0_weights.hdf5
              hefei0 1698.1697      0.51  0.42  0.37      0.55  0.40  0.40      0.56  0.37  0.42
              hefei0 4066.2621      0.95  0.26  0.71      0.95  0.21  0.76      0.94  0.18  0.78
forget mean min: 0.948202 0.216424
incx.max(), incx.min(), incx.mean() 4.01967 -3.8488 2.842
fgtx.max(), fgtx.min(), fgtx.mean() 2.31214 -2.41788 1.6042
abs_mean, abs_mean+, abs_mean-: 5.35404 3.30594 14.4516
U_c = [[-0.16774328]] U_f = [[ 0.]] b_c = [ 0.17338094] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.203657 -0.203694 -0.0198708 0.202002
W_f max, min, mean, abs_mean: 0.122667 -0.122704 -0.0119292 0.121431
Epoch 3/300
1s - loss: 1600.7750 - val_loss: 3697.2814
Epoch 00002: val_loss improved from 4066.26213 to 3697.28144, saving model to hefei0_weights.hdf5
              hefei0 1518.0433      0.61  0.45  0.41      0.65  0.44  0.43      0.66  0.40  0.46
              hefei0 3697.2814      0.96  0.23  0.75      0.96  0.18  0.79      0.95  0.15  0.82
forget mean min: 0.951796 0.342953
incx.max(), incx.min(), incx.mean() 5.48138 -4.87379 4.13252
fgtx.max(), fgtx.min(), fgtx.mean() 1.83041 -1.78523 1.35943
abs_mean, abs_mean+, abs_mean-: 5.93137 4.60605 9.19682
U_c = [[-0.15928942]] U_f = [[ 0.]] b_c = [ 0.23910552] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.269871 -0.269895 -0.0264929 0.268207
W_f max, min, mean, abs_mean: 0.0948896 -0.0949198 -0.00915666 0.0936482
Epoch 4/300
1s - loss: 1499.6671 - val_loss: 3622.2228
Epoch 00003: val_loss improved from 3697.28144 to 3622.22279, saving model to hefei0_weights.hdf5
              hefei0 1477.4571      0.68  0.45  0.44      0.72  0.44  0.46      0.74  0.40  0.50
              hefei0 3622.2228      0.96  0.21  0.76      0.96  0.16  0.81      0.95  0.13  0.83
forget mean min: 0.951531 0.353207
incx.max(), incx.min(), incx.mean() 6.31085 -5.47408 4.71194
fgtx.max(), fgtx.min(), fgtx.mean() 1.82003 -1.73396 1.33784
abs_mean, abs_mean+, abs_mean-: 6.40932 5.16726 9.12386
U_c = [[-0.13804634]] U_f = [[ 0.]] b_c = [ 0.27569532] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.308289 -0.308309 -0.0303344 0.30662
W_f max, min, mean, abs_mean: 0.0937222 -0.0937555 -0.00903957 0.092468
Epoch 5/300
1s - loss: 1467.9605 - val_loss: 3769.2393
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1450.1870 - val_loss: 3909.9180
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 1438.9133 - val_loss: 4012.5905
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1433.3470 - val_loss: 4112.5062
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1428.0767 - val_loss: 4106.1592
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1425.1432 - val_loss: 4124.3224
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1421.9234 - val_loss: 4196.0640
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1415.4641 - val_loss: 4236.0741
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1405.2868 - val_loss: 4175.0939
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1399.6379 - val_loss: 4135.2466
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 1391.5011 - val_loss: 4163.4717
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 1382.7396 - val_loss: 4178.0716
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 1367.0471 - val_loss: 4159.4707
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 1357.2788 - val_loss: 4280.5993
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 1345.5623 - val_loss: 4128.0676
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 1330.8711 - val_loss: 4157.6691
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 1307.7734 - val_loss: 4247.8865
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 1283.0894 - val_loss: 4240.9701
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 1257.9828 - val_loss: 4181.3673
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 1229.2819 - val_loss: 4159.4012
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 1212.5444 - val_loss: 4380.5698
Epoch 00024: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training wuhan0
Train on 6380 samples, validate on 1700 samples
Before training:
              wuhan0 5337.7283      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.90763 nan 3.90763
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
              wuhan016288.9442      0.02  -nan  0.02      0.01  -nan  0.01      0.01  -nan  0.01
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 7.21858 nan 7.21858
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 3698.6965 - val_loss: 9556.8262
Epoch 00000: val_loss improved from inf to 9556.82619, saving model to wuhan0_weights.hdf5
              wuhan0 2493.0482      0.22  0.43  0.18      0.24  0.38  0.20      0.23  0.34  0.21
              wuhan0 9556.8261      0.45  0.08  0.43      0.43  0.05  0.42      0.41  0.03  0.40
forget mean min: 0.776611 0.27054
incx.max(), incx.min(), incx.mean() 2.43581 -2.30628 0.703406
fgtx.max(), fgtx.min(), fgtx.mean() 2.07929 -2.1473 0.535213
abs_mean, abs_mean+, abs_mean-: 9.32726 2.11129 15.4862
U_c = [[-0.14062464]] U_f = [[ 0.]] b_c = [ 0.10291757] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.127006 -0.127137 -0.0128955 0.124749
W_f max, min, mean, abs_mean: 0.11258 -0.112626 -0.0116548 0.111188
Epoch 2/300
1s - loss: 1686.4329 - val_loss: 4832.3177
Epoch 00001: val_loss improved from 9556.82619 to 4832.31766, saving model to wuhan0_weights.hdf5
              wuhan0 1387.3073      0.62  0.45  0.41      0.66  0.42  0.45      0.66  0.40  0.46
              wuhan0 4832.3176      0.83  0.11  0.75      0.83  0.06  0.79      0.83  0.03  0.81
forget mean min: 0.952407 0.253066
incx.max(), incx.min(), incx.mean() 4.07135 -3.86354 2.88023
fgtx.max(), fgtx.min(), fgtx.mean() 2.1481 -2.23467 1.49019
abs_mean, abs_mean+, abs_mean-: 5.47756 3.34853 11.5053
U_c = [[-0.12109584]] U_f = [[ 0.]] b_c = [ 0.18228452] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.206816 -0.206948 -0.0208752 0.204562
W_f max, min, mean, abs_mean: 0.114324 -0.114373 -0.0118205 0.112988
Epoch 3/300
1s - loss: 1341.9589 - val_loss: 4613.8099
Epoch 00002: val_loss improved from 4832.31766 to 4613.80986, saving model to wuhan0_weights.hdf5
              wuhan0 1307.1658      0.64  0.47  0.41      0.67  0.45  0.43      0.68  0.44  0.44
              wuhan0 4613.8099      0.85  0.10  0.77      0.85  0.05  0.81      0.84  0.03  0.82
forget mean min: 0.957071 0.326142
incx.max(), incx.min(), incx.mean() 4.68869 -4.37038 3.50017
fgtx.max(), fgtx.min(), fgtx.mean() 1.81298 -1.86929 1.32988
abs_mean, abs_mean+, abs_mean-: 4.45041 3.28861 6.74077
U_c = [[-0.07425205]] U_f = [[ 0.]] b_c = [ 0.22842263] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.240917 -0.241047 -0.0242828 0.238667
W_f max, min, mean, abs_mean: 0.0983302 -0.098388 -0.0102216 0.0970113
Epoch 4/300
1s - loss: 1301.1255 - val_loss: 4701.2818
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 1288.4468 - val_loss: 4810.2802
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 1280.9589 - val_loss: 4260.4874
Epoch 00005: val_loss improved from 4613.80986 to 4260.48742, saving model to wuhan0_weights.hdf5
              wuhan0 1284.6403      0.63  0.47  0.40      0.66  0.45  0.43      0.65  0.45  0.43
              wuhan0 4260.4874      0.89  0.11  0.80      0.89  0.06  0.84      0.88  0.03  0.86
forget mean min: 0.96307 0.382
incx.max(), incx.min(), incx.mean() 4.72386 -3.51506 3.51279
fgtx.max(), fgtx.min(), fgtx.mean() 1.87673 -1.59 1.36714
abs_mean, abs_mean+, abs_mean-: 4.35958 3.18374 6.65019
U_c = [[-0.04656468]] U_f = [[ 0.]] b_c = [ 0.26364711] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.247176 -0.247301 -0.0248992 0.244924
W_f max, min, mean, abs_mean: 0.104363 -0.104432 -0.0108275 0.103057
Epoch 7/300
1s - loss: 1270.7862 - val_loss: 4511.7704
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 1261.7368 - val_loss: 4493.6918
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 1236.1782 - val_loss: 4584.6606
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 1194.6589 - val_loss: 4946.9407
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 1149.8320 - val_loss: 5449.9637
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 1110.6566 - val_loss: 5610.1106
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 1071.8691 - val_loss: 6146.1514
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 1037.1108 - val_loss: 5907.4272
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 999.8330 - val_loss: 6177.3618
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 969.9385 - val_loss: 6316.9016
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 936.0444 - val_loss: 6331.9992
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 907.9670 - val_loss: 6416.0512
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 886.2568 - val_loss: 6429.4111
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 865.5057 - val_loss: 6731.0123
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 846.8028 - val_loss: 6689.2013
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 826.0331 - val_loss: 6631.0882
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 806.3042 - val_loss: 6707.3802
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 785.6700 - val_loss: 6892.4592
Epoch 00023: val_loss did not improve
Epoch 25/300
1s - loss: 774.4502 - val_loss: 6854.3961
Epoch 00024: val_loss did not improve
Epoch 26/300
1s - loss: 754.9364 - val_loss: 6934.5182
Epoch 00025: val_loss did not improve
Epoch 27/300
1s - loss: 742.2865 - val_loss: 6505.8250
Epoch 00026: val_loss did not improve
X_train[0].shape = (5742, 40, 23)

training nanchang0
Train on 5742 samples, validate on 1530 samples
Before training:
           nanchang0 2631.9239      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 2.53118 nan 2.53118
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           nanchang0 7010.8419      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 4.54489 nan 4.54489
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 1861.3274 - val_loss: 3257.1210
Epoch 00000: val_loss improved from inf to 3257.12098, saving model to nanchang0_weights.hdf5
           nanchang0 1331.3709      0.09  0.52  0.08      0.10  0.45  0.09      0.10  0.45  0.09
           nanchang0 3257.1210      0.30  0.10  0.29      0.30  0.08  0.29      0.30  0.05  0.30
forget mean min: 0.770645 0.300029
incx.max(), incx.min(), incx.mean() 2.26994 -2.09113 0.584449
fgtx.max(), fgtx.min(), fgtx.mean() 1.99335 -1.99985 0.450038
abs_mean, abs_mean+, abs_mean-: 5.78311 1.86479 8.42229
U_c = [[-0.12274087]] U_f = [[ 0.]] b_c = [ 0.09295528] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.116976 -0.116624 0.0342554 0.115112
W_f max, min, mean, abs_mean: 0.106667 -0.106558 0.0315519 0.105403
Epoch 2/300
1s - loss: 1124.0913 - val_loss: 1935.5290
Epoch 00001: val_loss improved from 3257.12098 to 1935.52897, saving model to nanchang0_weights.hdf5
           nanchang0  964.4443      0.17  0.48  0.14      0.19  0.44  0.16      0.18  0.45  0.16
           nanchang0 1935.5290      0.62  0.33  0.47      0.61  0.32  0.48      0.62  0.30  0.49
forget mean min: 0.948484 0.200711
incx.max(), incx.min(), incx.mean() 3.06727 -2.85044 2.03699
fgtx.max(), fgtx.min(), fgtx.mean() 2.42279 -2.49645 1.56634
abs_mean, abs_mean+, abs_mean-: 3.47265 2.39365 6.55176
U_c = [[-0.09817084]] U_f = [[ 0.]] b_c = [ 0.1527209] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.158827 -0.158462 0.0468215 0.156998
W_f max, min, mean, abs_mean: 0.131779 -0.131602 0.0390969 0.130509
Epoch 3/300
1s - loss: 883.9481 - val_loss: 1842.8978
Epoch 00002: val_loss improved from 1935.52897 to 1842.89782, saving model to nanchang0_weights.hdf5
           nanchang0  836.8468      0.35  0.42  0.28      0.41  0.37  0.32      0.41  0.33  0.34
           nanchang0 1842.8978      0.68  0.32  0.51      0.67  0.30  0.52      0.69  0.29  0.54
forget mean min: 0.968707 0.340632
incx.max(), incx.min(), incx.mean() 3.05767 -2.27654 2.23182
fgtx.max(), fgtx.min(), fgtx.mean() 2.10219 -1.79684 1.49852
abs_mean, abs_mean+, abs_mean-: 3.02018 2.31602 4.77603
U_c = [[-0.0368063]] U_f = [[ 0.]] b_c = [ 0.18172252] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.171439 -0.171054 0.0506027 0.169615
W_f max, min, mean, abs_mean: 0.125292 -0.125025 0.0371614 0.123983
Epoch 4/300
1s - loss: 813.4809 - val_loss: 1966.7904
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 801.3312 - val_loss: 1953.2825
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 794.7841 - val_loss: 1965.8009
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 786.8597 - val_loss: 2062.2792
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 781.0477 - val_loss: 2025.5797
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 774.8499 - val_loss: 2135.6853
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 766.8265 - val_loss: 2127.5659
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 757.6274 - val_loss: 2166.3192
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 746.1468 - val_loss: 2189.5851
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 733.3615 - val_loss: 2153.3142
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 724.6198 - val_loss: 2200.7415
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 714.8548 - val_loss: 2244.0634
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 704.2688 - val_loss: 2067.2744
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 694.0555 - val_loss: 2150.8628
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 683.4097 - val_loss: 2156.5874
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 676.6913 - val_loss: 2143.2004
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 670.9238 - val_loss: 2311.7311
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 663.8321 - val_loss: 2283.2541
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 654.7441 - val_loss: 2112.4022
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 648.9738 - val_loss: 2262.1151
Epoch 00022: val_loss did not improve
Epoch 24/300
1s - loss: 638.8384 - val_loss: 2329.7848
Epoch 00023: val_loss did not improve
X_train[0].shape = (6380, 40, 23)

training changsha0
Train on 6380 samples, validate on 1700 samples
Before training:
           changsha0 3412.0045      0.01  -nan  0.01      0.00  -nan  0.00      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 3.54338 nan 3.54338
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
           changsha010772.0208      0.02  -nan  0.02      0.01  -nan  0.01      0.00  -nan  0.00
forget mean min: 0.7 0.7
incx.max(), incx.min(), incx.mean() 0.0 0.0 0.0
fgtx.max(), fgtx.min(), fgtx.mean() 0.0 0.0 0.0
abs_mean, abs_mean+, abs_mean-: 5.42507 nan 5.42507
U_c = [[-0.05]] U_f = [[ 0.]] b_c = [ 0.] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
W_f max, min, mean, abs_mean: 0.0 0.0 0.0 0.0
Epoch 1/300
1s - loss: 2074.6558 - val_loss: 6515.2568
Epoch 00000: val_loss improved from inf to 6515.25681, saving model to changsha0_weights.hdf5
           changsha0 1184.2237      0.28  0.40  0.24      0.30  0.35  0.26      0.31  0.30  0.28
           changsha0 6515.2568      0.28  0.13  0.27      0.28  0.08  0.27      0.27  0.03  0.27
forget mean min: 0.741202 0.326252
incx.max(), incx.min(), incx.mean() 2.35919 -2.08179 0.435282
fgtx.max(), fgtx.min(), fgtx.mean() 1.93253 -1.86874 0.285753
abs_mean, abs_mean+, abs_mean-: 7.37811 1.97759 10.4727
U_c = [[-0.13227364]] U_f = [[ 0.]] b_c = [ 0.10142893] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.123351 -0.123801 -0.04857 0.121759
W_f max, min, mean, abs_mean: 0.106112 -0.106034 -0.041241 0.104219
Epoch 2/300
1s - loss: 914.4303 - val_loss: 3442.0780
Epoch 00001: val_loss improved from 6515.25681 to 3442.07801, saving model to changsha0_weights.hdf5
           changsha0  814.5442      0.50  0.37  0.39      0.56  0.28  0.46      0.59  0.22  0.51
           changsha0 3442.0780      0.39  0.20  0.35      0.40  0.15  0.37      0.39  0.09  0.38
forget mean min: 0.930025 0.61097
incx.max(), incx.min(), incx.mean() 3.6865 -0.697012 2.49284
fgtx.max(), fgtx.min(), fgtx.mean() 1.77093 -0.445148 1.16749
abs_mean, abs_mean+, abs_mean-: 3.80692 2.40305 4.80929
U_c = [[-0.11642265]] U_f = [[ 0.]] b_c = [ 0.1834745] b_f = [ 1.]
W_c max, min, mean, abs_mean: 0.199745 -0.200196 -0.079135 0.198162
W_f max, min, mean, abs_mean: 0.102157 -0.101939 -0.0396345 0.100179
Epoch 3/300
1s - loss: 743.8181 - val_loss: 3883.6061
Epoch 00002: val_loss did not improve
Epoch 4/300
1s - loss: 675.1377 - val_loss: 3676.4967
Epoch 00003: val_loss did not improve
Epoch 5/300
1s - loss: 667.6597 - val_loss: 3895.1165
Epoch 00004: val_loss did not improve
Epoch 6/300
1s - loss: 661.7364 - val_loss: 3641.7103
Epoch 00005: val_loss did not improve
Epoch 7/300
1s - loss: 651.5693 - val_loss: 3485.2125
Epoch 00006: val_loss did not improve
Epoch 8/300
1s - loss: 638.1214 - val_loss: 3987.5695
Epoch 00007: val_loss did not improve
Epoch 9/300
1s - loss: 622.4491 - val_loss: 3822.4835
Epoch 00008: val_loss did not improve
Epoch 10/300
1s - loss: 604.2835 - val_loss: 3776.0475
Epoch 00009: val_loss did not improve
Epoch 11/300
1s - loss: 586.4546 - val_loss: 4019.3101
Epoch 00010: val_loss did not improve
Epoch 12/300
1s - loss: 570.6685 - val_loss: 4012.1390
Epoch 00011: val_loss did not improve
Epoch 13/300
1s - loss: 557.6283 - val_loss: 4010.1814
Epoch 00012: val_loss did not improve
Epoch 14/300
1s - loss: 547.4903 - val_loss: 3984.3774
Epoch 00013: val_loss did not improve
Epoch 15/300
1s - loss: 539.1407 - val_loss: 3968.5132
Epoch 00014: val_loss did not improve
Epoch 16/300
1s - loss: 531.5212 - val_loss: 4071.3216
Epoch 00015: val_loss did not improve
Epoch 17/300
1s - loss: 526.0272 - val_loss: 4020.5966
Epoch 00016: val_loss did not improve
Epoch 18/300
1s - loss: 518.0885 - val_loss: 4033.0499
Epoch 00017: val_loss did not improve
Epoch 19/300
1s - loss: 511.5494 - val_loss: 3915.4537
Epoch 00018: val_loss did not improve
Epoch 20/300
1s - loss: 503.7042 - val_loss: 3948.2248
Epoch 00019: val_loss did not improve
Epoch 21/300
1s - loss: 494.5051 - val_loss: 3991.6063
Epoch 00020: val_loss did not improve
Epoch 22/300
1s - loss: 488.0008 - val_loss: 3860.7032
Epoch 00021: val_loss did not improve
Epoch 23/300
1s - loss: 480.8308 - val_loss: 4042.3236
Epoch 00022: val_loss did not improve

nanjing
